{
  "metadata": {
    "chunk_number": 1,
    "timestamp": "2025-01-19T18:24:32.160778",
    "total_successful": 41
  },
  "documents": [
    {
      "url": "https://www.emerald.com/insight/content/doi/10.1108/k-08-2022-1118/full/html",
      "title": "Opening the black box of knowledge management mechanisms: exploring knowledge flows at a consultancy",
      "author": "Janek Richter can be contacted at: janek.richter@wiso.uni-koeln.de",
      "published_date": "2023-02-28T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<section>\n<h2>Abstract</h2>\n<div>\n<h3>Purpose</h3>\n<section>\n<p>Based on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.</p>\n</section>\n</div>\n<div>\n<h3>Design/methodology/approach</h3>\n<section>\n<p>This in-depth case study conducted at a medium-sized consultancy in the supply chain management industry empirically examines knowledge flows to uncover the relationships between KM inputs, knowledge processes and KM performance. We adopt the viable system model (VSM) as a theoretical lens to identify KM mechanisms.</p>\n</section>\n</div>\n<div>\n<h3>Findings</h3>\n<section>\n<p>By identifying six KM mechanisms, we contribute to the theoretical understanding of how KM inputs are interconnected and lead to KM performance via knowledge processes.</p>\n</section>\n</div>\n<div>\n<h3>Originality/value</h3>\n<section>\n<p>Based on the insights gained, we provide propositions that organizations should consider in designing viable KM. Our findings help organizations in understanding their KM with the help of knowledge flow analysis and identifying how critical KM elements are interconnected.</p>\n</section>\n</div>\n</section>\n<section>\n<h2>Keywords</h2>\n<ul>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Knowledge+management\"><span>Knowledge management</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Case+study+research\"><span>Case study research</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Viable+system+model\"><span>Viable system model</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Mechanisms\"><span>Mechanisms</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Knowledge+flows\"><span>Knowledge flows</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Consultancy\"><span>Consultancy</span></a></li>\n</ul>\n</section>\n<section>\n<h2>Citation</h2>\n<p>\n<a href=\"https://www.emerald.com/insight/search?q=Janek Richter\">Richter, J.</a>, <a href=\"https://www.emerald.com/insight/search?q=Dirk Basten\">Basten, D.</a>, <a href=\"https://www.emerald.com/insight/search?q=Bjoern Michalik\">Michalik, B.</a>, <a href=\"https://www.emerald.com/insight/search?q=Christoph Rosenkranz\">Rosenkranz, C.</a> and <a href=\"https://www.emerald.com/insight/search?q=Stefan Smolnik\">Smolnik, S.</a> (2023), \"Opening the black box of knowledge management mechanisms: exploring knowledge flows at a consultancy\", <i><a href=\"https://www.emerald.com/insight/publication/issn/0368-492X\">Kybernetes</a></i>, Vol. 52 No. 13, pp. 1-28. <a href=\"https://doi.org/10.1108/K-08-2022-1118\">https://doi.org/10.1108/K-08-2022-1118</a>\n</p>\n</section>\n<section>\n<h2>Publisher</h2>:\n<p> Emerald Publishing Limited </p>\n</section>\n<p>\nCopyright <span>© 2023, Janek Richter, Dirk Basten, Bjoern Michalik, Christoph Rosenkranz and Stefan Smolnik</span>\n</p>\n<section>\n<h2>License</h2>\n<p>Published by Emerald Publishing Limited. This article is published under the Creative Commons Attribution (CC BY 4.0) licence. Anyone may reproduce, distribute, translate and create derivative works of this article (for both commercial and non-commercial purposes), subject to full attribution to the original publication and authors. The full terms of this licence may be seen at <a href=\"http://creativecommons.org/licences/by/4.0/legalcode\">http://creativecommons.org/licences/by/4.0/legalcode</a></p>\n</section>\n<hr/>\n<section>\n<section> <h2>1. Introduction</h2><p><em>Knowledge management</em> (KM) comprises practices and processes that enable effective and efficient management of knowledge resources (<a href=\"#ref004\">Alavi and Leidner, 2001</a>).<span></span> Given the increasing knowledge intensity in business environments (<a href=\"#ref005\">Anand <em>et al</em>., 2007</a>;<span></span> <a href=\"#ref039\">Imran <em>et al</em>., 2022</a>),<span></span> organizations are continually intensifying their KM efforts due to its critical role in organizational performance (<a href=\"#ref031\">Gold <em>et al</em>., 2001</a>;<span></span> <a href=\"#ref050\">López-Cabarcos <em>et al</em>., 2020</a>;<span></span> <a href=\"#ref054\">Massingham, 2020</a>).<span></span> In this context, <em>information technology (IT)</em> is seen as a crucial element for storing, processing and communicating knowledge (<a href=\"#ref004\">Alavi and Leidner, 2001</a>).<span></span> For example, IT-based KM systems (KMS) such as Microsoft's SharePoint are nowadays a de-facto standard (<a href=\"#ref063\">Pah <em>et al</em>., 2018</a>).<span></span> Yet, KM remains a significant challenge. Due to its complexity, benefits of investments into KM are seldom predictable (<a href=\"#ref035\">Haas and Hansen, 2007</a>;<span></span> <a href=\"#ref075\">Setia and Patel, 2013</a>),<span></span> organizations struggle to achieve the expected return on investment and KM initiatives are challenged by drawbacks (<a href=\"#ref034\">Haamann and Basten, 2019</a>;<span></span> <a href=\"#ref020\">Choi <em>et al</em>., 2020</a>).<span></span></p><p>Recent research suggest that it is not crucial grasping all available knowledge. Rather it is important to evaluate <em>which</em> knowledge is relevant and <em>how</em> it flows through the organization (<a href=\"#ref009\">Barley <em>et al</em>., 2018</a>).<span></span> Combining two major lines of inquiry, earlier works emphasize the importance of combining both technology-driven and behavioural-research approaches in a social-technical perspective on KM and KMS (<a href=\"#ref074\">Schacht <em>et al</em>., 2015</a>).<span></span> Respective studies focus on <em>what</em> social, technical and organizational KM inputs contribute to KM success. <em>KM inputs</em>, which can either be knowledge resources or KM practices (see <a href=\"#sec002.1\">Section 2.1</a>),<span></span> are factors investigated in relation with successful KM implementation. Exemplary KM inputs in previous research comprise employee training, IT infrastructure, top management support and human resource management (<a href=\"#ref006\">Anand <em>et al</em>., 2015</a>).<span></span> However, our current understanding of how KM inputs should be organized, managed and integrated in order to contribute value to the organization is still limited (<a href=\"#ref027\">Engwall and Kipping, 2002</a>;<span></span> <a href=\"#ref023\">Donnelly, 2008</a>;<span></span> <a href=\"#ref055\">McIver <em>et al</em>., 2013</a>).<span></span> More specifically, theoretical explanations are missing that suggest how and why to develop processes in alignment with the nature of knowledge work organizations do (<a href=\"#ref055\">McIver <em>et al</em>., 2013</a>).<span></span> Accordingly, realistic, granular and context-specific studies are needed to open the KM black box (<a href=\"#ref019\">Carlile and Rebentisch, 2003</a>;<span></span> <a href=\"#ref055\">McIver <em>et al</em>., 2013</a>)<span></span> since we are missing an understanding about how KM inputs systemically lead to KM performance. Rather than taking an abstract view that masks concrete operational processes, we propose a systemic theoretical stance based on <em>knowledge flows</em>. If knowledge flows are improperly designed, the interdependent processes of KM are likely to exhibit substantial inefficiencies leading to financial losses and missed business opportunities (<a href=\"#ref060\">Nissen, 2005</a>;<span></span> <a href=\"#ref056\">Mehta <em>et al</em>., 2007</a>).<span></span> The focus on knowledge flows implies viewing knowledge as a process of simultaneously knowing and acting (<a href=\"#ref004\">Alavi and Leidner, 2001</a>).<span></span> Knowledge flows are dynamic knowledge and depict changes, movements and applications of knowledge over time (<a href=\"#ref060\">Nissen, 2005</a>;<span></span> <a href=\"#ref062\">Nonaka and Takeuchi, 2019</a>).<span></span> Thus, they are a useful element to analyse linkages between KM inputs and performance via KMS.</p><p>Hence, we ask the following research question (RQ): <em>How does the intertwinement of KM inputs (knowledge resources and KM practices) contribute to KM performance?</em></p><p>For answering this question, we follow a case-based research approach (<a href=\"#ref084\">Yin, 2009</a>)<span></span> in an a medium-sized consultancy operating in the supply chain management industry. With the qualitative case study, we follow a research approach that is widely disseminated in KM research (<a href=\"#ref053\">Martins <em>et al</em>., 2019</a>;<span></span> <a href=\"#ref010\">Barros <em>et al</em>., 2020</a>)<span></span> and complies with research that is realistic, granular and context-specific and is needed to open the black box under investigation (<a href=\"#ref019\">Carlile and Rebentisch, 2003</a>;<span></span> <a href=\"#ref055\">McIver <em>et al</em>., 2013</a>).<span></span> We relied on the viable system model (VSM) to analyse the organization's project-based structure. Due to its systemic nature, the VSM is particularly helpful when describing and analysing complex systems such as organizations' KM and KMS. Furthermore, the VSM provides a language for describing and understanding organizational structures and knowledge flows (<a href=\"#ref070\">Rosenkranz and Holten, 2011</a>).<span></span> To explain how and why KM inputs contribute to KM performance, our VSM-based empirical analysis of the case company yielded explanations in the form of six <em>KM mechanisms:</em> (1) project-based knowledge generation, (2) standardization of KM practices and resources, (3) putting people in the KM centre, (4) cyclic refinement of knowledge into a strategic asset, (5) allowing deliberate misalignment of KMS, KM identity and processes and (6) combining operational and strategic view.</p><p",
        "html": "<div><div>\n<section>\n<h2>Abstract</h2>\n<div>\n<h3>Purpose</h3>\n<section>\n<p>Based on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.</p>\n</section>\n</div>\n<div>\n<h3>Design/methodology/approach</h3>\n<section>\n<p>This in-depth case study conducted at a medium-sized consultancy in the supply chain management industry empirically examines knowledge flows to uncover the relationships between KM inputs, knowledge processes and KM performance. We adopt the viable system model (VSM) as a theoretical lens to identify KM mechanisms.</p>\n</section>\n</div>\n<div>\n<h3>Findings</h3>\n<section>\n<p>By identifying six KM mechanisms, we contribute to the theoretical understanding of how KM inputs are interconnected and lead to KM performance via knowledge processes.</p>\n</section>\n</div>\n<div>\n<h3>Originality/value</h3>\n<section>\n<p>Based on the insights gained, we provide propositions that organizations should consider in designing viable KM. Our findings help organizations in understanding their KM with the help of knowledge flow analysis and identifying how critical KM elements are interconnected.</p>\n</section>\n</div>\n</section>\n<section>\n<h2>Keywords</h2>\n<ul>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Knowledge+management\"><span>Knowledge management</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Case+study+research\"><span>Case study research</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Viable+system+model\"><span>Viable system model</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Mechanisms\"><span>Mechanisms</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Knowledge+flows\"><span>Knowledge flows</span></a></li>\n<li> <a href=\"https://www.emerald.com/insight/search?q=Consultancy\"><span>Consultancy</span></a></li>\n</ul>\n</section>\n<section>\n<h2>Citation</h2>\n<p>\n<a href=\"https://www.emerald.com/insight/search?q=Janek Richter\">Richter, J.</a>, <a href=\"https://www.emerald.com/insight/search?q=Dirk Basten\">Basten, D.</a>, <a href=\"https://www.emerald.com/insight/search?q=Bjoern Michalik\">Michalik, B.</a>, <a href=\"https://www.emerald.com/insight/search?q=Christoph Rosenkranz\">Rosenkranz, C.</a> and <a href=\"https://www.emerald.com/insight/search?q=Stefan Smolnik\">Smolnik, S.</a> (2023), \"Opening the black box of knowledge management mechanisms: exploring knowledge flows at a consultancy\", <i><a href=\"https://www.emerald.com/insight/publication/issn/0368-492X\">Kybernetes</a></i>, Vol. 52 No. 13, pp. 1-28. <a href=\"https://doi.org/10.1108/K-08-2022-1118\">https://doi.org/10.1108/K-08-2022-1118</a>\n</p>\n</section>\n<section>\n<h2>Publisher</h2>:\n<p> Emerald Publishing Limited </p>\n</section>\n<p>\nCopyright <span>© 2023, Janek Richter, Dirk Basten, Bjoern Michalik, Christoph Rosenkranz and Stefan Smolnik</span>\n</p>\n<section>\n<h2>License</h2>\n<p>Published by Emerald Publishing Limited. This article is published under the Creative Commons Attribution (CC BY 4.0) licence. Anyone may reproduce, distribute, translate and create derivative works of this article (for both commercial and non-commercial purposes), subject to full attribution to the original publication and authors. The full terms of this licence may be seen at <a href=\"http://creativecommons.org/licences/by/4.0/legalcode\">http://creativecommons.org/licences/by/4.0/legalcode</a></p>\n</section>\n<hr/>\n<section>\n<section> <h2>1. Introduction</h2><p><em>Knowledge management</em> (KM) comprises practices and processes that enable effective and efficient management of knowledge resources (<a href=\"#ref004\">Alavi and Leidner, 2001</a>).<span></span> Given the increasing knowledge intensity in business environments (<a href=\"#ref005\">Anand <em>et al</em>., 2007</a>;<span></span> <a href=\"#ref039\">Imran <em>et al</em>., 2022</a>),<span></span> organizations are continually intensifying their KM efforts due to its critical role in organizational performance (<a href=\"#ref031\">Gold <em>et al</em>., 2001</a>;<span></span> <a href=\"#ref050\">López-Cabarcos <em>et al</em>., 2020</a>;<span></span> <a href=\"#ref054\">Massingham, 2020</a>).<span></span> In this context, <em>information technology (IT)</em> is seen as a crucial element for storing, processing and communicating knowledge (<a href=\"#ref004\">Alavi and Leidner, 2001</a>).<span></span> For example, IT-based KM systems (KMS) such as Microsoft's SharePoint are nowadays a de-facto standard (<a href=\"#ref063\">Pah <em>et al</em>., 2018</a>).<span></span> Yet, KM remains a significant challenge. Due to its complexity, benefits of investments into KM are seldom predictable (<a href=\"#ref035\">Haas and Hansen, 2007</a>;<span></span> <a href=\"#ref075\">Setia and Patel, 2013</a>),<span></span> organizations struggle to achieve the expected return on investment and KM initiatives are challenged by drawbacks (<a href=\"#ref034\">Haamann and Basten, 2019</a>;<span></span> <a href=\"#ref020\">Choi <em>et al</em>., 2020</a>).<span></span></p><p>Recent research suggest that it is not crucial grasping all available knowledge. Rather it is important to evaluate <em>which</em> knowledge is relevant and <em>how</em> it flows through the organization (<a href=\"#ref009\">Barley <em>et al</em>., 2018</a>).<span></span> Combining two major lines of inquiry, earlier works emphasize the importance of combining both technology-driven and behavioural-research approaches in a social-technical perspective on KM and KMS (<a href=\"#ref074\">Schacht <em>et al</em>., 2015</a>).<span></span> Respective studies focus on <em>what</em> social, technical and organizational KM inputs contribute to KM success. <em>KM inputs</em>, which can either be knowledge resources or KM practices (see <a href=\"#sec002.1\">Section 2.1</a>),<span></span> are factors investigated in relation with successful KM implementation. Exemplary KM inputs in previous research comprise employee training, IT infrastructure, top management support and human resource management (<a href=\"#ref006\">Anand <em>et al</em>., 2015</a>).<span></span> However, our current understanding of how KM inputs should be organized, managed and integrated in order to contribute value to the organization is still limited (<a href=\"#ref027\">Engwall and Kipping, 2002</a>;<span></span> <a href=\"#ref023\">Donnelly, 2008</a>;<span></span> <a href=\"#ref055\">McIver <em>et al</em>., 2013</a>).<span></span> More specifically, theoretical explanations are missing that suggest how and why to develop processes in alignment with the nature of knowledge work organizations do (<a href=\"#ref055\">McIver <em>et al</em>., 2013</a>).<span></span> Accordingly, realistic, granular and context-specific studies are needed to open the KM black box (<a href=\"#ref019\">Carlile and Rebentisch, 2003</a>;<span></span> <a href=\"#ref055\">McIver <em>et al</em>., 2013</a>)<span></span> since we are missing an understanding about how KM inputs systemically lead to KM performance. Rather than taking an abstract view that masks concrete operational processes, we propose a systemic theoretical stance based on <em>knowledge flows</em>. If knowledge flows are improperly designed, the interdependent processes of KM are likely to exhibit substantial inefficiencies leading to financial losses and missed business opportunities (<a href=\"#ref060\">Nissen, 2005</a>;<span></span> <a href=\"#ref056\">Mehta <em>et al</em>., 2007</a>).<span></span> The focus on knowledge flows implies viewing knowledge as a process of simultaneously knowing and acting (<a href=\"#ref004\">Alavi and Leidner, 2001</a>).<span></span> Knowledge flows are dynamic knowledge and depict changes, movements and applications of knowledge over time (<a href=\"#ref060\">Nissen, 2005</a>;<span></span> <a href=\"#ref062\">Nonaka and Takeuchi, 2019</a>).<span></span> Thus, they are a useful element to analyse linkages between KM inputs and performance via KMS.</p><p>Hence, we ask the following research question (RQ): <em>How does the intertwinement of KM inputs (knowledge resources and KM practices) contribute to KM performance?</em></p><p>For answering this question, we follow a case-based research approach (<a href=\"#ref084\">Yin, 2009</a>)<span></span> in an a medium-sized consultancy operating in the supply chain management industry. With the qualitative case study, we follow a research approach that is widely disseminated in KM research (<a href=\"#ref053\">Martins <em>et al</em>., 2019</a>;<span></span> <a href=\"#ref010\">Barros <em>et al</em>., 2020</a>)<span></span> and complies with research that is realistic, granular and context-specific and is needed to open the black box under investigation (<a href=\"#ref019\">Carlile and Rebentisch, 2003</a>;<span></span> <a href=\"#ref055\">McIver <em>et al</em>., 2013</a>).<span></span> We relied on the viable system model (VSM) to analyse the organization's project-based structure. Due to its systemic nature, the VSM is particularly helpful when describing and analysing complex systems such as organizations' KM and KMS. Furthermore, the VSM provides a language for describing and understanding organizational structures and knowledge flows (<a href=\"#ref070\">Rosenkranz and Holten, 2011</a>).<span></span> To explain how and why KM inputs contribute to KM performance, our VSM-based empirical analysis of the case company yielded explanations in the form of six <em>KM mechanisms:</em> (1) project-based knowledge generation, (2) standardization of KM practices and resources, (3) putting people in the KM centre, (4) cyclic refinement of knowledge into a strategic asset, (5) allowing deliberate misalignment of KMS, KM identity and processes and (6) combining operational and strategic view.</p><p",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractPurposeBased on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.Design/methodology/approachThis in-depth case study conducted at a medium-sized consultancy in the supply chain management industr",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractPurposeBased on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.Design/methodology/approachThis in-depth case study conducted at a medium-sized consultancy in the supply chain management industr",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractPurposeBased on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.Design/methodology/approachThis in-depth case study conducted at a medium-sized consultancy in the supply chain management industr",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "PurposeBased on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Based on an exploratory case-based approach, the purpose of this paper is to open the KM black box and examine the relationships that link knowledge management (KM) inputs (i.e. knowledge resources and KM practices) via knowledge processes to KM performance. This paper aims to identify the underlying mechanisms and explain how KM performance is enabled.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Design/methodology/approachThis in-depth case study conducted at a medium-sized consultancy in the supply chain management industry empirically examines knowledge flows to uncover the relationships between KM inputs, knowledge processes and KM performance. We adopt the viable system model (VSM) as a theoretical lens to identify KM mechanisms.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "This in-depth case study conducted at a medium-sized consultancy in the supply chain management industry empirically examines knowledge flows to uncover the relationships between KM inputs, knowledge processes and KM performance. We adopt the viable system model (VSM) as a theoretical lens to identify KM mechanisms.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "FindingsBy identifying six KM mechanisms, we contribute to the theoretical understanding of how KM inputs are interconnected and lead to KM performance via knowledge processes.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "By identifying six KM mechanisms, we contribute to the theoretical understanding of how KM inputs are interconnected and lead to KM performance via knowledge processes.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Originality/valueBased on the insights gained, we provide propositions that organizations should consider in designing viable KM. Our findings help organizations in understanding their KM with the help of knowledge flow analysis and identifying how critical KM elements are interconnected.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Based on the insights gained, we provide propositions that organizations should consider in designing viable KM. Our findings help organizations in understanding their KM with the help of knowledge flow analysis and identifying how critical KM elements are interconnected.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "KeywordsKnowledge managementCase study researchViable system modelMechanismsKnowledge flowsConsultancy",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "CitationRichter, J.,Basten, D.,Michalik, B.,Rosenkranz, C.andSmolnik, S.(2023), \"Opening the black box of knowledge management mechanisms: exploring knowledge flows at a consultancy\",Kybernetes, Vol. 52 No. 13, pp. 1-28.https://doi.org/10.1108/K-08-2022-1118",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Publisher:Emerald Publishing Limited",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "LicensePublished by Emerald Publishing Limited. This article is published under the Creative Commons Attribution (CC BY 4.0) licence. Anyone may reproduce, distribute, translate and create derivative works of this article (for both commercial and non-commercial purposes), subject to full attribution to the original publication and authors. The full terms of this licence may be seen athttp://creativecommons.org/licences/by/4.0/legalcode",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. IntroductionKnowledge management(KM) comprises practices and processes that enable effective and efficient management of knowledge resources (Alavi and Leidner, 2001).Given the increasing knowledge intensity in business environments (Anandet al., 2007;Imranet al., 2022),organizations are continually intensifying their KM efforts due to its critical role in organizational performance (Goldet al., 2001;López-Cabarcoset al., 2020;Massingham, 2020).In this context,information technology (IT)is se",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. IntroductionKnowledge management(KM) comprises practices and processes that enable effective and efficient management of knowledge resources (Alavi and Leidner, 2001).Given the increasing knowledge intensity in business environments (Anandet al., 2007;Imranet al., 2022),organizations are continually intensifying their KM efforts due to its critical role in organizational performance (Goldet al., 2001;López-Cabarcoset al., 2020;Massingham, 2020).In this context,information technology (IT)is se",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Purpose",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Design/methodology/approach",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Findings",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Originality/value",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Keywords",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Citation",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Publisher",
              "id": ""
            },
            {
              "level": "h2",
              "text": "License",
              "id": ""
            },
            {
              "level": "h2",
              "text": "1. Introduction",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://uclouvain.be/en/research-institutes/ilc/cecl/transcription-guidelines.html",
      "title": "Transcription guidelines",
      "author": "",
      "published_date": "2025-01-01T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<h2>1. Interview identification</h2>\n<p>Each interview is preceded by a code of this type: &lt;h nt=\"FR\" nr=\"FR+<em>three-figure number</em>\"&gt;</p>\n<p>e.g. &lt;h nt=\"FR\" nr=\"FR004\"&gt; (4th interview with French mother tongue student)</p>\n<p>Examples of country codes:</p>\n<ul>\n<li>DUTCH = DU001</li>\n<li>GERMAN = GE001</li>\n<li>NORWEGIAN = NO001</li>\n<li>SPANISH = SP001</li>\n<li>SWEDISH = SW001</li>\n</ul>\n<p>All interviews should end with the following tag (on a separate line): &lt;/h&gt;</p>\n<h2>2. Speaker turns</h2>\n<p>Speaker turns are displayed in vertical format, i.e. one below the other. Whilst the letter \"A\" enclosed between angle brackets always signifies the interviewer's turn, the letter \"B\" between angle brackets indicates the interviewee's (learner's) turn. The end of each turn is indicated by either &lt;/A&gt; or &lt;/B&gt;.</p>\n<p>e.g. &lt;A&gt; okay so which topic have you chosen &lt;/A&gt;<br/>\n&lt;B&gt; the film or play that I thought was particularly good or bad really &lt;/B&gt;</p>\n<h2>3. Overlapping speech</h2>\n<p>The tag &lt;overlap /&gt; (with a space between \"overlap\" and the slash) is used to indicate the beginning of overlapping speech. It should be indicated in both turns. The end of overlapping speech is not indicated. </p>\n<p>e.g. &lt;B&gt; yeah I went on a bus to London once and I'll never &lt;overlap /&gt; do it again &lt;/B&gt;<br/>\n&lt;A&gt; &lt;overlap /&gt; that's even worse &lt;/A&gt;</p>\n<h2>4. Punctuation</h2>\n<p>No punctuation marks are used to indicate sentence or clause boundaries.</p>\n<h2>5. Empty pauses</h2>\n<p>Empty pauses are defined as a blank on the tape, i.e. no sound, or when someone is just breathing. </p>\n<p>The following three-tier system is used: one dot for a \"short\" pause (&lt; 1 second), two dots for a \"medium\" pause (1-3 seconds) and three dots for \"long\" pauses (&gt; 3 seconds). </p>\n<p>e.g. &lt;B&gt; (erm) .. it’s a British film there aren't many of those these days &lt;/B&gt;</p>\n<h2>6. Filled pauses and backchannelling</h2>\n<p>Filled pauses and backchannelling are put between brackets and marked as (eh) [brief], (er), (em), (erm), (mm), (uhu) and (mhm). No other fillers should be used.</p>\n<p>e.g. &lt;B&gt; yeah . well Namur was warmer (er) it was (eh) a really little town &lt;/B&gt;</p>\n<h2>7. Unclear passages</h2>\n<p>A three-tier system is used to indicate the length of unclear passages: &lt;X&gt; represents an unclear syllable or sound up to one word, &lt;XX&gt; represents two unclear words, and &lt;XXX&gt; represents more than two words.</p>\n<p>e.g. &lt;B&gt; &lt;X&gt; they're just begging &lt;XX&gt; there's there's honestly he did a course .. for a few weeks &lt;/B&gt;</p>\n<p>If transcribers are not entirely sure of a word or word ending, they should indicate this by having the word directly followed by the symbol &lt;?&gt;.</p>\n<p>e.g. &lt;B&gt; I went to see a&lt;?&gt; friend at university there and stayed &lt;/B&gt;</p>\n<p>Unclear names of towns or titles of films for example may be indicated as &lt;name of city&gt; or &lt;title of film&gt;.</p>\n<p>e.g. &lt;B&gt; where else did we go (er) &lt;name of city&gt; it's in Bolivia &lt;/B&gt;</p>\n<h2>8. Anonymisation</h2>\n<p>Data should be anonymised (names of famous people like singers or actors can be kept). Transcribers can use tags like &lt;first name of interviewee&gt;, &lt;first name and full name of interviewer&gt; or &lt;name of professor&gt; to replace names.</p>\n<p>e.g. &lt;A&gt; I'm &lt;first name of interviewer&gt; . what's your name &lt;/A&gt;</p>\n<h2>9. Truncated words</h2>\n<p>Truncated words are immediately followed by an equals sign.</p>\n<p>e.g. &lt;B&gt; it still resem= resembled the theatre &lt;/B&gt;</p>\n<h2>10. Spelling and capitalisation</h2>\n<p>British spelling conventions should be followed. Capital letters are only kept when required by spelling conventions on certain specific words (proper names, I, Mrs, etc.) – not at the beginning of turns.</p>\n<h2>11. Contracted forms</h2>\n<p>All standard contracted forms are retained as they are typical features of speech.</p>\n<h2>12. Non-standard forms</h2>\n<p>Non-standard forms that appear in the dictionary are transcribed orthographically in their dictionary accepted way: cos, dunno, gonna, gotta, kinda, wanna and yeah.</p>\n<h2>13. Acronyms</h2>\n<p>If acronyms are pronounced as sequences of letters, they are transcribed as a series of upper-case letters separated by spaces.</p>\n<p>e.g. &lt;B&gt; yes not really I did sort of basic G C S E French and German &lt;/B&gt;</p>\n<p>If, on the other hand, acronyms are pronounced as words, they are transcribed as a series of upper-case letters not separated by spaces.</p>\n<p>e.g. &lt;A&gt; (mhm) (er) you're doing a MAELT &lt;/A&gt;</p>\n<h2>14. Dates and numbers</h2>\n<p>Figures have to be written out in words. This avoids the ambiguity of, for example, \"1901\", which could be spoken in a number of different ways.</p>\n<p>e.g. &lt;B&gt; an awful lot of people complain and say well the grants were two thousand two hundred &lt;/B&gt;</p>\n<h2>15. Foreign words and pronunciation</h2>\n<p>Foreign words are indicated by &lt;foreign&gt; (before the word) and &lt;/foreign&gt; (after the word).</p>\n<p>e.g. &lt;B&gt; we couldn't go with (er) knives and so on &lt;foreign&gt; enfin &lt;/foreign&gt; we were (er) &lt;/B&gt;</p>\n<p>As a rule, foreign pronunciation is not noted, except in the case where the foreign word and the English word are identical. If in this case the word is pronounced as a foreign word, this is also marked using the &lt;foreign&gt; tag.</p>\n<p>e.g. &lt;B&gt; I didn't have the (erm) . &lt;foreign&gt; distinction &lt;/foreign&gt; &lt;/B&gt;</p>\n<h2>16. Phonetic features</h2>\n<h3>(a) Syllable lengthening</h3>\n<p>A colon is added at the end of a word to indicate that the last syllable is lengthened. It is typically used with small words like to, so or or. Colons should not be inserted within words.</p>\n<p>e.g. &lt;B&gt; that's something I'll I'll plan to: to learn &lt;/B&gt;</p>\n<h3>(b) Articles</h3>\n<p>- when pronounced as [ei], the article <em>a</em> is transcribed as a[ei];</p>\n<p>e.g. &lt;B&gt; and it's about (erm) . life in a[ei] (eh) public school in America I think &lt;/B&gt;</p>\n<p>- when pronounced as [i:], the article <em>the</em> is transcribed as the[i:].</p>\n<p>e.g. &lt;B&gt; and the[i:] villa we were staying in was in one of the valleys &lt;/B&gt;</p>\n<h2>17. Prosodic information: voice quality</h2>\n<p>If a particular stretch of text is said laughing or whispering for instance, this is marked by inserting &lt;starts laughing&gt; or &lt;starts whispering&gt; immediately before the specific stretch of speech and &lt;stops laughing&gt; or &lt;stops whispering&gt; at the end of it.</p>\n<p>e.g. &lt;B&gt; &lt;starts laughing&gt; I don't have to assess it I only have to write it &lt;stops laughing&gt; &lt;/B&gt;</p>\n<h2>18. Nonverbal vocal sounds</h2>\n<p>Nonverbal vocal sounds are enclosed between angle brackets.</p>\n<p>e.g. &lt;B&gt; I hope so I've I've got some &lt;coughs&gt; friends out there &lt;/B&gt;<br/>\ne.g. &lt;B&gt; so I went back into Breda .. and sat down again &lt;imitates the sound of a guitar&gt; &lt;/B&gt;</p>\n<h2>19. Contextual comments</h2>\n<p>Non-linguistic events are indicated between angle brackets only if they are deemed relevant to the interaction (if one of the participants reacts to it, for example).</p>\n<p>e.g. &lt;A&gt; no it's true it's nice to have your own bathroom &lt;/A&gt;<br/>\n&lt;somebody enters the room&gt;<br/>\n&lt;B&gt; hi &lt;/B&gt;</p>\n<h2>20. Tasks</h2>\n<p>The three tasks making up the interview (set topic, free discussion and picture description) should be separated from each other. This is done using the following tags: &lt;S&gt; (before the set topic), &lt;/S&gt; (after the set topic), &lt;F&gt; (before the free discussion), &lt;/F&gt; (after the free discussion), &lt;P&gt; (before the picture description), &lt;/P&gt; (after the picture description). These tags should occupy a separate line and should not interrupt a turn.</p>\n<p>e.g. &lt;S&gt;<br/>\n&lt;A&gt; did you . manage to choose a topic &lt;/A&gt;</p>\n<h2>Questions?<br/>\n</h2>\n<p>If you have any questions regarding these transcription guidelines, don't hesitate to get in touch with us.<a href=\"https://cdn.uclouvain.be/public/Exports%20reddot/cecl/documents/TRANSNEW_Sept_09.DOC\"><br/>\n</a></p><h3><a href=\"https://cdn.uclouvain.be/public/Exports%20reddot/cecl/documents/TRANSNEW_Sept_09.DOC\">\n</a></h3><a href=\"https://cdn.uclouvain.be/public/Exports%20reddot/cecl/documents/TRANSNEW_Sept_09.DOC\">\n</a>\n</div></div>",
        "html": "<div><div>\n<h2>1. Interview identification</h2>\n<p>Each interview is preceded by a code of this type: &lt;h nt=\"FR\" nr=\"FR+<em>three-figure number</em>\"&gt;</p>\n<p>e.g. &lt;h nt=\"FR\" nr=\"FR004\"&gt; (4th interview with French mother tongue student)</p>\n<p>Examples of country codes:</p>\n<ul>\n<li>DUTCH = DU001</li>\n<li>GERMAN = GE001</li>\n<li>NORWEGIAN = NO001</li>\n<li>SPANISH = SP001</li>\n<li>SWEDISH = SW001</li>\n</ul>\n<p>All interviews should end with the following tag (on a separate line): &lt;/h&gt;</p>\n<h2>2. Speaker turns</h2>\n<p>Speaker turns are displayed in vertical format, i.e. one below the other. Whilst the letter \"A\" enclosed between angle brackets always signifies the interviewer's turn, the letter \"B\" between angle brackets indicates the interviewee's (learner's) turn. The end of each turn is indicated by either &lt;/A&gt; or &lt;/B&gt;.</p>\n<p>e.g. &lt;A&gt; okay so which topic have you chosen &lt;/A&gt;<br/>\n&lt;B&gt; the film or play that I thought was particularly good or bad really &lt;/B&gt;</p>\n<h2>3. Overlapping speech</h2>\n<p>The tag &lt;overlap /&gt; (with a space between \"overlap\" and the slash) is used to indicate the beginning of overlapping speech. It should be indicated in both turns. The end of overlapping speech is not indicated. </p>\n<p>e.g. &lt;B&gt; yeah I went on a bus to London once and I'll never &lt;overlap /&gt; do it again &lt;/B&gt;<br/>\n&lt;A&gt; &lt;overlap /&gt; that's even worse &lt;/A&gt;</p>\n<h2>4. Punctuation</h2>\n<p>No punctuation marks are used to indicate sentence or clause boundaries.</p>\n<h2>5. Empty pauses</h2>\n<p>Empty pauses are defined as a blank on the tape, i.e. no sound, or when someone is just breathing. </p>\n<p>The following three-tier system is used: one dot for a \"short\" pause (&lt; 1 second), two dots for a \"medium\" pause (1-3 seconds) and three dots for \"long\" pauses (&gt; 3 seconds). </p>\n<p>e.g. &lt;B&gt; (erm) .. it’s a British film there aren't many of those these days &lt;/B&gt;</p>\n<h2>6. Filled pauses and backchannelling</h2>\n<p>Filled pauses and backchannelling are put between brackets and marked as (eh) [brief], (er), (em), (erm), (mm), (uhu) and (mhm). No other fillers should be used.</p>\n<p>e.g. &lt;B&gt; yeah . well Namur was warmer (er) it was (eh) a really little town &lt;/B&gt;</p>\n<h2>7. Unclear passages</h2>\n<p>A three-tier system is used to indicate the length of unclear passages: &lt;X&gt; represents an unclear syllable or sound up to one word, &lt;XX&gt; represents two unclear words, and &lt;XXX&gt; represents more than two words.</p>\n<p>e.g. &lt;B&gt; &lt;X&gt; they're just begging &lt;XX&gt; there's there's honestly he did a course .. for a few weeks &lt;/B&gt;</p>\n<p>If transcribers are not entirely sure of a word or word ending, they should indicate this by having the word directly followed by the symbol &lt;?&gt;.</p>\n<p>e.g. &lt;B&gt; I went to see a&lt;?&gt; friend at university there and stayed &lt;/B&gt;</p>\n<p>Unclear names of towns or titles of films for example may be indicated as &lt;name of city&gt; or &lt;title of film&gt;.</p>\n<p>e.g. &lt;B&gt; where else did we go (er) &lt;name of city&gt; it's in Bolivia &lt;/B&gt;</p>\n<h2>8. Anonymisation</h2>\n<p>Data should be anonymised (names of famous people like singers or actors can be kept). Transcribers can use tags like &lt;first name of interviewee&gt;, &lt;first name and full name of interviewer&gt; or &lt;name of professor&gt; to replace names.</p>\n<p>e.g. &lt;A&gt; I'm &lt;first name of interviewer&gt; . what's your name &lt;/A&gt;</p>\n<h2>9. Truncated words</h2>\n<p>Truncated words are immediately followed by an equals sign.</p>\n<p>e.g. &lt;B&gt; it still resem= resembled the theatre &lt;/B&gt;</p>\n<h2>10. Spelling and capitalisation</h2>\n<p>British spelling conventions should be followed. Capital letters are only kept when required by spelling conventions on certain specific words (proper names, I, Mrs, etc.) – not at the beginning of turns.</p>\n<h2>11. Contracted forms</h2>\n<p>All standard contracted forms are retained as they are typical features of speech.</p>\n<h2>12. Non-standard forms</h2>\n<p>Non-standard forms that appear in the dictionary are transcribed orthographically in their dictionary accepted way: cos, dunno, gonna, gotta, kinda, wanna and yeah.</p>\n<h2>13. Acronyms</h2>\n<p>If acronyms are pronounced as sequences of letters, they are transcribed as a series of upper-case letters separated by spaces.</p>\n<p>e.g. &lt;B&gt; yes not really I did sort of basic G C S E French and German &lt;/B&gt;</p>\n<p>If, on the other hand, acronyms are pronounced as words, they are transcribed as a series of upper-case letters not separated by spaces.</p>\n<p>e.g. &lt;A&gt; (mhm) (er) you're doing a MAELT &lt;/A&gt;</p>\n<h2>14. Dates and numbers</h2>\n<p>Figures have to be written out in words. This avoids the ambiguity of, for example, \"1901\", which could be spoken in a number of different ways.</p>\n<p>e.g. &lt;B&gt; an awful lot of people complain and say well the grants were two thousand two hundred &lt;/B&gt;</p>\n<h2>15. Foreign words and pronunciation</h2>\n<p>Foreign words are indicated by &lt;foreign&gt; (before the word) and &lt;/foreign&gt; (after the word).</p>\n<p>e.g. &lt;B&gt; we couldn't go with (er) knives and so on &lt;foreign&gt; enfin &lt;/foreign&gt; we were (er) &lt;/B&gt;</p>\n<p>As a rule, foreign pronunciation is not noted, except in the case where the foreign word and the English word are identical. If in this case the word is pronounced as a foreign word, this is also marked using the &lt;foreign&gt; tag.</p>\n<p>e.g. &lt;B&gt; I didn't have the (erm) . &lt;foreign&gt; distinction &lt;/foreign&gt; &lt;/B&gt;</p>\n<h2>16. Phonetic features</h2>\n<h3>(a) Syllable lengthening</h3>\n<p>A colon is added at the end of a word to indicate that the last syllable is lengthened. It is typically used with small words like to, so or or. Colons should not be inserted within words.</p>\n<p>e.g. &lt;B&gt; that's something I'll I'll plan to: to learn &lt;/B&gt;</p>\n<h3>(b) Articles</h3>\n<p>- when pronounced as [ei], the article <em>a</em> is transcribed as a[ei];</p>\n<p>e.g. &lt;B&gt; and it's about (erm) . life in a[ei] (eh) public school in America I think &lt;/B&gt;</p>\n<p>- when pronounced as [i:], the article <em>the</em> is transcribed as the[i:].</p>\n<p>e.g. &lt;B&gt; and the[i:] villa we were staying in was in one of the valleys &lt;/B&gt;</p>\n<h2>17. Prosodic information: voice quality</h2>\n<p>If a particular stretch of text is said laughing or whispering for instance, this is marked by inserting &lt;starts laughing&gt; or &lt;starts whispering&gt; immediately before the specific stretch of speech and &lt;stops laughing&gt; or &lt;stops whispering&gt; at the end of it.</p>\n<p>e.g. &lt;B&gt; &lt;starts laughing&gt; I don't have to assess it I only have to write it &lt;stops laughing&gt; &lt;/B&gt;</p>\n<h2>18. Nonverbal vocal sounds</h2>\n<p>Nonverbal vocal sounds are enclosed between angle brackets.</p>\n<p>e.g. &lt;B&gt; I hope so I've I've got some &lt;coughs&gt; friends out there &lt;/B&gt;<br/>\ne.g. &lt;B&gt; so I went back into Breda .. and sat down again &lt;imitates the sound of a guitar&gt; &lt;/B&gt;</p>\n<h2>19. Contextual comments</h2>\n<p>Non-linguistic events are indicated between angle brackets only if they are deemed relevant to the interaction (if one of the participants reacts to it, for example).</p>\n<p>e.g. &lt;A&gt; no it's true it's nice to have your own bathroom &lt;/A&gt;<br/>\n&lt;somebody enters the room&gt;<br/>\n&lt;B&gt; hi &lt;/B&gt;</p>\n<h2>20. Tasks</h2>\n<p>The three tasks making up the interview (set topic, free discussion and picture description) should be separated from each other. This is done using the following tags: &lt;S&gt; (before the set topic), &lt;/S&gt; (after the set topic), &lt;F&gt; (before the free discussion), &lt;/F&gt; (after the free discussion), &lt;P&gt; (before the picture description), &lt;/P&gt; (after the picture description). These tags should occupy a separate line and should not interrupt a turn.</p>\n<p>e.g. &lt;S&gt;<br/>\n&lt;A&gt; did you . manage to choose a topic &lt;/A&gt;</p>\n<h2>Questions?<br/>\n</h2>\n<p>If you have any questions regarding these transcription guidelines, don't hesitate to get in touch with us.<a href=\"https://cdn.uclouvain.be/public/Exports%20reddot/cecl/documents/TRANSNEW_Sept_09.DOC\"><br/>\n</a></p><h3><a href=\"https://cdn.uclouvain.be/public/Exports%20reddot/cecl/documents/TRANSNEW_Sept_09.DOC\">\n</a></h3><a href=\"https://cdn.uclouvain.be/public/Exports%20reddot/cecl/documents/TRANSNEW_Sept_09.DOC\">\n</a>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "1. Interview identificationEach interview is preceded by a code of this type: <h nt=\"FR\" nr=\"FR+three-figure number\">e.g. <h nt=\"FR\" nr=\"FR004\"> (4th interview with French mother tongue student)Examples of country codes:DUTCH = DU001GERMAN = GE001NORWEGIAN = NO001SPANISH = SP001SWEDISH = SW001All interviews should end with the following tag (on a separate line): </h>2. Speaker turnsSpeaker turns are displayed in vertical format, i.e. one below the other. Whilst the letter \"A\" enclosed between an",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "1. Interview identificationEach interview is preceded by a code of this type: <h nt=\"FR\" nr=\"FR+three-figure number\">e.g. <h nt=\"FR\" nr=\"FR004\"> (4th interview with French mother tongue student)Examples of country codes:DUTCH = DU001GERMAN = GE001NORWEGIAN = NO001SPANISH = SP001SWEDISH = SW001All interviews should end with the following tag (on a separate line): </h>2. Speaker turnsSpeaker turns are displayed in vertical format, i.e. one below the other. Whilst the letter \"A\" enclosed between an",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "1. Interview identification",
              "id": ""
            },
            {
              "level": "h2",
              "text": "2. Speaker turns",
              "id": ""
            },
            {
              "level": "h2",
              "text": "3. Overlapping speech",
              "id": ""
            },
            {
              "level": "h2",
              "text": "4. Punctuation",
              "id": ""
            },
            {
              "level": "h2",
              "text": "5. Empty pauses",
              "id": ""
            },
            {
              "level": "h2",
              "text": "6. Filled pauses and backchannelling",
              "id": ""
            },
            {
              "level": "h2",
              "text": "7. Unclear passages",
              "id": ""
            },
            {
              "level": "h2",
              "text": "8. Anonymisation",
              "id": ""
            },
            {
              "level": "h2",
              "text": "9. Truncated words",
              "id": ""
            },
            {
              "level": "h2",
              "text": "10. Spelling and capitalisation",
              "id": ""
            },
            {
              "level": "h2",
              "text": "11. Contracted forms",
              "id": ""
            },
            {
              "level": "h2",
              "text": "12. Non-standard forms",
              "id": ""
            },
            {
              "level": "h2",
              "text": "13. Acronyms",
              "id": ""
            },
            {
              "level": "h2",
              "text": "14. Dates and numbers",
              "id": ""
            },
            {
              "level": "h2",
              "text": "15. Foreign words and pronunciation",
              "id": ""
            },
            {
              "level": "h2",
              "text": "16. Phonetic features",
              "id": ""
            },
            {
              "level": "h3",
              "text": "(a) Syllable lengthening",
              "id": ""
            },
            {
              "level": "h3",
              "text": "(b) Articles",
              "id": ""
            },
            {
              "level": "h2",
              "text": "17. Prosodic information: voice quality",
              "id": ""
            },
            {
              "level": "h2",
              "text": "18. Nonverbal vocal sounds",
              "id": ""
            },
            {
              "level": "h2",
              "text": "19. Contextual comments",
              "id": ""
            },
            {
              "level": "h2",
              "text": "20. Tasks",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Questions?",
              "id": ""
            },
            {
              "level": "h3",
              "text": "",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10067271/",
      "title": "Mutation bias and the predictability of evolution",
      "author": "",
      "published_date": "2023-04-03T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Predicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these results for the problem of prediction, in regard to topics such as the evolution of infectious diseases, resistance to biochemical agents, as well as cancer and other kinds of somatic evolution. We argue that empirical knowledge of mutational biases is likely to improve in the near future, and that this knowledge is readily applicable to the challenges of short-term prediction.</p>\n<p>This article is part of the theme issue ‘Interdisciplinary approaches to predicting evolutionary biology’.</p>\n<section><p><strong>Keywords:</strong> adaptation, mutation, prediction, theory, population genetics</p></section></section><section><h2>1. Introduction</h2>\n<p>Predicting the dynamics and outcome of evolution is an important goal of the biological sciences, offering the potential to design better drugs, combat pathogens and conserve endangered species [<a href=\"#RSTB20220055C1\">1</a>–<a href=\"#RSTB20220055C11\">11</a>]. Targets of prediction include genetic changes underlying adaptation, such as those causing antibiotic resistance or enhancing thermostability, as well as their corresponding phenotypes, such as minimum inhibitory concentration or melting temperature [<a href=\"#RSTB20220055C12\">12</a>,<a href=\"#RSTB20220055C13\">13</a>]. Higher-level targets include the diversity, abundance and ecosystem functions of microbial communities [<a href=\"#RSTB20220055C14\">14</a>], as well as the rate of adaptation itself [<a href=\"#RSTB20220055C13\">13</a>].</p>\n<p>Owing to the stochastic nature of the evolutionary process, forecasting offers the greatest potential over short and intermediate timescales. Our ability to make accurate forecasts depends crucially on high-quality experimental data, such as those describing the phenotypic or fitness effects of mutations. For example, over short timescales, where one may wish to predict the next beneficial mutation to arise and go to fixation, empirical knowledge of the distribution of fitness effects is key, because this provides information about the fixation probabilities of new mutations [<a href=\"#RSTB20220055C15\">15</a>]. At intermediate timescales, where one may wish to predict which of several possible mutational trajectories to adaptation is the most likely, empirical knowledge of the fitness effects of combinations of mutations is key, because this can be used to delineate between mutational trajectories that ascend adaptive peaks from those that fall into maladaptive valleys [<a href=\"#RSTB20220055C2\">2</a>]. As such, the project of predicting evolution has benefited greatly from recent advances in high-throughput sequencing technologies and phenotypic assays, which ameliorate so-called ‘data limits’ on accurate forecasting [<a href=\"#RSTB20220055C7\">7</a>]. These technologies have been used to characterize the phenotypic and fitness effects of mutations in a diversity of biological systems, including regulatory elements [<a href=\"#RSTB20220055C16\">16</a>,<a href=\"#RSTB20220055C17\">17</a>], macromolecules [<a href=\"#RSTB20220055C18\">18</a>–<a href=\"#RSTB20220055C24\">24</a>], gene regulatory circuits [<a href=\"#RSTB20220055C25\">25</a>,<a href=\"#RSTB20220055C26\">26</a>] and metabolic pathways [<a href=\"#RSTB20220055C27\">27</a>].</p>\n<p>However, empirical knowledge of the phenotypic and fitness effects of mutations only takes us so far. Whereas these data provide useful information about the likelihood of mutations going to fixation, they tell us nothing about the rate with which new mutations are introduced into a population. This is an important limitation, because evolution often proceeds via the introduction of new mutations, and some types of mutations are more likely to arise than others [<a href=\"#RSTB20220055C28\">28</a>,<a href=\"#RSTB20220055C29\">29</a>]. For example, studies of the rates and spectra of spontaneous mutations, such as those based on mutation accumulation experiments, have revealed a bias towards transitions (purine-to-purine or pyrimidine-to-pyrimidine changes), relative to transversions (purine-to-pyrimidine changes, or vice versa) in a wide range of species [<a href=\"#RSTB20220055C30\">30</a>]. The exact degree of transition bias emerging under any particular set of conditions is the net outcome of biases in all stages in the genesis of nucleotide mutations, including biases in susceptibility to damage (e.g. oxidative damage), in the efficiency of damage recognition and repair, in rates of polymerase errors and proofreading, and in the efficiency of recognition and repair of mispaired bases (see [<a href=\"#RSTB20220055C31\">31</a>,<a href=\"#RSTB20220055C32\">32</a>]). Because transition bias and other kinds of mutation bias make some mutational steps to adaptation more likely than others, empirical knowledge of mutation bias offers the potential to improve evolutionary forecasting, both at short and intermediate timescales.</p>\n<p>Here, we address how effects of mutational biases—predictable differences in rates between different categories of mutational conversions—make evolution more predictable, focusing mostly on the case of short-term adaptation from new mutations, and setting aside some related topics such as the role of specialized mutation-generating systems [<a href=\"#RSTB20220055C33\">33</a>, ch. 5] and hypermutators [<a href=\"#RSTB20220055C34\">34</a>]. First, we review theoretical work suggesting that such biases can exert a strong influence on the outcome of evolutionary processes, including adaptive processes, that depend on new mutations. Next, we review the empirical case for an influence of mutation bias on adaptation in the laboratory and in nature. Finally, we discuss specific applications where empirical knowledge of mutation bias is anticipated to improve evolutionary forecasting, in regard to topics such as infectious diseases, cancer and other kinds of somatic evolution, as well as resistance to biochemical agents. We note some recurring themes: (i) the most commonly observed outcome is often the most mutationally favourable of the adaptive options, not the most fit, (ii) ordinary nucleotide mutation biases often have strong and predictable effects on the genetic changes underlying adaptation, (iii) perturbing the mutation spectrum alters the distribution of such changes, and (iv) the influence of mutation biases can be altered by the beneficial mutation supply and other population-genetic and environmental conditions. In general, we argue that knowledge of mutation can improve predictability in practical contexts. We conclude with comments on open questions and future prospects.</p></section><section><h2>2. Theory</h2>\n<p>Under what conditions will empirical knowledge of mutation bias improve evolutionary forecasting? To address this question, we first turn to theory. The classic ‘Modern Synthesis’ view assumes evolution from standing variation in an abundant gene pool, so that the process of evolution is formally a process of recombining and shifting frequencies of available alleles without new mutations [<a href=\"#RSTB20220055C33\">33</a>,<a href=\"#RSTB20220055C35\">35</a>,<a href=\"#RSTB20220055C36\">36</a>]. In this context, adaptation happens by selectively favourable shifts in frequencies of multi-locus combinations of small-effect alleles generated by recombination [<a href=\"#RSTB20220055C37\">37</a>–<a href=\"#RSTB20220055C40\">40</a>]. The role of mutation is strictly limited: recurrent mutation acts only as a weak pressure, ineffectual except when mutation rates are high and unopposed by selection [<a href=\"#RSTB20220055C41\">41</a>–<a href=\"#RSTB20220055C43\">43</a>]. Therefore, in this theory, the predictability of evolution emerges from a consideration of selection: in the short-term, an evolving population ascends a fitness gradient in a multi-locus allele-frequency space; in the long term, it approaches a local or global maximum of fitness.</p>\n<p>A different view of the roles of mutation and selection emerged during the molecular revolution. Comparisons of protein sequences suggested that evolutionary divergence occurs by the accumulation of individual substitutions of amino acid residues, where each substitution reflects a mutation that was promoted—or at least, tolerated—by selection, which was conceptualized as a filter acting on individual mutations [<a href=\"#RSTB20220055C44\">44</a>–<a href=\"#RSTB20220055C46\">46</a>]. This way of thinking placed the process of mutation in the more important role of offering individual variants directly for selective filtering (rather than merely filling up the gene pool to facilitate subsequent recombination). This conception of evolution as a two-step process was formalized in ‘origin-fixation’ models, which depict the limiting behaviour of evolution when the number of new mutations introduced per generation becomes arbitrarily small [<a href=\"#RSTB20220055C47\">47</a>]. In an origin-fixation model, the rate of evolution is determined by the product of a rate of ‘introduction’ or origin <em>Nμ</em> and a probability of fixation <em>π</em>, i.e. <em>R</em> = <em>Nμπ</em>.</p>\n<p>Importantly, this new way of thinking about evolution suggests an increased influence for mutation biases, because the likelihood of each possible step will depend on the likelihood of the underlying mutation. For evolution in the origin-fixation regime, mutational biases (i.e. biases in origination) and biases in fixation each have proportional effects",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Predicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these results for the problem of prediction, in regard to topics such as the evolution of infectious diseases, resistance to biochemical agents, as well as cancer and other kinds of somatic evolution. We argue that empirical knowledge of mutational biases is likely to improve in the near future, and that this knowledge is readily applicable to the challenges of short-term prediction.</p>\n<p>This article is part of the theme issue ‘Interdisciplinary approaches to predicting evolutionary biology’.</p>\n<section><p><strong>Keywords:</strong> adaptation, mutation, prediction, theory, population genetics</p></section></section><section><h2>1. Introduction</h2>\n<p>Predicting the dynamics and outcome of evolution is an important goal of the biological sciences, offering the potential to design better drugs, combat pathogens and conserve endangered species [<a href=\"#RSTB20220055C1\">1</a>–<a href=\"#RSTB20220055C11\">11</a>]. Targets of prediction include genetic changes underlying adaptation, such as those causing antibiotic resistance or enhancing thermostability, as well as their corresponding phenotypes, such as minimum inhibitory concentration or melting temperature [<a href=\"#RSTB20220055C12\">12</a>,<a href=\"#RSTB20220055C13\">13</a>]. Higher-level targets include the diversity, abundance and ecosystem functions of microbial communities [<a href=\"#RSTB20220055C14\">14</a>], as well as the rate of adaptation itself [<a href=\"#RSTB20220055C13\">13</a>].</p>\n<p>Owing to the stochastic nature of the evolutionary process, forecasting offers the greatest potential over short and intermediate timescales. Our ability to make accurate forecasts depends crucially on high-quality experimental data, such as those describing the phenotypic or fitness effects of mutations. For example, over short timescales, where one may wish to predict the next beneficial mutation to arise and go to fixation, empirical knowledge of the distribution of fitness effects is key, because this provides information about the fixation probabilities of new mutations [<a href=\"#RSTB20220055C15\">15</a>]. At intermediate timescales, where one may wish to predict which of several possible mutational trajectories to adaptation is the most likely, empirical knowledge of the fitness effects of combinations of mutations is key, because this can be used to delineate between mutational trajectories that ascend adaptive peaks from those that fall into maladaptive valleys [<a href=\"#RSTB20220055C2\">2</a>]. As such, the project of predicting evolution has benefited greatly from recent advances in high-throughput sequencing technologies and phenotypic assays, which ameliorate so-called ‘data limits’ on accurate forecasting [<a href=\"#RSTB20220055C7\">7</a>]. These technologies have been used to characterize the phenotypic and fitness effects of mutations in a diversity of biological systems, including regulatory elements [<a href=\"#RSTB20220055C16\">16</a>,<a href=\"#RSTB20220055C17\">17</a>], macromolecules [<a href=\"#RSTB20220055C18\">18</a>–<a href=\"#RSTB20220055C24\">24</a>], gene regulatory circuits [<a href=\"#RSTB20220055C25\">25</a>,<a href=\"#RSTB20220055C26\">26</a>] and metabolic pathways [<a href=\"#RSTB20220055C27\">27</a>].</p>\n<p>However, empirical knowledge of the phenotypic and fitness effects of mutations only takes us so far. Whereas these data provide useful information about the likelihood of mutations going to fixation, they tell us nothing about the rate with which new mutations are introduced into a population. This is an important limitation, because evolution often proceeds via the introduction of new mutations, and some types of mutations are more likely to arise than others [<a href=\"#RSTB20220055C28\">28</a>,<a href=\"#RSTB20220055C29\">29</a>]. For example, studies of the rates and spectra of spontaneous mutations, such as those based on mutation accumulation experiments, have revealed a bias towards transitions (purine-to-purine or pyrimidine-to-pyrimidine changes), relative to transversions (purine-to-pyrimidine changes, or vice versa) in a wide range of species [<a href=\"#RSTB20220055C30\">30</a>]. The exact degree of transition bias emerging under any particular set of conditions is the net outcome of biases in all stages in the genesis of nucleotide mutations, including biases in susceptibility to damage (e.g. oxidative damage), in the efficiency of damage recognition and repair, in rates of polymerase errors and proofreading, and in the efficiency of recognition and repair of mispaired bases (see [<a href=\"#RSTB20220055C31\">31</a>,<a href=\"#RSTB20220055C32\">32</a>]). Because transition bias and other kinds of mutation bias make some mutational steps to adaptation more likely than others, empirical knowledge of mutation bias offers the potential to improve evolutionary forecasting, both at short and intermediate timescales.</p>\n<p>Here, we address how effects of mutational biases—predictable differences in rates between different categories of mutational conversions—make evolution more predictable, focusing mostly on the case of short-term adaptation from new mutations, and setting aside some related topics such as the role of specialized mutation-generating systems [<a href=\"#RSTB20220055C33\">33</a>, ch. 5] and hypermutators [<a href=\"#RSTB20220055C34\">34</a>]. First, we review theoretical work suggesting that such biases can exert a strong influence on the outcome of evolutionary processes, including adaptive processes, that depend on new mutations. Next, we review the empirical case for an influence of mutation bias on adaptation in the laboratory and in nature. Finally, we discuss specific applications where empirical knowledge of mutation bias is anticipated to improve evolutionary forecasting, in regard to topics such as infectious diseases, cancer and other kinds of somatic evolution, as well as resistance to biochemical agents. We note some recurring themes: (i) the most commonly observed outcome is often the most mutationally favourable of the adaptive options, not the most fit, (ii) ordinary nucleotide mutation biases often have strong and predictable effects on the genetic changes underlying adaptation, (iii) perturbing the mutation spectrum alters the distribution of such changes, and (iv) the influence of mutation biases can be altered by the beneficial mutation supply and other population-genetic and environmental conditions. In general, we argue that knowledge of mutation can improve predictability in practical contexts. We conclude with comments on open questions and future prospects.</p></section><section><h2>2. Theory</h2>\n<p>Under what conditions will empirical knowledge of mutation bias improve evolutionary forecasting? To address this question, we first turn to theory. The classic ‘Modern Synthesis’ view assumes evolution from standing variation in an abundant gene pool, so that the process of evolution is formally a process of recombining and shifting frequencies of available alleles without new mutations [<a href=\"#RSTB20220055C33\">33</a>,<a href=\"#RSTB20220055C35\">35</a>,<a href=\"#RSTB20220055C36\">36</a>]. In this context, adaptation happens by selectively favourable shifts in frequencies of multi-locus combinations of small-effect alleles generated by recombination [<a href=\"#RSTB20220055C37\">37</a>–<a href=\"#RSTB20220055C40\">40</a>]. The role of mutation is strictly limited: recurrent mutation acts only as a weak pressure, ineffectual except when mutation rates are high and unopposed by selection [<a href=\"#RSTB20220055C41\">41</a>–<a href=\"#RSTB20220055C43\">43</a>]. Therefore, in this theory, the predictability of evolution emerges from a consideration of selection: in the short-term, an evolving population ascends a fitness gradient in a multi-locus allele-frequency space; in the long term, it approaches a local or global maximum of fitness.</p>\n<p>A different view of the roles of mutation and selection emerged during the molecular revolution. Comparisons of protein sequences suggested that evolutionary divergence occurs by the accumulation of individual substitutions of amino acid residues, where each substitution reflects a mutation that was promoted—or at least, tolerated—by selection, which was conceptualized as a filter acting on individual mutations [<a href=\"#RSTB20220055C44\">44</a>–<a href=\"#RSTB20220055C46\">46</a>]. This way of thinking placed the process of mutation in the more important role of offering individual variants directly for selective filtering (rather than merely filling up the gene pool to facilitate subsequent recombination). This conception of evolution as a two-step process was formalized in ‘origin-fixation’ models, which depict the limiting behaviour of evolution when the number of new mutations introduced per generation becomes arbitrarily small [<a href=\"#RSTB20220055C47\">47</a>]. In an origin-fixation model, the rate of evolution is determined by the product of a rate of ‘introduction’ or origin <em>Nμ</em> and a probability of fixation <em>π</em>, i.e. <em>R</em> = <em>Nμπ</em>.</p>\n<p>Importantly, this new way of thinking about evolution suggests an increased influence for mutation biases, because the likelihood of each possible step will depend on the likelihood of the underlying mutation. For evolution in the origin-fixation regime, mutational biases (i.e. biases in origination) and biases in fixation each have proportional effects",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractPredicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these resu",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractPredicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these resu",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractPredicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these resu",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractPredicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these resu",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractPredicting evolutionary outcomes is an important research goal in a diversity of contexts. The focus of evolutionary forecasting is usually on adaptive processes, and efforts to improve prediction typically focus on selection. However, adaptive processes often rely on new mutations, which can be strongly influenced by predictable biases in mutation. Here, we provide an overview of existing theory and evidence for such mutation-biased adaptation and consider the implications of these resu",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:adaptation, mutation, prediction, theory, population genetics",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. IntroductionPredicting the dynamics and outcome of evolution is an important goal of the biological sciences, offering the potential to design better drugs, combat pathogens and conserve endangered species [1–11]. Targets of prediction include genetic changes underlying adaptation, such as those causing antibiotic resistance or enhancing thermostability, as well as their corresponding phenotypes, such as minimum inhibitory concentration or melting temperature [12,13]. Higher-level targets inc",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "2. TheoryUnder what conditions will empirical knowledge of mutation bias improve evolutionary forecasting? To address this question, we first turn to theory. The classic ‘Modern Synthesis’ view assumes evolution from standing variation in an abundant gene pool, so that the process of evolution is formally a process of recombining and shifting frequencies of available alleles without new mutations [33,35,36]. In this context, adaptation happens by selectively favourable shifts in frequencies of m",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "1. Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "2. Theory",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC4814509/",
      "title": "Recursive Subsystems in Aphasia and Alzheimer's Disease: Case Studies in Syntax and Theory of Mind",
      "author": "",
      "published_date": "2016-03-31T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>The relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The expected answers typically involved subordinate clauses introduced by conjunctions or direct quotations of the characters' utterances. Broca's aphasics did not produce answers with recursive sentence embedding. Rather, they projected themselves into the characters' mental states and gave direct answers in the first person singular, with relevant ToM content. We call such replies “situative statements.” Where the question concerned the mental state of the character but did not require an answer with sentence embedding (“What does X hate?”), aphasics gave descriptive answers rather than situative statements. Most replies given by persons with AD to Type 4 questions were grammatical instances of recursive sentence embedding. They also gave a few situative statements but the ToM content of these was irrelevant. In more than one third of their well-formed sentence embeddings, too, they conveyed irrelevant ToM contents. Persons with moderate AD were unable to pass secondary false belief tests. The results reveal double dissociation: Broca's aphasics are unable to access recursive sentence embedding but they can make appropriate ToM inferences; moderate AD persons make the wrong ToM inferences but they are able to access recursive sentence embedding. The double dissociation may be relevant for the nature of the relationship between the two recursive capacities. Broca's aphasics compensated for the lack of recursive sentence embedding by recursive ToM reasoning represented in very simple syntactic forms: they used one recursive subsystem to stand in for another recursive subsystem.</p>\n<section><p><strong>Keywords:</strong> recursive sentence embedding, theory of mind, Broca's aphasia, Alzheimer's disease, compensatory strategy</p></section></section><section><h2>1. Introduction</h2>\n<p><strong>1.1</strong>. Most linguists use a kind of inductive definition of recursion (Tomalin, <a href=\"#B61\">2007</a>; Hulst, <a href=\"#B33\">2010b</a>): they define it as the embedding of a constituent in a constituent of the same type in linguistic expressions. Recursion builds complex structures by increasing embedding depth whereas simple iteration yields output structures which do not increase depth (cf. Karlsson, <a href=\"#B36\">2010</a>). Watumull et al. (<a href=\"#B66\">2014</a>) criticize the concept of recursion as articulated in linguistic analysis; they point out that “syntactic embedding is a sufficient, though not necessary, diagnostic of recursion” (p. 1). In the interpretation of our data we will extend the concept of recursion beyond linguistic syntax to the recursive logic of theory-of-mind (ToM) reasoning.</p>\n<p>One initial question of our research concerned the particular source of the human faculty of recursion. It is a debated issue whether recursivity, seen as a specific feature of human languageand mind, is a syntactic phenomenon: certain constituents can have the same types of constituents embedded in them, and this operation can be repeatedpotentially unbounded (cf. Hauser et al., <a href=\"#B29\">2002</a>; Fitch et al., <a href=\"#B19\">2005</a>; Rizzi, <a href=\"#B50\">2012</a>), or the source of recursion is semantics or pragmatics: complex propositions can be expressed recursively in human languages (cf. Evans and Levinson, <a href=\"#B15\">2009</a>; Everett, <a href=\"#B16\">2009</a>), or else recursion is found in general capacities of the human mind (Jackendoff and Pinker, <a href=\"#B35\">2005</a>; Pinker and Jackendoff, <a href=\"#B49\">2006</a>).</p>\n<p>It is also a debated issue what the relationship of those competing alternatives might be. Watumull et al. (<a href=\"#B66\">2014</a>) argue that recursion is a fundamental linguistic universal. Regarding language (in the wake of Chomsky, <a href=\"#B8\">1986</a>) as I-language, they define it as an intensional function that is a mental object, an internal function of all human brains/minds. One of its fundamental features is recursion, i.e., that it may generate infinite sets. They also assign three formal criteria to the capacity of recursion: “the computability of rules generative of non-arbitrary sets; definition by induction enabling the strong generation of increasingly structured expressions; and mathematical induction for the principled (and potentially unbounded) expansion of the generated sets of structures” (p. 6).</p>\n<p>Corballis (<a href=\"#B12\">2011</a>, <a href=\"#B11\">2014</a>) argues in favor of the primacy of the recursive operation of the human mind. ToM operations and mental time travel functions (memories of past experiences and imagined future experiences are embedded in present experiences and hence in one another) are operations and functions that involve fundamentally recursive principles and open up infinite possibilities for the mind, at least in principle. In this view, language is based on the recursive nature of ToM or, in a wider sense, on complex mental structures including ToM and recursive structures of mental travel time. Thus, recursive operations are not linguistic ones to begin with: rather, language was adapted to the recursive operation of the mind. The operative tool of recursion is attested in languages (but not to the same extent in all human languages): they are used by language wherever they are “needed,” but it is not a specific property of language itself. Corballis (<a href=\"#B12\">2011</a>) refers to Grice (<a href=\"#B27\">1975</a>, <a href=\"#B28\">1989</a>)'s theory that it is an essential feature of language (use) that is requires that the speaker should have the intention to change the beliefs in the listener's mind, carried out by making the listener aware of that intention. The interpretation of linguistic statements is based on inferences rather than on explicit decoding. Note that—granted that ToM recursion is crucial for language—in cases where a person has deficits or limitations in his/her ToM operations, we are to expect limitations in his/her linguistic behavior, too, as witnessed by cases of autism (Luyster et al., <a href=\"#B42\">2008</a>).</p>\n<p>Considering the neural basis of recursion, Friederici et al. (<a href=\"#B22\">2011</a>) assumed two different computational systems dealing with hierarchical structures: one determined by the cognitive control for complex sequences in non-language domains, and another one (confined to Broca's area) which is able to process hierarchically structured recursive sequences of artificial and natural grammars. The first computational system is less automatic; the second computational system is highly automatic.</p>\n<p>Zimmerer and Varley (<a href=\"#B70\">2010</a>) presented a case study in which syntactic-structural recursion was not available for an agrammatic aphasic participant but his mathematical skills and ToM inferences were unimpaired. Recursive thinking in non-linguistic cognitive domains can be unimpaired in agrammatic aphasia. Siegal and Varley (<a href=\"#B56\">2006</a>) and Apperly et al. (<a href=\"#B4\">2006</a>) found intact second order ToM reasoning in severe agrammatism.</p>\n<p>On the other hand, with respect to AD, a number of papers discussed deficits of ToM abilities. For instance, Fernandez-Duquet et al. (<a href=\"#B17\">2008</a>) found that AD persons and persons exhibiting the behavioral variant of fronto-temporal dementia (bFTD) faced similar difficulties in second order false belief tasks (while in other respects they differed from one another). Freedman et al. (<a href=\"#B21\">2013</a>) demonstrated significant ToM deficit in false belief tests and in visual perspective taking. According to a systematic review by Sandoz et al. (<a href=\"#B52\">2014</a>), the deficit shows up more markedly in complex ToM tasks like second-order false belief tasks, not independently of changes of ToM reasoning and other cognitive processes in old age. Moreau et al. (<a href=\"#B45\">2015</a>) demonstrated the presence of ToM deficit in AD persons in tasks requiring realistic communicative interaction, too. Other researchers (e.g., Choong and Doody, <a href=\"#B9\">2013</a>) did not find ToM deficit in AD.</p>\n<p><strong>1.2</strong>. The title of the present paper refers to the fact that our case studies in syntax and ToM are concerned with recursive <strong><em>sub</em></strong>systems, not all types of linguistic recursion. We focus on the effect of linguistic limitations in aphasia or Alzheimer's disease (AD) on syntactic recursion as it appears in the embedding of sentences. Of course, syntactic recursion has other instances, too, like the unbounded merge of DPs; and linguistic recursion has other, quite different aspects as well, like the recursion appearing in the hierarchy of prosodic phrases representing syntactic information (cf. Ladd, <a href=\"#B40\">1986</a>; Selkirk, <a href=\"#B55\">2009</a>; Wagner, <a href=\"#B64\">2010</a>). Schreuder et al. (<a href=\"#B54\">2009</a>) presented an experiment that revealed: edge-marking processes, such as early pitch accent placement (stress shift), are applied recursively to phonological phrases that are embedded in another phonological phrase. Recursive rules were found in phonotactic structures. According to Hulst (<a href=\"#B32\">2010a</a>), “phonotactic structure displays considerable recursion firstly at the syllable/foot level and, secondly at the word and phrase level” (p. 335). In an event-related brain potential (ERP) study, Honbolygó et al. (<a href=\"#B31\">2016</a",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>The relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The expected answers typically involved subordinate clauses introduced by conjunctions or direct quotations of the characters' utterances. Broca's aphasics did not produce answers with recursive sentence embedding. Rather, they projected themselves into the characters' mental states and gave direct answers in the first person singular, with relevant ToM content. We call such replies “situative statements.” Where the question concerned the mental state of the character but did not require an answer with sentence embedding (“What does X hate?”), aphasics gave descriptive answers rather than situative statements. Most replies given by persons with AD to Type 4 questions were grammatical instances of recursive sentence embedding. They also gave a few situative statements but the ToM content of these was irrelevant. In more than one third of their well-formed sentence embeddings, too, they conveyed irrelevant ToM contents. Persons with moderate AD were unable to pass secondary false belief tests. The results reveal double dissociation: Broca's aphasics are unable to access recursive sentence embedding but they can make appropriate ToM inferences; moderate AD persons make the wrong ToM inferences but they are able to access recursive sentence embedding. The double dissociation may be relevant for the nature of the relationship between the two recursive capacities. Broca's aphasics compensated for the lack of recursive sentence embedding by recursive ToM reasoning represented in very simple syntactic forms: they used one recursive subsystem to stand in for another recursive subsystem.</p>\n<section><p><strong>Keywords:</strong> recursive sentence embedding, theory of mind, Broca's aphasia, Alzheimer's disease, compensatory strategy</p></section></section><section><h2>1. Introduction</h2>\n<p><strong>1.1</strong>. Most linguists use a kind of inductive definition of recursion (Tomalin, <a href=\"#B61\">2007</a>; Hulst, <a href=\"#B33\">2010b</a>): they define it as the embedding of a constituent in a constituent of the same type in linguistic expressions. Recursion builds complex structures by increasing embedding depth whereas simple iteration yields output structures which do not increase depth (cf. Karlsson, <a href=\"#B36\">2010</a>). Watumull et al. (<a href=\"#B66\">2014</a>) criticize the concept of recursion as articulated in linguistic analysis; they point out that “syntactic embedding is a sufficient, though not necessary, diagnostic of recursion” (p. 1). In the interpretation of our data we will extend the concept of recursion beyond linguistic syntax to the recursive logic of theory-of-mind (ToM) reasoning.</p>\n<p>One initial question of our research concerned the particular source of the human faculty of recursion. It is a debated issue whether recursivity, seen as a specific feature of human languageand mind, is a syntactic phenomenon: certain constituents can have the same types of constituents embedded in them, and this operation can be repeatedpotentially unbounded (cf. Hauser et al., <a href=\"#B29\">2002</a>; Fitch et al., <a href=\"#B19\">2005</a>; Rizzi, <a href=\"#B50\">2012</a>), or the source of recursion is semantics or pragmatics: complex propositions can be expressed recursively in human languages (cf. Evans and Levinson, <a href=\"#B15\">2009</a>; Everett, <a href=\"#B16\">2009</a>), or else recursion is found in general capacities of the human mind (Jackendoff and Pinker, <a href=\"#B35\">2005</a>; Pinker and Jackendoff, <a href=\"#B49\">2006</a>).</p>\n<p>It is also a debated issue what the relationship of those competing alternatives might be. Watumull et al. (<a href=\"#B66\">2014</a>) argue that recursion is a fundamental linguistic universal. Regarding language (in the wake of Chomsky, <a href=\"#B8\">1986</a>) as I-language, they define it as an intensional function that is a mental object, an internal function of all human brains/minds. One of its fundamental features is recursion, i.e., that it may generate infinite sets. They also assign three formal criteria to the capacity of recursion: “the computability of rules generative of non-arbitrary sets; definition by induction enabling the strong generation of increasingly structured expressions; and mathematical induction for the principled (and potentially unbounded) expansion of the generated sets of structures” (p. 6).</p>\n<p>Corballis (<a href=\"#B12\">2011</a>, <a href=\"#B11\">2014</a>) argues in favor of the primacy of the recursive operation of the human mind. ToM operations and mental time travel functions (memories of past experiences and imagined future experiences are embedded in present experiences and hence in one another) are operations and functions that involve fundamentally recursive principles and open up infinite possibilities for the mind, at least in principle. In this view, language is based on the recursive nature of ToM or, in a wider sense, on complex mental structures including ToM and recursive structures of mental travel time. Thus, recursive operations are not linguistic ones to begin with: rather, language was adapted to the recursive operation of the mind. The operative tool of recursion is attested in languages (but not to the same extent in all human languages): they are used by language wherever they are “needed,” but it is not a specific property of language itself. Corballis (<a href=\"#B12\">2011</a>) refers to Grice (<a href=\"#B27\">1975</a>, <a href=\"#B28\">1989</a>)'s theory that it is an essential feature of language (use) that is requires that the speaker should have the intention to change the beliefs in the listener's mind, carried out by making the listener aware of that intention. The interpretation of linguistic statements is based on inferences rather than on explicit decoding. Note that—granted that ToM recursion is crucial for language—in cases where a person has deficits or limitations in his/her ToM operations, we are to expect limitations in his/her linguistic behavior, too, as witnessed by cases of autism (Luyster et al., <a href=\"#B42\">2008</a>).</p>\n<p>Considering the neural basis of recursion, Friederici et al. (<a href=\"#B22\">2011</a>) assumed two different computational systems dealing with hierarchical structures: one determined by the cognitive control for complex sequences in non-language domains, and another one (confined to Broca's area) which is able to process hierarchically structured recursive sequences of artificial and natural grammars. The first computational system is less automatic; the second computational system is highly automatic.</p>\n<p>Zimmerer and Varley (<a href=\"#B70\">2010</a>) presented a case study in which syntactic-structural recursion was not available for an agrammatic aphasic participant but his mathematical skills and ToM inferences were unimpaired. Recursive thinking in non-linguistic cognitive domains can be unimpaired in agrammatic aphasia. Siegal and Varley (<a href=\"#B56\">2006</a>) and Apperly et al. (<a href=\"#B4\">2006</a>) found intact second order ToM reasoning in severe agrammatism.</p>\n<p>On the other hand, with respect to AD, a number of papers discussed deficits of ToM abilities. For instance, Fernandez-Duquet et al. (<a href=\"#B17\">2008</a>) found that AD persons and persons exhibiting the behavioral variant of fronto-temporal dementia (bFTD) faced similar difficulties in second order false belief tasks (while in other respects they differed from one another). Freedman et al. (<a href=\"#B21\">2013</a>) demonstrated significant ToM deficit in false belief tests and in visual perspective taking. According to a systematic review by Sandoz et al. (<a href=\"#B52\">2014</a>), the deficit shows up more markedly in complex ToM tasks like second-order false belief tasks, not independently of changes of ToM reasoning and other cognitive processes in old age. Moreau et al. (<a href=\"#B45\">2015</a>) demonstrated the presence of ToM deficit in AD persons in tasks requiring realistic communicative interaction, too. Other researchers (e.g., Choong and Doody, <a href=\"#B9\">2013</a>) did not find ToM deficit in AD.</p>\n<p><strong>1.2</strong>. The title of the present paper refers to the fact that our case studies in syntax and ToM are concerned with recursive <strong><em>sub</em></strong>systems, not all types of linguistic recursion. We focus on the effect of linguistic limitations in aphasia or Alzheimer's disease (AD) on syntactic recursion as it appears in the embedding of sentences. Of course, syntactic recursion has other instances, too, like the unbounded merge of DPs; and linguistic recursion has other, quite different aspects as well, like the recursion appearing in the hierarchy of prosodic phrases representing syntactic information (cf. Ladd, <a href=\"#B40\">1986</a>; Selkirk, <a href=\"#B55\">2009</a>; Wagner, <a href=\"#B64\">2010</a>). Schreuder et al. (<a href=\"#B54\">2009</a>) presented an experiment that revealed: edge-marking processes, such as early pitch accent placement (stress shift), are applied recursively to phonological phrases that are embedded in another phonological phrase. Recursive rules were found in phonotactic structures. According to Hulst (<a href=\"#B32\">2010a</a>), “phonotactic structure displays considerable recursion firstly at the syllable/foot level and, secondly at the word and phrase level” (p. 335). In an event-related brain potential (ERP) study, Honbolygó et al. (<a href=\"#B31\">2016</a",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractThe relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The ex",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractThe relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The ex",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractThe relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The ex",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractThe relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The ex",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractThe relationship between recursive sentence embedding and theory-of-mind (ToM) inference is investigated in three persons with Broca's aphasia, two persons with Wernicke's aphasia, and six persons with mild and moderate Alzheimer's disease (AD). We asked questions of four types about photographs of various real-life situations. Type 4 questions asked participants about intentions, thoughts, or utterances of the characters in the pictures (“What may X be thinking/asking Y to do?”). The ex",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:recursive sentence embedding, theory of mind, Broca's aphasia, Alzheimer's disease, compensatory strategy",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. Introduction1.1. Most linguists use a kind of inductive definition of recursion (Tomalin,2007; Hulst,2010b): they define it as the embedding of a constituent in a constituent of the same type in linguistic expressions. Recursion builds complex structures by increasing embedding depth whereas simple iteration yields output structures which do not increase depth (cf. Karlsson,2010). Watumull et al. (2014) criticize the concept of recursion as articulated in linguistic analysis; they point out t",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "1. Introduction",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "http://www.tlainc.com/articl12.htm",
      "title": "",
      "author": "PETER A C SMITH",
      "published_date": "2023-02-06T11:12:31.000Z",
      "content": {
        "text": "<div>\n<address>\nJournal of Knowledge Management Practice, August 1999\n</address>\n<h3><strong>A Viable System Model:</strong></h3>\n<h3><strong>Consideration of Knowledge Management</strong></h3>\n<h5><strong>Allenna Leonard, PhD, The Complementary Set\n</strong></h5>\n<hr />\n<p>\nABSTRACT:\n</p><p>\nContends that individual and organizational knowledge is difficult\nto value and therefore difficult to manage. Looks at the management\nof knowledge from the perspective of the individual, the network\nand the organization using Stafford Beer's Viable System Model,\na powerful descriptive and diagnostic tool to map management capacities\nand promote viability.</p><hr />\n<p>\n<strong>Introduction</strong>\n</p><p>\nIndividuals who are knowledge workers in a knowledge economy may\nfind themselves, at different times and sometimes simultaneously,\nself-employed, working in an ad hoc network, or earning a salary\nwith an organization. To be successful, they need to have a sense\nof how different aspects of knowledge management fit together\nas they guide their own career paths and find ways to add value\nto ad hoc and formal organizations.\n</p><p>\nIn Western countries, an increasing proportion of the workforce\nis employed for their knowledge. That knowledge is for the most\npart up to individuals to acquire and maintain, and it is largely\nportable. It may be of content or process, tacit or explicit,\ngeneral or particular, linear or relational, timeless or up to\nthe minute. It is utilized by individuals working alone and in\nsmall groups or large organizations. Especially in the private\nsector, many knowledge workers are self-employed or members of\nad hoc virtual or network organizations rather than permanent\nsalaried employees.\n</p><p>\nThe knowledge marketplace is not always a comfortable place for\nthe individuals involved. They may suffer the disadvantages of\ninsecurity and cost absorption which have traditionally been associated\nwith the secondary labor market. The short term arrangements common\ntoday effect individuals differently. The same circumstances that\nprovide flexibility and adventure for the young single professional\nmay be highly stressful for someone with a family and a mortgage.\nThese are important considerations: not only for the more independent\nknowledge worker, but also for the large and small organizations\nwho outsource functions and contract for specialized talent and\nthe networks which provide it. At a minimum, temporary and contract\nworkers must have opportunities to keep their skills up to date\nto avoid depletion of the talent pool. If organizations are not\noffering the security of long term employment, other provisions\nmust be made which do not simply download the costs of knowledge\nmaintenance to those individuals least able to afford it.\n</p><p>\n<strong>The Value of Knowledge and Intellectual Capital</strong>\n</p><p>\nThe value of an individual's knowledge and intellectual capital\nis difficult to measure because it is usually time and context\nspecific. Individuals can and often do take a long term view.\nSome choices, like taking a liberal arts degree, may depress short\nterm earnings but be beneficial in the long run. Others, like\npursuing knowledge out of curiosity or for pleasure are their\nown reward although sometimes they also result in monetary gain.\nIn addition, some knowledge isn't of measurable external value,\nlike knowing how to keep emotionally and physically fit, but it\nmakes whatever a person does more effective. It bears consideration\nin these days of short term work and talent banks for individuals\nto assume conscious management of their personal intellectual\nassets. At the very least, individuals marketing themselves must\nknow what they are selling to get a fair price and be able to\nassess the strengths they bring to a networked group.\n</p><p>\nNetworks create value from a combination of content and people\nknowledge. They vary widely in the strength and permanence of\ntheir connections and the resources necessary to maintain them.\nSome have very informal structures and almost no independent assets.\nOthers do nearly the same work as formal organizations but operate\nwithout more than one or two full time employees or big offices.\nMost are characterized by heavy reliance on electronic communication.\nThe value of their intellectual capital is contingent on the match\nbetween the resources they can call upon and the needs of the\nmarketplace.*\n</p><p>\n[*For the purposes of this paper, I'll assume that the network\norganization described is closer to the ad hoc project group than\nto the 'formal organization in all but real estate'. Skunkworks\nand temporary teams in large organizations often operate as networks\nand may share many of the same characteristics - including an\nabsence of independent assets.]\n</p><p>\nEstimating the value of organization's knowledge and intellectual\ncapital is not straightforward either. Some can account for substantial\nassets in the form of documented intellectual property such as\npatents, trademarks and copyrights, which can be legally protected.\nFor others, their knowledge assets are in people, processes, infrastructure,\ncustomer knowledge and culture. Although some describe the value\nof an organization's intellectual capital in terms of the difference\nbetween book and market value - that assessment is necessarily\nan aggregate and provides little guidance on its management. Depending\non the business environment, the values of long term investments\nand potential liabilities may not be apparent. Nor does the presence\nor absence of general strengths such as strong shared internal\nvalues necessarily make a difference until the organization hits\na turbulent patch.\n</p><p>\n<strong>Integrating and Managing Knowledge</strong>\n</p><p>\nFor most individuals, integrating and managing the knowledge and\ninformation needed to perform effectively is a challenge. You\nmust learn to manage yourself and your formal and informal exchanges\nand interactions with others. This must be done in the context\nof your understanding of who you are: your goals, your capabilities,\nyour knowledge of your own strengths and weaknesses; and your\nappreciation of your social, technical and business environments.\nIndividuals must be able to engage in activities in different\n'markets', keep them from interfering with each other, manage\nthem together, focus an eye on the future, and assess their different\naspects from the perspective of the 'big picture' of their whole\nlife's narrative.\n</p><p>\nNetworks and organizations also have the challenge of maintaining\ncontinuity and identity over time - sometimes with minimal infrastructure.\nThey too must integrate and manage their knowledge and information\nand their exchanges with their environments to perform effectively.\nContinued viability depends on it.\n</p><p>\n<strong>The Viable System Model</strong>\n</p><p>\nThis paper looks at the management of knowledge from the perspective\nof the individual, the network and the organization using Stafford\nBeer's Viable System Model. The VSM is a powerful descriptive\nand diagnostic tool to map management capacities to promote viability.\n</p><p>\nManagement cybernetician Stafford Beer (1979, 81, 85) spent many\nyears researching the necessary and sufficient conditions for\na complex system to be viable. He determined that viability was\nmaintained by engaging in different activities, keeping them from\ninterfering with each other, managing them together, focusing\non the future and doing so in the context of an identity within\nwhich the interests of the whole over time could be considered.\nThis is how the human nervous system works, and how successful\ncollective enterprises work too. Many applications of the VSM\nhave been undertaken, by Beer and others, in business, government,\nnon-profit organizations and non-organizational systems. (Espejo\nand Harnden, 1985)\n</p><p>\nThe VSM labels these management functions Systems One through\nFive, and they are repeated at different levels: the individual,\nthe work group, and on to each successive category as long as\nit remains relevant. The only criterion is that the System One\nunits must which these management functions support must produce\nsomething of value for the environment such that it could be,\nin its own right, a viable system.\n</p><p>\nThe VSM has been used to both diagnose existing organizational\nstructures and to design new ones. It also provides a useful template\nagainst which to consider alternative structures and new challenges\nthe system is facing, like integrating its internal and its external\nknowledge or monitoring the evolution of its identity in a changing\nmarket.\n</p><p>\n<strong>Recursion</strong>\n</p><p>\nThe repetition of the same patterns and relationships at different\nlevels or scales is called recursion. It enables the same functions\nto be mapped up and down and compared for appropriate matches\nof attention, consistency and completeness. From the perspective\nof any particular level, it is possible to look up a level or\ndown a level to see which information is key. Both individuals\nand organizations will be part of a number of systems at higher\nlevels of recursion. Recursive levels of networks are fuzzier\nbut may still be explored. Local networks are often part of national\nor international communities; networks which occupy market niches\nare embedded in larger market segments; and clusters of users\nof a specific technology may be linked to more generic user groups.\n</p><p>\n</p><h3>Figure One</h3>\n<h3>A circle with radiating demarcated rays</h3>\n<p>\nSome recursive relationships, like government jurisdictions are\nneatly nested like a set of Russian dolls. Others, like coalitions\nor work teams have fluctuating boundaries. In each case, an identity\nis assumed which accepts some restraints on its autonomy in the\ninterests of fitting into the larger system. Each also harmonizes\nthe associated information and criteria of its different memberships\n- with more or less success.\n</p><p>\nPeople in an",
        "html": "<div>\n<address>\nJournal of Knowledge Management Practice, August 1999\n</address>\n<h3><strong>A Viable System Model:</strong></h3>\n<h3><strong>Consideration of Knowledge Management</strong></h3>\n<h5><strong>Allenna Leonard, PhD, The Complementary Set\n</strong></h5>\n<hr />\n<p>\nABSTRACT:\n</p><p>\nContends that individual and organizational knowledge is difficult\nto value and therefore difficult to manage. Looks at the management\nof knowledge from the perspective of the individual, the network\nand the organization using Stafford Beer's Viable System Model,\na powerful descriptive and diagnostic tool to map management capacities\nand promote viability.</p><hr />\n<p>\n<strong>Introduction</strong>\n</p><p>\nIndividuals who are knowledge workers in a knowledge economy may\nfind themselves, at different times and sometimes simultaneously,\nself-employed, working in an ad hoc network, or earning a salary\nwith an organization. To be successful, they need to have a sense\nof how different aspects of knowledge management fit together\nas they guide their own career paths and find ways to add value\nto ad hoc and formal organizations.\n</p><p>\nIn Western countries, an increasing proportion of the workforce\nis employed for their knowledge. That knowledge is for the most\npart up to individuals to acquire and maintain, and it is largely\nportable. It may be of content or process, tacit or explicit,\ngeneral or particular, linear or relational, timeless or up to\nthe minute. It is utilized by individuals working alone and in\nsmall groups or large organizations. Especially in the private\nsector, many knowledge workers are self-employed or members of\nad hoc virtual or network organizations rather than permanent\nsalaried employees.\n</p><p>\nThe knowledge marketplace is not always a comfortable place for\nthe individuals involved. They may suffer the disadvantages of\ninsecurity and cost absorption which have traditionally been associated\nwith the secondary labor market. The short term arrangements common\ntoday effect individuals differently. The same circumstances that\nprovide flexibility and adventure for the young single professional\nmay be highly stressful for someone with a family and a mortgage.\nThese are important considerations: not only for the more independent\nknowledge worker, but also for the large and small organizations\nwho outsource functions and contract for specialized talent and\nthe networks which provide it. At a minimum, temporary and contract\nworkers must have opportunities to keep their skills up to date\nto avoid depletion of the talent pool. If organizations are not\noffering the security of long term employment, other provisions\nmust be made which do not simply download the costs of knowledge\nmaintenance to those individuals least able to afford it.\n</p><p>\n<strong>The Value of Knowledge and Intellectual Capital</strong>\n</p><p>\nThe value of an individual's knowledge and intellectual capital\nis difficult to measure because it is usually time and context\nspecific. Individuals can and often do take a long term view.\nSome choices, like taking a liberal arts degree, may depress short\nterm earnings but be beneficial in the long run. Others, like\npursuing knowledge out of curiosity or for pleasure are their\nown reward although sometimes they also result in monetary gain.\nIn addition, some knowledge isn't of measurable external value,\nlike knowing how to keep emotionally and physically fit, but it\nmakes whatever a person does more effective. It bears consideration\nin these days of short term work and talent banks for individuals\nto assume conscious management of their personal intellectual\nassets. At the very least, individuals marketing themselves must\nknow what they are selling to get a fair price and be able to\nassess the strengths they bring to a networked group.\n</p><p>\nNetworks create value from a combination of content and people\nknowledge. They vary widely in the strength and permanence of\ntheir connections and the resources necessary to maintain them.\nSome have very informal structures and almost no independent assets.\nOthers do nearly the same work as formal organizations but operate\nwithout more than one or two full time employees or big offices.\nMost are characterized by heavy reliance on electronic communication.\nThe value of their intellectual capital is contingent on the match\nbetween the resources they can call upon and the needs of the\nmarketplace.*\n</p><p>\n[*For the purposes of this paper, I'll assume that the network\norganization described is closer to the ad hoc project group than\nto the 'formal organization in all but real estate'. Skunkworks\nand temporary teams in large organizations often operate as networks\nand may share many of the same characteristics - including an\nabsence of independent assets.]\n</p><p>\nEstimating the value of organization's knowledge and intellectual\ncapital is not straightforward either. Some can account for substantial\nassets in the form of documented intellectual property such as\npatents, trademarks and copyrights, which can be legally protected.\nFor others, their knowledge assets are in people, processes, infrastructure,\ncustomer knowledge and culture. Although some describe the value\nof an organization's intellectual capital in terms of the difference\nbetween book and market value - that assessment is necessarily\nan aggregate and provides little guidance on its management. Depending\non the business environment, the values of long term investments\nand potential liabilities may not be apparent. Nor does the presence\nor absence of general strengths such as strong shared internal\nvalues necessarily make a difference until the organization hits\na turbulent patch.\n</p><p>\n<strong>Integrating and Managing Knowledge</strong>\n</p><p>\nFor most individuals, integrating and managing the knowledge and\ninformation needed to perform effectively is a challenge. You\nmust learn to manage yourself and your formal and informal exchanges\nand interactions with others. This must be done in the context\nof your understanding of who you are: your goals, your capabilities,\nyour knowledge of your own strengths and weaknesses; and your\nappreciation of your social, technical and business environments.\nIndividuals must be able to engage in activities in different\n'markets', keep them from interfering with each other, manage\nthem together, focus an eye on the future, and assess their different\naspects from the perspective of the 'big picture' of their whole\nlife's narrative.\n</p><p>\nNetworks and organizations also have the challenge of maintaining\ncontinuity and identity over time - sometimes with minimal infrastructure.\nThey too must integrate and manage their knowledge and information\nand their exchanges with their environments to perform effectively.\nContinued viability depends on it.\n</p><p>\n<strong>The Viable System Model</strong>\n</p><p>\nThis paper looks at the management of knowledge from the perspective\nof the individual, the network and the organization using Stafford\nBeer's Viable System Model. The VSM is a powerful descriptive\nand diagnostic tool to map management capacities to promote viability.\n</p><p>\nManagement cybernetician Stafford Beer (1979, 81, 85) spent many\nyears researching the necessary and sufficient conditions for\na complex system to be viable. He determined that viability was\nmaintained by engaging in different activities, keeping them from\ninterfering with each other, managing them together, focusing\non the future and doing so in the context of an identity within\nwhich the interests of the whole over time could be considered.\nThis is how the human nervous system works, and how successful\ncollective enterprises work too. Many applications of the VSM\nhave been undertaken, by Beer and others, in business, government,\nnon-profit organizations and non-organizational systems. (Espejo\nand Harnden, 1985)\n</p><p>\nThe VSM labels these management functions Systems One through\nFive, and they are repeated at different levels: the individual,\nthe work group, and on to each successive category as long as\nit remains relevant. The only criterion is that the System One\nunits must which these management functions support must produce\nsomething of value for the environment such that it could be,\nin its own right, a viable system.\n</p><p>\nThe VSM has been used to both diagnose existing organizational\nstructures and to design new ones. It also provides a useful template\nagainst which to consider alternative structures and new challenges\nthe system is facing, like integrating its internal and its external\nknowledge or monitoring the evolution of its identity in a changing\nmarket.\n</p><p>\n<strong>Recursion</strong>\n</p><p>\nThe repetition of the same patterns and relationships at different\nlevels or scales is called recursion. It enables the same functions\nto be mapped up and down and compared for appropriate matches\nof attention, consistency and completeness. From the perspective\nof any particular level, it is possible to look up a level or\ndown a level to see which information is key. Both individuals\nand organizations will be part of a number of systems at higher\nlevels of recursion. Recursive levels of networks are fuzzier\nbut may still be explored. Local networks are often part of national\nor international communities; networks which occupy market niches\nare embedded in larger market segments; and clusters of users\nof a specific technology may be linked to more generic user groups.\n</p><p>\n</p><h3>Figure One</h3>\n<h3>A circle with radiating demarcated rays</h3>\n<p>\nSome recursive relationships, like government jurisdictions are\nneatly nested like a set of Russian dolls. Others, like coalitions\nor work teams have fluctuating boundaries. In each case, an identity\nis assumed which accepts some restraints on its autonomy in the\ninterests of fitting into the larger system. Each also harmonizes\nthe associated information and criteria of its different memberships\n- with more or less success.\n</p><p>\nPeople in an",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Journal of Knowledge Management Practice, August 1999A Viable System Model:Consideration of Knowledge ManagementAllenna Leonard, PhD, The Complementary SetABSTRACT:Contends that individual and organizational knowledge is difficult\nto value and therefore difficult to manage. Looks at the management\nof knowledge from the perspective of the individual, the network\nand the organization using Stafford Beer's Viable System Model,\na powerful descriptive and diagnostic tool to map management capacities\n",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "A Viable System Model:",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Consideration of Knowledge Management",
              "id": ""
            },
            {
              "level": "h5",
              "text": "Allenna Leonard, PhD, The Complementary Set",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Figure One",
              "id": ""
            },
            {
              "level": "h3",
              "text": "A circle with radiating demarcated rays",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC8432276/",
      "title": "Transcription and Qualitative Methods: Implications for Third Sector Research",
      "author": "",
      "published_date": "2021-09-10T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>While there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcription in qualitative research articles.</p>\n<section><p><strong>Keywords:</strong> Qualitative methods, Transcription</p></section></section><section><h2>Introduction</h2>\n<p>The field of third sector studies is inherently interdisciplinary, with studies from political science, management, sociology and social work, among others. Within the field of research, a large percentage (between 40–80%) of studies employ qualitative methods such as interviews, focus groups and ethnographic observations (von Schnurbein et al., <a href=\"#CR31\">2018</a>). In order to ensure rigor, qualitative researchers devote considerable time to developing interview guides, consent forms and coding frameworks. While there is a vast literature that considers the <em>collection</em> and the <em>analysis</em> of qualitative data, there has been comparatively limited attention paid to audio transcription, which is the conversion of recorded audio material into a written form that can be analyzed. Despite advances made in qualitative methodologies and increasing attention to positionality, subjectivity and reliability in qualitative data analysis, the transcription of interviews and focus groups is often presented uncritically as a direct conversion of recorded audio to text. As technology to facilitate transcription improves, many researchers have shifted to using voice-to-text software and companies that employ AI rather than human transcription. These technological advances in transcription, along with shifts in the way that research is undertaken (for example, increasingly via video conferencing as a result of the COVID-19 pandemic), mean that the need to critically reflect upon the place of transcription in third sector research is more urgent.</p>\n<p>In this article, I explore the place of transcription in qualitative research, with a focus on the importance of this process for third sector researchers. The article is structured as follows. First, I review the qualitative methods literature on audio transcription and the key themes that arise. Next, I report on a review undertaken of recent qualitative research articles in Voluntas and the way that authors discuss transcription in these articles. Finally, I propose a framework for qualitative third sector researchers to include transcription as part of their research design and elements to consider in including descriptions of the transcription process in writing up qualitative research.</p></section><section><h2>Audio Transcription: What We Know</h2>\n<p>At a basic level, transcription refers to the transformation of recorded audio (usually spoken word) into a written form that can be used to analyze a particular phenomenon or event (Duranti, <a href=\"#CR8\">2006</a>). For many qualitative researchers, transcription has become a fairly taken-for-granted aspect of the research process. In this section, I review the methods literature on the process of audio (and video) transcription as part of qualitative research on the third sector, focusing on three key areas—how transcription is undertaken, epistemological and ethical considerations, and the role of technology.</p>\n<section><h3>Qualitative research and transcription</h3>\n<p>While quantitative research seeks to explain, generalize and predict patterns through the analysis of variables, qualitative research questions are more interested in understanding and interpreting the socially constructed world around us (Bryman, <a href=\"#CR3\">2016</a>). This means that data are collected through documents, observation and interviews, and the latter are often recorded in order to analyze these as documents. For third sector research, recordings are most commonly made of interviews and focus groups, but may also be of meetings, events and other activities to ensure that researchers do not have to rely on their power of recall or scribbled notes.</p>\n<p>Transcription is a notoriously time-consuming and often tedious task which can take between three hours and over eight hours to transcribe one hour of audio, depending on typing speed. Transcription is not, however, a mechanical process where the written document becomes an objective record of the event—indeed, written text varies from the spoken word in terms of syntax, word choice and accepted grammar (Davidson, <a href=\"#CR6\">2009</a>). The transcriber therefore has to make subjective decisions throughout about what to include (or not), whether to correct mistakes and edit grammar and repetitions. This has been described as a spectrum between “naturalized” transcription (or “intelligent verbatim”) which adapts the oral to written norms, and “denaturalized” transcription (“full verbatim”), where everything is left in, including utterances, mistakes, repetitions and all grammatical errors (Bucholtz, <a href=\"#CR4\">2000</a>).</p>\n<p>While some contend that denaturalized transcription is more ‘accurate’, the same can equally be argued for naturalized, as it allows the transcriber to omit occasions when, for instance, an individual mis-speaks and corrects themselves, thereby allowing the transcriber to record closer to what was intended and how the interviewee might have portrayed themselves in a written form. As Lapadat (<a href=\"#CR14\">2000</a>, p. 206) explains, “Spoken language is structured and accomplished differently than written text, so when talk is re-presented as written text, it is not surprising that readers draw on their knowledge of written language to evaluate it.” Other nonverbal cues, such as laughter, tone of voice (e.g. sarcasm, frustration, emphasis) and the use or omission of punctuation, can also drastically alter the meaning or intention of what an individual says. In addition, the transcriber must make decisions about how much contextual information to include, such as interruptions, crosstalk and inaudible segments (Lapadat, <a href=\"#CR14\">2000</a>). Because of the range of types of research that employ qualitative methods, there is no single set of rules for transcription but rather these decisions must be based on the research questions and approach.</p></section><section><h3>Epistemological and Ethical Considerations</h3>\n<p>Because the researcher (or external transcriber) must make these decisions as they translate audio into written text, transcription is an inherently interpretative and political act, influenced by the transcriber’s own assumptions and biases (Jaffe, <a href=\"#CR12\">2007</a>). Every choice that the transcriber makes therefore shapes how the research participant is portrayed and determines what knowledge or information is relevant and valuable and what is not. Indeed, two transcribers may hear differently and select relevant spoken material differently (Stelma &amp; Cameron, <a href=\"#CR28\">2007</a>). As Davidson (<a href=\"#CR6\">2009</a>) notes (and as I explore in further detail in the next section), despite being a highly interpretive process, transcription is frequently depicted using positivist norms of knowledge creation.</p>\n<p>Transcription also involves potential ethical considerations and dilemmas. When working with disadvantaged communities, deciding how to depict research participants in written text can highlight the challenges of ethical representation. As Kvale (<a href=\"#CR13\">1996</a>, pp. 172–3) notes, “Be mindful that the publication of incoherent and repetitive verbatim interview transcripts may involve an unethical stigmatization of specific persons or groups of people”. Oliver et al. (<a href=\"#CR23\">2005</a>) similarly demonstrate how transcribers must make decisions about how to represent participants’ use of slang, colloquialisms and accents in ways that are accurate but also respectful of the respondent’s intended meaning. Some researchers decide to send finished transcriptions to interviewees for approval in order to honor commitments to fully informed consent, to ensure transcription accuracy or in some cases as a means to address the balance of power between the researcher and interviewee. As Mero-Jaffe (<a href=\"#CR20\">2011</a>) describes, on the one hand, this may empower interviewees to control the way that they are portrayed in the research. On the other hand, Mero-Jaffe found that seeking transcript approval from interviewees sometimes increased their embarrassment at the way that their statements appear in text. This may be especially problematic with full verbatim transcriptions.</p></section><section><h3>Technology and Transcription</h3>\n<p>As technology improves and AI becomes increasingly able to create written text from recorded audio, researchers might ask—is human transcription even necessary? New options in Computer Assisted Qualitative Data Analysis Software (CAQDAS) such as NVivo, Atlas.ti and MAXQDA give qualitative researchers the option to forgo audio-to-text transcription altogether, and instead engage in live coding of audio or video files. Using this method, researchers first watch or listen to recordings to code for nonverbal cues, followed by a stage of note taking and coding based on pre-defined themes and matching these with time codes and nonverbal cues. Finally, researchers then transcribe specific quotes of interest from the recording (Parameswaran et al., <a href=\"#CR25\">2020</a>). This process may improve immersion in the data and allow researchers to account for dynamics that are often lost in complete audio-to-text transcriptio",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>While there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcription in qualitative research articles.</p>\n<section><p><strong>Keywords:</strong> Qualitative methods, Transcription</p></section></section><section><h2>Introduction</h2>\n<p>The field of third sector studies is inherently interdisciplinary, with studies from political science, management, sociology and social work, among others. Within the field of research, a large percentage (between 40–80%) of studies employ qualitative methods such as interviews, focus groups and ethnographic observations (von Schnurbein et al., <a href=\"#CR31\">2018</a>). In order to ensure rigor, qualitative researchers devote considerable time to developing interview guides, consent forms and coding frameworks. While there is a vast literature that considers the <em>collection</em> and the <em>analysis</em> of qualitative data, there has been comparatively limited attention paid to audio transcription, which is the conversion of recorded audio material into a written form that can be analyzed. Despite advances made in qualitative methodologies and increasing attention to positionality, subjectivity and reliability in qualitative data analysis, the transcription of interviews and focus groups is often presented uncritically as a direct conversion of recorded audio to text. As technology to facilitate transcription improves, many researchers have shifted to using voice-to-text software and companies that employ AI rather than human transcription. These technological advances in transcription, along with shifts in the way that research is undertaken (for example, increasingly via video conferencing as a result of the COVID-19 pandemic), mean that the need to critically reflect upon the place of transcription in third sector research is more urgent.</p>\n<p>In this article, I explore the place of transcription in qualitative research, with a focus on the importance of this process for third sector researchers. The article is structured as follows. First, I review the qualitative methods literature on audio transcription and the key themes that arise. Next, I report on a review undertaken of recent qualitative research articles in Voluntas and the way that authors discuss transcription in these articles. Finally, I propose a framework for qualitative third sector researchers to include transcription as part of their research design and elements to consider in including descriptions of the transcription process in writing up qualitative research.</p></section><section><h2>Audio Transcription: What We Know</h2>\n<p>At a basic level, transcription refers to the transformation of recorded audio (usually spoken word) into a written form that can be used to analyze a particular phenomenon or event (Duranti, <a href=\"#CR8\">2006</a>). For many qualitative researchers, transcription has become a fairly taken-for-granted aspect of the research process. In this section, I review the methods literature on the process of audio (and video) transcription as part of qualitative research on the third sector, focusing on three key areas—how transcription is undertaken, epistemological and ethical considerations, and the role of technology.</p>\n<section><h3>Qualitative research and transcription</h3>\n<p>While quantitative research seeks to explain, generalize and predict patterns through the analysis of variables, qualitative research questions are more interested in understanding and interpreting the socially constructed world around us (Bryman, <a href=\"#CR3\">2016</a>). This means that data are collected through documents, observation and interviews, and the latter are often recorded in order to analyze these as documents. For third sector research, recordings are most commonly made of interviews and focus groups, but may also be of meetings, events and other activities to ensure that researchers do not have to rely on their power of recall or scribbled notes.</p>\n<p>Transcription is a notoriously time-consuming and often tedious task which can take between three hours and over eight hours to transcribe one hour of audio, depending on typing speed. Transcription is not, however, a mechanical process where the written document becomes an objective record of the event—indeed, written text varies from the spoken word in terms of syntax, word choice and accepted grammar (Davidson, <a href=\"#CR6\">2009</a>). The transcriber therefore has to make subjective decisions throughout about what to include (or not), whether to correct mistakes and edit grammar and repetitions. This has been described as a spectrum between “naturalized” transcription (or “intelligent verbatim”) which adapts the oral to written norms, and “denaturalized” transcription (“full verbatim”), where everything is left in, including utterances, mistakes, repetitions and all grammatical errors (Bucholtz, <a href=\"#CR4\">2000</a>).</p>\n<p>While some contend that denaturalized transcription is more ‘accurate’, the same can equally be argued for naturalized, as it allows the transcriber to omit occasions when, for instance, an individual mis-speaks and corrects themselves, thereby allowing the transcriber to record closer to what was intended and how the interviewee might have portrayed themselves in a written form. As Lapadat (<a href=\"#CR14\">2000</a>, p. 206) explains, “Spoken language is structured and accomplished differently than written text, so when talk is re-presented as written text, it is not surprising that readers draw on their knowledge of written language to evaluate it.” Other nonverbal cues, such as laughter, tone of voice (e.g. sarcasm, frustration, emphasis) and the use or omission of punctuation, can also drastically alter the meaning or intention of what an individual says. In addition, the transcriber must make decisions about how much contextual information to include, such as interruptions, crosstalk and inaudible segments (Lapadat, <a href=\"#CR14\">2000</a>). Because of the range of types of research that employ qualitative methods, there is no single set of rules for transcription but rather these decisions must be based on the research questions and approach.</p></section><section><h3>Epistemological and Ethical Considerations</h3>\n<p>Because the researcher (or external transcriber) must make these decisions as they translate audio into written text, transcription is an inherently interpretative and political act, influenced by the transcriber’s own assumptions and biases (Jaffe, <a href=\"#CR12\">2007</a>). Every choice that the transcriber makes therefore shapes how the research participant is portrayed and determines what knowledge or information is relevant and valuable and what is not. Indeed, two transcribers may hear differently and select relevant spoken material differently (Stelma &amp; Cameron, <a href=\"#CR28\">2007</a>). As Davidson (<a href=\"#CR6\">2009</a>) notes (and as I explore in further detail in the next section), despite being a highly interpretive process, transcription is frequently depicted using positivist norms of knowledge creation.</p>\n<p>Transcription also involves potential ethical considerations and dilemmas. When working with disadvantaged communities, deciding how to depict research participants in written text can highlight the challenges of ethical representation. As Kvale (<a href=\"#CR13\">1996</a>, pp. 172–3) notes, “Be mindful that the publication of incoherent and repetitive verbatim interview transcripts may involve an unethical stigmatization of specific persons or groups of people”. Oliver et al. (<a href=\"#CR23\">2005</a>) similarly demonstrate how transcribers must make decisions about how to represent participants’ use of slang, colloquialisms and accents in ways that are accurate but also respectful of the respondent’s intended meaning. Some researchers decide to send finished transcriptions to interviewees for approval in order to honor commitments to fully informed consent, to ensure transcription accuracy or in some cases as a means to address the balance of power between the researcher and interviewee. As Mero-Jaffe (<a href=\"#CR20\">2011</a>) describes, on the one hand, this may empower interviewees to control the way that they are portrayed in the research. On the other hand, Mero-Jaffe found that seeking transcript approval from interviewees sometimes increased their embarrassment at the way that their statements appear in text. This may be especially problematic with full verbatim transcriptions.</p></section><section><h3>Technology and Transcription</h3>\n<p>As technology improves and AI becomes increasingly able to create written text from recorded audio, researchers might ask—is human transcription even necessary? New options in Computer Assisted Qualitative Data Analysis Software (CAQDAS) such as NVivo, Atlas.ti and MAXQDA give qualitative researchers the option to forgo audio-to-text transcription altogether, and instead engage in live coding of audio or video files. Using this method, researchers first watch or listen to recordings to code for nonverbal cues, followed by a stage of note taking and coding based on pre-defined themes and matching these with time codes and nonverbal cues. Finally, researchers then transcribe specific quotes of interest from the recording (Parameswaran et al., <a href=\"#CR25\">2020</a>). This process may improve immersion in the data and allow researchers to account for dynamics that are often lost in complete audio-to-text transcriptio",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractWhile there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcripti",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractWhile there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcripti",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractWhile there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcripti",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractWhile there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcripti",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractWhile there is a vast literature that considers the collection and analysis of qualitative data, there has been limited attention to audio transcription as part of this process. In this paper, I address this gap by discussing the main considerations, challenges and implications of audio transcription for qualitative research on the third sector. I present a framework for conducting audio transcription for researchers and transcribers, as well as recommendations for writing up transcripti",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:Qualitative methods, Transcription",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "IntroductionThe field of third sector studies is inherently interdisciplinary, with studies from political science, management, sociology and social work, among others. Within the field of research, a large percentage (between 40–80%) of studies employ qualitative methods such as interviews, focus groups and ethnographic observations (von Schnurbein et al.,2018). In order to ensure rigor, qualitative researchers devote considerable time to developing interview guides, consent forms and coding fr",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Audio Transcription: What We KnowAt a basic level, transcription refers to the transformation of recorded audio (usually spoken word) into a written form that can be used to analyze a particular phenomenon or event (Duranti,2006). For many qualitative researchers, transcription has become a fairly taken-for-granted aspect of the research process. In this section, I review the methods literature on the process of audio (and video) transcription as part of qualitative research on the third sector,",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Qualitative research and transcriptionWhile quantitative research seeks to explain, generalize and predict patterns through the analysis of variables, qualitative research questions are more interested in understanding and interpreting the socially constructed world around us (Bryman,2016). This means that data are collected through documents, observation and interviews, and the latter are often recorded in order to analyze these as documents. For third sector research, recordings are most commo",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Epistemological and Ethical ConsiderationsBecause the researcher (or external transcriber) must make these decisions as they translate audio into written text, transcription is an inherently interpretative and political act, influenced by the transcriber’s own assumptions and biases (Jaffe,2007). Every choice that the transcriber makes therefore shapes how the research participant is portrayed and determines what knowledge or information is relevant and valuable and what is not. Indeed, two tran",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Technology and TranscriptionAs technology improves and AI becomes increasingly able to create written text from recorded audio, researchers might ask—is human transcription even necessary? New options in Computer Assisted Qualitative Data Analysis Software (CAQDAS) such as NVivo, Atlas.ti and MAXQDA give qualitative researchers the option to forgo audio-to-text transcription altogether, and instead engage in live coding of audio or video files. Using this method, researchers first watch or liste",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Audio Transcription: What We Know",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Qualitative research and transcription",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Epistemological and Ethical Considerations",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Technology and Transcription",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7575679/",
      "title": "Toward understanding of evolutionary constraints: experimental and theoretical approaches",
      "author": "",
      "published_date": "2020-06-22T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Although organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints, which are based on the quantification of high-dimensional phenotypic and genotypic data. Furthermore, we present a theoretical analysis that enables us to predict evolutionary constraints on the basis of phenotypic fluctuation, modeled on the fluctuation–response relationship in statistical physics. The review lays emphasis on the tight interactions between experimental and theoretical analyses in evolutionary biology that will contribute to a better understanding of evolutionary constraints.</p>\n<section><p><strong>Keywords:</strong> Evolutionary constraints, Microbial laboratory evolution, Developmental hourglass model, Evolutionary fluctuation–response relationship</p></section></section><section><h2>Introduction</h2>\n<p>Although organisms have undergone remarkable diversification during evolution, it has not occurred in entirely random directions. Previous studies have shown unevenness and directionality in the evolutionary changes and phenotypic variations (Arnold <a href=\"#CR1\">1992</a>; Smith et al. <a href=\"#CR30\">1985</a>). For example, all vertebrates have a maximum of two pairs of limbs, and all insects have the same basic body plan (Urry et al. <a href=\"#CR35\">2016</a>). These limits of diversity have often been attributed to the limited potential for diversification or constraints on the production of variable phenotypes; however, the exact mechanism remains largely unclear.</p>\n<p>The theoretical approach, which is based on the concept of statistical physics, contributed significantly toward formulating the constraints, leading to tight collaborations between theoretical and experimental studies (Kaneko and Furusawa <a href=\"#CR19\">2018</a>; Sato et al. <a href=\"#CR27\">2003</a>). Technological innovations also enabled the quantitative analyses of high-dimensional phenotypic and genotypic data, allowing scientists to experimentally test the theoretical frameworks. The present review highlights the contribution of quantitative and theoretical analyses of evolutionary dynamics toward the understanding of its constraints. The three topics are presented below, including studies on bacterial evolution, animal development, and the fluctuation–response relationship in evolution. Here, we discuss a variety of biological targets since the purpose of this review article is to offer a general concept and theoretical framework toward the understanding of evolutionary constraints.</p></section><section><h2>Analysis of evolutionary constraints in bacterial laboratory evolution</h2>\n<p>Laboratory evolution of bacterial cells is a powerful method for understanding the nature of evolutionary dynamics (Conrad et al. <a href=\"#CR3\">2011</a>; Elena and Lenski <a href=\"#CR5\">2003</a>). Technological advances, such as high-throughput sequencing, have enabled us to quantify the phenotypic and genetic changes occurring during their adaptive evolution. In these experiments, bacterial cells are exposed to environmental stresses, which cause a partial or complete inhibition of cell growth, resulting in a selective advantage for strains resistant to the corresponding stress. An interesting phenomenon observed here is that the evolutionary adaptation to a specific environment is frequently accompanied by fitness changes in other environments. For instance, in the phenomenon of cross-resistance, the acquisition of resistance to one antibiotic is often accompanied by resistance to other antibiotics as well. On the other hand, it can also cause increased sensitivity to other drugs, known as collateral sensitivity (Lázár et al. <a href=\"#CR21\">2013</a>; Munck et al. <a href=\"#CR24\">2014</a>; Suzuki et al. <a href=\"#CR32\">2014</a>). The interplay between mechanisms of stress resistance could constrain possible phenotypic changes during adaptive evolution. In the following section, we discuss the results of our previous study (Suzuki et al. <a href=\"#CR32\">2014</a>) on the laboratory evolution of <em>Escherichia coli</em> under antibiotics to propose a possible approach to the study of evolutionary constraints.</p>\n<p>In our study, the laboratory evolution of <em>E. coli</em> cells on the addition of 10 antibiotics with different action mechanisms was investigated. The range of antibiotics included those that disrupt bacterial cell wall synthesis, protein synthesis, folic acid biosynthesis, and DNA replication. After 90 days of experimental evolution in the presence of each of these antibiotics, we obtained 40 resistant strains (4 independently evolved strains for 10 antibiotics), which showed significant increases in minimum inhibitory concentrations (MICs; Fig. 1a, b). For each drug-resistant strain, transcriptome and genome resequencing analyses were performed to identify fixed mutations and changes in gene expression. We also studied the effect of acquisition of resistance to one drug on the resistance and susceptibility to other drugs (Fig. <a href=\"#Fig1\">1c</a>, for example). The results demonstrated that cross-resistance and collateral sensitivity are ubiquitous in antibiotic resistance evolution. For instance, the acquisition of resistance to enoxacin, a DNA replication inhibitor, is accompanied by collateral sensitivity to aminoglycosides, which are protein synthesis inhibitors, and vice versa. The newly acquired sensitivity to aminoglycosides could possibly be due to the changes in proton-motive force across the cell membrane (Lázár et al. <a href=\"#CR21\">2013</a>; Suzuki et al. <a href=\"#CR32\">2014</a>). It was also demonstrated that <em>E. coli</em> cells cannot acquire resistance to both aminoglycosides and various other antibiotics simultaneously (Munck et al. <a href=\"#CR24\">2014</a>; Suzuki et al. <a href=\"#CR33\">2017</a>). These results demonstrated the constraint placed by the network of cross-resistance and collateral sensitivity on the possible course of drug-resistance evolution in <em>E. coli</em>.</p>\n<figure><h3>Fig. 1.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=7575679_12551_2020_708_Fig1_HTML.jpg\"></a></p>\n<figcaption><p>Laboratory evolution of <em>E. coli</em> under antibiotics. <strong>a</strong>, <strong>b</strong> The time courses of the increase in MIC for enoxacin (ENX) and Cefixime (CFIX) in 90-day laboratory evolution, respectively. Four parallel series of experiments were performed. <strong>c</strong> Changes in MICs for other antibiotics in ENX-resistant strains, respectively. The radial axis depicts the log2-transformed relative MIC to the parent strain. The thick black line indicates MICs of the parent strain, and the colored thick lines indicate relative MICs of four parallel-evolved ENX resistant strains. <strong>d</strong> Comparisons between observed and predicted MICs calculated by using expression levels of 8 genes. See reference Suzuki et al. (<a href=\"#CR32\">2014</a>)) for details</p></figcaption></figure><p>Constraints represented by the network of cross-resistance and collateral sensitivity probably represent a low-dimensional nature of possible phenotypic changes. To check the dimensionality of phenotypic changes, we analyzed the transcriptome data of the drug-resistant strains<em>.</em> It showed that the level of resistance can be quantitatively predicted based on the expression levels of a small number of genes (e.g., 8 genes), using a simple linear model (Fig. <a href=\"#Fig1\">1d</a>). The results suggest that, even though the expression profile is governed by complex interactions of thousands of genes, the changes in the expression profile during evolution are constrained by low-dimensional dynamics, which results in predictable antibiotic resistance. It should be noted that recent theoretical studies have demonstrated that phenotypic changes during adaptive evolution can be constrained by low-dimensional dynamics, which is consistent with the observed low dimensionality in the adaptive evolution of <em>E. coli</em> (Furusawa and Kaneko <a href=\"#CR8\">2018</a>; Kaneko and Furusawa <a href=\"#CR19\">2018</a>).</p>\n<p>To further analyze the evolutionary constraint in bacterial adaptive evolution, we utilized an automated system developed in-house to perform a high-throughput laboratory evolution of <em>E. coli</em> under 95 stress environments (Maeda et al. <a href=\"#CR23\">2020</a>). Again, significant collateral resistance and sensitivity were found to be ubiquitous during the evolution. By applying interpretable machine learning techniques to transcriptome and resistance profile data, the emergence of low-dimensional phenotypic states in the evolved strains was observed, indicating the presence of evolutionary constraints. These findings bridge the gap between genotypic, gene expression, and drug resistance spaces and lead to a better understanding of the constraints for antibiotic resistance evolution.</p></section><section><h2>The developmental hourglass model: pleiotropic constraint behind animal body plan</h2>\n<p>The basic anatomical pattern of animals, or body plans, show striking conservation during evolution and are often considered as a typical example of phylogenetic inertia (Shanahan <a href=\"#CR29\">2011</a>). Because of its conservativeness, the body plan is one of the criteria for defining the largest phylogenetic category or phylum. The vertebrate body plan, for example, includes the hear",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Although organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints, which are based on the quantification of high-dimensional phenotypic and genotypic data. Furthermore, we present a theoretical analysis that enables us to predict evolutionary constraints on the basis of phenotypic fluctuation, modeled on the fluctuation–response relationship in statistical physics. The review lays emphasis on the tight interactions between experimental and theoretical analyses in evolutionary biology that will contribute to a better understanding of evolutionary constraints.</p>\n<section><p><strong>Keywords:</strong> Evolutionary constraints, Microbial laboratory evolution, Developmental hourglass model, Evolutionary fluctuation–response relationship</p></section></section><section><h2>Introduction</h2>\n<p>Although organisms have undergone remarkable diversification during evolution, it has not occurred in entirely random directions. Previous studies have shown unevenness and directionality in the evolutionary changes and phenotypic variations (Arnold <a href=\"#CR1\">1992</a>; Smith et al. <a href=\"#CR30\">1985</a>). For example, all vertebrates have a maximum of two pairs of limbs, and all insects have the same basic body plan (Urry et al. <a href=\"#CR35\">2016</a>). These limits of diversity have often been attributed to the limited potential for diversification or constraints on the production of variable phenotypes; however, the exact mechanism remains largely unclear.</p>\n<p>The theoretical approach, which is based on the concept of statistical physics, contributed significantly toward formulating the constraints, leading to tight collaborations between theoretical and experimental studies (Kaneko and Furusawa <a href=\"#CR19\">2018</a>; Sato et al. <a href=\"#CR27\">2003</a>). Technological innovations also enabled the quantitative analyses of high-dimensional phenotypic and genotypic data, allowing scientists to experimentally test the theoretical frameworks. The present review highlights the contribution of quantitative and theoretical analyses of evolutionary dynamics toward the understanding of its constraints. The three topics are presented below, including studies on bacterial evolution, animal development, and the fluctuation–response relationship in evolution. Here, we discuss a variety of biological targets since the purpose of this review article is to offer a general concept and theoretical framework toward the understanding of evolutionary constraints.</p></section><section><h2>Analysis of evolutionary constraints in bacterial laboratory evolution</h2>\n<p>Laboratory evolution of bacterial cells is a powerful method for understanding the nature of evolutionary dynamics (Conrad et al. <a href=\"#CR3\">2011</a>; Elena and Lenski <a href=\"#CR5\">2003</a>). Technological advances, such as high-throughput sequencing, have enabled us to quantify the phenotypic and genetic changes occurring during their adaptive evolution. In these experiments, bacterial cells are exposed to environmental stresses, which cause a partial or complete inhibition of cell growth, resulting in a selective advantage for strains resistant to the corresponding stress. An interesting phenomenon observed here is that the evolutionary adaptation to a specific environment is frequently accompanied by fitness changes in other environments. For instance, in the phenomenon of cross-resistance, the acquisition of resistance to one antibiotic is often accompanied by resistance to other antibiotics as well. On the other hand, it can also cause increased sensitivity to other drugs, known as collateral sensitivity (Lázár et al. <a href=\"#CR21\">2013</a>; Munck et al. <a href=\"#CR24\">2014</a>; Suzuki et al. <a href=\"#CR32\">2014</a>). The interplay between mechanisms of stress resistance could constrain possible phenotypic changes during adaptive evolution. In the following section, we discuss the results of our previous study (Suzuki et al. <a href=\"#CR32\">2014</a>) on the laboratory evolution of <em>Escherichia coli</em> under antibiotics to propose a possible approach to the study of evolutionary constraints.</p>\n<p>In our study, the laboratory evolution of <em>E. coli</em> cells on the addition of 10 antibiotics with different action mechanisms was investigated. The range of antibiotics included those that disrupt bacterial cell wall synthesis, protein synthesis, folic acid biosynthesis, and DNA replication. After 90 days of experimental evolution in the presence of each of these antibiotics, we obtained 40 resistant strains (4 independently evolved strains for 10 antibiotics), which showed significant increases in minimum inhibitory concentrations (MICs; Fig. 1a, b). For each drug-resistant strain, transcriptome and genome resequencing analyses were performed to identify fixed mutations and changes in gene expression. We also studied the effect of acquisition of resistance to one drug on the resistance and susceptibility to other drugs (Fig. <a href=\"#Fig1\">1c</a>, for example). The results demonstrated that cross-resistance and collateral sensitivity are ubiquitous in antibiotic resistance evolution. For instance, the acquisition of resistance to enoxacin, a DNA replication inhibitor, is accompanied by collateral sensitivity to aminoglycosides, which are protein synthesis inhibitors, and vice versa. The newly acquired sensitivity to aminoglycosides could possibly be due to the changes in proton-motive force across the cell membrane (Lázár et al. <a href=\"#CR21\">2013</a>; Suzuki et al. <a href=\"#CR32\">2014</a>). It was also demonstrated that <em>E. coli</em> cells cannot acquire resistance to both aminoglycosides and various other antibiotics simultaneously (Munck et al. <a href=\"#CR24\">2014</a>; Suzuki et al. <a href=\"#CR33\">2017</a>). These results demonstrated the constraint placed by the network of cross-resistance and collateral sensitivity on the possible course of drug-resistance evolution in <em>E. coli</em>.</p>\n<figure><h3>Fig. 1.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=7575679_12551_2020_708_Fig1_HTML.jpg\"></a></p>\n<figcaption><p>Laboratory evolution of <em>E. coli</em> under antibiotics. <strong>a</strong>, <strong>b</strong> The time courses of the increase in MIC for enoxacin (ENX) and Cefixime (CFIX) in 90-day laboratory evolution, respectively. Four parallel series of experiments were performed. <strong>c</strong> Changes in MICs for other antibiotics in ENX-resistant strains, respectively. The radial axis depicts the log2-transformed relative MIC to the parent strain. The thick black line indicates MICs of the parent strain, and the colored thick lines indicate relative MICs of four parallel-evolved ENX resistant strains. <strong>d</strong> Comparisons between observed and predicted MICs calculated by using expression levels of 8 genes. See reference Suzuki et al. (<a href=\"#CR32\">2014</a>)) for details</p></figcaption></figure><p>Constraints represented by the network of cross-resistance and collateral sensitivity probably represent a low-dimensional nature of possible phenotypic changes. To check the dimensionality of phenotypic changes, we analyzed the transcriptome data of the drug-resistant strains<em>.</em> It showed that the level of resistance can be quantitatively predicted based on the expression levels of a small number of genes (e.g., 8 genes), using a simple linear model (Fig. <a href=\"#Fig1\">1d</a>). The results suggest that, even though the expression profile is governed by complex interactions of thousands of genes, the changes in the expression profile during evolution are constrained by low-dimensional dynamics, which results in predictable antibiotic resistance. It should be noted that recent theoretical studies have demonstrated that phenotypic changes during adaptive evolution can be constrained by low-dimensional dynamics, which is consistent with the observed low dimensionality in the adaptive evolution of <em>E. coli</em> (Furusawa and Kaneko <a href=\"#CR8\">2018</a>; Kaneko and Furusawa <a href=\"#CR19\">2018</a>).</p>\n<p>To further analyze the evolutionary constraint in bacterial adaptive evolution, we utilized an automated system developed in-house to perform a high-throughput laboratory evolution of <em>E. coli</em> under 95 stress environments (Maeda et al. <a href=\"#CR23\">2020</a>). Again, significant collateral resistance and sensitivity were found to be ubiquitous during the evolution. By applying interpretable machine learning techniques to transcriptome and resistance profile data, the emergence of low-dimensional phenotypic states in the evolved strains was observed, indicating the presence of evolutionary constraints. These findings bridge the gap between genotypic, gene expression, and drug resistance spaces and lead to a better understanding of the constraints for antibiotic resistance evolution.</p></section><section><h2>The developmental hourglass model: pleiotropic constraint behind animal body plan</h2>\n<p>The basic anatomical pattern of animals, or body plans, show striking conservation during evolution and are often considered as a typical example of phylogenetic inertia (Shanahan <a href=\"#CR29\">2011</a>). Because of its conservativeness, the body plan is one of the criteria for defining the largest phylogenetic category or phylum. The vertebrate body plan, for example, includes the hear",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractAlthough organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractAlthough organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractAlthough organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractAlthough organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractAlthough organisms have diversified remarkably through evolution, they do not exhibit unlimited variability. During evolution, the phenotypic changes do not occur at random; instead, they are directional and restricted by the constraints imposed on them. Despite the perceived importance of characterizing the unevenness of these changes, studies on evolutionary constraints have been primarily qualitative in nature. In this review, we focus on the recent studies of evolutionary constraints",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:Evolutionary constraints, Microbial laboratory evolution, Developmental hourglass model, Evolutionary fluctuation–response relationship",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "IntroductionAlthough organisms have undergone remarkable diversification during evolution, it has not occurred in entirely random directions. Previous studies have shown unevenness and directionality in the evolutionary changes and phenotypic variations (Arnold1992; Smith et al.1985). For example, all vertebrates have a maximum of two pairs of limbs, and all insects have the same basic body plan (Urry et al.2016). These limits of diversity have often been attributed to the limited potential for ",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Analysis of evolutionary constraints in bacterial laboratory evolutionLaboratory evolution of bacterial cells is a powerful method for understanding the nature of evolutionary dynamics (Conrad et al.2011; Elena and Lenski2003). Technological advances, such as high-throughput sequencing, have enabled us to quantify the phenotypic and genetic changes occurring during their adaptive evolution. In these experiments, bacterial cells are exposed to environmental stresses, which cause a partial or comp",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "The developmental hourglass model: pleiotropic constraint behind animal body planThe basic anatomical pattern of animals, or body plans, show striking conservation during evolution and are often considered as a typical example of phylogenetic inertia (Shanahan2011). Because of its conservativeness, the body plan is one of the criteria for defining the largest phylogenetic category or phylum. The vertebrate body plan, for example, includes the hear",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Analysis of evolutionary constraints in bacterial laboratory evolution",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Fig. 1.",
              "id": ""
            },
            {
              "level": "h2",
              "text": "The developmental hourglass model: pleiotropic constraint behind animal body plan",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "http://blogs.evergreen.edu/sosw/files/2014/04/Green-Vol5-DBS-017.pdf",
      "title": "Datalog and Recursive Query Processing",
      "author": "",
      "published_date": "2023-01-07T09:38:33.000Z",
      "content": {
        "text": "Datalog and Recursive Query Processing\nPublisher: Now Publishers\nDate Published: 2012\nAuthors:\nTodd J Green, todd.green@logicblox.com\nShan Shan Huang\nThau Loo\nWenchao Zhou, wzhou@cs.georgetown.edu\nAbstract\nIn recent years, we have witnessed a revival of the use of recursive queries in a variety of emerging application domains such as data integration and exchange, information extraction, networking, and program analysis. A popular language used for expressing these queries is Datalog. This paper surveys for a general audience the Datalog language, recursive query processing, and optimization techniques. This survey differs from prior surveys written in the eighties and nineties in its comprehensiveness of topics, its coverage of recent developments and applications, and its emphasis on features and techniques beyond \"classical\" Datalog which are vital for practical applications. Specifically, the topics covered include the core Datalog language and various extensions, semantics, query optimizations, magic-sets optimizations, incremental view maintenance, aggregates, negation, and types. We conclude the paper with a survey of recent systems and applications that use Datalog and recursive queries.\n1 Introduction\nMainstream interest in Datalog in the database systems community flourished in the eighties and early nineties. During this period, there were several pioneering Datalog systems, primarily from academia. Two of the more prominent ones with complete implementations include Coral [99] and LDL++ [20] . Some ideas from these early research prototypes made it into mainstream commercial databases. For instance, Oracle, DB2, and SQL Server provide support for limited forms of support for recursion, based on SQL-99 standards. However, a perceived lack of compelling applications at the time [113] ultimately forced Datalog research into a long dormancy, and stifled its use in practice. Coral and LDL++ ceased active development in 1997 and 2000 respectively, and commercial systems did not extend a limited form of Datalog.\nIn recent years, however, Datalog has reemerged at the center of a wide range of new applications, including data integration [68, 43, 50] , declarative networking [80, 77, 75] , program analysis [29] , information extraction [110] , network monitoring [10] , security [85, 60] , optimizations [73] , and cloud computing [15, 16] . Compared to the state-of-theart of two decades ago, the modern systems that drives these emerging applications have significantly more mature and complete Datalog im-plementations, and often times deploy applications that are orders of magnitude larger in code size and complexity compared to the older generation of Datalog programs.\nIn terms of modern academic systems, the IRIS reasoner [59] is an open-source general purpose Datalog execution engine with support for optimizations, stratified and locally stratified negation. There are also publicly available Datalog systems tailored for specific applications. These include the Orchestra system for collaborative data sharing [92] , BDDBDD [24] for program analysis, the RapidNet [101] declarative networking platforms, and the Bloom [16] platform for declarative programming in the cloud.\nIn the commercial world, a major development is the emergence of enterprise Datalog systems, most notably LogicBlox [4] , Datomic [2] , Semmle [7] , and Lixto [49] . Semmle and Lixto are targeted at specific domains of program analysis and information extraction respectively, while LogicBlox and Datomic aim to provide a general platform for developing enterprise software.\nThe revival of Datalog in the new generation of applications is driven by the increasing need for high-level abstractions for reasoning about and rapidly developing complex systems that process large amounts of data, and are sometimes distributed and parallel. Datalog provides a declarative interface that allows the programmer to focus on the tasks (\"what\"), not the low-level details (\"how\"). A common thread across these systems is the use of the Datalog language as a declarative abstraction for querying graphs and relational structures, and implementing iterations and recursions. Its clear and simple syntax with well understood semantics aims to achieve the best of both worlds -having a rich enough language to support a wide range of applications, yet at a high and concise level that makes rapid prototyping easy for programmers without having to worry about low level messy details related to robustness and parallelism. The high-level specifications also make code analysis easier, for applying optimizations and for reasoning about transactions and safety.\n1.1 Contributions and Roadmap\nThis survey paper aims to provide an accessible and gentle introduction to Datalog and recursive query processing to readers with some basic background in databases (in particular, SQL and the relational model). Given the wide range of research literature on Datalog spanning decades, we identify a \"practical\" subset of Datalog based on recent advances in the adoption of Datalog. In particular, our survey aims to cover the following:\n• Language. Core Datalog syntax and semantics. (Chapter 2)\n• Query processing. Recursive query processing techniques for executing Datalog programs efficiently, using the bottom-up and top-down evaluation strategies, such as the well-known seminaïve [22, 21] and Query/Subquery (QSQ) [67] evaluation strategies. (Chapter 3)\n• Incremental maintenance. Extensions to query processing techniques in the previous chapter, to include mechanisms for incrementally updating the materialized views of a Datalog program, as the input data changes, without having to recompute the entire Datalog program from scratch. (Chapter 4)\n• Common extensions. Each application domain takes the core Datalog language and then further customizes and extends the core language and implementation techniques to meet its particular needs. Here, we discuss extensions to incorporate negation, aggregation, arithmetic, uninterpreted functions, and updates, as well as the query processing techniques to handle these extensions. (Chapter 5).\nThe survey concludes in Chapter 6 with a brief survey of recent applications of Datalog, in the domains of program analysis, declarative networking, data integration and exchange, enterprise software systems, etc.\n1.2 Relationship with Previous Surveys\nOur survey serves as an entry point into several other survey papers and books on Datalog. We briefly mention some of them:\n• Bancilhon et al. [23] surveys and compares various strategies for processing and optimizing recursive queries in a greater depth compared to our survey.\n• Ceri et al. [32] presents the syntax and semantics of Datalog along with evaluation and optimization techniques for efficient execution. Extensions to the Datalog language, such as built-in predicates and negation are also discussed.\n• Ramakrishnan and Ullman [100] provides a high-level overview of the Datalog language, query evaluation and optimizations, and more advanced topics on negation and aggregation in a few pages. This should be viewed as a \"quick-starter\" guide for someone exposed to Datalog for the first time.\n• Textbooks [12, 27, 33, 118, 36] cover some topics (e.g. language, semantics, magic sets) in greater detail than our survey. Abiteboul et al. [12] in particular is a widely used textbook geared towards a database theory audience.\n1.3 First Example: All-Pairs Reachability\nWe begin with a high level introduction to the Datalog language and its basic evaluation strategy. As our first example, we consider a Datalog program that computes all-pairs reachability, essentially a transitive closure computation in a graph for figuring out all pairs of nodes that are connected (reachable) to each other.\nr1 reachable(X,Y) :-link(X,Y). r2 reachable(X,Y) :-link(X,Z), reachable(Z,Y). query(X,Y) :-reachable(X,Y).\nThe above two rules, named as r1 and r2, derive the reachable nodes (i.e. reachable(X,Y) using facts about directly linked nodes (i.e. link(X,Y)). Here, we use capital letters X and Y to signify that they are variables in the domain of all the nodes. The output of interest in this program, as denoted by the special predicate query(X,Y), is the set of derived reachable facts. The input graph in this case can represent a network of routers, and forms a basis for implementing network routing protocols [80] , web crawlers [81] , and network crawlers [79] .\nRule r1 expresses that node X is reachable from Y (i.e. reachable(X,Y)) if they are directly linked. Rule r2 is a bit more interesting, as it specifies the reachable relation in terms of itself: (X,Y) are reachable from one another if X has a direct link to a node (Z) that is reachable to Y. We refer to rules such as r2 as recursive rules, since the reachable relation appears in both the rule body (right of \" :-\") and head (left of \" :-\"). Rule r2 is also a linear recursive rule ,since reachable appears only once in the rule body. We illustrate the execution of Datalog rules by evaluating the reachable rules over the graph shown in Figure 1 .1, which depicts a network consisting of three nodes and four direct links. Thus, there are hops apart. Iteration 4 (not shown in the figure) derives the same set of tuples as iteration 3, and hence, a fixpoint is reached. Given that no two nodes are separated by more than 3 hops, the recursive query completes in 4 iterations.\nAs an optimization, instead of using all derived facts as input to rules at each iteration, one can suppress the evaluation that uses only tuples already learned in prior iterations when computing new tuples the next iteration. For instance, when generating new facts in iteration 3, rule r2 will not evaluate for inputs reachable(b,c) and link(a,b), since they have already been used in iteration 1. The intuitive description above corresponds loosely to the semi-naïve evaluation strategy, which will be described in greater detail ",
        "html": "Datalog and Recursive Query Processing\nPublisher: Now Publishers\nDate Published: 2012\nAuthors:\nTodd J Green, todd.green@logicblox.com\nShan Shan Huang\nThau Loo\nWenchao Zhou, wzhou@cs.georgetown.edu\nAbstract\nIn recent years, we have witnessed a revival of the use of recursive queries in a variety of emerging application domains such as data integration and exchange, information extraction, networking, and program analysis. A popular language used for expressing these queries is Datalog. This paper surveys for a general audience the Datalog language, recursive query processing, and optimization techniques. This survey differs from prior surveys written in the eighties and nineties in its comprehensiveness of topics, its coverage of recent developments and applications, and its emphasis on features and techniques beyond \"classical\" Datalog which are vital for practical applications. Specifically, the topics covered include the core Datalog language and various extensions, semantics, query optimizations, magic-sets optimizations, incremental view maintenance, aggregates, negation, and types. We conclude the paper with a survey of recent systems and applications that use Datalog and recursive queries.\n1 Introduction\nMainstream interest in Datalog in the database systems community flourished in the eighties and early nineties. During this period, there were several pioneering Datalog systems, primarily from academia. Two of the more prominent ones with complete implementations include Coral [99] and LDL++ [20] . Some ideas from these early research prototypes made it into mainstream commercial databases. For instance, Oracle, DB2, and SQL Server provide support for limited forms of support for recursion, based on SQL-99 standards. However, a perceived lack of compelling applications at the time [113] ultimately forced Datalog research into a long dormancy, and stifled its use in practice. Coral and LDL++ ceased active development in 1997 and 2000 respectively, and commercial systems did not extend a limited form of Datalog.\nIn recent years, however, Datalog has reemerged at the center of a wide range of new applications, including data integration [68, 43, 50] , declarative networking [80, 77, 75] , program analysis [29] , information extraction [110] , network monitoring [10] , security [85, 60] , optimizations [73] , and cloud computing [15, 16] . Compared to the state-of-theart of two decades ago, the modern systems that drives these emerging applications have significantly more mature and complete Datalog im-plementations, and often times deploy applications that are orders of magnitude larger in code size and complexity compared to the older generation of Datalog programs.\nIn terms of modern academic systems, the IRIS reasoner [59] is an open-source general purpose Datalog execution engine with support for optimizations, stratified and locally stratified negation. There are also publicly available Datalog systems tailored for specific applications. These include the Orchestra system for collaborative data sharing [92] , BDDBDD [24] for program analysis, the RapidNet [101] declarative networking platforms, and the Bloom [16] platform for declarative programming in the cloud.\nIn the commercial world, a major development is the emergence of enterprise Datalog systems, most notably LogicBlox [4] , Datomic [2] , Semmle [7] , and Lixto [49] . Semmle and Lixto are targeted at specific domains of program analysis and information extraction respectively, while LogicBlox and Datomic aim to provide a general platform for developing enterprise software.\nThe revival of Datalog in the new generation of applications is driven by the increasing need for high-level abstractions for reasoning about and rapidly developing complex systems that process large amounts of data, and are sometimes distributed and parallel. Datalog provides a declarative interface that allows the programmer to focus on the tasks (\"what\"), not the low-level details (\"how\"). A common thread across these systems is the use of the Datalog language as a declarative abstraction for querying graphs and relational structures, and implementing iterations and recursions. Its clear and simple syntax with well understood semantics aims to achieve the best of both worlds -having a rich enough language to support a wide range of applications, yet at a high and concise level that makes rapid prototyping easy for programmers without having to worry about low level messy details related to robustness and parallelism. The high-level specifications also make code analysis easier, for applying optimizations and for reasoning about transactions and safety.\n1.1 Contributions and Roadmap\nThis survey paper aims to provide an accessible and gentle introduction to Datalog and recursive query processing to readers with some basic background in databases (in particular, SQL and the relational model). Given the wide range of research literature on Datalog spanning decades, we identify a \"practical\" subset of Datalog based on recent advances in the adoption of Datalog. In particular, our survey aims to cover the following:\n• Language. Core Datalog syntax and semantics. (Chapter 2)\n• Query processing. Recursive query processing techniques for executing Datalog programs efficiently, using the bottom-up and top-down evaluation strategies, such as the well-known seminaïve [22, 21] and Query/Subquery (QSQ) [67] evaluation strategies. (Chapter 3)\n• Incremental maintenance. Extensions to query processing techniques in the previous chapter, to include mechanisms for incrementally updating the materialized views of a Datalog program, as the input data changes, without having to recompute the entire Datalog program from scratch. (Chapter 4)\n• Common extensions. Each application domain takes the core Datalog language and then further customizes and extends the core language and implementation techniques to meet its particular needs. Here, we discuss extensions to incorporate negation, aggregation, arithmetic, uninterpreted functions, and updates, as well as the query processing techniques to handle these extensions. (Chapter 5).\nThe survey concludes in Chapter 6 with a brief survey of recent applications of Datalog, in the domains of program analysis, declarative networking, data integration and exchange, enterprise software systems, etc.\n1.2 Relationship with Previous Surveys\nOur survey serves as an entry point into several other survey papers and books on Datalog. We briefly mention some of them:\n• Bancilhon et al. [23] surveys and compares various strategies for processing and optimizing recursive queries in a greater depth compared to our survey.\n• Ceri et al. [32] presents the syntax and semantics of Datalog along with evaluation and optimization techniques for efficient execution. Extensions to the Datalog language, such as built-in predicates and negation are also discussed.\n• Ramakrishnan and Ullman [100] provides a high-level overview of the Datalog language, query evaluation and optimizations, and more advanced topics on negation and aggregation in a few pages. This should be viewed as a \"quick-starter\" guide for someone exposed to Datalog for the first time.\n• Textbooks [12, 27, 33, 118, 36] cover some topics (e.g. language, semantics, magic sets) in greater detail than our survey. Abiteboul et al. [12] in particular is a widely used textbook geared towards a database theory audience.\n1.3 First Example: All-Pairs Reachability\nWe begin with a high level introduction to the Datalog language and its basic evaluation strategy. As our first example, we consider a Datalog program that computes all-pairs reachability, essentially a transitive closure computation in a graph for figuring out all pairs of nodes that are connected (reachable) to each other.\nr1 reachable(X,Y) :-link(X,Y). r2 reachable(X,Y) :-link(X,Z), reachable(Z,Y). query(X,Y) :-reachable(X,Y).\nThe above two rules, named as r1 and r2, derive the reachable nodes (i.e. reachable(X,Y) using facts about directly linked nodes (i.e. link(X,Y)). Here, we use capital letters X and Y to signify that they are variables in the domain of all the nodes. The output of interest in this program, as denoted by the special predicate query(X,Y), is the set of derived reachable facts. The input graph in this case can represent a network of routers, and forms a basis for implementing network routing protocols [80] , web crawlers [81] , and network crawlers [79] .\nRule r1 expresses that node X is reachable from Y (i.e. reachable(X,Y)) if they are directly linked. Rule r2 is a bit more interesting, as it specifies the reachable relation in terms of itself: (X,Y) are reachable from one another if X has a direct link to a node (Z) that is reachable to Y. We refer to rules such as r2 as recursive rules, since the reachable relation appears in both the rule body (right of \" :-\") and head (left of \" :-\"). Rule r2 is also a linear recursive rule ,since reachable appears only once in the rule body. We illustrate the execution of Datalog rules by evaluating the reachable rules over the graph shown in Figure 1 .1, which depicts a network consisting of three nodes and four direct links. Thus, there are hops apart. Iteration 4 (not shown in the figure) derives the same set of tuples as iteration 3, and hence, a fixpoint is reached. Given that no two nodes are separated by more than 3 hops, the recursive query completes in 4 iterations.\nAs an optimization, instead of using all derived facts as input to rules at each iteration, one can suppress the evaluation that uses only tuples already learned in prior iterations when computing new tuples the next iteration. For instance, when generating new facts in iteration 3, rule r2 will not evaluate for inputs reachable(b,c) and link(a,b), since they have already been used in iteration 1. The intuitive description above corresponds loosely to the semi-naïve evaluation strategy, which will be described in greater detail ",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.transcriptioncertificationinstitute.org/blog/transcription-guidelines-transcribers",
      "title": "Everything About Transcription Guidelines for Transcribers",
      "author": "Transcription Certification Institute",
      "published_date": "2022-10-18T06:54:27.000Z",
      "content": {
        "text": "<div><div>\n<p>When <a href=\"https://www.transcriptioncertificationinstitute.org/blog/get-started-as-a-transcriptionist-guide-part-1?utm_source=transcription-guidelines-transcribers&amp;utm_medium=blog&amp;utm_campaign=started_as_a_transcriptionist\"><strong>getting started as a transcriber</strong></a>, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions.</p>\n<h2>Read on for an introduction to basic transcription guidelines.</h2>\n<p>But before we get started with the basics </p>\n<p><strong>Note:</strong> Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work. Most companies offer a base pay amount for their jobs.</p>\n<p>There is also a score-based bonus transcriber can earn by doing better work, i.e., following formatting guidelines and special instructions and returning work early. Any submission that does not meet the company's minimum requirements may be rejected.</p>\n<p>Some companies will allow you to redo the job, while others will assign it to other transcribers. Rejected work may not be paid for. Therefore, you should carefully learn and master the transcription style guide of the company you are working for. </p>\n<h3>Basic Transcription Guidelines</h3>\n<ol>\n<li><strong>Accuracy.</strong> Only type the words that are spoken in the audio file. Phrases or words you don't understand should not be omitted. Instead, they should be tagged appropriately according to the company's guidelines.</li>\n<li><strong>US English.</strong> Use proper US English capitalization, punctuation and spelling. Do not write phonetics or netspeak such as “u” for “you\".</li>\n<li><strong>Do Not Paraphrase.</strong> Do not correct the speaker's grammar nor rearrange words. Also, do not cut words that you think are off-topic or irrelevant. Any words not spoken should not be included. Type the actual words spoken.</li>\n<li><strong>Do Not Add Additional Information.</strong> Do not add additional information such as page numbers, job numbers, titles, or your comments in your submission. Such information can be added in separate fields below the transcript.</li>\n<li><strong>“Clean Up” Non-Verbatim Jobs.</strong> Lightly edit non-verbatim work to remove false starts, filler, and stutters. Check the company's guidelines on what should be removed.</li>\n<li><strong>Verbatim Work Should Be Truly Verbatim.</strong> When transcribing verbatim work, include every utterance and sound exactly as you hear. Unless directed in the work's “Notes” section, all filler words should be included. Also, transcribe stutters as accurately as possible.</li>\n</ol>\n<h3>Transcript Formatting</h3>\n<p>In most cases, the file you will be transcribing will be part of a larger audio file. Transcription companies require transcribers to deliver consistent results from one file to the next. This is why they have format transcripts.</p>\n<p><span><em><strong>Note:</strong> Check the format transcript rules of the transcription company you wish to work with. </em></span></p>\n<h3><span><strong>Here is a rundown of the general transcription format guidelines.</strong></span></h3>\n<h3>Sentence and Paragraph Structure</h3>\n<ul>\n<li>Use word wrap when writing. Fix any line breaks in the middle of your paragraphs before submitting the work.</li>\n<li>Do not use double spaces after sentences or anywhere else. You can use Search &amp; Replace function in your word processor to change all double spaces to single ones.</li>\n<li>Follow correct grammar. All sentences should start with a capital letter and have the correct punctuation.</li>\n<li>Where possible, break compound sentences into smaller ones. Long sentences should be broken into fragments.</li>\n<li>Keep your paragraphs short to a maximum of 400 characters.</li>\n<li>Insert a blank line between paragraphs. Also, start a new paragraph at every speaker change.</li>\n<li>Do not indent anything.</li>\n</ul>\n<h3>Conjunctions</h3>\n<p>Conjunctions such as “so”, “or”, “but”, “because”, “and,” and others are used to join two parts of a sentence together. Whenever possible, do not start a sentence with conjunctions. Most of the time, you can cut off the words without changing the meaning of a sentence. Conjunctions should only be used at the start of a sentence if omitting them will change the meaning.</p>\n<h3>Speaker Labels</h3>\n<p>Speaker labels are words used to identify a person speaking in audio. The label is usually the speaker's name, role, or other identifying attributes.</p>\n<ul>\n<li>Use speaker labels to identify a speaker as specifically as possible</li>\n<li>Format speaker labels correctly according to the company's rules</li>\n</ul>\n<p>The speaker label should be followed by a colon and space. Also, capitalize each speaker label word.</p>\n<h3>Example</h3>\n<p><span><strong>Interviewer:</strong> </span>Hello, and welcome. I'm Jack. And you are?</p>\n<p><span><strong>Woman 1:</strong></span> I'm Rachel</p>\n<p><span><strong>Woman 2:</strong></span> I'm Samantha</p>\n<p>Let's wind up this guideline with both basic and verbatim interview transcription examples.</p>\n<h3>Basic Transcription Example</h3>\n<p>With basic transcripts, filler words, conjunctions that start sentences, and false starts should be removed from your transcript. <strong>e.g.</strong></p>\n<h5>Original Audio:</h5>\n<p><strong><span>Jack:</span> </strong>It was quite, it was quite challenging to ride a horse for the first time.</p>\n<h5>Transcribed Audio:</h5>\n<p><strong><span>Jack:</span></strong> It was quite challenging to ride a horse for the first time.</p>\n<h4>Verbatim Transcription Example</h4>\n<p>With verbatim transcripts, all words you hear should be typed as they are. These include conjunctions, filler words, and unobtrusive sound events (e.g., car sounds) that can be heard.</p>\n<p><strong>Here is an example:</strong></p>\n<h4>Transcribed Audio</h4>\n<p>[dog barks] <span><strong>Paul:</strong></span> If only I had come earlier, I wouldn't have missed a spot.</p>\n<p><span><strong>Annie:</strong></span> Oh, that's really sad [dog barks]</p>\n<p>Transcription companies may have specific guidelines to be followed. Go through the guidelines, even if you have experience transcribing before, as there may be different rules to follow. The guidelines are usually comprehensive. You can create a cheat sheet to refer to when transcribing the company's work.</p>\n<h3>Is a Transcription Career Right for You?</h3>\n<p><a href=\"https://www.transcriptioncertificationinstitute.org/quick-quiz-registration?utm_source=transcription-guidelines-transcribers&amp;utm_medium=blog&amp;utm_campaign=take_a_quiz_image\"></a></p>\n<p><strong>Also Read: <a href=\"https://www.transcriptioncertificationinstitute.org/blog/how-to-get-a-transcription-job-guide-part-2?utm_source=transcription_guidelines_transcribers&amp;utm_medium=blog&amp;utm_campaign=get_a_transcription_job\">How To Get A Transcription Job – A Complete Guide [Part 2]</a></strong></p>\n</div></div>",
        "html": "<div><div>\n<p>When <a href=\"https://www.transcriptioncertificationinstitute.org/blog/get-started-as-a-transcriptionist-guide-part-1?utm_source=transcription-guidelines-transcribers&amp;utm_medium=blog&amp;utm_campaign=started_as_a_transcriptionist\"><strong>getting started as a transcriber</strong></a>, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions.</p>\n<h2>Read on for an introduction to basic transcription guidelines.</h2>\n<p>But before we get started with the basics </p>\n<p><strong>Note:</strong> Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work. Most companies offer a base pay amount for their jobs.</p>\n<p>There is also a score-based bonus transcriber can earn by doing better work, i.e., following formatting guidelines and special instructions and returning work early. Any submission that does not meet the company's minimum requirements may be rejected.</p>\n<p>Some companies will allow you to redo the job, while others will assign it to other transcribers. Rejected work may not be paid for. Therefore, you should carefully learn and master the transcription style guide of the company you are working for. </p>\n<h3>Basic Transcription Guidelines</h3>\n<ol>\n<li><strong>Accuracy.</strong> Only type the words that are spoken in the audio file. Phrases or words you don't understand should not be omitted. Instead, they should be tagged appropriately according to the company's guidelines.</li>\n<li><strong>US English.</strong> Use proper US English capitalization, punctuation and spelling. Do not write phonetics or netspeak such as “u” for “you\".</li>\n<li><strong>Do Not Paraphrase.</strong> Do not correct the speaker's grammar nor rearrange words. Also, do not cut words that you think are off-topic or irrelevant. Any words not spoken should not be included. Type the actual words spoken.</li>\n<li><strong>Do Not Add Additional Information.</strong> Do not add additional information such as page numbers, job numbers, titles, or your comments in your submission. Such information can be added in separate fields below the transcript.</li>\n<li><strong>“Clean Up” Non-Verbatim Jobs.</strong> Lightly edit non-verbatim work to remove false starts, filler, and stutters. Check the company's guidelines on what should be removed.</li>\n<li><strong>Verbatim Work Should Be Truly Verbatim.</strong> When transcribing verbatim work, include every utterance and sound exactly as you hear. Unless directed in the work's “Notes” section, all filler words should be included. Also, transcribe stutters as accurately as possible.</li>\n</ol>\n<h3>Transcript Formatting</h3>\n<p>In most cases, the file you will be transcribing will be part of a larger audio file. Transcription companies require transcribers to deliver consistent results from one file to the next. This is why they have format transcripts.</p>\n<p><span><em><strong>Note:</strong> Check the format transcript rules of the transcription company you wish to work with. </em></span></p>\n<h3><span><strong>Here is a rundown of the general transcription format guidelines.</strong></span></h3>\n<h3>Sentence and Paragraph Structure</h3>\n<ul>\n<li>Use word wrap when writing. Fix any line breaks in the middle of your paragraphs before submitting the work.</li>\n<li>Do not use double spaces after sentences or anywhere else. You can use Search &amp; Replace function in your word processor to change all double spaces to single ones.</li>\n<li>Follow correct grammar. All sentences should start with a capital letter and have the correct punctuation.</li>\n<li>Where possible, break compound sentences into smaller ones. Long sentences should be broken into fragments.</li>\n<li>Keep your paragraphs short to a maximum of 400 characters.</li>\n<li>Insert a blank line between paragraphs. Also, start a new paragraph at every speaker change.</li>\n<li>Do not indent anything.</li>\n</ul>\n<h3>Conjunctions</h3>\n<p>Conjunctions such as “so”, “or”, “but”, “because”, “and,” and others are used to join two parts of a sentence together. Whenever possible, do not start a sentence with conjunctions. Most of the time, you can cut off the words without changing the meaning of a sentence. Conjunctions should only be used at the start of a sentence if omitting them will change the meaning.</p>\n<h3>Speaker Labels</h3>\n<p>Speaker labels are words used to identify a person speaking in audio. The label is usually the speaker's name, role, or other identifying attributes.</p>\n<ul>\n<li>Use speaker labels to identify a speaker as specifically as possible</li>\n<li>Format speaker labels correctly according to the company's rules</li>\n</ul>\n<p>The speaker label should be followed by a colon and space. Also, capitalize each speaker label word.</p>\n<h3>Example</h3>\n<p><span><strong>Interviewer:</strong> </span>Hello, and welcome. I'm Jack. And you are?</p>\n<p><span><strong>Woman 1:</strong></span> I'm Rachel</p>\n<p><span><strong>Woman 2:</strong></span> I'm Samantha</p>\n<p>Let's wind up this guideline with both basic and verbatim interview transcription examples.</p>\n<h3>Basic Transcription Example</h3>\n<p>With basic transcripts, filler words, conjunctions that start sentences, and false starts should be removed from your transcript. <strong>e.g.</strong></p>\n<h5>Original Audio:</h5>\n<p><strong><span>Jack:</span> </strong>It was quite, it was quite challenging to ride a horse for the first time.</p>\n<h5>Transcribed Audio:</h5>\n<p><strong><span>Jack:</span></strong> It was quite challenging to ride a horse for the first time.</p>\n<h4>Verbatim Transcription Example</h4>\n<p>With verbatim transcripts, all words you hear should be typed as they are. These include conjunctions, filler words, and unobtrusive sound events (e.g., car sounds) that can be heard.</p>\n<p><strong>Here is an example:</strong></p>\n<h4>Transcribed Audio</h4>\n<p>[dog barks] <span><strong>Paul:</strong></span> If only I had come earlier, I wouldn't have missed a spot.</p>\n<p><span><strong>Annie:</strong></span> Oh, that's really sad [dog barks]</p>\n<p>Transcription companies may have specific guidelines to be followed. Go through the guidelines, even if you have experience transcribing before, as there may be different rules to follow. The guidelines are usually comprehensive. You can create a cheat sheet to refer to when transcribing the company's work.</p>\n<h3>Is a Transcription Career Right for You?</h3>\n<p><a href=\"https://www.transcriptioncertificationinstitute.org/quick-quiz-registration?utm_source=transcription-guidelines-transcribers&amp;utm_medium=blog&amp;utm_campaign=take_a_quiz_image\"></a></p>\n<p><strong>Also Read: <a href=\"https://www.transcriptioncertificationinstitute.org/blog/how-to-get-a-transcription-job-guide-part-2?utm_source=transcription_guidelines_transcribers&amp;utm_medium=blog&amp;utm_campaign=get_a_transcription_job\">How To Get A Transcription Job – A Complete Guide [Part 2]</a></strong></p>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Whengetting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions.Read on for an introduction to basic transcription guidelines.But before we get started with the basicsNote:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work. Most companies offer a base pay amount for the",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Whengetting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions.Read on for an introduction to basic transcription guidelines.But before we get started with the basicsNote:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work. Most companies offer a base pay amount for the",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Read on for an introduction to basic transcription guidelines.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Basic Transcription Guidelines",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Transcript Formatting",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Here is a rundown of the general transcription format guidelines.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Sentence and Paragraph Structure",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Conjunctions",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Speaker Labels",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Example",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Basic Transcription Example",
              "id": ""
            },
            {
              "level": "h5",
              "text": "Original Audio:",
              "id": ""
            },
            {
              "level": "h5",
              "text": "Transcribed Audio:",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Verbatim Transcription Example",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Transcribed Audio",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Is a Transcription Career Right for You?",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://evolution.berkeley.edu/evo-devo/constraints-on-evolutionary-change/",
      "title": "Constraints on evolutionary change",
      "author": "",
      "published_date": "2024-01-01T00:00:00.000Z",
      "content": {
        "text": "<div><div><main><p><span><a href=\"https://evolution.berkeley.edu/\"><span>Home</span></a></span> → <span><a href=\"https://evolution.berkeley.edu/evo-devo/\"><span>Evo-devo</span></a></span> → Constraints on evolutionary change</p><article><div><p>A lineage’s development may limit the sorts of <a href=\"https://evolution.berkeley.edu/glossary/phenotype\">phenotypes</a> that it can evolve. This limitation is called a developmental constraint.</p>\n<p><a href=\"https://evolution.berkeley.edu/wp-content/uploads/2021/08/winged_pig.jpg\"></a>The idea of constraint helps us explain why some things <i>didn’t</i> happen in evolution that we might think would be advantageous: why <i>didn’t</i> any <a href=\"https://evolution.berkeley.edu/glossary/tetrapod\">tetrapods</a> evolve more than five real fingers and toes, why <i>didn’t</i> caterpillars evolve to have the complex eye of adult butterflies, and why <i>didn’t</i> pigs evolve wings? Although difficult to figure out, the answers to these questions likely have to do with the developmental processes of tetrapods, insects, and pigs. Perhaps these features would fatally interrupt other aspects of the organism’s development — or perhaps these features would require so many other drastic changes in development that they are unlikely to arise through mutation.</p>\n<p>To look at an example in more detail, horses (and all tetrapods — from sloths to salamanders) develop through a stage where the embryo has limbs with five digits, even though some of these will be lost or greatly modified. One might think that it would be advantageous for horses to develop hooves directly, but they don’t — they retain the five-digit developmental stage. The explanation for this may be developmental in nature — skipping the five-digit stage may simply not be an option in tetrapods’ developmental processes.</p>\n<figure><a href=\"https://evolution.berkeley.edu/wp-content/uploads/2021/08/horse-sloth-and-salamander.jpg\"></a><figcaption>Horses, sloths, and salamanders all develop through an embryonic stage with five-digit limbs — even though, the digits of the adult forms look quite different. Horse image © 2001 John White; Sloth image © California Academy of Sciences; photo by Dr. Lloyd Glenn Ingles; Salamander image © 2002 William Flaxington.</figcaption></figure>\n</div></article></main></div></div>",
        "html": "<div><div><main><p><span><a href=\"https://evolution.berkeley.edu/\"><span>Home</span></a></span> → <span><a href=\"https://evolution.berkeley.edu/evo-devo/\"><span>Evo-devo</span></a></span> → Constraints on evolutionary change</p><article><div><p>A lineage’s development may limit the sorts of <a href=\"https://evolution.berkeley.edu/glossary/phenotype\">phenotypes</a> that it can evolve. This limitation is called a developmental constraint.</p>\n<p><a href=\"https://evolution.berkeley.edu/wp-content/uploads/2021/08/winged_pig.jpg\"></a>The idea of constraint helps us explain why some things <i>didn’t</i> happen in evolution that we might think would be advantageous: why <i>didn’t</i> any <a href=\"https://evolution.berkeley.edu/glossary/tetrapod\">tetrapods</a> evolve more than five real fingers and toes, why <i>didn’t</i> caterpillars evolve to have the complex eye of adult butterflies, and why <i>didn’t</i> pigs evolve wings? Although difficult to figure out, the answers to these questions likely have to do with the developmental processes of tetrapods, insects, and pigs. Perhaps these features would fatally interrupt other aspects of the organism’s development — or perhaps these features would require so many other drastic changes in development that they are unlikely to arise through mutation.</p>\n<p>To look at an example in more detail, horses (and all tetrapods — from sloths to salamanders) develop through a stage where the embryo has limbs with five digits, even though some of these will be lost or greatly modified. One might think that it would be advantageous for horses to develop hooves directly, but they don’t — they retain the five-digit developmental stage. The explanation for this may be developmental in nature — skipping the five-digit stage may simply not be an option in tetrapods’ developmental processes.</p>\n<figure><a href=\"https://evolution.berkeley.edu/wp-content/uploads/2021/08/horse-sloth-and-salamander.jpg\"></a><figcaption>Horses, sloths, and salamanders all develop through an embryonic stage with five-digit limbs — even though, the digits of the adult forms look quite different. Horse image © 2001 John White; Sloth image © California Academy of Sciences; photo by Dr. Lloyd Glenn Ingles; Salamander image © 2002 William Flaxington.</figcaption></figure>\n</div></article></main></div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Home→Evo-devo→ Constraints on evolutionary changeA lineage’s development may limit the sorts ofphenotypesthat it can evolve. This limitation is called a developmental constraint.The idea of constraint helps us explain why some thingsdidn’thappen in evolution that we might think would be advantageous: whydidn’tanytetrapodsevolve more than five real fingers and toes, whydidn’tcaterpillars evolve to have the complex eye of adult butterflies, and whydidn’tpigs evolve wings? Although difficult to fig",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Home→Evo-devo→ Constraints on evolutionary changeA lineage’s development may limit the sorts ofphenotypesthat it can evolve. This limitation is called a developmental constraint.The idea of constraint helps us explain why some thingsdidn’thappen in evolution that we might think would be advantageous: whydidn’tanytetrapodsevolve more than five real fingers and toes, whydidn’tcaterpillars evolve to have the complex eye of adult butterflies, and whydidn’tpigs evolve wings? Although difficult to fig",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "A lineage’s development may limit the sorts ofphenotypesthat it can evolve. This limitation is called a developmental constraint.The idea of constraint helps us explain why some thingsdidn’thappen in evolution that we might think would be advantageous: whydidn’tanytetrapodsevolve more than five real fingers and toes, whydidn’tcaterpillars evolve to have the complex eye of adult butterflies, and whydidn’tpigs evolve wings? Although difficult to figure out, the answers to these questions likely ha",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "A lineage’s development may limit the sorts ofphenotypesthat it can evolve. This limitation is called a developmental constraint.The idea of constraint helps us explain why some thingsdidn’thappen in evolution that we might think would be advantageous: whydidn’tanytetrapodsevolve more than five real fingers and toes, whydidn’tcaterpillars evolve to have the complex eye of adult butterflies, and whydidn’tpigs evolve wings? Although difficult to figure out, the answers to these questions likely ha",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://verbit.ai/transcription/full-transcription-style-guide/",
      "title": "Transcription Guidelines for Professionals",
      "author": "Danielle Chazen",
      "published_date": "2024-05-01T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<article>\n<div>\n<p><span>Serving as an effective stenographer or professional transcriptionist requires both skill and speed. In addition to personal preferences for how to tackle projects efficiently, there are <strong>transcription guidelines</strong> and <strong>transcription rules</strong> to be aware of when producing materials.</span><span><br/>\n</span><span><br/>\n</span><span>For example, there are many transcription nuances to consider. Is there a correct way to handle transcribing numbers? Do you know how to timestamp transcriptions in media? Transcription details, use cases and requirements are seemingly endless. These include meeting legal requirements to ensure transcripts are admissible in court, writing a <a href=\"https://verbit.ai/interview-transcription/\">transcript of an interview for media purposes</a> and transcribing verbal statements from courses for students who are hearing impaired. </span><span>We’ve assembled high-level transcription guidelines with general tips to help professionals succeed. Many of these tips may seem intuitive, but they’re worth noting.</span><span><br/>\n</span></p>\n<h2><strong>Transcription Rules and Guidelines</strong></h2>\n<h3><strong>Do: Research difficult words</strong></h3>\n<p><span>With the quick-paced nature of this profession, it’s common to not catch or understand certain words you are transcribing the first time around. If you encounter </span><span>difficult words, context should never be guessed. If you encounter a speech or a term that is unclear, try to resolve it with research. You may also hear the term clearer in another location in the audio. If it’s still unclear, it’s good practice to use an [inaudible] tag. Sometimes, you may need to do a research search, such as looking for terms on Wikipedia, Google or Bing.</span></p>\n<h3><strong>Do: Use appropriate regional spellings</strong></h3>\n<p><span>It’s important to use the appropriate language variation for your location and for the purpose of the transcription. Words spelled differently in the US vs. the UK should be spelled to match the spelling of that region.</span><span><br/>\n</span><b></b></p>\n<h3><strong>Do: Make transcripts verbatim if required</strong></h3>\n<p><span>A <a href=\"https://verbit.ai/verbatim-transcription-101-benefits/\">verbatim transcript</a> includes all</span> <span>dialogue spoken, word for word, including fillers, false starts, incorrect sentences, slang words, stutters and repetitions. When approaching a Verbatim job, you must ensure that everything the speaker utters is written. For stutters (I- I was going), use a dash. For fillers (about the, um, presentation), use a comma. For example, here’s the difference between a clean read vs. verbatim: </span><b><i>Clean read</i></b><i><span>:</span></i><span> “I was about to tell you about the presentation that we saw yesterday.” </span><b><i>Verbatim</i></b><i><span>: </span></i><span>“</span><span>Um, like, I- I was about to tell you, you know, about the presentation that, um, we saw yesterday.”</span><span><br/>\n</span><span><br/>\n</span><b></b></p>\n<h3><strong>Don’t: Paraphrase or change grammar</strong></h3>\n<p><span>Don’t paraphrase or change grammar even if a speaker makes mistakes. </span><span>Use the original speaker words. Don’t alter speaker words even if they’re incorrect grammatically. </span><span>Don’t add or remove any words or information regardless or how relevant or irrelevant they seem. For example, a single word changed can make or break a case when considering transcriptions in legal settings.</span><span><br/>\n</span><b></b></p>\n<h3><strong>Do: Note interrupting noises</strong></h3>\n<p><span>It’s rare for transcripts to not include sound events that interrupt the flow of a lecture, deposition or dialogue. Note any background noise when it occurs with brackets and a short description explaining the sound. A note should also be made for silence when necessary. Try to keep these descriptors at one-to-three words. Examples include: [laughter], [applause], [phone ringing] and [music] for noise, or [silence], [cuts off] or an ellipsis: “I think… John is the one who should be responsible for that payment.” when you encounter silence.</span></p>\n<h3><strong>Do: Take into account transcript structure requirements</strong></h3>\n<p><span>Clients, depending on whether they are <a href=\"https://verbit.ai/disability-coordination/\">academic</a>, legal, media or others, often have specific requirements for the format of their transcripts. From breaking the transcript into paragraphs to how to use spaces to items to keep an eye on for grammar, it’s best to gain knowledge of these requirements ahead of time. Technology-based transcription tools can also help to make customization processes less manual. For example, media entities have specific requirements around timestamps or SMPTE timecodes and </span><a href=\"https://verbit.ai/legal-transcription-2030-what-you-should-know/\"><span>legal agencies</span></a><span> may request speaker differentiation to be presented in specific ways and in custom templates.</span><span><br/>\n</span><b></b></p>\n<h3><strong>Do: Consider using technology, including Artificial Intelligence</strong></h3>\n<p><span>Many technologies have been developed to help speed up <a href=\"https://verbit.ai/solutions-transcription/\">transcription services</a>. Technology can help to ensure both accuracy and speed, so you don’t have to turn away projects and can expand your services. </span><span>The most advanced method of <a href=\"https://verbit.ai/solutions-legal-transcription/\">legal transcription</a></span><span> is AI software, or speech-to-text transcription software. This software utilizes artificial intelligence and machine learning to process audio or video and produce a transcript, often <a href=\"https://verbit.ai/solutions-real-time/\">in real time</a>.</span><span><br/>\n</span><span><br/>\n</span><span>AI-based software allows for an efficient, affordable and accurate <a href=\"https://verbit.ai/how-does-artificial-intelligence-fit-into-the-transcription-process/\">transcription process</a>. Automatic speech recognition machines often self-learn to ‘get smarter’ and recognize more terms to provide more accuracy with each use. Technology can also help to detect difficult terminology or accents and differentiate between speakers accurately in instances when humans may struggle more to detect these differences. Then, transcriptionists can allocate time to fact checking and editing the technology’s work and get time back to work on additional projects. </span><span><br/>\n</span><span><br/>\n</span><span>Therefore, automating the process with technology and <a href=\"https://verbit.ai/\">AI-based transcription software</a> can not only save transcriptionists time, but it can help them reduce operating costs and make more money with the ability to handle more work.</span></p>\n</div>\n</article>\n</div></div>",
        "html": "<div><div>\n<article>\n<div>\n<p><span>Serving as an effective stenographer or professional transcriptionist requires both skill and speed. In addition to personal preferences for how to tackle projects efficiently, there are <strong>transcription guidelines</strong> and <strong>transcription rules</strong> to be aware of when producing materials.</span><span><br/>\n</span><span><br/>\n</span><span>For example, there are many transcription nuances to consider. Is there a correct way to handle transcribing numbers? Do you know how to timestamp transcriptions in media? Transcription details, use cases and requirements are seemingly endless. These include meeting legal requirements to ensure transcripts are admissible in court, writing a <a href=\"https://verbit.ai/interview-transcription/\">transcript of an interview for media purposes</a> and transcribing verbal statements from courses for students who are hearing impaired. </span><span>We’ve assembled high-level transcription guidelines with general tips to help professionals succeed. Many of these tips may seem intuitive, but they’re worth noting.</span><span><br/>\n</span></p>\n<h2><strong>Transcription Rules and Guidelines</strong></h2>\n<h3><strong>Do: Research difficult words</strong></h3>\n<p><span>With the quick-paced nature of this profession, it’s common to not catch or understand certain words you are transcribing the first time around. If you encounter </span><span>difficult words, context should never be guessed. If you encounter a speech or a term that is unclear, try to resolve it with research. You may also hear the term clearer in another location in the audio. If it’s still unclear, it’s good practice to use an [inaudible] tag. Sometimes, you may need to do a research search, such as looking for terms on Wikipedia, Google or Bing.</span></p>\n<h3><strong>Do: Use appropriate regional spellings</strong></h3>\n<p><span>It’s important to use the appropriate language variation for your location and for the purpose of the transcription. Words spelled differently in the US vs. the UK should be spelled to match the spelling of that region.</span><span><br/>\n</span><b></b></p>\n<h3><strong>Do: Make transcripts verbatim if required</strong></h3>\n<p><span>A <a href=\"https://verbit.ai/verbatim-transcription-101-benefits/\">verbatim transcript</a> includes all</span> <span>dialogue spoken, word for word, including fillers, false starts, incorrect sentences, slang words, stutters and repetitions. When approaching a Verbatim job, you must ensure that everything the speaker utters is written. For stutters (I- I was going), use a dash. For fillers (about the, um, presentation), use a comma. For example, here’s the difference between a clean read vs. verbatim: </span><b><i>Clean read</i></b><i><span>:</span></i><span> “I was about to tell you about the presentation that we saw yesterday.” </span><b><i>Verbatim</i></b><i><span>: </span></i><span>“</span><span>Um, like, I- I was about to tell you, you know, about the presentation that, um, we saw yesterday.”</span><span><br/>\n</span><span><br/>\n</span><b></b></p>\n<h3><strong>Don’t: Paraphrase or change grammar</strong></h3>\n<p><span>Don’t paraphrase or change grammar even if a speaker makes mistakes. </span><span>Use the original speaker words. Don’t alter speaker words even if they’re incorrect grammatically. </span><span>Don’t add or remove any words or information regardless or how relevant or irrelevant they seem. For example, a single word changed can make or break a case when considering transcriptions in legal settings.</span><span><br/>\n</span><b></b></p>\n<h3><strong>Do: Note interrupting noises</strong></h3>\n<p><span>It’s rare for transcripts to not include sound events that interrupt the flow of a lecture, deposition or dialogue. Note any background noise when it occurs with brackets and a short description explaining the sound. A note should also be made for silence when necessary. Try to keep these descriptors at one-to-three words. Examples include: [laughter], [applause], [phone ringing] and [music] for noise, or [silence], [cuts off] or an ellipsis: “I think… John is the one who should be responsible for that payment.” when you encounter silence.</span></p>\n<h3><strong>Do: Take into account transcript structure requirements</strong></h3>\n<p><span>Clients, depending on whether they are <a href=\"https://verbit.ai/disability-coordination/\">academic</a>, legal, media or others, often have specific requirements for the format of their transcripts. From breaking the transcript into paragraphs to how to use spaces to items to keep an eye on for grammar, it’s best to gain knowledge of these requirements ahead of time. Technology-based transcription tools can also help to make customization processes less manual. For example, media entities have specific requirements around timestamps or SMPTE timecodes and </span><a href=\"https://verbit.ai/legal-transcription-2030-what-you-should-know/\"><span>legal agencies</span></a><span> may request speaker differentiation to be presented in specific ways and in custom templates.</span><span><br/>\n</span><b></b></p>\n<h3><strong>Do: Consider using technology, including Artificial Intelligence</strong></h3>\n<p><span>Many technologies have been developed to help speed up <a href=\"https://verbit.ai/solutions-transcription/\">transcription services</a>. Technology can help to ensure both accuracy and speed, so you don’t have to turn away projects and can expand your services. </span><span>The most advanced method of <a href=\"https://verbit.ai/solutions-legal-transcription/\">legal transcription</a></span><span> is AI software, or speech-to-text transcription software. This software utilizes artificial intelligence and machine learning to process audio or video and produce a transcript, often <a href=\"https://verbit.ai/solutions-real-time/\">in real time</a>.</span><span><br/>\n</span><span><br/>\n</span><span>AI-based software allows for an efficient, affordable and accurate <a href=\"https://verbit.ai/how-does-artificial-intelligence-fit-into-the-transcription-process/\">transcription process</a>. Automatic speech recognition machines often self-learn to ‘get smarter’ and recognize more terms to provide more accuracy with each use. Technology can also help to detect difficult terminology or accents and differentiate between speakers accurately in instances when humans may struggle more to detect these differences. Then, transcriptionists can allocate time to fact checking and editing the technology’s work and get time back to work on additional projects. </span><span><br/>\n</span><span><br/>\n</span><span>Therefore, automating the process with technology and <a href=\"https://verbit.ai/\">AI-based transcription software</a> can not only save transcriptionists time, but it can help them reduce operating costs and make more money with the ability to handle more work.</span></p>\n</div>\n</article>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Serving as an effective stenographer or professional transcriptionist requires both skill and speed. In addition to personal preferences for how to tackle projects efficiently, there aretranscription guidelinesandtranscription rulesto be aware of when producing materials.For example, there are many transcription nuances to consider. Is there a correct way to handle transcribing numbers? Do you know how to timestamp transcriptions in media? Transcription details, use cases and requirements are se",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Serving as an effective stenographer or professional transcriptionist requires both skill and speed. In addition to personal preferences for how to tackle projects efficiently, there aretranscription guidelinesandtranscription rulesto be aware of when producing materials.For example, there are many transcription nuances to consider. Is there a correct way to handle transcribing numbers? Do you know how to timestamp transcriptions in media? Transcription details, use cases and requirements are se",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "Serving as an effective stenographer or professional transcriptionist requires both skill and speed. In addition to personal preferences for how to tackle projects efficiently, there aretranscription guidelinesandtranscription rulesto be aware of when producing materials.For example, there are many transcription nuances to consider. Is there a correct way to handle transcribing numbers? Do you know how to timestamp transcriptions in media? Transcription details, use cases and requirements are se",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Serving as an effective stenographer or professional transcriptionist requires both skill and speed. In addition to personal preferences for how to tackle projects efficiently, there aretranscription guidelinesandtranscription rulesto be aware of when producing materials.For example, there are many transcription nuances to consider. Is there a correct way to handle transcribing numbers? Do you know how to timestamp transcriptions in media? Transcription details, use cases and requirements are se",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Transcription Rules and Guidelines",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Do: Research difficult words",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Do: Use appropriate regional spellings",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Do: Make transcripts verbatim if required",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Don’t: Paraphrase or change grammar",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Do: Note interrupting noises",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Do: Take into account transcript structure requirements",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Do: Consider using technology, including Artificial Intelligence",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://www.linkedin.com/pulse/everything-transcription-guidelines-transcribers-mahesh-kumar",
      "title": "Everything About Transcription Guidelines for Transcribers",
      "author": "Mahesh Kumar",
      "published_date": "2018-03-09T20:16:32.000Z",
      "content": {
        "text": "<div><div>\n<div>\n<article>\n<figure>\n</figure>\n<header>\n<div>\n<p><a href=\"https://www.linkedin.com/in/team-tci\">\n<span>\nMahesh Kumar\n</span>\n</a></p><div>\n<h3>\nMahesh Kumar\n</h3>\n<h4>\nSpokesperson at Transcription Certification Institute\n</h4>\n<p>\nPublished Oct 12, 2017\n</p>\n</div>\n</div>\n</header>\n<div><p>When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.</p>\n<p><strong>Note:</strong> Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work.</p>\n<p>Most companies offer a base pay amount for their jobs. There is also a score-based bonus transcribers can earn by doing better work i.e. following formatting guidelines, special instructions and returning work early.</p>\n<p>Any submission that does not meet the company’s minimum requirements may be rejected. Some companies will allow you to redo the job while others will assign it to other transcribers. Rejected work may not be paid for. Therefore, you should carefully learn and master the transcription style guide of the company you are working for.</p>\n<p>Let’s get started with the basics.</p>\n<h3>Basic Transcription Guidelines</h3>\n<ol>\n<li><strong>Accuracy.</strong> Only type the words that are spoken in the audio file. Phrases or words you don’t understand should not be omitted. Instead, they should be tagged appropriately according to the company’s guidelines.</li>\n<li><strong>US English.</strong> Use proper US English capitalization, punctuation and spelling. Do not write phonetics or netspeak such as “u” for “you’.</li>\n<li><strong>Do Not Paraphrase.</strong> Do not correct the speaker’s grammar nor rearrange words. Also, do not cut words that you think are off-topic or irrelevant. Any words not spoken should not be included. Type the actual words spoken.</li>\n<li><strong>Do Not Add Additional Information.</strong> Do not add additional information such as page numbers, job numbers, titles or your comments in your submission. Such information can be added in separate fields below the transcript.</li>\n<li><strong>“Clean Up” Non-Verbatim Jobs.</strong> Lightly edit non-verbatim work to remove false starts, filler, and stutters. Check the company’s guidelines on what should be removed.</li>\n<li><strong>Verbatim Work Should Be Truly Verbatim.</strong> When transcribing verbatim work, include every utterance and sound exactly as you hear. Unless directed in the work’s “Notes” section, all filler words should be included. Also, transcribe stutters as accurately as possible.</li>\n</ol>\n<h3>Transcript Formatting</h3>\n<p>In most cases, the file you will be transcribing will be part of a larger audio file. Transcription companies require transcribers to deliver consistent results from one file to the next. This is why they have format transcripts.</p>\n<p><strong>Note:</strong> Check the format transcript rules of the transcription company you wish to work with.</p>\n<p>Here is a rundown of the general transcription format guidelines.</p>\n<h3>Sentence and Paragraph Structure</h3>\n<ul>\n<li>Use word wrap when writing. Fix any line breaks in the middle of your paragraphs before submitting the work.</li>\n<li>Do not use double spaces after sentences or anywhere else. You can use Search &amp; Replace function in your word processor to change all double spaces to single ones.</li>\n<li>Follow correct grammar. All sentences should start with a capital letter and have the correct punctuation.</li>\n<li>Where possible, break compound sentences into smaller ones. Long sentences should be broken into fragments.</li>\n<li>Keep your paragraphs short to a maximum of 400 characters.</li>\n<li>Insert a blank line between paragraphs. Also, start a new paragraph at every speaker change.</li>\n<li>Do not indent anything.</li>\n</ul>\n<h3>Conjunctions</h3>\n<p>Conjunctions such as “so”, “or”, “but”, “because”, “and” and others are used to join two parts of a sentence together. Whenever possible, do not start a sentence with conjunctions. Most of the time, you can cut off the words without changing the meaning of a sentence.</p>\n<p>Conjunctions should only be used at the start of a sentence if omitting them will change the meaning.</p>\n<h3>Speaker Labels</h3>\n<p>Speaker labels are words used to identify a person speaking in an audio. The label is usually the speaker’s name, role or other identifying attribute.</p>\n<ul>\n<li>Use speaker labels to identify a speaker as specifically as possible</li>\n<li>Format speaker labels correctly according to the company’s rules</li>\n</ul>\n<p>The speaker label should be followed by a colon and space. Also, capitalize each speaker label word.</p>\n<h3>Example</h3>\n<p>Interviewer: Hello, and welcome. I’m Jack. And you are?</p>\n<p>Woman 1: I’m Rachel</p>\n<p>Woman 2: I’m Samantha</p>\n<p>Let’s wind up this guideline with both basic and verbatim interview transcription examples.</p>\n<h3>Basic Transcription Example</h3>\n<p>With basic transcripts, filler words, conjunctions that start sentences and false starts should be removed from your transcript e.g.</p>\n<h3>Original Audio</h3>\n<p>Jack: It was quite, it was quite challenging to ride a horse for the first time.</p>\n<p>Transcribed Audio</p>\n<p>Jack: It was quite challenging to ride a horse for the first time.</p>\n<h3>Verbatim Transcription Example</h3>\n<p>With verbatim transcripts, all words you hear should be typed as they are. These include conjunctions, filler words and unobtrusive sound events (e.g. car sounds) that can be heard.</p>\n<p>Here is an example:</p>\n<h3>Transcribed Audio</h3>\n<p>[dog barks]</p>\n<p><strong>Paul:</strong> If only I had come earlier, I wouldn’t have missed a spot.</p>\n<p><strong>Annie:</strong> Oh, that’s really sad</p>\n<p>[dog barks]</p>\n<p>Transcription companies may have specific guidelines to be followed. Go through the guidelines, even if you have experience transcribing before, as there may be different rules to follow. The guidelines are usually comprehensive. You can create a cheat sheet to refer to when transcribing the company’s work.</p>\n<p><em>The article has been previously published on TCI Blog as </em><a href=\"https://blog.transcriptioncertificationinstitute.org/transcription-guidelines-transcribers/\"><em>Everything About Transcription Guidelines for Transcribers</em></a><em>.</em></p>\n</div>\n</article>\n<section>\n<h2>\nMore articles by Mahesh Kumar\n</h2>\n<div>\n<ul>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/conversation-stacy-caprio-owner-herceo-mahesh-kumar\">\n<span>\nIn Conversation with Stacy Caprio, Owner of HER.CEO\n</span>\n</a></p>\n<div>\n<p><span>Aug 11, 2020</span>\n</p>\n<h3>\nIn Conversation with Stacy Caprio, Owner of HER.CEO\n</h3>\n<p>\nStacy is a business and life coach as well as a marketing guru. She is the founder of Her.\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/beth-worthy-president-gmr-transcription-what-companies-mahesh-kumar\">\n<span>\nBeth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...\n</span>\n</a></p>\n<div>\n<p><span>Jul 8, 2020</span>\n</p>\n<h3>\nBeth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...\n</h3>\n<p>\nWe just launched our podcast channel and Beth Worthy, President of GMR Transcription, is our first guest. Beth joined…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/hiring-transcriber-matching-employers-mahesh-kumar\">\n<span>\nHiring a Transcriber: Matching Transcriptionists/Translators with Employers\n</span>\n</a></p>\n<div>\n<p><span>Mar 14, 2019</span>\n</p>\n<h3>\nHiring a Transcriber: Matching Transcriptionists/Translators with Employers\n</h3>\n<p>\nLand your dream work from home transcribing jobs or hire a transcriber that fits your need through TCI Job Board. Are…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/how-land-your-first-client-freelance-transcription-mahesh-kumar\">\n<span>\nHow to Land Your First Client for Freelance Transcription\n</span>\n</a></p>\n<div>\n<p><span>Nov 15, 2018</span>\n</p>\n<h3>\nHow to Land Your First Client for Freelance Transcription\n</h3>\n<p>\nGetting your first freelance business transcription client can be a challenge. You need to take action and not give up…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/10-transcription-companies-pay-12-more-per-hour-mahesh-kumar\">\n<span>\n10 Transcription Companies That Pay $12 &amp; More Per Hour\n</span>\n</a></p>\n<div>\n<p><span>Jul 13, 2018</span>\n</p>\n<h3>\n10 Transcription Companies That Pay $12 &amp; More Per Hour\n</h3>\n<p>\nDo you know that transcription is one of the most searched for and popular work at home jobs due to its flexibility?…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/how-get-transcription-job-complete-guide-part-2-mahesh-kumar\">\n<span>\nHow To Get A Transcription Job – A Complete Guide [Part 2]\n</span>\n</a></p>\n<div>\n<p><span>May 14, 2018</span>\n</p>\n<h3>\nHow To Get A Transcription Job – A Complete Guide [Part 2]\n</h3>\n<p>\nIn case you have missed out on our previous segment of the series to get started as a transcriptionist, please check it…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/how-get-started-transcriptionist-complete-guide-part-1-mahesh-kumar\">\n<span>\nHow To Get Started As A Transcriptionist – A Complete Guide [Part 1]\n</span>\n</a></p>\n<div>\n<p><span>Mar 6, 2018</span>\n</p>\n<h3>\nHow To Get Started As A Transcriptionist – A Complete Guide [Part 1]\n</h3>\n<p>\nBecoming a transcriptionist is a very straightforward way for people to make money from home. However, getting started…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/myths-transcription-indust",
        "html": "<div><div>\n<div>\n<article>\n<figure>\n</figure>\n<header>\n<div>\n<p><a href=\"https://www.linkedin.com/in/team-tci\">\n<span>\nMahesh Kumar\n</span>\n</a></p><div>\n<h3>\nMahesh Kumar\n</h3>\n<h4>\nSpokesperson at Transcription Certification Institute\n</h4>\n<p>\nPublished Oct 12, 2017\n</p>\n</div>\n</div>\n</header>\n<div><p>When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.</p>\n<p><strong>Note:</strong> Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work.</p>\n<p>Most companies offer a base pay amount for their jobs. There is also a score-based bonus transcribers can earn by doing better work i.e. following formatting guidelines, special instructions and returning work early.</p>\n<p>Any submission that does not meet the company’s minimum requirements may be rejected. Some companies will allow you to redo the job while others will assign it to other transcribers. Rejected work may not be paid for. Therefore, you should carefully learn and master the transcription style guide of the company you are working for.</p>\n<p>Let’s get started with the basics.</p>\n<h3>Basic Transcription Guidelines</h3>\n<ol>\n<li><strong>Accuracy.</strong> Only type the words that are spoken in the audio file. Phrases or words you don’t understand should not be omitted. Instead, they should be tagged appropriately according to the company’s guidelines.</li>\n<li><strong>US English.</strong> Use proper US English capitalization, punctuation and spelling. Do not write phonetics or netspeak such as “u” for “you’.</li>\n<li><strong>Do Not Paraphrase.</strong> Do not correct the speaker’s grammar nor rearrange words. Also, do not cut words that you think are off-topic or irrelevant. Any words not spoken should not be included. Type the actual words spoken.</li>\n<li><strong>Do Not Add Additional Information.</strong> Do not add additional information such as page numbers, job numbers, titles or your comments in your submission. Such information can be added in separate fields below the transcript.</li>\n<li><strong>“Clean Up” Non-Verbatim Jobs.</strong> Lightly edit non-verbatim work to remove false starts, filler, and stutters. Check the company’s guidelines on what should be removed.</li>\n<li><strong>Verbatim Work Should Be Truly Verbatim.</strong> When transcribing verbatim work, include every utterance and sound exactly as you hear. Unless directed in the work’s “Notes” section, all filler words should be included. Also, transcribe stutters as accurately as possible.</li>\n</ol>\n<h3>Transcript Formatting</h3>\n<p>In most cases, the file you will be transcribing will be part of a larger audio file. Transcription companies require transcribers to deliver consistent results from one file to the next. This is why they have format transcripts.</p>\n<p><strong>Note:</strong> Check the format transcript rules of the transcription company you wish to work with.</p>\n<p>Here is a rundown of the general transcription format guidelines.</p>\n<h3>Sentence and Paragraph Structure</h3>\n<ul>\n<li>Use word wrap when writing. Fix any line breaks in the middle of your paragraphs before submitting the work.</li>\n<li>Do not use double spaces after sentences or anywhere else. You can use Search &amp; Replace function in your word processor to change all double spaces to single ones.</li>\n<li>Follow correct grammar. All sentences should start with a capital letter and have the correct punctuation.</li>\n<li>Where possible, break compound sentences into smaller ones. Long sentences should be broken into fragments.</li>\n<li>Keep your paragraphs short to a maximum of 400 characters.</li>\n<li>Insert a blank line between paragraphs. Also, start a new paragraph at every speaker change.</li>\n<li>Do not indent anything.</li>\n</ul>\n<h3>Conjunctions</h3>\n<p>Conjunctions such as “so”, “or”, “but”, “because”, “and” and others are used to join two parts of a sentence together. Whenever possible, do not start a sentence with conjunctions. Most of the time, you can cut off the words without changing the meaning of a sentence.</p>\n<p>Conjunctions should only be used at the start of a sentence if omitting them will change the meaning.</p>\n<h3>Speaker Labels</h3>\n<p>Speaker labels are words used to identify a person speaking in an audio. The label is usually the speaker’s name, role or other identifying attribute.</p>\n<ul>\n<li>Use speaker labels to identify a speaker as specifically as possible</li>\n<li>Format speaker labels correctly according to the company’s rules</li>\n</ul>\n<p>The speaker label should be followed by a colon and space. Also, capitalize each speaker label word.</p>\n<h3>Example</h3>\n<p>Interviewer: Hello, and welcome. I’m Jack. And you are?</p>\n<p>Woman 1: I’m Rachel</p>\n<p>Woman 2: I’m Samantha</p>\n<p>Let’s wind up this guideline with both basic and verbatim interview transcription examples.</p>\n<h3>Basic Transcription Example</h3>\n<p>With basic transcripts, filler words, conjunctions that start sentences and false starts should be removed from your transcript e.g.</p>\n<h3>Original Audio</h3>\n<p>Jack: It was quite, it was quite challenging to ride a horse for the first time.</p>\n<p>Transcribed Audio</p>\n<p>Jack: It was quite challenging to ride a horse for the first time.</p>\n<h3>Verbatim Transcription Example</h3>\n<p>With verbatim transcripts, all words you hear should be typed as they are. These include conjunctions, filler words and unobtrusive sound events (e.g. car sounds) that can be heard.</p>\n<p>Here is an example:</p>\n<h3>Transcribed Audio</h3>\n<p>[dog barks]</p>\n<p><strong>Paul:</strong> If only I had come earlier, I wouldn’t have missed a spot.</p>\n<p><strong>Annie:</strong> Oh, that’s really sad</p>\n<p>[dog barks]</p>\n<p>Transcription companies may have specific guidelines to be followed. Go through the guidelines, even if you have experience transcribing before, as there may be different rules to follow. The guidelines are usually comprehensive. You can create a cheat sheet to refer to when transcribing the company’s work.</p>\n<p><em>The article has been previously published on TCI Blog as </em><a href=\"https://blog.transcriptioncertificationinstitute.org/transcription-guidelines-transcribers/\"><em>Everything About Transcription Guidelines for Transcribers</em></a><em>.</em></p>\n</div>\n</article>\n<section>\n<h2>\nMore articles by Mahesh Kumar\n</h2>\n<div>\n<ul>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/conversation-stacy-caprio-owner-herceo-mahesh-kumar\">\n<span>\nIn Conversation with Stacy Caprio, Owner of HER.CEO\n</span>\n</a></p>\n<div>\n<p><span>Aug 11, 2020</span>\n</p>\n<h3>\nIn Conversation with Stacy Caprio, Owner of HER.CEO\n</h3>\n<p>\nStacy is a business and life coach as well as a marketing guru. She is the founder of Her.\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/beth-worthy-president-gmr-transcription-what-companies-mahesh-kumar\">\n<span>\nBeth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...\n</span>\n</a></p>\n<div>\n<p><span>Jul 8, 2020</span>\n</p>\n<h3>\nBeth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...\n</h3>\n<p>\nWe just launched our podcast channel and Beth Worthy, President of GMR Transcription, is our first guest. Beth joined…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/hiring-transcriber-matching-employers-mahesh-kumar\">\n<span>\nHiring a Transcriber: Matching Transcriptionists/Translators with Employers\n</span>\n</a></p>\n<div>\n<p><span>Mar 14, 2019</span>\n</p>\n<h3>\nHiring a Transcriber: Matching Transcriptionists/Translators with Employers\n</h3>\n<p>\nLand your dream work from home transcribing jobs or hire a transcriber that fits your need through TCI Job Board. Are…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/how-land-your-first-client-freelance-transcription-mahesh-kumar\">\n<span>\nHow to Land Your First Client for Freelance Transcription\n</span>\n</a></p>\n<div>\n<p><span>Nov 15, 2018</span>\n</p>\n<h3>\nHow to Land Your First Client for Freelance Transcription\n</h3>\n<p>\nGetting your first freelance business transcription client can be a challenge. You need to take action and not give up…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/10-transcription-companies-pay-12-more-per-hour-mahesh-kumar\">\n<span>\n10 Transcription Companies That Pay $12 &amp; More Per Hour\n</span>\n</a></p>\n<div>\n<p><span>Jul 13, 2018</span>\n</p>\n<h3>\n10 Transcription Companies That Pay $12 &amp; More Per Hour\n</h3>\n<p>\nDo you know that transcription is one of the most searched for and popular work at home jobs due to its flexibility?…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/how-get-transcription-job-complete-guide-part-2-mahesh-kumar\">\n<span>\nHow To Get A Transcription Job – A Complete Guide [Part 2]\n</span>\n</a></p>\n<div>\n<p><span>May 14, 2018</span>\n</p>\n<h3>\nHow To Get A Transcription Job – A Complete Guide [Part 2]\n</h3>\n<p>\nIn case you have missed out on our previous segment of the series to get started as a transcriptionist, please check it…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/how-get-started-transcriptionist-complete-guide-part-1-mahesh-kumar\">\n<span>\nHow To Get Started As A Transcriptionist – A Complete Guide [Part 1]\n</span>\n</a></p>\n<div>\n<p><span>Mar 6, 2018</span>\n</p>\n<h3>\nHow To Get Started As A Transcriptionist – A Complete Guide [Part 1]\n</h3>\n<p>\nBecoming a transcriptionist is a very straightforward way for people to make money from home. However, getting started…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/myths-transcription-indust",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Mahesh KumarMahesh KumarSpokesperson at Transcription Certification InstitutePublished Oct 12, 2017When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.Note:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mahesh KumarMahesh KumarSpokesperson at Transcription Certification InstitutePublished Oct 12, 2017When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.Note:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mahesh KumarMahesh KumarSpokesperson at Transcription Certification InstitutePublished Oct 12, 2017When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.Note:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transc",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "Mahesh KumarMahesh KumarSpokesperson at Transcription Certification InstitutePublished Oct 12, 2017When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.Note:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mahesh KumarMahesh KumarSpokesperson at Transcription Certification InstitutePublished Oct 12, 2017",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mahesh KumarSpokesperson at Transcription Certification InstitutePublished Oct 12, 2017",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "When getting started as a transcriber, you may be confused about the rules to follow, how to format your transcripts and when to use colloquial expressions. Read on for an introduction to basic transcription guidelines.Note:Different transcription companies may have specific additional rules to be followed. You should confirm and conform to the rules of the company where you are applying for transcription work.Most companies offer a base pay amount for their jobs. There is also a score-based bon",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "More articles by Mahesh KumarIn Conversation with Stacy Caprio, Owner of HER.CEOAug 11, 2020In Conversation with Stacy Caprio, Owner of HER.CEOStacy is a business and life coach as well as a marketing guru. She is the founder of Her.Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...Jul 8, 2020Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...We just launched our podcast channel and Beth Worthy, ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "In Conversation with Stacy Caprio, Owner of HER.CEOAug 11, 2020In Conversation with Stacy Caprio, Owner of HER.CEOStacy is a business and life coach as well as a marketing guru. She is the founder of Her.Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...Jul 8, 2020Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...We just launched our podcast channel and Beth Worthy, President of GMR Transcriptio",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "In Conversation with Stacy Caprio, Owner of HER.CEOAug 11, 2020In Conversation with Stacy Caprio, Owner of HER.CEOStacy is a business and life coach as well as a marketing guru. She is the founder of Her.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Aug 11, 2020In Conversation with Stacy Caprio, Owner of HER.CEOStacy is a business and life coach as well as a marketing guru. She is the founder of Her.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...Jul 8, 2020Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...We just launched our podcast channel and Beth Worthy, President of GMR Transcription, is our first guest. Beth joined…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jul 8, 2020Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...We just launched our podcast channel and Beth Worthy, President of GMR Transcription, is our first guest. Beth joined…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Hiring a Transcriber: Matching Transcriptionists/Translators with EmployersMar 14, 2019Hiring a Transcriber: Matching Transcriptionists/Translators with EmployersLand your dream work from home transcribing jobs or hire a transcriber that fits your need through TCI Job Board. Are…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mar 14, 2019Hiring a Transcriber: Matching Transcriptionists/Translators with EmployersLand your dream work from home transcribing jobs or hire a transcriber that fits your need through TCI Job Board. Are…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "How to Land Your First Client for Freelance TranscriptionNov 15, 2018How to Land Your First Client for Freelance TranscriptionGetting your first freelance business transcription client can be a challenge. You need to take action and not give up…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Nov 15, 2018How to Land Your First Client for Freelance TranscriptionGetting your first freelance business transcription client can be a challenge. You need to take action and not give up…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "10 Transcription Companies That Pay $12 & More Per HourJul 13, 201810 Transcription Companies That Pay $12 & More Per HourDo you know that transcription is one of the most searched for and popular work at home jobs due to its flexibility?…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jul 13, 201810 Transcription Companies That Pay $12 & More Per HourDo you know that transcription is one of the most searched for and popular work at home jobs due to its flexibility?…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "How To Get A Transcription Job – A Complete Guide [Part 2]May 14, 2018How To Get A Transcription Job – A Complete Guide [Part 2]In case you have missed out on our previous segment of the series to get started as a transcriptionist, please check it…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "May 14, 2018How To Get A Transcription Job – A Complete Guide [Part 2]In case you have missed out on our previous segment of the series to get started as a transcriptionist, please check it…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "How To Get Started As A Transcriptionist – A Complete Guide [Part 1]Mar 6, 2018How To Get Started As A Transcriptionist – A Complete Guide [Part 1]Becoming a transcriptionist is a very straightforward way for people to make money from home. However, getting started…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mar 6, 2018How To Get Started As A Transcriptionist – A Complete Guide [Part 1]Becoming a transcriptionist is a very straightforward way for people to make money from home. However, getting started…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "<a href=\"https://www.linkedin.com/pulse/myths-transcription-indust",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "Mahesh Kumar",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Spokesperson at Transcription Certification Institute",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Basic Transcription Guidelines",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Transcript Formatting",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Sentence and Paragraph Structure",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Conjunctions",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Speaker Labels",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Example",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Basic Transcription Example",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Original Audio",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Verbatim Transcription Example",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Transcribed Audio",
              "id": ""
            },
            {
              "level": "h2",
              "text": "More articles by Mahesh Kumar",
              "id": ""
            },
            {
              "level": "h3",
              "text": "In Conversation with Stacy Caprio, Owner of HER.CEO",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Beth Worthy: President, GMR Transcription On What Companies Look for In Transcriptionists and More...",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Hiring a Transcriber: Matching Transcriptionists/Translators with Employers",
              "id": ""
            },
            {
              "level": "h3",
              "text": "How to Land Your First Client for Freelance Transcription",
              "id": ""
            },
            {
              "level": "h3",
              "text": "10 Transcription Companies That Pay $12 & More Per Hour",
              "id": ""
            },
            {
              "level": "h3",
              "text": "How To Get A Transcription Job – A Complete Guide [Part 2]",
              "id": ""
            },
            {
              "level": "h3",
              "text": "How To Get Started As A Transcriptionist – A Complete Guide [Part 1]",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://www.dittotranscripts.com/blog/4-must-know-legal-transcription-rules-to-avoid-disaster/",
      "title": "4 Must-Know Legal Transcription Rules To Avoid Disaster - Ditto",
      "author": "Ben Walker",
      "published_date": "2025-01-03T09:02:41.000Z",
      "content": {
        "text": "<div><div>\n<p>The legal world drowns in endless spoken words that cry out for crystal-clear documentation—every court hearing, witness interview, deposition, and so on hangs in the balance. <strong>Fortunately, successful law firms now turn to </strong><a href=\"https://www.dittotranscripts.com/transcription-services/legal/\"><strong>legal transcription companies</strong></a><strong> to convert this verbal chaos into precise, court-ready documentation.</strong> However, one must consider if the company knows the legal transcription rules. Formatting, style, word choice, legalese, and several other factors must be kept precise and follow guidelines to the letter.</p>\n<p>Otherwise, you run the risk of negating the value of your transcription efforts. </p>\n<p><strong>In this article, you’ll learn how:</strong></p>\n<ul>\n<li>Transcriptionists must never correct grammar in verbatim transcription, even if incorrect, as speech patterns can provide important context.</li>\n<li>All background noises and non-verbal sounds must be documented. These can serve as timeline markers in legal proceedings.</li>\n<li>Every filler word (“um,” “uh,” “like”) must be included, as these verbal tics can indicate witness credibility, deception, or state of mind during testimony.</li>\n</ul>\n<h2><strong>What Is Legal Transcription?</strong></h2>\n<p>Legal transcription converts spoken words from audio and video recordings of any event in an official legal setting. <strong>Such events include </strong><a href=\"https://www.dittotranscripts.com/blog/virtual-court-hearings/\"><strong>virtual court hearings</strong></a><strong>, witness interviews, depositions, etc. Crucially, transcription happens after the event. </strong></p>\n<p>Legal transcribers can be self-employed or work for a transcription company. If they work for a transcription company, the transcriptionists usually have access to technology that court reporters don’t have, such as cloud hosting for documents, online systems for downloading and completing dictations, etc. <strong>This is important, as a court reporter can lose the transcript and recording of a trial.</strong> Today, however, it’s commonplace for a court to retain the tapes, and the court reporter obtains a copy when available.</p>\n<p><strong>That’s not to say that legal transcription is less important than court reporting</strong>. Cases can hinge on the quality and accuracy of legal transcripts, and incorrect transcription has led to notable errors in the justice system, such as a guilty party being set free or an innocent person being imprisoned. </p>\n<p>This is why a legal transcriptionist must maintain accuracy with all projects. They need to understand the terminology and legal procedures and be proficient in transcription.</p>\n<h2><strong>Most Common Types of Legal Transcription</strong></h2>\n<p>There are several types of transcription in legal settings, and the most utilized ones are listed below.</p>\n<figure><table><tbody><tr><td><strong>Types</strong></td><td><strong>Description</strong></td></tr><tr><td>Pleadings</td><td>Written statements that outline legal claims or defenses.</td></tr><tr><td>Subpoenas</td><td>Legal demands for witness testimony or evidence.</td></tr><tr><td>Summonses</td><td>Official notices to appear in court or respond to legal action.</td></tr><tr><td>Depositions</td><td>Sworn out-of-court testimony from witnesses.</td></tr><tr><td>Interrogations</td><td>Formal questioning sessions, typically in criminal cases.</td></tr><tr><td>Hearings</td><td>Official court proceedings before a judge.</td></tr><tr><td>Wiretaps and Phone Calls</td><td>Recorded conversations obtained through legal surveillance.</td></tr><tr><td>Memorandums</td><td>Internal legal documents outlining case details or arguments.</td></tr></tbody></table></figure>\n<h2><strong>Why Are Legal Transcription Rules Important?</strong></h2>\n<p>Even though it’s much more complicated,<strong> you can think of legal transcription rules as the guardrails keeping justice from careening off a cliff of misinterpretation</strong>. These aren’t arbitrary requirements dreamed up by particularly persnickety legal professionals.</p>\n<p><strong>Every non-verbal and grammatical disasters captured in a legal transcript could turn into a domino effect, changing the entire outcome of a case</strong>. Imagine a witness whose testimony seems rock-solid on paper yet whose recorded “us” and “ahs” reveal more nervous energy than a caffeinated squirrel – that’s a valuable insight for attorneys and judges alike.</p>\n<p>Or consider how a simple background sound [Door slams] might establish timeline evidence about who was present during the testimony. <strong>Legal transcription rules ensure that these verbal and auditory are preserved with the same care as a crime scene investigator bagging evidence.</strong></p>\n<p>Because in the grand scheme of the law, every cough, stutter, and “like, you know” is part of the show, and professional transcriptionists <strong>are both the audience and the chroniclers of this sometimes-messy human drama.</strong></p>\n<h2><strong>The 4 Rules of Legal Transcription</strong></h2>\n<p><strong>These are the four legal requirements</strong> <strong>of legal transcription. </strong>Consider them as gospel—because the courts certainly will.</p>\n<h3><strong>1. Never “Fix” Grammar in Verbatim Transcription – Even When It Hurts Your Soul</strong></h3>\n<p>I get it – <strong>as a legal transcriptionist, watching someone butcher the English language can feel like watching someone use your favorite book as a coaster. </strong>However, in legal transcription, grammar correction is a big no-no. It doesn’t matter if it’s a Harvard-educated lawyer or someone who thinks “irregardless” is perfectly cromulent; y<strong>ou must transcribe exactly what was said.</strong></p>\n<p>Legal transcription services thrive on accuracy, not perfection. So, when you create a legal document, <strong>your job is to capture the authentic voice of each speaker</strong>, complete with all their linguistic quirks and grammatical faux pas.</p>\n<p><strong>This requirement might seem counterintuitive, especially when transcribing professional legal proceedings</strong>. However, there’s a method to this madness. How someone speaks can provide context about their education level, state of mind, or cultural background – <strong>all of which might be relevant to the case.</strong></p>\n<p><strong>Examples of what must be preserved:</strong></p>\n<ul>\n<li>“Ain’t nobody told me nothing about that.”</li>\n<li>“I seen him when he done it.”</li>\n<li>“We was going to the store.”</li>\n</ul>\n<p>Again, your job isn’t to make people sound like they recently stepped out of an English literature symposium. Your inner grammar nerd might be screaming, yet keep those correction urges firmly in check! <strong>Many of our legal transcriptionists say that learning to suppress their correction instincts was one of the hardest parts of their training.</strong></p>\n<h3><strong>2. Include All Background and Nonverbal Sounds</strong></h3>\n<p>Court proceedings can sound like a symphony of random noises, and guess what?<strong> You’re the conductor who needs to document it all!</strong> Your legal transcript should be so detailed that someone reading it feels like they’re right there in the courtroom.</p>\n<p>This requirement goes far beyond capturing spoken words. Legal transcriptionists must develop a keen ear for every audible detail in the recording. <strong>Why? Because these seemingly trivial sounds can become important evidence.</strong></p>\n<p>Hear me out. That background conversation might reveal witness tampering. That nervous throat-clearing could indicate discomfort with a line of questioning. Even that embarrassing stomach growl might help establish the timeline of a lengthy deposition!</p>\n<p>Professional transcription services often provide their transcribers with specialized software to help capture these nuances. Think of yourself as the David Attenborough of the courtroom, narrating every sound in its natural habitat:</p>\n<ul>\n<li><strong>Physical actions</strong>: [Witness nods], [Attorney shuffles papers]</li>\n<li><strong>Background sounds</strong>: [Door slams], [Phone rings]</li>\n<li><strong>Bodily functions</strong>: [Coughs], [Clears throat], [Stomach audibly growls]</li>\n<li><strong>Emotional responses</strong>: [Laughs], [Cries], [Sighs heavily]</li>\n</ul>\n<p>And yes, that includes when someone’s phone starts playing Bruno Mars’ “Die With A Smile” in the middle of testimony. <strong>Trust me; it happens more often than you’d think in court proceedings</strong> – though not with that song.</p>\n<h3><strong>3. Transcribe All Filler Words – Um, Like, You Know, Everything</strong></h3>\n<p>Those little verbal tics that pepper everyday speech? They’re gold in legal transcription.<strong> Every “um,” “uh,” “like,” and “you know” is a tiny window into someone’s state of mind.</strong> Legal professionals can use these verbal breadcrumbs to analyze everything from witness credibility to deception.</p>\n<p>A witness who rarely uses filler words suddenly peppering their testimony with “ums” and “uhs” might signal discomfort or deception. A deposition where the speaker frequently says “like” might indicate youth or a casual attitude – both potentially relevant to the case. <strong>That’s why professional transcriptionists should treat these verbal hiccups with the same respect as substantive testimony.</strong></p>\n<p>Your transcript becomes part of the official legal record, and these seemingly meaningless utterances could become evidence in appeals or cross-examinations. <strong>While it might make your document look like a teenager’s text message, every utterance serves a purpose:</strong></p>\n<p><strong>What to capture:</strong></p>\n<ul>\n<li>Every single “um” and “uh.”</li>\n<li>All instances of “you know,” “like,” “well.”</li>\n<li>Repeated words: “I, I, I think…”.</li>\n<li>Thinking so",
        "html": "<div><div>\n<p>The legal world drowns in endless spoken words that cry out for crystal-clear documentation—every court hearing, witness interview, deposition, and so on hangs in the balance. <strong>Fortunately, successful law firms now turn to </strong><a href=\"https://www.dittotranscripts.com/transcription-services/legal/\"><strong>legal transcription companies</strong></a><strong> to convert this verbal chaos into precise, court-ready documentation.</strong> However, one must consider if the company knows the legal transcription rules. Formatting, style, word choice, legalese, and several other factors must be kept precise and follow guidelines to the letter.</p>\n<p>Otherwise, you run the risk of negating the value of your transcription efforts. </p>\n<p><strong>In this article, you’ll learn how:</strong></p>\n<ul>\n<li>Transcriptionists must never correct grammar in verbatim transcription, even if incorrect, as speech patterns can provide important context.</li>\n<li>All background noises and non-verbal sounds must be documented. These can serve as timeline markers in legal proceedings.</li>\n<li>Every filler word (“um,” “uh,” “like”) must be included, as these verbal tics can indicate witness credibility, deception, or state of mind during testimony.</li>\n</ul>\n<h2><strong>What Is Legal Transcription?</strong></h2>\n<p>Legal transcription converts spoken words from audio and video recordings of any event in an official legal setting. <strong>Such events include </strong><a href=\"https://www.dittotranscripts.com/blog/virtual-court-hearings/\"><strong>virtual court hearings</strong></a><strong>, witness interviews, depositions, etc. Crucially, transcription happens after the event. </strong></p>\n<p>Legal transcribers can be self-employed or work for a transcription company. If they work for a transcription company, the transcriptionists usually have access to technology that court reporters don’t have, such as cloud hosting for documents, online systems for downloading and completing dictations, etc. <strong>This is important, as a court reporter can lose the transcript and recording of a trial.</strong> Today, however, it’s commonplace for a court to retain the tapes, and the court reporter obtains a copy when available.</p>\n<p><strong>That’s not to say that legal transcription is less important than court reporting</strong>. Cases can hinge on the quality and accuracy of legal transcripts, and incorrect transcription has led to notable errors in the justice system, such as a guilty party being set free or an innocent person being imprisoned. </p>\n<p>This is why a legal transcriptionist must maintain accuracy with all projects. They need to understand the terminology and legal procedures and be proficient in transcription.</p>\n<h2><strong>Most Common Types of Legal Transcription</strong></h2>\n<p>There are several types of transcription in legal settings, and the most utilized ones are listed below.</p>\n<figure><table><tbody><tr><td><strong>Types</strong></td><td><strong>Description</strong></td></tr><tr><td>Pleadings</td><td>Written statements that outline legal claims or defenses.</td></tr><tr><td>Subpoenas</td><td>Legal demands for witness testimony or evidence.</td></tr><tr><td>Summonses</td><td>Official notices to appear in court or respond to legal action.</td></tr><tr><td>Depositions</td><td>Sworn out-of-court testimony from witnesses.</td></tr><tr><td>Interrogations</td><td>Formal questioning sessions, typically in criminal cases.</td></tr><tr><td>Hearings</td><td>Official court proceedings before a judge.</td></tr><tr><td>Wiretaps and Phone Calls</td><td>Recorded conversations obtained through legal surveillance.</td></tr><tr><td>Memorandums</td><td>Internal legal documents outlining case details or arguments.</td></tr></tbody></table></figure>\n<h2><strong>Why Are Legal Transcription Rules Important?</strong></h2>\n<p>Even though it’s much more complicated,<strong> you can think of legal transcription rules as the guardrails keeping justice from careening off a cliff of misinterpretation</strong>. These aren’t arbitrary requirements dreamed up by particularly persnickety legal professionals.</p>\n<p><strong>Every non-verbal and grammatical disasters captured in a legal transcript could turn into a domino effect, changing the entire outcome of a case</strong>. Imagine a witness whose testimony seems rock-solid on paper yet whose recorded “us” and “ahs” reveal more nervous energy than a caffeinated squirrel – that’s a valuable insight for attorneys and judges alike.</p>\n<p>Or consider how a simple background sound [Door slams] might establish timeline evidence about who was present during the testimony. <strong>Legal transcription rules ensure that these verbal and auditory are preserved with the same care as a crime scene investigator bagging evidence.</strong></p>\n<p>Because in the grand scheme of the law, every cough, stutter, and “like, you know” is part of the show, and professional transcriptionists <strong>are both the audience and the chroniclers of this sometimes-messy human drama.</strong></p>\n<h2><strong>The 4 Rules of Legal Transcription</strong></h2>\n<p><strong>These are the four legal requirements</strong> <strong>of legal transcription. </strong>Consider them as gospel—because the courts certainly will.</p>\n<h3><strong>1. Never “Fix” Grammar in Verbatim Transcription – Even When It Hurts Your Soul</strong></h3>\n<p>I get it – <strong>as a legal transcriptionist, watching someone butcher the English language can feel like watching someone use your favorite book as a coaster. </strong>However, in legal transcription, grammar correction is a big no-no. It doesn’t matter if it’s a Harvard-educated lawyer or someone who thinks “irregardless” is perfectly cromulent; y<strong>ou must transcribe exactly what was said.</strong></p>\n<p>Legal transcription services thrive on accuracy, not perfection. So, when you create a legal document, <strong>your job is to capture the authentic voice of each speaker</strong>, complete with all their linguistic quirks and grammatical faux pas.</p>\n<p><strong>This requirement might seem counterintuitive, especially when transcribing professional legal proceedings</strong>. However, there’s a method to this madness. How someone speaks can provide context about their education level, state of mind, or cultural background – <strong>all of which might be relevant to the case.</strong></p>\n<p><strong>Examples of what must be preserved:</strong></p>\n<ul>\n<li>“Ain’t nobody told me nothing about that.”</li>\n<li>“I seen him when he done it.”</li>\n<li>“We was going to the store.”</li>\n</ul>\n<p>Again, your job isn’t to make people sound like they recently stepped out of an English literature symposium. Your inner grammar nerd might be screaming, yet keep those correction urges firmly in check! <strong>Many of our legal transcriptionists say that learning to suppress their correction instincts was one of the hardest parts of their training.</strong></p>\n<h3><strong>2. Include All Background and Nonverbal Sounds</strong></h3>\n<p>Court proceedings can sound like a symphony of random noises, and guess what?<strong> You’re the conductor who needs to document it all!</strong> Your legal transcript should be so detailed that someone reading it feels like they’re right there in the courtroom.</p>\n<p>This requirement goes far beyond capturing spoken words. Legal transcriptionists must develop a keen ear for every audible detail in the recording. <strong>Why? Because these seemingly trivial sounds can become important evidence.</strong></p>\n<p>Hear me out. That background conversation might reveal witness tampering. That nervous throat-clearing could indicate discomfort with a line of questioning. Even that embarrassing stomach growl might help establish the timeline of a lengthy deposition!</p>\n<p>Professional transcription services often provide their transcribers with specialized software to help capture these nuances. Think of yourself as the David Attenborough of the courtroom, narrating every sound in its natural habitat:</p>\n<ul>\n<li><strong>Physical actions</strong>: [Witness nods], [Attorney shuffles papers]</li>\n<li><strong>Background sounds</strong>: [Door slams], [Phone rings]</li>\n<li><strong>Bodily functions</strong>: [Coughs], [Clears throat], [Stomach audibly growls]</li>\n<li><strong>Emotional responses</strong>: [Laughs], [Cries], [Sighs heavily]</li>\n</ul>\n<p>And yes, that includes when someone’s phone starts playing Bruno Mars’ “Die With A Smile” in the middle of testimony. <strong>Trust me; it happens more often than you’d think in court proceedings</strong> – though not with that song.</p>\n<h3><strong>3. Transcribe All Filler Words – Um, Like, You Know, Everything</strong></h3>\n<p>Those little verbal tics that pepper everyday speech? They’re gold in legal transcription.<strong> Every “um,” “uh,” “like,” and “you know” is a tiny window into someone’s state of mind.</strong> Legal professionals can use these verbal breadcrumbs to analyze everything from witness credibility to deception.</p>\n<p>A witness who rarely uses filler words suddenly peppering their testimony with “ums” and “uhs” might signal discomfort or deception. A deposition where the speaker frequently says “like” might indicate youth or a casual attitude – both potentially relevant to the case. <strong>That’s why professional transcriptionists should treat these verbal hiccups with the same respect as substantive testimony.</strong></p>\n<p>Your transcript becomes part of the official legal record, and these seemingly meaningless utterances could become evidence in appeals or cross-examinations. <strong>While it might make your document look like a teenager’s text message, every utterance serves a purpose:</strong></p>\n<p><strong>What to capture:</strong></p>\n<ul>\n<li>Every single “um” and “uh.”</li>\n<li>All instances of “you know,” “like,” “well.”</li>\n<li>Repeated words: “I, I, I think…”.</li>\n<li>Thinking so",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "The legal world drowns in endless spoken words that cry out for crystal-clear documentation—every court hearing, witness interview, deposition, and so on hangs in the balance.Fortunately, successful law firms now turn tolegal transcription companiesto convert this verbal chaos into precise, court-ready documentation.However, one must consider if the company knows the legal transcription rules. Formatting, style, word choice, legalese, and several other factors must be kept precise and follow gui",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The legal world drowns in endless spoken words that cry out for crystal-clear documentation—every court hearing, witness interview, deposition, and so on hangs in the balance.Fortunately, successful law firms now turn tolegal transcription companiesto convert this verbal chaos into precise, court-ready documentation.However, one must consider if the company knows the legal transcription rules. Formatting, style, word choice, legalese, and several other factors must be kept precise and follow gui",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "What Is Legal Transcription?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Most Common Types of Legal Transcription",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Why Are Legal Transcription Rules Important?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "The 4 Rules of Legal Transcription",
              "id": ""
            },
            {
              "level": "h3",
              "text": "1. Never “Fix” Grammar in Verbatim Transcription – Even When It Hurts Your Soul",
              "id": ""
            },
            {
              "level": "h3",
              "text": "2. Include All Background and Nonverbal Sounds",
              "id": ""
            },
            {
              "level": "h3",
              "text": "3. Transcribe All Filler Words – Um, Like, You Know, Everything",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://onlinelibrary.wiley.com/doi/10.1111/mec.17350",
      "title": "Rapid evolutionary adaptation: Potential and constraints",
      "author": "Aurélien Tellier",
      "published_date": "2024-05-01T00:00:00.000Z",
      "content": {
        "text": "<div><section>\n<section>\n<p>The vast diversity of life on earth is the result of evolutionary processes that acted over billions of years. Historically it was assumed that adaptation and the origin of new species required long periods of time. However, it is now well established that adaptation to new environments can occur rapidly and sometimes even within a few generations. We define here rapid adaptation as a selective process, which allows a population or species to substantially improve its average fitness in the short time scale of few tens of generations, typically within a hundred years for annual species. More precisely, rapid adaptation occurs through natural selection acting on the phenotype (and ultimately on the underlying genetic variants) over short time scale and therefore encompasses both ecological (demographic abundance and inter-specific interactions within a given habitat and species community) and evolutionary (genetic drift, mutation, recombination, gene flow and selection) processes (Hairston et al., <span><a href=\"#mec17350-bib-0020\">2005</a></span>; Kokko et al., <span><a href=\"#mec17350-bib-0027\">2017</a></span>). The occurrence and speed of rapid adaptation is thus determined by the feedback between ecological and evolutionary (eco-evo) processes. A large body of literature now documents examples of eco-evo feedbacks driving rapid adaptation especially as consequences of human activities, with damaging consequences in agriculture (e.g. invasion of crop pests and pathogens resistant to fungicides) (Fisher et al., <span><a href=\"#mec17350-bib-0014\">2022</a></span>), medicine (e.g. parasite resistance to drugs/antibiotics) (Birkholtz et al., <span><a href=\"#mec17350-bib-0005\">2022</a></span>; Zhang et al., <span><a href=\"#mec17350-bib-0046\">2022</a></span>) and/or ecosystems (e.g. new invasive species and emergent diseases) (Fisher et al., <span><a href=\"#mec17350-bib-0015\">2012</a></span>). Indeed, rapid adaptation underpins species' invasion of new habitats, coevolution between hosts and their parasites, fluctuating selection due to fast environmental change or adaptation to human-altered environments. Deciphering the evolutionary mechanisms of rapid adaptation is thus critical given the current rate of global change and loss of biodiversity to forecast the evolutionary potential of species and promote ad hoc conservation measures and/or to prevent the emergence of novel and unwanted pathogens. This research endeavour entails two major questions bridging ecological and evolutionary processes and mechanisms: What are the sources of genetic variation for rapid evolution? Which evolutionary, ecological and genetic factors enable (hasten) and which factors constrain (slow down) rapid evolution?</p>\n<p>In this special issue on ‘Rapid evolutionary adaptation: Potential and constraints’ we address these questions by presenting new developments in evolutionary theory concerning rapid evolution and/or in combination with empirical investigations of rapidly evolving systems from all kingdoms of life. Two questions percolate through the studies presented here. The first central question is whether rapid evolution is predominately reliant on small changes in allele frequencies from standing genetic variation at many loci (polygenic adaptation) or on large effect mutations arising either de novo or entering the population through migration. A second important topic is the identification and investigation of factors that constrain rapid evolution such as demographic parameters (e.g. population size), genetic/genomic architecture, life-history traits or environmental heterogeneity. To provide answers to these questions, we grouped the contributions in three main topical parts.</p>\n<p>First, we start with the simple case of adaptation occurring at major genes with major phenotypic effects, which spread through the population by a ‘selective sweep’ mechanism. This mode of positive selection generates fast adaptation as the time to fixation of advantageous alleles can be very short. Two theoretical contributions investigate how a life-history trait, sweepstake reproduction (i.e. reproduction with large variance in offspring production) common to many fish, invertebrates and fungi, can on one hand hasten the fixation of beneficial alleles but on the other hand make it less likely to occur (Eldon &amp; Stephan, <span><a href=\"#mec17350-bib-0013\">2023</a></span>; Korfmann et al., <span><a href=\"#mec17350-bib-0028\">2023</a></span>). Two examples of adaptation (invasion) to new habitats by strong positive selection are then presented in population genomics studies of the fall webworm (FWW; Dai et al., <span><a href=\"#mec17350-bib-0009\">2023</a></span>) and the common hairfin anchovy (<i>Setipinna tenuifilis</i>) (Liu et al., <span><a href=\"#mec17350-bib-0033\">2023</a></span>). Finally, a review summarises findings from genomic studies on the role of transposable elements (TEs) in determining the evolutionary potential of crop pathogens. The dynamics of TEs and the resulting mutational changes play an important role in the fungal mildew pathogen <i>Blumeria</i> of cereal crops to evade crop resistance and promote resistance to fungicides (Kusch et al., <span><a href=\"#mec17350-bib-0029\">2023</a></span>).</p>\n<p>Conversely, in the second part, we focus on the theory and empirical evidence for rapid adaptation via quantitative (polygenic) traits and potential constraints. More precisely, three theoretical papers investigate the core assumptions underpinning and slowing down adaptation by polygenic traits: the existence of (metabolic) trade-offs (Hashemi et al., <span><a href=\"#mec17350-bib-0021\">2023</a></span>; Laitinen &amp; Nikoloski, <span><a href=\"#mec17350-bib-0030\">2023</a></span>) and the effects of epistatic interactions and recombination (Li et al., <span><a href=\"#mec17350-bib-0032\">2023</a></span>). Three further genomic studies reveal how recombination and genetic architecture of traits determine the speed of adaptation in the invasive brown anole (<i>Anolis sagrei</i>) (Bock et al., <span><a href=\"#mec17350-bib-0006\">2023</a></span>), in the Italian wall lizard (<i>Podarcis siculus</i>) (Sabolić et al., <span><a href=\"#mec17350-bib-0039\">2023</a></span>) and during domestication of yeast (<i>Saccharomyces cerevisiae</i>) (Raas &amp; Dutheil, <span><a href=\"#mec17350-bib-0037\">2023</a></span>).</p>\n<p>Third, we focus on rapid adaptation in response to fluctuating selection over time due to eco-evo feedbacks, which is a common feature of antagonistic coevolution (e.g. between sexes or between hosts and their parasites). We present a range of empirical studies generating coevolution/fluctuating selection in controlled set-ups using species with short generation time. Fluctuating selection is chiefly characterised by fast changes in allele frequencies at the loci under selection and across the whole genome as documented and analysed in <i>Drosophila melanogaster</i> (Glaser-Schmitt et al., <span><a href=\"#mec17350-bib-0017\">2023</a></span>) and in a fungal pathogen of poplars (Saubin et al., <span><a href=\"#mec17350-bib-0041\">2023</a></span>). Furthermore, fluctuating selection in host–parasite systems also coincide with eco-evo feedback which affects the population sizes of antagonistic species over time, which in turn has consequences on the available genetic diversity (Le Pennec et al., <span><a href=\"#mec17350-bib-0031\">2023</a></span>). Finally, we present two studies dissecting the effects of the environment and trade-offs on the occurrence and speed of fluctuating selection and rapid co-adaptation (Goehlich et al., <span><a href=\"#mec17350-bib-0018\">2023</a></span>; Hernandez et al., <span><a href=\"#mec17350-bib-0022\">2023</a></span>).</p>\n</section>\n<section>\n<h2>1 RAPID ADAPTATION BY POSITIVE SELECTION AT MAJOR GENES</h2>\n<p>Strong positive selection at loci with major effects on an adaptive phenotype generates selective sweeps with rapid fixation of the selected allele (typically within tens of generation). In finite populations, the speed of population adaptation to changing biotic and abiotic environments is determined by the probability of fixation and time to fixation of such a beneficial allele under the action of genetic drift, the initial frequency of this allele as well as possible linkage effects with neighbouring genes. The waiting time for a new mutation to occur is inversely proportional to the population mutation rate, the latter being, for example, very high in bacteria or viruses. In contrast, most eukaryotic multi-cellular species exhibit typically lower genomic mutation rates (on the order of 10<sup>−9</sup> up to 10<sup>−7</sup> per site per generation) and smaller effective population sizes than bacteria and viruses, meaning that the mutational fuel for rapid adaptation is limited in comparison. Rapid adaptation is thus more likely to originate from existing standing variation, from which one allele with large selective advantage is becoming advantageous after a change of environmental conditions. These predictions on the waiting time for a new mutation to arise, the probability of fixation and time to fixation of an advantageous allele, which characterise a selective sweep, are chiefly obtained under the two standard models of population genetics: the Moran and the Wright–Fisher models (Charlesworth &amp; Charlesworth, <span><a href=\"#mec17350-bib-0008\">2010</a></span>). Both conceptualise the evolution of a population by modelling the stochastic distribution of offspring produced by a parental generation and integrate the Mendelian rules of heredity and character transmission. Both models rely on the binomial distribution of offspring numbers per parent under the assumption that such a distribution has a small variance. However, many marine species (fish, crustaceans), invertebrates and pathogens of humans and crops, exhibit so-called sweepstakes reproduction which is",
        "html": "<div><section>\n<section>\n<p>The vast diversity of life on earth is the result of evolutionary processes that acted over billions of years. Historically it was assumed that adaptation and the origin of new species required long periods of time. However, it is now well established that adaptation to new environments can occur rapidly and sometimes even within a few generations. We define here rapid adaptation as a selective process, which allows a population or species to substantially improve its average fitness in the short time scale of few tens of generations, typically within a hundred years for annual species. More precisely, rapid adaptation occurs through natural selection acting on the phenotype (and ultimately on the underlying genetic variants) over short time scale and therefore encompasses both ecological (demographic abundance and inter-specific interactions within a given habitat and species community) and evolutionary (genetic drift, mutation, recombination, gene flow and selection) processes (Hairston et al., <span><a href=\"#mec17350-bib-0020\">2005</a></span>; Kokko et al., <span><a href=\"#mec17350-bib-0027\">2017</a></span>). The occurrence and speed of rapid adaptation is thus determined by the feedback between ecological and evolutionary (eco-evo) processes. A large body of literature now documents examples of eco-evo feedbacks driving rapid adaptation especially as consequences of human activities, with damaging consequences in agriculture (e.g. invasion of crop pests and pathogens resistant to fungicides) (Fisher et al., <span><a href=\"#mec17350-bib-0014\">2022</a></span>), medicine (e.g. parasite resistance to drugs/antibiotics) (Birkholtz et al., <span><a href=\"#mec17350-bib-0005\">2022</a></span>; Zhang et al., <span><a href=\"#mec17350-bib-0046\">2022</a></span>) and/or ecosystems (e.g. new invasive species and emergent diseases) (Fisher et al., <span><a href=\"#mec17350-bib-0015\">2012</a></span>). Indeed, rapid adaptation underpins species' invasion of new habitats, coevolution between hosts and their parasites, fluctuating selection due to fast environmental change or adaptation to human-altered environments. Deciphering the evolutionary mechanisms of rapid adaptation is thus critical given the current rate of global change and loss of biodiversity to forecast the evolutionary potential of species and promote ad hoc conservation measures and/or to prevent the emergence of novel and unwanted pathogens. This research endeavour entails two major questions bridging ecological and evolutionary processes and mechanisms: What are the sources of genetic variation for rapid evolution? Which evolutionary, ecological and genetic factors enable (hasten) and which factors constrain (slow down) rapid evolution?</p>\n<p>In this special issue on ‘Rapid evolutionary adaptation: Potential and constraints’ we address these questions by presenting new developments in evolutionary theory concerning rapid evolution and/or in combination with empirical investigations of rapidly evolving systems from all kingdoms of life. Two questions percolate through the studies presented here. The first central question is whether rapid evolution is predominately reliant on small changes in allele frequencies from standing genetic variation at many loci (polygenic adaptation) or on large effect mutations arising either de novo or entering the population through migration. A second important topic is the identification and investigation of factors that constrain rapid evolution such as demographic parameters (e.g. population size), genetic/genomic architecture, life-history traits or environmental heterogeneity. To provide answers to these questions, we grouped the contributions in three main topical parts.</p>\n<p>First, we start with the simple case of adaptation occurring at major genes with major phenotypic effects, which spread through the population by a ‘selective sweep’ mechanism. This mode of positive selection generates fast adaptation as the time to fixation of advantageous alleles can be very short. Two theoretical contributions investigate how a life-history trait, sweepstake reproduction (i.e. reproduction with large variance in offspring production) common to many fish, invertebrates and fungi, can on one hand hasten the fixation of beneficial alleles but on the other hand make it less likely to occur (Eldon &amp; Stephan, <span><a href=\"#mec17350-bib-0013\">2023</a></span>; Korfmann et al., <span><a href=\"#mec17350-bib-0028\">2023</a></span>). Two examples of adaptation (invasion) to new habitats by strong positive selection are then presented in population genomics studies of the fall webworm (FWW; Dai et al., <span><a href=\"#mec17350-bib-0009\">2023</a></span>) and the common hairfin anchovy (<i>Setipinna tenuifilis</i>) (Liu et al., <span><a href=\"#mec17350-bib-0033\">2023</a></span>). Finally, a review summarises findings from genomic studies on the role of transposable elements (TEs) in determining the evolutionary potential of crop pathogens. The dynamics of TEs and the resulting mutational changes play an important role in the fungal mildew pathogen <i>Blumeria</i> of cereal crops to evade crop resistance and promote resistance to fungicides (Kusch et al., <span><a href=\"#mec17350-bib-0029\">2023</a></span>).</p>\n<p>Conversely, in the second part, we focus on the theory and empirical evidence for rapid adaptation via quantitative (polygenic) traits and potential constraints. More precisely, three theoretical papers investigate the core assumptions underpinning and slowing down adaptation by polygenic traits: the existence of (metabolic) trade-offs (Hashemi et al., <span><a href=\"#mec17350-bib-0021\">2023</a></span>; Laitinen &amp; Nikoloski, <span><a href=\"#mec17350-bib-0030\">2023</a></span>) and the effects of epistatic interactions and recombination (Li et al., <span><a href=\"#mec17350-bib-0032\">2023</a></span>). Three further genomic studies reveal how recombination and genetic architecture of traits determine the speed of adaptation in the invasive brown anole (<i>Anolis sagrei</i>) (Bock et al., <span><a href=\"#mec17350-bib-0006\">2023</a></span>), in the Italian wall lizard (<i>Podarcis siculus</i>) (Sabolić et al., <span><a href=\"#mec17350-bib-0039\">2023</a></span>) and during domestication of yeast (<i>Saccharomyces cerevisiae</i>) (Raas &amp; Dutheil, <span><a href=\"#mec17350-bib-0037\">2023</a></span>).</p>\n<p>Third, we focus on rapid adaptation in response to fluctuating selection over time due to eco-evo feedbacks, which is a common feature of antagonistic coevolution (e.g. between sexes or between hosts and their parasites). We present a range of empirical studies generating coevolution/fluctuating selection in controlled set-ups using species with short generation time. Fluctuating selection is chiefly characterised by fast changes in allele frequencies at the loci under selection and across the whole genome as documented and analysed in <i>Drosophila melanogaster</i> (Glaser-Schmitt et al., <span><a href=\"#mec17350-bib-0017\">2023</a></span>) and in a fungal pathogen of poplars (Saubin et al., <span><a href=\"#mec17350-bib-0041\">2023</a></span>). Furthermore, fluctuating selection in host–parasite systems also coincide with eco-evo feedback which affects the population sizes of antagonistic species over time, which in turn has consequences on the available genetic diversity (Le Pennec et al., <span><a href=\"#mec17350-bib-0031\">2023</a></span>). Finally, we present two studies dissecting the effects of the environment and trade-offs on the occurrence and speed of fluctuating selection and rapid co-adaptation (Goehlich et al., <span><a href=\"#mec17350-bib-0018\">2023</a></span>; Hernandez et al., <span><a href=\"#mec17350-bib-0022\">2023</a></span>).</p>\n</section>\n<section>\n<h2>1 RAPID ADAPTATION BY POSITIVE SELECTION AT MAJOR GENES</h2>\n<p>Strong positive selection at loci with major effects on an adaptive phenotype generates selective sweeps with rapid fixation of the selected allele (typically within tens of generation). In finite populations, the speed of population adaptation to changing biotic and abiotic environments is determined by the probability of fixation and time to fixation of such a beneficial allele under the action of genetic drift, the initial frequency of this allele as well as possible linkage effects with neighbouring genes. The waiting time for a new mutation to occur is inversely proportional to the population mutation rate, the latter being, for example, very high in bacteria or viruses. In contrast, most eukaryotic multi-cellular species exhibit typically lower genomic mutation rates (on the order of 10<sup>−9</sup> up to 10<sup>−7</sup> per site per generation) and smaller effective population sizes than bacteria and viruses, meaning that the mutational fuel for rapid adaptation is limited in comparison. Rapid adaptation is thus more likely to originate from existing standing variation, from which one allele with large selective advantage is becoming advantageous after a change of environmental conditions. These predictions on the waiting time for a new mutation to arise, the probability of fixation and time to fixation of an advantageous allele, which characterise a selective sweep, are chiefly obtained under the two standard models of population genetics: the Moran and the Wright–Fisher models (Charlesworth &amp; Charlesworth, <span><a href=\"#mec17350-bib-0008\">2010</a></span>). Both conceptualise the evolution of a population by modelling the stochastic distribution of offspring produced by a parental generation and integrate the Mendelian rules of heredity and character transmission. Both models rely on the binomial distribution of offspring numbers per parent under the assumption that such a distribution has a small variance. However, many marine species (fish, crustaceans), invertebrates and pathogens of humans and crops, exhibit so-called sweepstakes reproduction which is",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "The vast diversity of life on earth is the result of evolutionary processes that acted over billions of years. Historically it was assumed that adaptation and the origin of new species required long periods of time. However, it is now well established that adaptation to new environments can occur rapidly and sometimes even within a few generations. We define here rapid adaptation as a selective process, which allows a population or species to substantially improve its average fitness in the shor",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "The vast diversity of life on earth is the result of evolutionary processes that acted over billions of years. Historically it was assumed that adaptation and the origin of new species required long periods of time. However, it is now well established that adaptation to new environments can occur rapidly and sometimes even within a few generations. We define here rapid adaptation as a selective process, which allows a population or species to substantially improve its average fitness in the shor",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "The vast diversity of life on earth is the result of evolutionary processes that acted over billions of years. Historically it was assumed that adaptation and the origin of new species required long periods of time. However, it is now well established that adaptation to new environments can occur rapidly and sometimes even within a few generations. We define here rapid adaptation as a selective process, which allows a population or species to substantially improve its average fitness in the shor",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1 RAPID ADAPTATION BY POSITIVE SELECTION AT MAJOR GENESStrong positive selection at loci with major effects on an adaptive phenotype generates selective sweeps with rapid fixation of the selected allele (typically within tens of generation). In finite populations, the speed of population adaptation to changing biotic and abiotic environments is determined by the probability of fixation and time to fixation of such a beneficial allele under the action of genetic drift, the initial frequency of th",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "1 RAPID ADAPTATION BY POSITIVE SELECTION AT MAJOR GENES",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://escribr.com/transcribers/free-training/module-1-transcription-rules-and-guidelines/",
      "title": "Module 1 : Transcription Rules & Guidelines - Escribr",
      "author": "",
      "published_date": "2023-12-08T14:13:17.000Z",
      "content": {
        "text": "<div><article><div><p><strong>The Complete Course in Audio Transcription (For Beginners)</strong></p><p>\n</p>\n<p>You may use these guidelines for transcript consistency if the client does not require you to follow a specific set of rules.</p><p><strong>If you’re a subcontractor for a transcription company</strong>, rules and formatting style may vary.</p><h3><strong>Clean verbatim versus full verbatim.</strong></h3><p><strong>Clean verbatim</strong> transcription does not include false starts, verbal tics, stutters, and other speech or sounds not relevant to the transcript. However, sentences are not paraphrased.</p><p><strong>Full verbatim</strong>, on the other hand, includes false starts, verbal tics, stutters, and all utterances.</p><p>1. <strong>Filler words</strong> or <strong>verbal tics </strong>are words that are meaningless and mark a pause or hesitation.</p><p>For example, you know, um, uh, like, kind of. These are examples of filler words or verbal tics.</p><p>Example: The process is, um, it’s still in its, uh, you know, infancy.</p><p>This is a sentence full of filler words or verbal tics.</p><p>Take note: Be careful not to omit words that are not used as fillers but are necessary to make the sentence complete.</p><p>Example: What was that like for you?</p><p>The word “like” is needed in the sentence.</p><p>So it’s incorrect to type “What was that for you?”</p><p>2. A <strong>false start </strong>means that the speaker says one thing and then goes back and changes what he is saying.</p><p>To make the speaker’s message clearer, you don’t have to include everything else before the actual start of the sentence that is irrelevant.</p><p><strong>Example 1:</strong></p><p><strong>Dictation: </strong>This — the process is still in its infancy.</p><p><strong>Transcription: </strong>The process is still in its infancy.</p><p><strong>Example 2:</strong></p><p><strong>Dictation: </strong>So my — I would say — the only thing I would say is that we’re doing our best.</p><p><strong>Transcription: </strong>The only thing I would say is that we’re doing our best.</p><p>This is an example of a full verbatim. The words highlighted in blue are filler words or verbal tics and false starts.</p><p>I do have — I have a question about, you know, the implications for like insurance covered. Um, what kind of treatments are covered? If we stop using like the word cancer for, uh, some of these, you know, conditions, are insurance companies going to, you know, stop reimbursing?</p><p>Let’s remove all the words highlighted in blue and full verbatim becomes clean verbatim.</p><p>I have a question about the implications for insurance covered. What kind of treatments are covered? If we stop using the word cancer for some of these conditions, are insurance companies going to stop reimbursing?</p><p>This is the correct and final sentence.</p><p>Always use clean verbatim unless the client instructed to use full verbatim.</p><p>And take note, sentences are cleaned but not paraphrased.</p><p>3. Don’t transcribe <strong>thinking noises</strong>.</p><p>Thinking noises are if one just keeps on saying “uh-huh,” “right, “okay,” “yeah” while someone else is talking.</p><p>It’s a thinking noise if it’s not a direct response to what the other person is saying.</p><p>Example:</p><p><strong>INCORRECT</strong><br/>Interviewer: How do you proceed with your inquiries?<br/>Respondent: We try to narrow it down to —<br/>Interviewer: Right. (thinking noise)<br/>Respondent: — a few questions.<br/>Interviewer: Is the process already old, or is it still new?<br/>Respondent: The process is still in its —<br/>Interviewer: Yeah. (thinking noise)<br/>Respondent: — infancy.</p><p>Let’s remove the thinking noises highlighted in blue.</p><p><strong>CORRECT</strong><br/>Interviewer: How do you proceed with your inquiries?<br/>Respondent: We try to narrow it down to a few questions.<br/>Interviewer: Is the process already old, or is it still new?<br/>Respondent: The process is still in its infancy.</p><p>This is the right way to type the conversation.</p><p>Still under thinking noises, do not omit if it’s a direct response to a question or statement.</p><p>Example:</p><p>Interviewer: You have been there, right?</p><p>Respondent: Uh-huh.</p><p>“Uh-huh” is a direct response to the interviewer’s question, so it should not be omitted.</p><h3><strong>Slang forms should not be used</strong>.</h3><p>Examples of slang forms are gonna, wanna, gotta, alright, ‘coz, and others. These slang forms should not be used.</p><p>Instead, use going to, want to, got to, all right, and because.</p><h3><strong>Conjunction “and”.</strong></h3><p>Speakers often overuse “and” and sometimes transcriptionists tend to create very long sentences because of this conjunction.</p><p>You may divide a long sentence into short sentences and drop the conjunction “and” if it’s unnecessary.</p><p>Take into consideration clarity and readability.</p><p>Example:</p><p><strong>Dictation:</strong> I painted this in Photoshop myself <span>and</span> it was the most spectacular vision I’ve ever seen in my life <span>and</span> I cannot forget it <span>and</span> it was the first time I had ever seen anything like it <span>and</span> my whole body went electric <span>and</span> when it went electric, I was in that pulsating, throbbing, vibrating state.</p><p>Now, let’s remove the conjunction “and” and replace it with a period.</p><p><strong>Transcription:</strong> I painted this in Photoshop myself. It was the most spectacular vision I’ve ever seen in my life, and I cannot forget it. It was the first time I had ever seen anything like it. My whole body went electric. When it went electric, I was in that pulsating, throbbing, vibrating state.</p><p>This is the clean and clear and final version of the paragraph.</p><h3><strong>If there are words in the audio that you can’t decipher</strong>,</h3><p>you may mark them with [Indiscernible] or [Inaudible] or [Unintelligible].</p><p>You can also include timestamps so that the client can go back to that portion and relisten to it.</p><p>Example format: [0:01:00] [Indiscernible]</p><p>This means that the word or words at the one-minute mark are indiscernible.</p><h3><strong>Speaker tokens</strong>.</h3><p>Identify the speakers by first name unless your client instructed otherwise.</p><p>If it’s an interview and the speakers’ names are not identifiable, use Interviewer and Respondent.</p><h3><strong>Keep paragraphs short</strong>.</h3><p>White spaces make a transcript more readable.</p><h3><strong>Please do take note of the following:</strong></h3><p>As a freelance transcriber or independent subcontractor, you can always accept or decline transcription assignments.</p><p>Never accept assignments you’re not 100% sure you’re able to produce quality transcripts for, especially if you’re just starting.</p><p>Always submit on time. Communicate with your client if you need more time to finish the transcript or if there’s going to be a delay in the delivery of the transcript.</p><p>Inform your client if and when problems arise. Never leave your client hanging.</p><p><a href=\"https://escribr.com/transcribers/free-training/\">All Modules</a> | <a href=\"https://escribr.com/transcribers/free-training/introduction/\">Previous</a> | <a href=\"https://escribr.com/transcribers/free-training/module-2-word-usage/\">Next</a></p></div></article></div>",
        "html": "<div><article><div><p><strong>The Complete Course in Audio Transcription (For Beginners)</strong></p><p>\n</p>\n<p>You may use these guidelines for transcript consistency if the client does not require you to follow a specific set of rules.</p><p><strong>If you’re a subcontractor for a transcription company</strong>, rules and formatting style may vary.</p><h3><strong>Clean verbatim versus full verbatim.</strong></h3><p><strong>Clean verbatim</strong> transcription does not include false starts, verbal tics, stutters, and other speech or sounds not relevant to the transcript. However, sentences are not paraphrased.</p><p><strong>Full verbatim</strong>, on the other hand, includes false starts, verbal tics, stutters, and all utterances.</p><p>1. <strong>Filler words</strong> or <strong>verbal tics </strong>are words that are meaningless and mark a pause or hesitation.</p><p>For example, you know, um, uh, like, kind of. These are examples of filler words or verbal tics.</p><p>Example: The process is, um, it’s still in its, uh, you know, infancy.</p><p>This is a sentence full of filler words or verbal tics.</p><p>Take note: Be careful not to omit words that are not used as fillers but are necessary to make the sentence complete.</p><p>Example: What was that like for you?</p><p>The word “like” is needed in the sentence.</p><p>So it’s incorrect to type “What was that for you?”</p><p>2. A <strong>false start </strong>means that the speaker says one thing and then goes back and changes what he is saying.</p><p>To make the speaker’s message clearer, you don’t have to include everything else before the actual start of the sentence that is irrelevant.</p><p><strong>Example 1:</strong></p><p><strong>Dictation: </strong>This — the process is still in its infancy.</p><p><strong>Transcription: </strong>The process is still in its infancy.</p><p><strong>Example 2:</strong></p><p><strong>Dictation: </strong>So my — I would say — the only thing I would say is that we’re doing our best.</p><p><strong>Transcription: </strong>The only thing I would say is that we’re doing our best.</p><p>This is an example of a full verbatim. The words highlighted in blue are filler words or verbal tics and false starts.</p><p>I do have — I have a question about, you know, the implications for like insurance covered. Um, what kind of treatments are covered? If we stop using like the word cancer for, uh, some of these, you know, conditions, are insurance companies going to, you know, stop reimbursing?</p><p>Let’s remove all the words highlighted in blue and full verbatim becomes clean verbatim.</p><p>I have a question about the implications for insurance covered. What kind of treatments are covered? If we stop using the word cancer for some of these conditions, are insurance companies going to stop reimbursing?</p><p>This is the correct and final sentence.</p><p>Always use clean verbatim unless the client instructed to use full verbatim.</p><p>And take note, sentences are cleaned but not paraphrased.</p><p>3. Don’t transcribe <strong>thinking noises</strong>.</p><p>Thinking noises are if one just keeps on saying “uh-huh,” “right, “okay,” “yeah” while someone else is talking.</p><p>It’s a thinking noise if it’s not a direct response to what the other person is saying.</p><p>Example:</p><p><strong>INCORRECT</strong><br/>Interviewer: How do you proceed with your inquiries?<br/>Respondent: We try to narrow it down to —<br/>Interviewer: Right. (thinking noise)<br/>Respondent: — a few questions.<br/>Interviewer: Is the process already old, or is it still new?<br/>Respondent: The process is still in its —<br/>Interviewer: Yeah. (thinking noise)<br/>Respondent: — infancy.</p><p>Let’s remove the thinking noises highlighted in blue.</p><p><strong>CORRECT</strong><br/>Interviewer: How do you proceed with your inquiries?<br/>Respondent: We try to narrow it down to a few questions.<br/>Interviewer: Is the process already old, or is it still new?<br/>Respondent: The process is still in its infancy.</p><p>This is the right way to type the conversation.</p><p>Still under thinking noises, do not omit if it’s a direct response to a question or statement.</p><p>Example:</p><p>Interviewer: You have been there, right?</p><p>Respondent: Uh-huh.</p><p>“Uh-huh” is a direct response to the interviewer’s question, so it should not be omitted.</p><h3><strong>Slang forms should not be used</strong>.</h3><p>Examples of slang forms are gonna, wanna, gotta, alright, ‘coz, and others. These slang forms should not be used.</p><p>Instead, use going to, want to, got to, all right, and because.</p><h3><strong>Conjunction “and”.</strong></h3><p>Speakers often overuse “and” and sometimes transcriptionists tend to create very long sentences because of this conjunction.</p><p>You may divide a long sentence into short sentences and drop the conjunction “and” if it’s unnecessary.</p><p>Take into consideration clarity and readability.</p><p>Example:</p><p><strong>Dictation:</strong> I painted this in Photoshop myself <span>and</span> it was the most spectacular vision I’ve ever seen in my life <span>and</span> I cannot forget it <span>and</span> it was the first time I had ever seen anything like it <span>and</span> my whole body went electric <span>and</span> when it went electric, I was in that pulsating, throbbing, vibrating state.</p><p>Now, let’s remove the conjunction “and” and replace it with a period.</p><p><strong>Transcription:</strong> I painted this in Photoshop myself. It was the most spectacular vision I’ve ever seen in my life, and I cannot forget it. It was the first time I had ever seen anything like it. My whole body went electric. When it went electric, I was in that pulsating, throbbing, vibrating state.</p><p>This is the clean and clear and final version of the paragraph.</p><h3><strong>If there are words in the audio that you can’t decipher</strong>,</h3><p>you may mark them with [Indiscernible] or [Inaudible] or [Unintelligible].</p><p>You can also include timestamps so that the client can go back to that portion and relisten to it.</p><p>Example format: [0:01:00] [Indiscernible]</p><p>This means that the word or words at the one-minute mark are indiscernible.</p><h3><strong>Speaker tokens</strong>.</h3><p>Identify the speakers by first name unless your client instructed otherwise.</p><p>If it’s an interview and the speakers’ names are not identifiable, use Interviewer and Respondent.</p><h3><strong>Keep paragraphs short</strong>.</h3><p>White spaces make a transcript more readable.</p><h3><strong>Please do take note of the following:</strong></h3><p>As a freelance transcriber or independent subcontractor, you can always accept or decline transcription assignments.</p><p>Never accept assignments you’re not 100% sure you’re able to produce quality transcripts for, especially if you’re just starting.</p><p>Always submit on time. Communicate with your client if you need more time to finish the transcript or if there’s going to be a delay in the delivery of the transcript.</p><p>Inform your client if and when problems arise. Never leave your client hanging.</p><p><a href=\"https://escribr.com/transcribers/free-training/\">All Modules</a> | <a href=\"https://escribr.com/transcribers/free-training/introduction/\">Previous</a> | <a href=\"https://escribr.com/transcribers/free-training/module-2-word-usage/\">Next</a></p></div></article></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "The Complete Course in Audio Transcription (For Beginners)You may use these guidelines for transcript consistency if the client does not require you to follow a specific set of rules.If you’re a subcontractor for a transcription company, rules and formatting style may vary.Clean verbatim versus full verbatim.Clean verbatimtranscription does not include false starts, verbal tics, stutters, and other speech or sounds not relevant to the transcript. However, sentences are not paraphrased.Full verba",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "The Complete Course in Audio Transcription (For Beginners)You may use these guidelines for transcript consistency if the client does not require you to follow a specific set of rules.If you’re a subcontractor for a transcription company, rules and formatting style may vary.Clean verbatim versus full verbatim.Clean verbatimtranscription does not include false starts, verbal tics, stutters, and other speech or sounds not relevant to the transcript. However, sentences are not paraphrased.Full verba",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Complete Course in Audio Transcription (For Beginners)You may use these guidelines for transcript consistency if the client does not require you to follow a specific set of rules.If you’re a subcontractor for a transcription company, rules and formatting style may vary.Clean verbatim versus full verbatim.Clean verbatimtranscription does not include false starts, verbal tics, stutters, and other speech or sounds not relevant to the transcript. However, sentences are not paraphrased.Full verba",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "Clean verbatim versus full verbatim.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Slang forms should not be used.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Conjunction “and”.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "If there are words in the audio that you can’t decipher,",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Speaker tokens.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Keep paragraphs short.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Please do take note of the following:",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://dl.acm.org/doi/10.1145/16856.16859",
      "title": "An amateur's introduction to recursive query processing strategies",
      "author": "Francots  Banctlhon, Raghu  Ramakrrshnan, Umverslty of Texas at Austin Austin, 78712, Texas",
      "published_date": null,
      "content": {
        "text": "<div><div>\n<main>\n<div>\n<article><div><div><p></p></div><div><nav></nav><div><div><p><a href=\"\"></a><a href=\"#\">Skip Abstract Section</a></p><div><p><h2>Abstract</h2></p><div><p>This paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detailed description. We also give an example of a query evaluation. The third part of the paper compares the strategies on performance grounds. We first present a set of sample rules and queries which are used for the performance comparisons, and then we characterize the data. Finally, we give an analytical solution for each query/rule system. Cost curves are plotted for specific configurations of the data.</p></div></div></div><div><div><h2>\nReferences\n</h2></div><ol><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ol></div>\n<div>\n<p>\n<h2>Index Terms</h2>\n</p>\n<ol><li><h6>An amateur's introduction to recursive query processing strategies</h6><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li><li><ol><li><ol></ol></li></ol></li><li><ol><li><ol><li><ol></ol></li><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li></ol></li></ol>\n</div>\n<p> <h2>Recommendations</h2> </p>\n<div><ul><li><div><a href=\"https://dl.acm.org/doi/10.1145/16894.16859\"><h5>An amateur's introduction to recursive query processing strategies</h5></a><p>SIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of data </p><div><p>This paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in ...</p></div></div></li><li></li><li></li></ul></div>\n</div><div><div><div><h3>Login options</h3><div><p>Check if you have access through your login credentials or your institution to get full access on this article.</p><p><a href=\"https://dl.acm.org/action/showLogin?redirectUri=/doi/10.1145/16856.16859\">Sign in</a></p></div></div><div><h3>Full Access</h3></div></div><div><ul><li><a href=\"#pill-information__content\">Information</a></li><li><a href=\"#pill-authors__content\">Contributors</a></li></ul><ul><li><div><div><h3>Published in</h3><div>\n<div>\n<div><p></p><div><p> </p><p>June 1986</p><p>407 pages</p></div></div><ul><li><p></p><div><p>SIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of data</p><p>June 1986</p><p>407 pages</p></div></li></ul>\n</div>\n<p>Copyright © 1986 ACM</p><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from <a href=\"https://dl.acm.org/cdn-cgi/l/email-protection\">[email protected]</a></p></div></div><div><h3>Publisher</h3><div><p>Association for Computing Machinery</p><p>New York, NY, United States</p></div></div>\n<div>\n<h3>\nPublication History\n</h3>\n<div><ul><li> 15 June 1986</li></ul></div>\n</div>\n<div><h3>Check for updates</h3><p><a href=\"\"></a></p></div>\n<p><h3>Conference</h3></p></div></li></ul></div><div><ul><li><a href=\"#pill-bibliometrics__content\">Bibliometrics</a></li><li><a href=\"#pill-citations__content\">Citations</a></li></ul><ul><li><div><div><h3>Article Metrics</h3><div><ul><li><a href=\"#pill-citations__contentcon\">View Citations</a></li><li></li></ul><ul><li></li><li></li></ul></div></div><div><h3>Other Metrics</h3></div></div></li></ul></div><div><div><h3>PDF Format</h3><div><p>View or Download as a PDF file.</p><p><a href=\"https://dl.acm.org/doi/pdf/10.1145/16856.16859\">PDF</a></p></div></div><div><h3>eReader</h3><div><p>View online with eReader.</p><p><a href=\"https://dl.acm.org/doi/epdf/10.1145/16856.16859\">eReader</a></p></div></div></div></div></div></div></article>\n</div>\n</main>\n</div></div>",
        "html": "<div><div>\n<main>\n<div>\n<article><div><div><p></p></div><div><nav></nav><div><div><p><a href=\"\"></a><a href=\"#\">Skip Abstract Section</a></p><div><p><h2>Abstract</h2></p><div><p>This paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detailed description. We also give an example of a query evaluation. The third part of the paper compares the strategies on performance grounds. We first present a set of sample rules and queries which are used for the performance comparisons, and then we characterize the data. Finally, we give an analytical solution for each query/rule system. Cost curves are plotted for specific configurations of the data.</p></div></div></div><div><div><h2>\nReferences\n</h2></div><ol><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ol></div>\n<div>\n<p>\n<h2>Index Terms</h2>\n</p>\n<ol><li><h6>An amateur's introduction to recursive query processing strategies</h6><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li><li><ol><li><ol></ol></li></ol></li><li><ol><li><ol><li><ol></ol></li><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li><li><ol><li><ol><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li></ol></li></ol>\n</div>\n<p> <h2>Recommendations</h2> </p>\n<div><ul><li><div><a href=\"https://dl.acm.org/doi/10.1145/16894.16859\"><h5>An amateur's introduction to recursive query processing strategies</h5></a><p>SIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of data </p><div><p>This paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in ...</p></div></div></li><li></li><li></li></ul></div>\n</div><div><div><div><h3>Login options</h3><div><p>Check if you have access through your login credentials or your institution to get full access on this article.</p><p><a href=\"https://dl.acm.org/action/showLogin?redirectUri=/doi/10.1145/16856.16859\">Sign in</a></p></div></div><div><h3>Full Access</h3></div></div><div><ul><li><a href=\"#pill-information__content\">Information</a></li><li><a href=\"#pill-authors__content\">Contributors</a></li></ul><ul><li><div><div><h3>Published in</h3><div>\n<div>\n<div><p></p><div><p> </p><p>June 1986</p><p>407 pages</p></div></div><ul><li><p></p><div><p>SIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of data</p><p>June 1986</p><p>407 pages</p></div></li></ul>\n</div>\n<p>Copyright © 1986 ACM</p><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from <a href=\"https://dl.acm.org/cdn-cgi/l/email-protection\">[email protected]</a></p></div></div><div><h3>Publisher</h3><div><p>Association for Computing Machinery</p><p>New York, NY, United States</p></div></div>\n<div>\n<h3>\nPublication History\n</h3>\n<div><ul><li> 15 June 1986</li></ul></div>\n</div>\n<div><h3>Check for updates</h3><p><a href=\"\"></a></p></div>\n<p><h3>Conference</h3></p></div></li></ul></div><div><ul><li><a href=\"#pill-bibliometrics__content\">Bibliometrics</a></li><li><a href=\"#pill-citations__content\">Citations</a></li></ul><ul><li><div><div><h3>Article Metrics</h3><div><ul><li><a href=\"#pill-citations__contentcon\">View Citations</a></li><li></li></ul><ul><li></li><li></li></ul></div></div><div><h3>Other Metrics</h3></div></div></li></ul></div><div><div><h3>PDF Format</h3><div><p>View or Download as a PDF file.</p><p><a href=\"https://dl.acm.org/doi/pdf/10.1145/16856.16859\">PDF</a></p></div></div><div><h3>eReader</h3><div><p>View online with eReader.</p><p><a href=\"https://dl.acm.org/doi/epdf/10.1145/16856.16859\">eReader</a></p></div></div></div></div></div></div></article>\n</div>\n</main>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Skip Abstract SectionAbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detaile",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detailed description. We als",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "This paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in three parts. In the first part, we introduce the main concepts and definitions. In the second, we describe the various strategies. For each strategy, we give its main characteristics, its application range and a detailed description. We also give a",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "References",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "References",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Index TermsAn amateur's introduction to recursive query processing strategies",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "An amateur's introduction to recursive query processing strategiesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in ...",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "An amateur's introduction to recursive query processing strategiesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataThis paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in ...",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "This paper surveys and compares various strategies for processing logic queries in relational databases. The survey and comparison is limited to the case of Horn Clauses with evaluable predicates but without function symbols. The paper is organized in ...",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Login optionsCheck if you have access through your login credentials or your institution to get full access on this article.Sign inFull AccessInformationContributorsPublished inJune 1986407 pagesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pagesCopyright © 1986 ACMPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed fo",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Login optionsCheck if you have access through your login credentials or your institution to get full access on this article.Sign inFull Access",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Login optionsCheck if you have access through your login credentials or your institution to get full access on this article.Sign in",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Check if you have access through your login credentials or your institution to get full access on this article.Sign in",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Full Access",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "InformationContributorsPublished inJune 1986407 pagesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pagesCopyright © 1986 ACMPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this w",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Published inJune 1986407 pagesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pagesCopyright © 1986 ACMPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others tha",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Published inJune 1986407 pagesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pagesCopyright © 1986 ACMPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others tha",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "June 1986407 pagesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pagesCopyright © 1986 ACMPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must b",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "June 1986407 pagesSIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pages",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "June 1986407 pages",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "June 1986407 pages",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "SIGMOD '86: Proceedings of the 1986 ACM SIGMOD international conference on Management of dataJune 1986407 pages",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "PublisherAssociation for Computing MachineryNew York, NY, United States",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Association for Computing MachineryNew York, NY, United States",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Publication History15 June 1986",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "15 June 1986",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Check for updates",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "BibliometricsCitationsArticle MetricsView CitationsOther Metrics",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Article MetricsView CitationsOther Metrics",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Article MetricsView Citations",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "View Citations",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Other Metrics",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "PDF FormatView or Download as a PDF file.PDFeReaderView online with eReader.eReader",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "PDF FormatView or Download as a PDF file.PDF",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "View or Download as a PDF file.PDF",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "eReaderView online with eReader.eReader",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "View online with eReader.eReader",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "References",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Index Terms",
              "id": ""
            },
            {
              "level": "h6",
              "text": "An amateur's introduction to recursive query processing strategies",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Recommendations",
              "id": ""
            },
            {
              "level": "h5",
              "text": "An amateur's introduction to recursive query processing strategies",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Login options",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Full Access",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Published in",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Publisher",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Publication History",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Check for updates",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Conference",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Article Metrics",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Other Metrics",
              "id": ""
            },
            {
              "level": "h3",
              "text": "PDF Format",
              "id": ""
            },
            {
              "level": "h3",
              "text": "eReader",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.semantix.com/resources/blog/full-guide-how-to-transcribe/transcription-rules",
      "title": "Different transcription rules and types",
      "author": "",
      "published_date": "2023-07-11T11:12:45.000Z",
      "content": {
        "text": "<div><div>\n<h4>Download our free transcription template</h4>\n<p>Get started with transcription. <a href=\"#download\">Here you will find templates for both detailed transcription and standard transcription</a>. You can use the formats and examples in your own working document.</p>\n</div><div>\n<h2>Why are transcriptions used? </h2>\n<p>Transcriptions are useful for many purposes, including: </p>\n<ol><li><strong>Accessibility</strong>: Transcriptions improve accessibility for people with hearing impairments, cognitive processing difficulties or for those who require more time to absorb information. </li><li><strong>Legal purposes:</strong> Legal proceedings, such as court hearings, depositions and interviews, are transcribed so that a permanent record is available of conversations that can be used in official records and evidence. </li><li><strong>Media</strong>: Transcriptions are used to create subtitling, captioning or dubbing. This is particularly important in multilingual media. </li><li><strong>Business</strong>: Transcriptions are used for transcribing meetings, interviews and presentations to keep a formal record of information and any decisions taken. </li><li><strong>Education</strong>: Transcriptions are used for transcribing lectures, webinars and other learning content to create documents that can be referred to in future studies. </li></ol>\n<h2>How are transcriptions created? </h2>\n<h3>Human transcribers </h3>\n<p>Professional human transcribers listen to an audio or video recording and transcribe it into written text. If multilingual transcription is required, they may also translate between languages. Here’s the process that a professional transcriber follows to create a transcription: </p>\n<ol><li>The transcriber listens carefully to the audio, paying attention to the speaker's tone, pace and the emotion of the content. </li><li>As the transcriber listens, they type what they hear either using word processing or specialised transcription software. </li><li>The transcriber ensures that the written text is accurate and grammatically correct. </li><li>If it’s part of the client’s brief, the transcriber can add timestamps to indicate when each sentence or paragraph was spoken. </li><li>If there are multiple speakers in a recording, the transcriber can indicate on the transcription when the speaker changes. </li><li>After the transcription is complete, it's given a final edit and proofread to ensure accuracy and consistency. </li></ol>\n<h3>AI transcribers </h3>\n<p>Artificial intelligence (AI) transcription software is now available and it’s rapidly becoming more reliable. Here's how an AI transcriber works: </p>\n<ol><li>The AI transcriber app receives an audio or video file as input. </li><li>The AI transcriber uses automatic speech recognition (ASR) technology to convert the audio content into written text. </li><li>The AI transcriber uses natural language processing (NLP) to interpret the transcribed text. NLP helps to identify and correct any grammatical errors, spelling mistakes and inconsistencies. </li><li>The final output is a text file of the audio content. Some AI transcribers can also create transcripts with timestamps and speaker identification. </li></ol>\n<p>AI transcribers continuously learn as they process more data, and this means that they improve over time. However, it's important to remember that AI transcribers can make mistakes, particularly when dealing with different accents, background noise or low quality recordings. This means that it’s always important for a human transcriber to check the AI’s results and to edit the final transcript as necessary. </p>\n<h2>Can transcriptions be referenced? </h2>\n<p>Transcriptions can be referenced using systems like Harvard, APA (American Psychological Association) and MLA (Modern Language Association) to provide proper citations for sources included in the transcription. </p>\n<p>Using <a href=\"https://www.rlf.org.uk/resources/mla-apa-harvard-or-mhra/\">referencing systems</a> like Harvard, APA or MLA is important in some forms of transcription, such as legal or academic, because it ensures sources in the text are properly acknowledged. </p>\n<h2>Can AI reference transcription? </h2>\n<p>While AI transcription software can transcribe speech to text, it cannot yet automatically generate reliable citations and listings using the standard referencing systems. However, with AI transcription capabilities developing rapidly, this will undoubtedly become possible in time. </p>\n<p>Currently, if accurate referencing is required, it must be carried out by a human transcriber. </p>\n<h2>Final thoughts </h2>\n<p>The general rules that apply to creating transcriptions are simple. However, applying different systems and using different types of transcription requires specialist knowledge. </p>\n<p><a href=\"https://www.semantix.com/solutions/translation/transcription-services-audio-video\">Our multilingual transcription services</a> offer fast, accurate transcriptions, with translations available in over 170 languages, and we offer all transcription types. We can also reference transcriptions if required. </p>\n<p>If you’d like to talk to our team about transcription, or have a project you’d like to discuss, <a href=\"https://www.semantix.com/solutions/translation/transcription-services-audio-video#form-transcription\">fill in this form and we’ll be in touch</a>. </p>\n</div></div>",
        "html": "<div><div>\n<h4>Download our free transcription template</h4>\n<p>Get started with transcription. <a href=\"#download\">Here you will find templates for both detailed transcription and standard transcription</a>. You can use the formats and examples in your own working document.</p>\n</div><div>\n<h2>Why are transcriptions used? </h2>\n<p>Transcriptions are useful for many purposes, including: </p>\n<ol><li><strong>Accessibility</strong>: Transcriptions improve accessibility for people with hearing impairments, cognitive processing difficulties or for those who require more time to absorb information. </li><li><strong>Legal purposes:</strong> Legal proceedings, such as court hearings, depositions and interviews, are transcribed so that a permanent record is available of conversations that can be used in official records and evidence. </li><li><strong>Media</strong>: Transcriptions are used to create subtitling, captioning or dubbing. This is particularly important in multilingual media. </li><li><strong>Business</strong>: Transcriptions are used for transcribing meetings, interviews and presentations to keep a formal record of information and any decisions taken. </li><li><strong>Education</strong>: Transcriptions are used for transcribing lectures, webinars and other learning content to create documents that can be referred to in future studies. </li></ol>\n<h2>How are transcriptions created? </h2>\n<h3>Human transcribers </h3>\n<p>Professional human transcribers listen to an audio or video recording and transcribe it into written text. If multilingual transcription is required, they may also translate between languages. Here’s the process that a professional transcriber follows to create a transcription: </p>\n<ol><li>The transcriber listens carefully to the audio, paying attention to the speaker's tone, pace and the emotion of the content. </li><li>As the transcriber listens, they type what they hear either using word processing or specialised transcription software. </li><li>The transcriber ensures that the written text is accurate and grammatically correct. </li><li>If it’s part of the client’s brief, the transcriber can add timestamps to indicate when each sentence or paragraph was spoken. </li><li>If there are multiple speakers in a recording, the transcriber can indicate on the transcription when the speaker changes. </li><li>After the transcription is complete, it's given a final edit and proofread to ensure accuracy and consistency. </li></ol>\n<h3>AI transcribers </h3>\n<p>Artificial intelligence (AI) transcription software is now available and it’s rapidly becoming more reliable. Here's how an AI transcriber works: </p>\n<ol><li>The AI transcriber app receives an audio or video file as input. </li><li>The AI transcriber uses automatic speech recognition (ASR) technology to convert the audio content into written text. </li><li>The AI transcriber uses natural language processing (NLP) to interpret the transcribed text. NLP helps to identify and correct any grammatical errors, spelling mistakes and inconsistencies. </li><li>The final output is a text file of the audio content. Some AI transcribers can also create transcripts with timestamps and speaker identification. </li></ol>\n<p>AI transcribers continuously learn as they process more data, and this means that they improve over time. However, it's important to remember that AI transcribers can make mistakes, particularly when dealing with different accents, background noise or low quality recordings. This means that it’s always important for a human transcriber to check the AI’s results and to edit the final transcript as necessary. </p>\n<h2>Can transcriptions be referenced? </h2>\n<p>Transcriptions can be referenced using systems like Harvard, APA (American Psychological Association) and MLA (Modern Language Association) to provide proper citations for sources included in the transcription. </p>\n<p>Using <a href=\"https://www.rlf.org.uk/resources/mla-apa-harvard-or-mhra/\">referencing systems</a> like Harvard, APA or MLA is important in some forms of transcription, such as legal or academic, because it ensures sources in the text are properly acknowledged. </p>\n<h2>Can AI reference transcription? </h2>\n<p>While AI transcription software can transcribe speech to text, it cannot yet automatically generate reliable citations and listings using the standard referencing systems. However, with AI transcription capabilities developing rapidly, this will undoubtedly become possible in time. </p>\n<p>Currently, if accurate referencing is required, it must be carried out by a human transcriber. </p>\n<h2>Final thoughts </h2>\n<p>The general rules that apply to creating transcriptions are simple. However, applying different systems and using different types of transcription requires specialist knowledge. </p>\n<p><a href=\"https://www.semantix.com/solutions/translation/transcription-services-audio-video\">Our multilingual transcription services</a> offer fast, accurate transcriptions, with translations available in over 170 languages, and we offer all transcription types. We can also reference transcriptions if required. </p>\n<p>If you’d like to talk to our team about transcription, or have a project you’d like to discuss, <a href=\"https://www.semantix.com/solutions/translation/transcription-services-audio-video#form-transcription\">fill in this form and we’ll be in touch</a>. </p>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Download our free transcription templateGet started with transcription.Here you will find templates for both detailed transcription and standard transcription. You can use the formats and examples in your own working document.Why are transcriptions used?Transcriptions are useful for many purposes, including:Accessibility: Transcriptions improve accessibility for people with hearing impairments, cognitive processing difficulties or for those who require more time to absorb information.Legal purpo",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Download our free transcription templateGet started with transcription.Here you will find templates for both detailed transcription and standard transcription. You can use the formats and examples in your own working document.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Why are transcriptions used?Transcriptions are useful for many purposes, including:Accessibility: Transcriptions improve accessibility for people with hearing impairments, cognitive processing difficulties or for those who require more time to absorb information.Legal purposes:Legal proceedings, such as court hearings, depositions and interviews, are transcribed so that a permanent record is available of conversations that can be used in official records and evidence.Media: Transcriptions are us",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h4",
              "text": "Download our free transcription template",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Why are transcriptions used?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "How are transcriptions created?",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Human transcribers",
              "id": ""
            },
            {
              "level": "h3",
              "text": "AI transcribers",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Can transcriptions be referenced?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Can AI reference transcription?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Final thoughts",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://www.nature.com/articles/s42003-024-06117-5",
      "title": "A unified analysis of evolutionary and population constraint in protein domains highlights structural features and pathogenic sites",
      "author": "Barton, Geoffrey J.",
      "published_date": "2024-04-11T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<div><h2>Introduction</h2><div><p>Comparative analysis of homologous proteins and their three-dimensional structures has systematically established that sequence is constrained by structure and function<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR1\">1</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR2\">2</a></sup>. This classic result is fundamental to our understanding of molecular evolution and underlies the development of methods to predict protein structure<sup><a href=\"#ref-CR3\">3</a>,<a href=\"#ref-CR4\">4</a>,<a href=\"#ref-CR5\">5</a>,<a href=\"#ref-CR6\">6</a>,<a href=\"#ref-CR7\">7</a>,<a href=\"#ref-CR8\">8</a>,<a href=\"#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR10\">10</a></sup> and to interpret human genomes<sup><a href=\"#ref-CR11\">11</a>,<a href=\"#ref-CR12\">12</a>,<a href=\"#ref-CR13\">13</a>,<a href=\"#ref-CR14\">14</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR15\">15</a></sup>. Key elements of the sequence-structure-function relationship are that buried residues evolve more slowly than exposed residues<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR16\">16</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR17\">17</a></sup>, residues at interfaces tend to conserve physicochemical properties<sup><a href=\"#ref-CR18\">18</a>,<a href=\"#ref-CR19\">19</a>,<a href=\"#ref-CR20\">20</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR21\">21</a></sup> and co-varying residues are often close in space<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR9\">9</a></sup>. These trends, together with secondary structure<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR3\">3</a></sup> and other positional physicochemical preferences<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR22\">22</a></sup>, are among the patterns that AI algorithms like AlphaFold<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR23\">23</a></sup> can exploit and are therefore crucial to their success.</p><p>The same structural constraints that mark evolutionary variation were also expected to influence population polymorphisms<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR24\">24</a></sup>. However, systematic confirmation of the effect had to wait until resequencing projects<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR25\">25</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR26\">26</a></sup> sampled enough variation to enable the analysis. Since then the distribution of missense variants in humans was shown to be strongly influenced by protein structure, with features like core residues, catalytic sites, and interfaces showing evidence of constraint in aggregate<sup><a href=\"#ref-CR27\">27</a>,<a href=\"#ref-CR28\">28</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR29\">29</a></sup>. In parallel, several methods emerged to calculate population constraint at different scales and were consistently found to be useful for variant pathogenicity prediction<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR25\">25</a>,<a href=\"#ref-CR30\">30</a>,<a href=\"#ref-CR31\">31</a>,<a href=\"#ref-CR32\">32</a>,<a href=\"#ref-CR33\">33</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR34\">34</a></sup>. However, despite this progress, the application of population constraint for structural inference is less well-developed.</p><p>One challenge is that structural constraints in proteins are inferred from residue-level conservation patterns and so most existing constraint scores, which apply to whole genes or domains, are too coarse for this task. However, residue-level resolution is possible with the aid of protein family sequence alignments where the signal can be enhanced by combining variation across homologous sites. This approach previously enabled the detection of low-frequency cancer driver mutations<sup><a href=\"#ref-CR35\">35</a>,<a href=\"#ref-CR36\">36</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR37\">37</a></sup> and clusters of pathogenic mutations in domain families<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR38\">38</a></sup>, while population variant distributions in pseudo-paralogous alignments were shown to highlight a range of genomic features, including start codons, 5’-UTRs, CDS regions, and wobble nucleotides<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR26\">26</a></sup>. Since then, population constraint computed in this way has also proven useful for pathogenicity prediction<sup><a href=\"#ref-CR39\">39</a>,<a href=\"#ref-CR40\">40</a>,<a href=\"#ref-CR41\">41</a>,<a href=\"#ref-CR42\">42</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR43\">43</a></sup>, and its association with structural features has been observed in specific proteins<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR39\">39</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR44\">44</a></sup>.</p><p>The capacity to calculate population constraint at the residue-level, presents a unique opportunity to conduct a comparative analysis of population and evolutionary constraint in proteins. At the outset, we can consider the essential differences between the underlying datasets. The diversity catalogued in databases like Pfam<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR45\">45</a></sup> reflects the cumulative effects of hundreds of millions of years of evolution, shaped by spatial and temporal scales that give rise to an enormous potential for variation and selection. In contrast, population datasets like gnomAD<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR46\">46</a></sup> capture genetic diversity influenced by more recent events, migrations and drift, all within the genomic context of a single species. Given these profound differences, the question arises whether the signatures of population constraint within humans offer a distinct perspective from the deep evolutionary conservation observed across species. Theoretical frameworks, such as the McDonald-Kreitman test<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR47\">47</a></sup>, have exploited such contrasts to discern selection pressures, underscoring the potential of an integrated approach, but to our knowledge, it has never been applied at as fine a resolution as single amino acids.</p><p>In this work, we develop a new residue-level population constraint metric computed over the columns of protein family alignments with variants from gnomAD<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR48\">48</a></sup>. We apply this method to classify residues in thousands of protein families from Pfam<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR45\">45</a></sup>, and assess their properties with respect to features from experimentally determined protein three-dimensional structures<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR48\">48</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR49\">49</a></sup>, including solvent accessibility, protein-protein and protein-ligand interfaces and pathogenic variants from ClinVar<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR50\">50</a></sup>. We then combine our population constraint score with a conventional measure of evolutionary conservation, based on residue diversity in protein family alignments, to reveal the structural and functional properties of a new classification of residues.</p></div></div><div><h2>Results</h2><div><h3>A residue level map of population constraint in the human proteome</h3><h4>The distribution of population missense variants amongst humans is correlated with evolutionary conservation in protein domain families</h4><p>We mapped 2.4 million population missense variants from gnomAD<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR46\">46</a></sup> to 1.2 million positions within 5,885 protein domain families from Pfam<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR45\">45</a></sup>. This covers 5.2 million residues of the human proteome. Figure <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1</a> shows a schematic of a variant annotated alignment (Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1a</a>) alongside illustrations of the distribution of variants within domains in different contexts (Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1b–e</a>; Supplementary Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#MOESM2\">1</a>). In any given protein, most residues are not variable at all in gnomAD and the observed missense variants are sparsely distributed across the sequence (Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1b</a>). As a result, the distribution of missense variants along a sequence provides limited information about constraint at individual residues, which is why existing methods average over larger windows, such as continuous ranges of linear sequence<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR31\">31</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR33\">33</a></sup> or volumes in 3D space<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR34\">34</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR51\">51</a></sup>.</p><div><figure><figcaption><b>Fig. 1: Population diversity in Pfam domains is often positively correlated with evolutionary diversity.</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s42003-024-06117-5/figures/1\"></a></div><p><b>a</b> An ",
        "html": "<div><div>\n<div><h2>Introduction</h2><div><p>Comparative analysis of homologous proteins and their three-dimensional structures has systematically established that sequence is constrained by structure and function<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR1\">1</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR2\">2</a></sup>. This classic result is fundamental to our understanding of molecular evolution and underlies the development of methods to predict protein structure<sup><a href=\"#ref-CR3\">3</a>,<a href=\"#ref-CR4\">4</a>,<a href=\"#ref-CR5\">5</a>,<a href=\"#ref-CR6\">6</a>,<a href=\"#ref-CR7\">7</a>,<a href=\"#ref-CR8\">8</a>,<a href=\"#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR10\">10</a></sup> and to interpret human genomes<sup><a href=\"#ref-CR11\">11</a>,<a href=\"#ref-CR12\">12</a>,<a href=\"#ref-CR13\">13</a>,<a href=\"#ref-CR14\">14</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR15\">15</a></sup>. Key elements of the sequence-structure-function relationship are that buried residues evolve more slowly than exposed residues<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR16\">16</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR17\">17</a></sup>, residues at interfaces tend to conserve physicochemical properties<sup><a href=\"#ref-CR18\">18</a>,<a href=\"#ref-CR19\">19</a>,<a href=\"#ref-CR20\">20</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR21\">21</a></sup> and co-varying residues are often close in space<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR9\">9</a></sup>. These trends, together with secondary structure<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR3\">3</a></sup> and other positional physicochemical preferences<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR22\">22</a></sup>, are among the patterns that AI algorithms like AlphaFold<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR23\">23</a></sup> can exploit and are therefore crucial to their success.</p><p>The same structural constraints that mark evolutionary variation were also expected to influence population polymorphisms<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR24\">24</a></sup>. However, systematic confirmation of the effect had to wait until resequencing projects<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR25\">25</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR26\">26</a></sup> sampled enough variation to enable the analysis. Since then the distribution of missense variants in humans was shown to be strongly influenced by protein structure, with features like core residues, catalytic sites, and interfaces showing evidence of constraint in aggregate<sup><a href=\"#ref-CR27\">27</a>,<a href=\"#ref-CR28\">28</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR29\">29</a></sup>. In parallel, several methods emerged to calculate population constraint at different scales and were consistently found to be useful for variant pathogenicity prediction<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR25\">25</a>,<a href=\"#ref-CR30\">30</a>,<a href=\"#ref-CR31\">31</a>,<a href=\"#ref-CR32\">32</a>,<a href=\"#ref-CR33\">33</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR34\">34</a></sup>. However, despite this progress, the application of population constraint for structural inference is less well-developed.</p><p>One challenge is that structural constraints in proteins are inferred from residue-level conservation patterns and so most existing constraint scores, which apply to whole genes or domains, are too coarse for this task. However, residue-level resolution is possible with the aid of protein family sequence alignments where the signal can be enhanced by combining variation across homologous sites. This approach previously enabled the detection of low-frequency cancer driver mutations<sup><a href=\"#ref-CR35\">35</a>,<a href=\"#ref-CR36\">36</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR37\">37</a></sup> and clusters of pathogenic mutations in domain families<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR38\">38</a></sup>, while population variant distributions in pseudo-paralogous alignments were shown to highlight a range of genomic features, including start codons, 5’-UTRs, CDS regions, and wobble nucleotides<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR26\">26</a></sup>. Since then, population constraint computed in this way has also proven useful for pathogenicity prediction<sup><a href=\"#ref-CR39\">39</a>,<a href=\"#ref-CR40\">40</a>,<a href=\"#ref-CR41\">41</a>,<a href=\"#ref-CR42\">42</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR43\">43</a></sup>, and its association with structural features has been observed in specific proteins<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR39\">39</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR44\">44</a></sup>.</p><p>The capacity to calculate population constraint at the residue-level, presents a unique opportunity to conduct a comparative analysis of population and evolutionary constraint in proteins. At the outset, we can consider the essential differences between the underlying datasets. The diversity catalogued in databases like Pfam<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR45\">45</a></sup> reflects the cumulative effects of hundreds of millions of years of evolution, shaped by spatial and temporal scales that give rise to an enormous potential for variation and selection. In contrast, population datasets like gnomAD<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR46\">46</a></sup> capture genetic diversity influenced by more recent events, migrations and drift, all within the genomic context of a single species. Given these profound differences, the question arises whether the signatures of population constraint within humans offer a distinct perspective from the deep evolutionary conservation observed across species. Theoretical frameworks, such as the McDonald-Kreitman test<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR47\">47</a></sup>, have exploited such contrasts to discern selection pressures, underscoring the potential of an integrated approach, but to our knowledge, it has never been applied at as fine a resolution as single amino acids.</p><p>In this work, we develop a new residue-level population constraint metric computed over the columns of protein family alignments with variants from gnomAD<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR48\">48</a></sup>. We apply this method to classify residues in thousands of protein families from Pfam<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR45\">45</a></sup>, and assess their properties with respect to features from experimentally determined protein three-dimensional structures<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR48\">48</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR49\">49</a></sup>, including solvent accessibility, protein-protein and protein-ligand interfaces and pathogenic variants from ClinVar<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR50\">50</a></sup>. We then combine our population constraint score with a conventional measure of evolutionary conservation, based on residue diversity in protein family alignments, to reveal the structural and functional properties of a new classification of residues.</p></div></div><div><h2>Results</h2><div><h3>A residue level map of population constraint in the human proteome</h3><h4>The distribution of population missense variants amongst humans is correlated with evolutionary conservation in protein domain families</h4><p>We mapped 2.4 million population missense variants from gnomAD<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR46\">46</a></sup> to 1.2 million positions within 5,885 protein domain families from Pfam<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR45\">45</a></sup>. This covers 5.2 million residues of the human proteome. Figure <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1</a> shows a schematic of a variant annotated alignment (Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1a</a>) alongside illustrations of the distribution of variants within domains in different contexts (Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1b–e</a>; Supplementary Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#MOESM2\">1</a>). In any given protein, most residues are not variable at all in gnomAD and the observed missense variants are sparsely distributed across the sequence (Fig. <a href=\"https://www.nature.com/articles/s42003-024-06117-5#Fig1\">1b</a>). As a result, the distribution of missense variants along a sequence provides limited information about constraint at individual residues, which is why existing methods average over larger windows, such as continuous ranges of linear sequence<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR31\">31</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR33\">33</a></sup> or volumes in 3D space<sup><a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR34\">34</a>,<a href=\"https://www.nature.com/articles/s42003-024-06117-5#ref-CR51\">51</a></sup>.</p><div><figure><figcaption><b>Fig. 1: Population diversity in Pfam domains is often positively correlated with evolutionary diversity.</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s42003-024-06117-5/figures/1\"></a></div><p><b>a</b> An ",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "IntroductionComparative analysis of homologous proteins and their three-dimensional structures has systematically established that sequence is constrained by structure and function1,2. This classic result is fundamental to our understanding of molecular evolution and underlies the development of methods to predict protein structure3,4,5,6,7,8,9,10and to interpret human genomes11,12,13,14,15. Key elements of the sequence-structure-function relationship are that buried residues evolve more slowly ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionComparative analysis of homologous proteins and their three-dimensional structures has systematically established that sequence is constrained by structure and function1,2. This classic result is fundamental to our understanding of molecular evolution and underlies the development of methods to predict protein structure3,4,5,6,7,8,9,10and to interpret human genomes11,12,13,14,15. Key elements of the sequence-structure-function relationship are that buried residues evolve more slowly ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionComparative analysis of homologous proteins and their three-dimensional structures has systematically established that sequence is constrained by structure and function1,2. This classic result is fundamental to our understanding of molecular evolution and underlies the development of methods to predict protein structure3,4,5,6,7,8,9,10and to interpret human genomes11,12,13,14,15. Key elements of the sequence-structure-function relationship are that buried residues evolve more slowly ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Comparative analysis of homologous proteins and their three-dimensional structures has systematically established that sequence is constrained by structure and function1,2. This classic result is fundamental to our understanding of molecular evolution and underlies the development of methods to predict protein structure3,4,5,6,7,8,9,10and to interpret human genomes11,12,13,14,15. Key elements of the sequence-structure-function relationship are that buried residues evolve more slowly than exposed",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "ResultsA residue level map of population constraint in the human proteomeThe distribution of population missense variants amongst humans is correlated with evolutionary conservation in protein domain familiesWe mapped 2.4 million population missense variants from gnomAD46to 1.2 million positions within 5,885 protein domain families from Pfam45. This covers 5.2 million residues of the human proteome. Figure1shows a schematic of a variant annotated alignment (Fig.1a) alongside illustrations of the",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "A residue level map of population constraint in the human proteomeThe distribution of population missense variants amongst humans is correlated with evolutionary conservation in protein domain familiesWe mapped 2.4 million population missense variants from gnomAD46to 1.2 million positions within 5,885 protein domain families from Pfam45. This covers 5.2 million residues of the human proteome. Figure1shows a schematic of a variant annotated alignment (Fig.1a) alongside illustrations of the distri",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Fig. 1: Population diversity in Pfam domains is often positively correlated with evolutionary diversity.aAn",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "aAn",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Results",
              "id": ""
            },
            {
              "level": "h3",
              "text": "A residue level map of population constraint in the human proteome",
              "id": ""
            },
            {
              "level": "h4",
              "text": "The distribution of population missense variants amongst humans is correlated with evolutionary conservation in protein domain families",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://easychair.org/publications/preprint/dWLr/open",
      "title": "",
      "author": "",
      "published_date": null,
      "content": {
        "text": "EasyChair Preprint\n№ 2505\nArtificial Superintelligence: A Recursive\nSelf-Improvement Model\nPoondru Prithvinath Reddy\nEasyChair preprints are intended for rapid\ndissemination of research results and are\nintegrated with the rest of EasyChair.\nJanuary 30, 2020\nArtificial Superintelligence : A Recursive Self-Improvement Model\nPoondru Prithvinath Reddy\nABSTRACT\nRecursive self-improving( RSI ) systems create new software iteratively. The newly\ncreated software iteratively generates a greater intelligent system using the current\nsystem, then this process leads to a phenomenon referred to as superintelligence.\nHowever, many existing studies on RSI systems lack clear mathematical formulation or\nresults. In this paper, we provide a formal definition of RSI systems and then we present\na recursive self-improvement model by three different approaches. The first one is to\nfind an optimal program defined by given scores and program generation probabilities\nusing Markov chain. The second one is to model by embedding histories when\ngenerating a new program. And the third is to model the programs taking a program as\nan argument and return a suggested improvement of the given program. We use\nsimulation to show that we achieve logarithmic runtime complexity with respect to the\nsize of the search space and realize good accuracy to a AI model of embedding\nhistories. The results suggest that it is possible to achieve an efficient recursive self\u0002improvement.\nINTRODUCTION\nIf research into strong AI produced sufficiently intelligent software, it would be able to\nreprogram and improve itself – a feature called \"recursive self-improvement( RSI )\". It\nwould then be even better at improving itself, and could continue doing so in a rapidly\nincreasing cycle, leading to a superintelligence. This scenario is known as an\nintelligence explosion. Such an intelligence would not have the limitations of human\nintellect, and may be able to invent or discover almost anything.\nThus, the simplest example of a superintelligence may be an emulated human mind\nthat's run on much faster hardware than the brain. A human-like reasoner that could\nthink millions of times faster than current humans would have a dominant advantage in\nmost reasoning tasks, particularly ones that require haste or long strings of actions. This\nalso raises the possibility of collective superintelligence : a large enough number of\nseparate reasoning systems, if they communicated and coordinated well enough, could\nact in aggregate with far greater capabilities than any sub-agent.\nThe technological singularity – is a hypothetical future point in time at which\ntechnological growth becomes called intelligence explosion, an upgradable intelligent\nagent (such as a computer running software-based artificial general intelligence) will\neventually enter a \"runaway reaction\" of self-improvement cycles, with each new and\nmore intelligent generation appearing more and more rapidly, causing an \"explosion\" in\nintelligence and resulting in a powerful superintelligence that qualitatively far surpasses\nall human intelligence.\nRecursive self-improving( RSI ) systems create new software iteratively. The newly\ncreated software should be better at creating future software. With this property, the\nsystem has potential to completely rewrite its original implementation, and take\ncompletely different approaches. Chalmers’ proportionality thesis hypothesizes that an\nincrease in the capability of creating future systems proportionally increases the\nintelligence of the resulting system. With this hypothesis, he shows if a process\niteratively generates a greater intelligent system using the current system, then this\nprocess leads to a phenomenon many refer to as super-intelligence. However, many\nexisting studies of RSI systems remain philosophical or lack clear mathematical\nformulation or results.\nMETHODOLOGY\nIf it is possible for a system to improve itself, for example, for a program to rewrite its\nown source code to learn faster, or to store more knowledge in a fixed space, without\nbeing given any information except its own source code. This is a different problem than\nlearning, where a program gets better at achieving goals as it receives input. An\nexample of a self improving program would be a program that gets better at playing\nchess by playing games against itself. Another example would be a program with the\ngoal of finding large prime numbers within t steps given t. The program might improve\nitself by varying its source code and testing whether the changes find larger primes for\nvarious t.\nIn this paper, we provide a mathematical and other formulations for a class of RSI\nprocedures and show that there are such different computable RSI systems or\napproaches.\nThe methodology essentially consist of the following :\n To find the optimal program following RSI procedure defined by given scores\nand program generation probabilities using Markov chain.\n To model by embedding histories when generating a new program.\n To model the programs taking a program as an argument and return a suggested\nimprovement of the given program.\nARCHITECTURE\nOPTIMAL PROGRAM FOLLOWING RSI\nRecursive Self Improvement : Define an improving sequence with respect to G as an\ninfinite sequence of programs P1, P2, P3,... such that for all i > 0, Pi+1 improves on Pi\nwith respect to goal G and G be the identity goal.\nDefinition: P1 is a recursively self improving (RSI) program with respect to G if and only\nif Pi(-1) = Pi+1 for all i > 0 and the sequence Pi, i = 1, 2, 3...is an improving sequence\nwith respect to G.\nDefinition (RSI system).Given a finite set of programs P and a score function S over P.\nInitialize p from P to be the system’s current program. Repeat until certain criterion\nsatisfied, generate p'∈ P using p. If p'is better than p according to S, replace p by p'.\nFrom this definition, one needs to decide how p ∈ P generates a program. In general,\nwe should allow the RSI system to generate programs based on the history of the entire\nprocess. The way a program generates a new program is independent, and each\nprogram defines a fixed probabilistic distribution over P. This procedure defines a\nhomogeneous Markov chain. We will see that even with this restriction, with some score\nfunction, the model is able to achieve a desirable performance.\nWe illustrate the proposed formulation by an example. Consider a set of programs\nP={p1, p2, p3, p4} and a score function S over P such that S(pi) =i. According to our\nformulation, each program can be abstracted as a probabilistic distribution over P. To\nspecify the distributions, let wi be a vector of probabilistic weights of length 4 that\nrepresents the probabilistic distribution over P corresponding to pi. In this example we\nset w1= [0.97,0.01,0.01,0.01], w2= [0.75,0,0.25,0], w3= [0.25,0.25,0.25,0.25],\nw4= [0,0.58,0,0.42].Then a possible RSI procedure may do the flowing. It starts from p3.\nFirst p3 generates p4. Since S(p4)> S(p3), the current program is not updated. Then p3\ngenerates p2. The current program is updated to p2 because S(p2)< S(p3). Next p2\ngenerates p1, and the current program updates to p1. Since p1 has the lowest score\n(highest order), no future program will be updated. Figure 1 shows the corresponding\nMarkov chain.\nFigure 1 The Markov chain corresponding to the RSI\nFig. 1: The Markov chain corresponding to the RSI procedure defined by given scores\nand program generation probabilities.\nA reasonable utility measure is the expected numbers of steps starting from a program\nto find the optimal program following our RSI definition. Furthermore, the score function\nneeds to be consistent with the expected numbers of steps from programs to the\noptimal program following the process defined by itself. We mean that a score function\nS is consistent if for all p, p′∈P, S(p)> S(p′)implies that the expected number of steps to\nreach the optimal program from p is greater than starting from p′. More generally, if one\ntakes some measure for a programs’ ability to generate future programs, the score\nfunction needs to be consistent with this measure.\nTwo nice properties hold for this construction. First, the programs are added in a non\u0002decreasing order of scores. Second, the score function equals the expected numbers of\nsteps to reach the optimal program defined by this score function. We will prove the first\nproperty. The second property and the consistency of the score function are\nstraightforward from the first property. We describe an example of how such score\nfunction is computed given the distributions to generate programs of each program and\nthe optimal program. Consider the same abstraction of programs as the above example,\nwhere P={p1, p2, p3, p4} with corresponding probabilistic weights w1=\n[0.97,0.01,0.01,0.01], w2= [0.75,0,0.25,0], w3= [0.25,0.25,0.25,0.25], w4=\n[0,0.58,0,0.42]. Fix p1 to be the optimal program. Initially set S(p1) = 0 and S(pi) =∞,\ni=2,3,4. The transition function of initial Markov chain is\nAt the first step, the expected number of steps from p2, p3, p4 following the current\nMarkov chain are 4/3,4,∞. Hence we update S(p2) = 4/3. Because of the change of\nscore, transition of the Markov chain change to\nThen we compute the expected number of steps from p3 and p4 following the updated\nMarkov chain. By some arithmetic we get the expectation are 8/3 for p3 and\n(approximately) 3.057 for p4. Since 8/3<3.057, update S(p3) = 8/3. By similar\nprocedures, one can compute the score for S(p4).\nEMBEDDDING HISTORIES\nRecursive self-improvement describes software that writes its own code in repeated\ncycles of improvement. It is associated with artificial intelligence as self-improving\nsoftware has potential to develop superintelligence.\nRecursion can be seen as an elegant 'architectural factorization' - building complexity by\ncombining the results of smaller, similar patterns previously encountered.\nComputationally, recursion can always be converted into iteration so this form of\nelegance is m",
        "html": "EasyChair Preprint\n№ 2505\nArtificial Superintelligence: A Recursive\nSelf-Improvement Model\nPoondru Prithvinath Reddy\nEasyChair preprints are intended for rapid\ndissemination of research results and are\nintegrated with the rest of EasyChair.\nJanuary 30, 2020\nArtificial Superintelligence : A Recursive Self-Improvement Model\nPoondru Prithvinath Reddy\nABSTRACT\nRecursive self-improving( RSI ) systems create new software iteratively. The newly\ncreated software iteratively generates a greater intelligent system using the current\nsystem, then this process leads to a phenomenon referred to as superintelligence.\nHowever, many existing studies on RSI systems lack clear mathematical formulation or\nresults. In this paper, we provide a formal definition of RSI systems and then we present\na recursive self-improvement model by three different approaches. The first one is to\nfind an optimal program defined by given scores and program generation probabilities\nusing Markov chain. The second one is to model by embedding histories when\ngenerating a new program. And the third is to model the programs taking a program as\nan argument and return a suggested improvement of the given program. We use\nsimulation to show that we achieve logarithmic runtime complexity with respect to the\nsize of the search space and realize good accuracy to a AI model of embedding\nhistories. The results suggest that it is possible to achieve an efficient recursive self\u0002improvement.\nINTRODUCTION\nIf research into strong AI produced sufficiently intelligent software, it would be able to\nreprogram and improve itself – a feature called \"recursive self-improvement( RSI )\". It\nwould then be even better at improving itself, and could continue doing so in a rapidly\nincreasing cycle, leading to a superintelligence. This scenario is known as an\nintelligence explosion. Such an intelligence would not have the limitations of human\nintellect, and may be able to invent or discover almost anything.\nThus, the simplest example of a superintelligence may be an emulated human mind\nthat's run on much faster hardware than the brain. A human-like reasoner that could\nthink millions of times faster than current humans would have a dominant advantage in\nmost reasoning tasks, particularly ones that require haste or long strings of actions. This\nalso raises the possibility of collective superintelligence : a large enough number of\nseparate reasoning systems, if they communicated and coordinated well enough, could\nact in aggregate with far greater capabilities than any sub-agent.\nThe technological singularity – is a hypothetical future point in time at which\ntechnological growth becomes called intelligence explosion, an upgradable intelligent\nagent (such as a computer running software-based artificial general intelligence) will\neventually enter a \"runaway reaction\" of self-improvement cycles, with each new and\nmore intelligent generation appearing more and more rapidly, causing an \"explosion\" in\nintelligence and resulting in a powerful superintelligence that qualitatively far surpasses\nall human intelligence.\nRecursive self-improving( RSI ) systems create new software iteratively. The newly\ncreated software should be better at creating future software. With this property, the\nsystem has potential to completely rewrite its original implementation, and take\ncompletely different approaches. Chalmers’ proportionality thesis hypothesizes that an\nincrease in the capability of creating future systems proportionally increases the\nintelligence of the resulting system. With this hypothesis, he shows if a process\niteratively generates a greater intelligent system using the current system, then this\nprocess leads to a phenomenon many refer to as super-intelligence. However, many\nexisting studies of RSI systems remain philosophical or lack clear mathematical\nformulation or results.\nMETHODOLOGY\nIf it is possible for a system to improve itself, for example, for a program to rewrite its\nown source code to learn faster, or to store more knowledge in a fixed space, without\nbeing given any information except its own source code. This is a different problem than\nlearning, where a program gets better at achieving goals as it receives input. An\nexample of a self improving program would be a program that gets better at playing\nchess by playing games against itself. Another example would be a program with the\ngoal of finding large prime numbers within t steps given t. The program might improve\nitself by varying its source code and testing whether the changes find larger primes for\nvarious t.\nIn this paper, we provide a mathematical and other formulations for a class of RSI\nprocedures and show that there are such different computable RSI systems or\napproaches.\nThe methodology essentially consist of the following :\n To find the optimal program following RSI procedure defined by given scores\nand program generation probabilities using Markov chain.\n To model by embedding histories when generating a new program.\n To model the programs taking a program as an argument and return a suggested\nimprovement of the given program.\nARCHITECTURE\nOPTIMAL PROGRAM FOLLOWING RSI\nRecursive Self Improvement : Define an improving sequence with respect to G as an\ninfinite sequence of programs P1, P2, P3,... such that for all i > 0, Pi+1 improves on Pi\nwith respect to goal G and G be the identity goal.\nDefinition: P1 is a recursively self improving (RSI) program with respect to G if and only\nif Pi(-1) = Pi+1 for all i > 0 and the sequence Pi, i = 1, 2, 3...is an improving sequence\nwith respect to G.\nDefinition (RSI system).Given a finite set of programs P and a score function S over P.\nInitialize p from P to be the system’s current program. Repeat until certain criterion\nsatisfied, generate p'∈ P using p. If p'is better than p according to S, replace p by p'.\nFrom this definition, one needs to decide how p ∈ P generates a program. In general,\nwe should allow the RSI system to generate programs based on the history of the entire\nprocess. The way a program generates a new program is independent, and each\nprogram defines a fixed probabilistic distribution over P. This procedure defines a\nhomogeneous Markov chain. We will see that even with this restriction, with some score\nfunction, the model is able to achieve a desirable performance.\nWe illustrate the proposed formulation by an example. Consider a set of programs\nP={p1, p2, p3, p4} and a score function S over P such that S(pi) =i. According to our\nformulation, each program can be abstracted as a probabilistic distribution over P. To\nspecify the distributions, let wi be a vector of probabilistic weights of length 4 that\nrepresents the probabilistic distribution over P corresponding to pi. In this example we\nset w1= [0.97,0.01,0.01,0.01], w2= [0.75,0,0.25,0], w3= [0.25,0.25,0.25,0.25],\nw4= [0,0.58,0,0.42].Then a possible RSI procedure may do the flowing. It starts from p3.\nFirst p3 generates p4. Since S(p4)> S(p3), the current program is not updated. Then p3\ngenerates p2. The current program is updated to p2 because S(p2)< S(p3). Next p2\ngenerates p1, and the current program updates to p1. Since p1 has the lowest score\n(highest order), no future program will be updated. Figure 1 shows the corresponding\nMarkov chain.\nFigure 1 The Markov chain corresponding to the RSI\nFig. 1: The Markov chain corresponding to the RSI procedure defined by given scores\nand program generation probabilities.\nA reasonable utility measure is the expected numbers of steps starting from a program\nto find the optimal program following our RSI definition. Furthermore, the score function\nneeds to be consistent with the expected numbers of steps from programs to the\noptimal program following the process defined by itself. We mean that a score function\nS is consistent if for all p, p′∈P, S(p)> S(p′)implies that the expected number of steps to\nreach the optimal program from p is greater than starting from p′. More generally, if one\ntakes some measure for a programs’ ability to generate future programs, the score\nfunction needs to be consistent with this measure.\nTwo nice properties hold for this construction. First, the programs are added in a non\u0002decreasing order of scores. Second, the score function equals the expected numbers of\nsteps to reach the optimal program defined by this score function. We will prove the first\nproperty. The second property and the consistency of the score function are\nstraightforward from the first property. We describe an example of how such score\nfunction is computed given the distributions to generate programs of each program and\nthe optimal program. Consider the same abstraction of programs as the above example,\nwhere P={p1, p2, p3, p4} with corresponding probabilistic weights w1=\n[0.97,0.01,0.01,0.01], w2= [0.75,0,0.25,0], w3= [0.25,0.25,0.25,0.25], w4=\n[0,0.58,0,0.42]. Fix p1 to be the optimal program. Initially set S(p1) = 0 and S(pi) =∞,\ni=2,3,4. The transition function of initial Markov chain is\nAt the first step, the expected number of steps from p2, p3, p4 following the current\nMarkov chain are 4/3,4,∞. Hence we update S(p2) = 4/3. Because of the change of\nscore, transition of the Markov chain change to\nThen we compute the expected number of steps from p3 and p4 following the updated\nMarkov chain. By some arithmetic we get the expectation are 8/3 for p3 and\n(approximately) 3.057 for p4. Since 8/3<3.057, update S(p3) = 8/3. By similar\nprocedures, one can compute the score for S(p4).\nEMBEDDDING HISTORIES\nRecursive self-improvement describes software that writes its own code in repeated\ncycles of improvement. It is associated with artificial intelligence as self-improving\nsoftware has potential to develop superintelligence.\nRecursion can be seen as an elegant 'architectural factorization' - building complexity by\ncombining the results of smaller, similar patterns previously encountered.\nComputationally, recursion can always be converted into iteration so this form of\nelegance is m",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.leydesdorff.net/luhmann_simulated/",
      "title": "Meaning, Anticipation, and Codification in Functionally Differentiated Systems of Communication",
      "author": "",
      "published_date": "2023-02-06T17:04:16.000Z",
      "content": {
        "text": "<div><div>\n<p><a href=\"http://www.leydesdorff.net/list.htm\">return</a></p>\n<p><b>Meaning, Anticipation, and Codification in </b></p>\n<p><b>Functionally Differentiated Systems of Communication</b></p>\n<p><a href=\"http://www.leydesdorff.net/luhmann_simulated/leydesdorff2004.pdf\">&lt;click here for pdf&gt;</a></p>\n<p>Loet Leydesdorff</p>\n<p>Science &amp; Technology Dynamics, University of Amsterdam</p>\n<p>Amsterdam School of Communications Research (ASCoR)</p>\n<p>Kloveniersburgwal 48, 1012 CX Amsterdam, The Netherlands</p>\n<p><a href=\"mailto:loet@leydesdorff.net\">loet@leydesdorff.net</a>\n; <a href=\"http://www.leydesdorff.net/\">http://www.leydesdorff.net</a> </p>\n<p>In: Thomas Kron, Uwe Schimank,\nand Lars Winter (Eds.), </p>\n<p><i>Luhmann simulated  </i></p>\n<p><i>Computer Simulations\nto the Theory of Social Systems</i></p>\n<p><b>1. Introduction</b></p>\n<p>In order to generate and process meaning, a communication\nsystem has to entertain a model of itself. A system which contains a model of\nitself can function in an anticipatory mode. The anticipatory subsystem\noperates on the system from the perspective of hindsight, and thus an observer\ncan be generated. The hindsight perspective is based on advancing the clock of\nthe modeling subsystem by one time-step. From this next stage the model looks\nback reflexively. However, the ensemble of the system and its model move\nhistorically, that is, with the arrow of time. The forward movement can be\nsimulated as a <i>recursive </i>routine, while the reflexive subroutine\noperates <i>incursively</i>, that is, as a feedback against the arrow of time. </p>\n<p>In this contribution, I shall show that a differentiated\nsystem of communications can be expected to contain two anticipatory\nmechanisms: (1) meaning is provided with hindsight, i.e., with a time-step\ndifference from the reflected operation in both differentiated and\nundifferentiated systems; and (2) differentiation in the social system\ngenerates an asynchronicity (Δt) between the operation of its differently\ncodified subsystems at each moment in time. The codes of the subsystems provide\nthem concurrently (in the present) with representations of each other. For\nexample, the state of the art in a technology is reflected in prices on the\nmarket. The historical development of the technology follows a dynamics which\nis in important respects different from the price mechanism (Rosenberg, 1976).\nThe two subdynamics, however, can be expected to interact.</p>\n<p>When two anticipatory mechanisms operate on each other, a\nso-called strongly anticipatory system can be shaped as the result of a\nresonance or a coevolution between the two subdynamics. While weakly\nanticipatory systems contain a model of themselveswhich can be used by the\nsystem as a predictiona strongly anticipatory system is also able to rewrite\nitself. Thus, a differentiated system of communication can endogenously\ngenerate mechanisms for its reconstruction. For example, this system can be\nreconstructed in a techno-economic evolution. </p>\n<p>Incursive subdynamics operating upon each other may also\nlead to hyper-incursion. Knowledge, for example, further codifies the meaning\nin communication. The formula for the hyper-incursion indicates an uncertainty\nin the decision-rule which can be appreciated as the need for organization at\nthe interfaces. The knowledge base of the system and its subsystems (e.g., the\neconomy) is based on adding this third subdynamic to the system. The\nglobalizing knowledge base can be expected to rest on a relatively stabilized knowledge\ninfrastructure. </p>\n<p><b>2. Meaning and anticipation as systems operations</b></p>\n<p>In addition to his inheritance of Parsonss (1937, 1951)\nrepertoire of systems theory,<a></a><a href=\"#_ftn1\"><sup>[1]</sup></a>\none can recognize in Luhmanns writings a relation with American pragmatism and\nwith systems and operations research as other semantic resources. First, the\nproposal to consider meaning (<i>Sinn</i>) as the operator of social systems\nrefers to a central assumption in symbolic interactionism: inter-human interaction\ngenerates meaning in a social situation (Blumer, 1969; Lindesmith <i>et al</i>.,\n1975; Mead, 1934; cf. Luhmann, 1997, at pp. 205 ff.). In this sociological\nelaboration of the pragmatist tradition and with equal reference to Weber as in\nthe systems tradition, meaning has been considered as the constitutive\noperator that distinguishes the domains of the social sciences from the natural\nand life sciences. While the latter define their objects naturalistically, in\nthe social sciences one approaches the objects of study reflexively. Schutz\n(1951), for example, analyzed the codes of communication in a social system\nwhen one is making music together. However, the systems approach was\nnever appreciated from the perspective of symbolic interactionism (Grathof, 1952;\nGrant, 2003).</p>\n<p>A third tradition which resounds in social systems theory is\nthe quantitative one that roots systems theory in operations research and\nsimulation studies. At several places Luhmann refers to the modeling efforts in\nsystems research. For example, when discussing the relative autonomy of the\nsciences as subsystems of communication within society, he noted that the\nclosure of the subsystem science can be understood from the epistemological\nperspective as a condition for scientific progress, but that this perspective\ndoes not exhaust the advantages of the systems-theoretical description. Luhmann\n(1990, at p. 340) formulated the additional perspective as follows:</p>\n<p>The\ndifferentiation of science as an autonomous, operationally closed system using\na binary code for its operations is not only a historical self-realization of\nscience. Indeed, one is able to describe this process from the perspective of\nscientific progress. [ ] However, the theme of relative autonomy based on\nfunctional differentiation provides options for further development within the\nsciences in addition to the philosophical reconstruction. The differentiation\nof science in society changes also the social system in which it occurs, and this\ncan again be made the subject of scientific theorizing. </p>\n<p>\nDeveloping this perspective, however, is only possible if an accordingly\ncomplex systems theoretical arrangement is specified. It remains the case that\nthe sciences can only communicate what they communicate; science observes\naccording to its own procedures. This is also the case when considering\nquestions about the social system that encompasses the science system. However,\nwhen one analyzes the social system as a differentiated system, one can also\nreflexively consider science as one of its subsystems. From this external\nperspective the sociologist can study the sciences scientifically and compare\ntheir development with other subsystems of society. <a></a><a href=\"#_ftn2\"><sup>[2]</sup></a></p>\n<p>How can such an accordingly complex systems-theoretical\narrangement be constructed? How can one move from the theoretical reflection\nto a model specified in terms of systems operations? Would the specification of\nsuch a model of a complex system enable us to run simulations? (Kron, 2002)</p>\n<p>Although Luhmann disclaimed the\nstandard methodologies of the social sciences, he saw a key role for\nmethodological developments from this perspective. In his opinion, theoretical\nprograms cannot be further developed without the intervention of methodological\nprograms. For example, Luhmann (1990, at p. 413f.) formulated: </p>\n<p>In\norder to validate the binary code that distinguishes true from false, one needs\nprograms of a different type. Lets call them <i>methods</i>.</p>\n<p>\nProgrammatically, methods provide the perspective that the system lost when it\nwas codified in binary terms. The methods force the specification of the\nobservation in terms of levels and therefore the specification of second-order\nobservations, that is, observations of previous observations by the same\nsystem. [ ] The methodology enables us to formulate programs for a historical\nmachine.<a></a><a href=\"#_ftn3\"><sup>[3]</sup></a></p>\n<p>However, this methodological reflection requires the\nspecification of the problems in a language more formal than the theoretical\nlanguage. Theories and methods have first to be distinguished and then to be\nrecombined (<i>ibid</i>., p. 428). Among Luhmanns students, Dirk Baecker has\nbeen most prominent in attempts to use George Spencer Browns (1969) <i>Laws of\nForms </i>for the formalization of the theory.<a></a><a href=\"#_ftn4\"><sup>[4]</sup></a> </p>\n<p>Following Von Foerster, Pask, and other systems\ntheoreticians (cf. Glanville, 1996), Baecker (2002) distinguished between two\ntypes of models. First-order models aim at improving the quality of theoretical\nstatements about observations, but second-order models consider the first-order\ndescriptions as operating within the systems under observation. For example,\nscientists report on their observations in the scientific literature, and these\nreports can again be observed. Consequently, one can attribute the uncertainty\nin second-order observations to two sources of error: the first-order\nobservations and/or the reflections on these observations. The causality thus\nbecomes undetermined and the system under study can therefore be considered\nnon-trivial. </p>\n<p>For example, if one provides a dually-layered\nsystemprocessing both information and menaingwith an input, it can be\nexpected to produce an output on the basis of two operations in parallel. The\ntwo parallel operations can additionally interact with each other. Thus, a\nwhole range of outputs becomes possible on the basis of a single input. The\noutput is no longer dependent on the input only, but also on the path of the\nprocessing of the signal through the complex system. Furthermore, the\nprocessing of meaning on top of the information exchange generates meaningful\n(that is, new) information that can recursively be communicated within ",
        "html": "<div><div>\n<p><a href=\"http://www.leydesdorff.net/list.htm\">return</a></p>\n<p><b>Meaning, Anticipation, and Codification in </b></p>\n<p><b>Functionally Differentiated Systems of Communication</b></p>\n<p><a href=\"http://www.leydesdorff.net/luhmann_simulated/leydesdorff2004.pdf\">&lt;click here for pdf&gt;</a></p>\n<p>Loet Leydesdorff</p>\n<p>Science &amp; Technology Dynamics, University of Amsterdam</p>\n<p>Amsterdam School of Communications Research (ASCoR)</p>\n<p>Kloveniersburgwal 48, 1012 CX Amsterdam, The Netherlands</p>\n<p><a href=\"mailto:loet@leydesdorff.net\">loet@leydesdorff.net</a>\n; <a href=\"http://www.leydesdorff.net/\">http://www.leydesdorff.net</a> </p>\n<p>In: Thomas Kron, Uwe Schimank,\nand Lars Winter (Eds.), </p>\n<p><i>Luhmann simulated  </i></p>\n<p><i>Computer Simulations\nto the Theory of Social Systems</i></p>\n<p><b>1. Introduction</b></p>\n<p>In order to generate and process meaning, a communication\nsystem has to entertain a model of itself. A system which contains a model of\nitself can function in an anticipatory mode. The anticipatory subsystem\noperates on the system from the perspective of hindsight, and thus an observer\ncan be generated. The hindsight perspective is based on advancing the clock of\nthe modeling subsystem by one time-step. From this next stage the model looks\nback reflexively. However, the ensemble of the system and its model move\nhistorically, that is, with the arrow of time. The forward movement can be\nsimulated as a <i>recursive </i>routine, while the reflexive subroutine\noperates <i>incursively</i>, that is, as a feedback against the arrow of time. </p>\n<p>In this contribution, I shall show that a differentiated\nsystem of communications can be expected to contain two anticipatory\nmechanisms: (1) meaning is provided with hindsight, i.e., with a time-step\ndifference from the reflected operation in both differentiated and\nundifferentiated systems; and (2) differentiation in the social system\ngenerates an asynchronicity (Δt) between the operation of its differently\ncodified subsystems at each moment in time. The codes of the subsystems provide\nthem concurrently (in the present) with representations of each other. For\nexample, the state of the art in a technology is reflected in prices on the\nmarket. The historical development of the technology follows a dynamics which\nis in important respects different from the price mechanism (Rosenberg, 1976).\nThe two subdynamics, however, can be expected to interact.</p>\n<p>When two anticipatory mechanisms operate on each other, a\nso-called strongly anticipatory system can be shaped as the result of a\nresonance or a coevolution between the two subdynamics. While weakly\nanticipatory systems contain a model of themselveswhich can be used by the\nsystem as a predictiona strongly anticipatory system is also able to rewrite\nitself. Thus, a differentiated system of communication can endogenously\ngenerate mechanisms for its reconstruction. For example, this system can be\nreconstructed in a techno-economic evolution. </p>\n<p>Incursive subdynamics operating upon each other may also\nlead to hyper-incursion. Knowledge, for example, further codifies the meaning\nin communication. The formula for the hyper-incursion indicates an uncertainty\nin the decision-rule which can be appreciated as the need for organization at\nthe interfaces. The knowledge base of the system and its subsystems (e.g., the\neconomy) is based on adding this third subdynamic to the system. The\nglobalizing knowledge base can be expected to rest on a relatively stabilized knowledge\ninfrastructure. </p>\n<p><b>2. Meaning and anticipation as systems operations</b></p>\n<p>In addition to his inheritance of Parsonss (1937, 1951)\nrepertoire of systems theory,<a></a><a href=\"#_ftn1\"><sup>[1]</sup></a>\none can recognize in Luhmanns writings a relation with American pragmatism and\nwith systems and operations research as other semantic resources. First, the\nproposal to consider meaning (<i>Sinn</i>) as the operator of social systems\nrefers to a central assumption in symbolic interactionism: inter-human interaction\ngenerates meaning in a social situation (Blumer, 1969; Lindesmith <i>et al</i>.,\n1975; Mead, 1934; cf. Luhmann, 1997, at pp. 205 ff.). In this sociological\nelaboration of the pragmatist tradition and with equal reference to Weber as in\nthe systems tradition, meaning has been considered as the constitutive\noperator that distinguishes the domains of the social sciences from the natural\nand life sciences. While the latter define their objects naturalistically, in\nthe social sciences one approaches the objects of study reflexively. Schutz\n(1951), for example, analyzed the codes of communication in a social system\nwhen one is making music together. However, the systems approach was\nnever appreciated from the perspective of symbolic interactionism (Grathof, 1952;\nGrant, 2003).</p>\n<p>A third tradition which resounds in social systems theory is\nthe quantitative one that roots systems theory in operations research and\nsimulation studies. At several places Luhmann refers to the modeling efforts in\nsystems research. For example, when discussing the relative autonomy of the\nsciences as subsystems of communication within society, he noted that the\nclosure of the subsystem science can be understood from the epistemological\nperspective as a condition for scientific progress, but that this perspective\ndoes not exhaust the advantages of the systems-theoretical description. Luhmann\n(1990, at p. 340) formulated the additional perspective as follows:</p>\n<p>The\ndifferentiation of science as an autonomous, operationally closed system using\na binary code for its operations is not only a historical self-realization of\nscience. Indeed, one is able to describe this process from the perspective of\nscientific progress. [ ] However, the theme of relative autonomy based on\nfunctional differentiation provides options for further development within the\nsciences in addition to the philosophical reconstruction. The differentiation\nof science in society changes also the social system in which it occurs, and this\ncan again be made the subject of scientific theorizing. </p>\n<p>\nDeveloping this perspective, however, is only possible if an accordingly\ncomplex systems theoretical arrangement is specified. It remains the case that\nthe sciences can only communicate what they communicate; science observes\naccording to its own procedures. This is also the case when considering\nquestions about the social system that encompasses the science system. However,\nwhen one analyzes the social system as a differentiated system, one can also\nreflexively consider science as one of its subsystems. From this external\nperspective the sociologist can study the sciences scientifically and compare\ntheir development with other subsystems of society. <a></a><a href=\"#_ftn2\"><sup>[2]</sup></a></p>\n<p>How can such an accordingly complex systems-theoretical\narrangement be constructed? How can one move from the theoretical reflection\nto a model specified in terms of systems operations? Would the specification of\nsuch a model of a complex system enable us to run simulations? (Kron, 2002)</p>\n<p>Although Luhmann disclaimed the\nstandard methodologies of the social sciences, he saw a key role for\nmethodological developments from this perspective. In his opinion, theoretical\nprograms cannot be further developed without the intervention of methodological\nprograms. For example, Luhmann (1990, at p. 413f.) formulated: </p>\n<p>In\norder to validate the binary code that distinguishes true from false, one needs\nprograms of a different type. Lets call them <i>methods</i>.</p>\n<p>\nProgrammatically, methods provide the perspective that the system lost when it\nwas codified in binary terms. The methods force the specification of the\nobservation in terms of levels and therefore the specification of second-order\nobservations, that is, observations of previous observations by the same\nsystem. [ ] The methodology enables us to formulate programs for a historical\nmachine.<a></a><a href=\"#_ftn3\"><sup>[3]</sup></a></p>\n<p>However, this methodological reflection requires the\nspecification of the problems in a language more formal than the theoretical\nlanguage. Theories and methods have first to be distinguished and then to be\nrecombined (<i>ibid</i>., p. 428). Among Luhmanns students, Dirk Baecker has\nbeen most prominent in attempts to use George Spencer Browns (1969) <i>Laws of\nForms </i>for the formalization of the theory.<a></a><a href=\"#_ftn4\"><sup>[4]</sup></a> </p>\n<p>Following Von Foerster, Pask, and other systems\ntheoreticians (cf. Glanville, 1996), Baecker (2002) distinguished between two\ntypes of models. First-order models aim at improving the quality of theoretical\nstatements about observations, but second-order models consider the first-order\ndescriptions as operating within the systems under observation. For example,\nscientists report on their observations in the scientific literature, and these\nreports can again be observed. Consequently, one can attribute the uncertainty\nin second-order observations to two sources of error: the first-order\nobservations and/or the reflections on these observations. The causality thus\nbecomes undetermined and the system under study can therefore be considered\nnon-trivial. </p>\n<p>For example, if one provides a dually-layered\nsystemprocessing both information and menaingwith an input, it can be\nexpected to produce an output on the basis of two operations in parallel. The\ntwo parallel operations can additionally interact with each other. Thus, a\nwhole range of outputs becomes possible on the basis of a single input. The\noutput is no longer dependent on the input only, but also on the path of the\nprocessing of the signal through the complex system. Furthermore, the\nprocessing of meaning on top of the information exchange generates meaningful\n(that is, new) information that can recursively be communicated within ",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "returnMeaning, Anticipation, and Codification inFunctionally Differentiated Systems of Communication<click here for pdf>Loet LeydesdorffScience & Technology Dynamics, University of AmsterdamAmsterdam School of Communications Research (ASCoR)Kloveniersburgwal 48, 1012 CX Amsterdam, The Netherlandsloet@leydesdorff.net;http://www.leydesdorff.netIn: Thomas Kron, Uwe Schimank,\nand Lars Winter (Eds.),Luhmann simulated Computer Simulations\nto the Theory of Social Systems1. IntroductionIn order to gene",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "returnMeaning, Anticipation, and Codification inFunctionally Differentiated Systems of Communication<click here for pdf>Loet LeydesdorffScience & Technology Dynamics, University of AmsterdamAmsterdam School of Communications Research (ASCoR)Kloveniersburgwal 48, 1012 CX Amsterdam, The Netherlandsloet@leydesdorff.net;http://www.leydesdorff.netIn: Thomas Kron, Uwe Schimank,\nand Lars Winter (Eds.),Luhmann simulated Computer Simulations\nto the Theory of Social Systems1. IntroductionIn order to gene",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://plato.stanford.edu/entries/recursive-functions/",
      "title": "Recursive Functions",
      "author": "Naibo, Alberto",
      "published_date": "2020-04-23T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<h2>1. Historical Background</h2>\n<p>\nThe theory of recursive functions is often presented as a chapter in\nthe history of the subject originally known as <em>recursive function\ntheory</em>. This subject has its roots in the foundational debates of\nthe first half of the twentieth century. Within this context, the need\narose to provide a precise analysis of what we would naturally\ndescribe as inductive or recursive modes of reasoning which play a\npart in the deductive machinery of axiomatic theories in mathematics.\nThis history will be traced in the current section, with an emphasis\non how different forms of recursion have been understood as\nexemplifying various kinds of step-by-step algorithmic processes. </p>\n<p>\nThis section assumes some familiarity with some of the terminology\nintroduced in\n<a href=\"#FormRecu\">Section 2</a>\nand\n<a href=\"#CompTheo\">Section 3</a>.\nReaders looking for a technical overview of recursive functions or\ncomputability theory are advised to start there.</p>\n<h3>1.1 The Early History of Recursive Definitions</h3>\n<p>\nExamples of recursive definitions can be found intermittently in the\nhistory of ancient and medieval mathematics. A familiar illustration\nis the sequence \\(F_i\\) of <em>Fibonacci numbers</em>\n\\(1,1,2,3,5,8,13, \\ldots\\) given by the recurrence \\(F_0 = 1, F_1 =\n1\\) and \\(F_{n} = F_{n-1} + F_{n-2}\\) (see\n<a href=\"#AddiClosPropPrimRecuFunc\">Section 2.1.3</a>).\nThe definition of this sequence has traditionally been attributed to\nthe thirteenth century Italian mathematician Leonardo of Pisa (also\nknown as Fibonacci) who introduced it in his <em>Liber Abaci</em> in\nthe context of an example involving population genetics (see Fibonacci\n1202 [2003: 404–405]). But descriptions of similar sequences can\nalso be found in Greek, Egyptian, and Sanskrit sources dating as early\nas 700 BCE (see, e.g., Singh 1985).</p>\n<p>\nGeneral interest in recursion as a mode of function definition\noriginated in the mid-nineteenth century as part of the broader\nprogram of arithmetizing analysis and the ensuing discussions of the\nfoundations of arithmetic itself. In this context, the formulation of\nrecursive definitions for number theoretic functions was closely tied\nto the isolation of mathematical induction as a mode of reasoning\nabout the natural numbers. It was in this setting in which Grassmann\n(1861) and Peirce (1881) first gave the familiar recursive definitions\nof addition and\nmultiplication:<sup>[<a href=\"https://plato.stanford.edu/entries/recursive-functions/notes.html#note-1\">1</a>]</sup>\n</p><p>\n\\[\\begin{align} \\label{defnadd}\n\\text{i.}\\quad &amp;&amp; x + 0 &amp; = x \\\\ \\nonumber\n\\text{ii.}\\quad &amp;&amp; x + (y+1) &amp; = (x+y)+1\\\\\n\\end{align}\\]\n\\[\\begin{align} \\label{defnmult}\n\\text{i.}\\quad &amp;&amp; x \\times 0 &amp; = 0 \\\\ \\nonumber\n\\text{ii.}\\quad &amp;&amp; x \\times (y+1) &amp; = (x\\times y) + x\n\\end{align}\\]\n</p><p>\nThey then used these definition to prove the associative, commutative,\nand distributive laws for these\noperations.<sup>[<a href=\"https://plato.stanford.edu/entries/recursive-functions/notes.html#note-2\">2</a>]</sup>\n</p>\n<p>\nThe first person to employ the expression “definition by\nrecursion” appears to have been Dedekind in his essay <em>Was\nsind und was sollen die Zahlen</em> (1888). This work presents a set\ntheoretic foundation for arithmetic wherein Dedekind demonstrated that\nit was possible to state and prove the existence and uniqueness of\nfunctions defined by primitive recursion as mathematical theorems\n(§125–126). He formulated recursive definitions of addition\n(§135), multiplication (§147), and exponentiation\n(§155) and then also formally proved by induction that the\nfunctions so defined satisfy the expected algebraic identities. The\nfirst two of these definitions would later be adopted by Peano (1889)\nas defining the symbols \\(+\\) and \\(\\times\\) in the direct\naxiomatization of arithmetic he based on Dedekind’s\nmonograph.</p>\n<h3>1.2 The Origins of Primitive Recursion</h3>\n<p>\nThe first work devoted exclusively to recursive definability was\nSkolem’s (1923) paper </p>\n<blockquote>\n<p>\nThe foundations of elementary arithmetic established by the recursive\nmode of thought, without the use of apparent variables ranging over\ninfinite domains. </p>\n</blockquote>\n<p>\nThis work is significant with respect to the subsequent development of\ncomputability theory for at least three reasons. First, it contains a\ninformal description of what we now call the <em>primitive recursive\nfunctions</em>. Second, it can be regarded as the first place where\nrecursive definability is linked to effective computability (see also\nSkolem 1946). And third, it demonstrates that a wide range of\nfunctions and relations are primitive recursive in a manner which\nanticipates Gödel’s (1931) use of primitive recursion for\nthe arithmetization of syntax. </p>\n<p>\nOne of Skolem’s stated goals was to present a logical foundation\nfor number theory which avoids the use of unrestricted quantifiers. He\nwas inspired in this regard by the observation that it is possible to\ndevelop much of elementary arithmetic without the use of the\nexpressions “always” (i.e., <em>for all</em>) and\n“sometimes” (i.e., <em>there exists</em>) which figure in\nthe formalization of number theory given by Russell and Whitehead in\n<em>Principia Mathematica</em> (1910–1913). This was to be\naccomplished by formulating arithmetical theorems as what he referred\nto as <em>functional assertions</em>. These took the form of\nidentities between terms defined by primitive recursive operations\nwhich Skolem referred to as <em>descriptive functions</em>. For\ninstance, the commutativity of addition is expressed in this form by\nan equation with free variables </p><p>\n\\[\\begin{equation}\\label{funassert}\nx + y = y + x\n\\end{equation}\\]\n</p><p>\nIn cases where such statements are provable in the system Skolem\ndescribes, the intended interpretation is that the claim holds\nuniversally for all natural numbers—e.g., \\(\\forall x \\forall y\n(x + y = y + x)\\). But in Skolem’s system there is no means of\nnegating such a statement to express a bare existential assertion\nwithout producing a witness.</p>\n<p>\nStatements like (\\ref{funassert}) would later be referred to by\nHilbert &amp; Bernays (1934) (who provided the first textbook\ntreatment of recursion) as <em>verifiable</em> in the sense that their\nindividual instances can be verified computationally by replacing\nvariables with concrete numerals. This is accomplished by what Skolem\nreferred to as the “recursive mode of thought”. The sense\nof this phrase is clarified by the following properties of the system\nhe describes: </p>\n<ol>\n<li> the natural numbers are taken as basic objects\ntogether with the successor function \\(x + 1\\); </li>\n<li> it is assumed that descriptive functions proven to\nbe equal may be substituted for one another in other expressions;\n</li>\n<li> all definitions of functions and relations on\nnatural numbers are given by recursion; </li>\n<li>functional assertions such as (\\ref{funassert}) must\nbe proven by induction. </li>\n</ol>\n<p>\nTaking these principles as a foundation, Skolem showed how to obtain\nrecursive definitions of the <em>predecessor</em> and\n<em>subtraction</em> functions, the <em>less than</em>,\n<em>divisibility</em>, and <em>primality</em> relations, <em>greatest\ncommon divisors</em>, <em>least common multiples</em>, and <em>bounded\nsums and products</em> which are similar to those given in\n<a href=\"#Exam\"> Section 2.1.2 </a>\nbelow.</p>\n<p>\nOverall Skolem considered instances of what we would now refer to as\nprimitive recursion, course of values recursion, double recursion, and\nrecursion on functions of type \\(\\mathbb{N} \\rightarrow \\mathbb{N}\\).\nHe did not, however, introduce general schemas so as to systematically\ndistinguish these modes of definition. Nonetheless, properties\ni–iv of Skolem’s treatment provide a means of assimilating\ncalculations like (\\ref{factcalc}) to derivations in quantifier-free\nfirst-order logic. It is thus not difficult to discern in Skolem\n(1923) the kernel of the system we now know as <em>Primitive Recursive\nArithmetic</em> (as later formally introduced by Hilbert &amp; Bernays\n1934: ch. 7).</p>\n<p>\nThe next important steps in the development of a general theory of\nrecursive function arose as a consequence of the interaction between\n<a href=\"https://plato.stanford.edu/entries/hilbert-program/\">Hilbert’s Program</a>\nand Gödel’s (1931) proof of the Incompleteness Theorems.\nHilbert (1900) had announced the goal of proving the consistency of\narithmetic—and ultimately also analysis and set theory—in\nthe face of the set theoretic paradoxes. His initial plans for\ncarrying out such a proof are described in a series of lectures and\naddresses in the 1910s–1920s which provide a description of what\nwould come to be called the <em>finitary standpoint</em>—i.e.,\nthe fragment of mathematical reasoning pertaining to finite\ncombinatorial objects which was intended to serve as the secure basis\nfor a consistency proof. The proof itself was to be carried out using\nthe methods of what Hilbert referred to as\n<em>metamathematics</em>—i.e., the formal study of axioms and\nderivations which would grow into the subject now known as\n<a href=\"https://plato.stanford.edu/entries/proof-theory/\"><em>proof theory</em></a>.</p>\n<p>\nIn one of his initial descriptions of this program Hilbert (1905)\nsketched the basic form which a metamathematical proof of consistency\nmight take. Suppose, for instance, that \\(\\mathsf{T}\\) is a\nmathematical theory about which it is possible to prove the following\nconditional:</p>\n<ol>\n<li>If \\(n\\) applications of rules of inference applied to the axioms\nof a system \\(\\mathsf{T}\\) do not lead to a contradiction, then\n\\(n+1\\) applications also do not lead to a contradiction.</li>\n</ol>\n<p>\nWere it possible to provide a mathematical demonstration of i), it\nmight seem possible to conclude</p>\n<ol>\n<li>\\(\\mathsf{T}\\) is consistent.</li>\n</ol>\n<p>\nHowever P",
        "html": "<div><div>\n<h2>1. Historical Background</h2>\n<p>\nThe theory of recursive functions is often presented as a chapter in\nthe history of the subject originally known as <em>recursive function\ntheory</em>. This subject has its roots in the foundational debates of\nthe first half of the twentieth century. Within this context, the need\narose to provide a precise analysis of what we would naturally\ndescribe as inductive or recursive modes of reasoning which play a\npart in the deductive machinery of axiomatic theories in mathematics.\nThis history will be traced in the current section, with an emphasis\non how different forms of recursion have been understood as\nexemplifying various kinds of step-by-step algorithmic processes. </p>\n<p>\nThis section assumes some familiarity with some of the terminology\nintroduced in\n<a href=\"#FormRecu\">Section 2</a>\nand\n<a href=\"#CompTheo\">Section 3</a>.\nReaders looking for a technical overview of recursive functions or\ncomputability theory are advised to start there.</p>\n<h3>1.1 The Early History of Recursive Definitions</h3>\n<p>\nExamples of recursive definitions can be found intermittently in the\nhistory of ancient and medieval mathematics. A familiar illustration\nis the sequence \\(F_i\\) of <em>Fibonacci numbers</em>\n\\(1,1,2,3,5,8,13, \\ldots\\) given by the recurrence \\(F_0 = 1, F_1 =\n1\\) and \\(F_{n} = F_{n-1} + F_{n-2}\\) (see\n<a href=\"#AddiClosPropPrimRecuFunc\">Section 2.1.3</a>).\nThe definition of this sequence has traditionally been attributed to\nthe thirteenth century Italian mathematician Leonardo of Pisa (also\nknown as Fibonacci) who introduced it in his <em>Liber Abaci</em> in\nthe context of an example involving population genetics (see Fibonacci\n1202 [2003: 404–405]). But descriptions of similar sequences can\nalso be found in Greek, Egyptian, and Sanskrit sources dating as early\nas 700 BCE (see, e.g., Singh 1985).</p>\n<p>\nGeneral interest in recursion as a mode of function definition\noriginated in the mid-nineteenth century as part of the broader\nprogram of arithmetizing analysis and the ensuing discussions of the\nfoundations of arithmetic itself. In this context, the formulation of\nrecursive definitions for number theoretic functions was closely tied\nto the isolation of mathematical induction as a mode of reasoning\nabout the natural numbers. It was in this setting in which Grassmann\n(1861) and Peirce (1881) first gave the familiar recursive definitions\nof addition and\nmultiplication:<sup>[<a href=\"https://plato.stanford.edu/entries/recursive-functions/notes.html#note-1\">1</a>]</sup>\n</p><p>\n\\[\\begin{align} \\label{defnadd}\n\\text{i.}\\quad &amp;&amp; x + 0 &amp; = x \\\\ \\nonumber\n\\text{ii.}\\quad &amp;&amp; x + (y+1) &amp; = (x+y)+1\\\\\n\\end{align}\\]\n\\[\\begin{align} \\label{defnmult}\n\\text{i.}\\quad &amp;&amp; x \\times 0 &amp; = 0 \\\\ \\nonumber\n\\text{ii.}\\quad &amp;&amp; x \\times (y+1) &amp; = (x\\times y) + x\n\\end{align}\\]\n</p><p>\nThey then used these definition to prove the associative, commutative,\nand distributive laws for these\noperations.<sup>[<a href=\"https://plato.stanford.edu/entries/recursive-functions/notes.html#note-2\">2</a>]</sup>\n</p>\n<p>\nThe first person to employ the expression “definition by\nrecursion” appears to have been Dedekind in his essay <em>Was\nsind und was sollen die Zahlen</em> (1888). This work presents a set\ntheoretic foundation for arithmetic wherein Dedekind demonstrated that\nit was possible to state and prove the existence and uniqueness of\nfunctions defined by primitive recursion as mathematical theorems\n(§125–126). He formulated recursive definitions of addition\n(§135), multiplication (§147), and exponentiation\n(§155) and then also formally proved by induction that the\nfunctions so defined satisfy the expected algebraic identities. The\nfirst two of these definitions would later be adopted by Peano (1889)\nas defining the symbols \\(+\\) and \\(\\times\\) in the direct\naxiomatization of arithmetic he based on Dedekind’s\nmonograph.</p>\n<h3>1.2 The Origins of Primitive Recursion</h3>\n<p>\nThe first work devoted exclusively to recursive definability was\nSkolem’s (1923) paper </p>\n<blockquote>\n<p>\nThe foundations of elementary arithmetic established by the recursive\nmode of thought, without the use of apparent variables ranging over\ninfinite domains. </p>\n</blockquote>\n<p>\nThis work is significant with respect to the subsequent development of\ncomputability theory for at least three reasons. First, it contains a\ninformal description of what we now call the <em>primitive recursive\nfunctions</em>. Second, it can be regarded as the first place where\nrecursive definability is linked to effective computability (see also\nSkolem 1946). And third, it demonstrates that a wide range of\nfunctions and relations are primitive recursive in a manner which\nanticipates Gödel’s (1931) use of primitive recursion for\nthe arithmetization of syntax. </p>\n<p>\nOne of Skolem’s stated goals was to present a logical foundation\nfor number theory which avoids the use of unrestricted quantifiers. He\nwas inspired in this regard by the observation that it is possible to\ndevelop much of elementary arithmetic without the use of the\nexpressions “always” (i.e., <em>for all</em>) and\n“sometimes” (i.e., <em>there exists</em>) which figure in\nthe formalization of number theory given by Russell and Whitehead in\n<em>Principia Mathematica</em> (1910–1913). This was to be\naccomplished by formulating arithmetical theorems as what he referred\nto as <em>functional assertions</em>. These took the form of\nidentities between terms defined by primitive recursive operations\nwhich Skolem referred to as <em>descriptive functions</em>. For\ninstance, the commutativity of addition is expressed in this form by\nan equation with free variables </p><p>\n\\[\\begin{equation}\\label{funassert}\nx + y = y + x\n\\end{equation}\\]\n</p><p>\nIn cases where such statements are provable in the system Skolem\ndescribes, the intended interpretation is that the claim holds\nuniversally for all natural numbers—e.g., \\(\\forall x \\forall y\n(x + y = y + x)\\). But in Skolem’s system there is no means of\nnegating such a statement to express a bare existential assertion\nwithout producing a witness.</p>\n<p>\nStatements like (\\ref{funassert}) would later be referred to by\nHilbert &amp; Bernays (1934) (who provided the first textbook\ntreatment of recursion) as <em>verifiable</em> in the sense that their\nindividual instances can be verified computationally by replacing\nvariables with concrete numerals. This is accomplished by what Skolem\nreferred to as the “recursive mode of thought”. The sense\nof this phrase is clarified by the following properties of the system\nhe describes: </p>\n<ol>\n<li> the natural numbers are taken as basic objects\ntogether with the successor function \\(x + 1\\); </li>\n<li> it is assumed that descriptive functions proven to\nbe equal may be substituted for one another in other expressions;\n</li>\n<li> all definitions of functions and relations on\nnatural numbers are given by recursion; </li>\n<li>functional assertions such as (\\ref{funassert}) must\nbe proven by induction. </li>\n</ol>\n<p>\nTaking these principles as a foundation, Skolem showed how to obtain\nrecursive definitions of the <em>predecessor</em> and\n<em>subtraction</em> functions, the <em>less than</em>,\n<em>divisibility</em>, and <em>primality</em> relations, <em>greatest\ncommon divisors</em>, <em>least common multiples</em>, and <em>bounded\nsums and products</em> which are similar to those given in\n<a href=\"#Exam\"> Section 2.1.2 </a>\nbelow.</p>\n<p>\nOverall Skolem considered instances of what we would now refer to as\nprimitive recursion, course of values recursion, double recursion, and\nrecursion on functions of type \\(\\mathbb{N} \\rightarrow \\mathbb{N}\\).\nHe did not, however, introduce general schemas so as to systematically\ndistinguish these modes of definition. Nonetheless, properties\ni–iv of Skolem’s treatment provide a means of assimilating\ncalculations like (\\ref{factcalc}) to derivations in quantifier-free\nfirst-order logic. It is thus not difficult to discern in Skolem\n(1923) the kernel of the system we now know as <em>Primitive Recursive\nArithmetic</em> (as later formally introduced by Hilbert &amp; Bernays\n1934: ch. 7).</p>\n<p>\nThe next important steps in the development of a general theory of\nrecursive function arose as a consequence of the interaction between\n<a href=\"https://plato.stanford.edu/entries/hilbert-program/\">Hilbert’s Program</a>\nand Gödel’s (1931) proof of the Incompleteness Theorems.\nHilbert (1900) had announced the goal of proving the consistency of\narithmetic—and ultimately also analysis and set theory—in\nthe face of the set theoretic paradoxes. His initial plans for\ncarrying out such a proof are described in a series of lectures and\naddresses in the 1910s–1920s which provide a description of what\nwould come to be called the <em>finitary standpoint</em>—i.e.,\nthe fragment of mathematical reasoning pertaining to finite\ncombinatorial objects which was intended to serve as the secure basis\nfor a consistency proof. The proof itself was to be carried out using\nthe methods of what Hilbert referred to as\n<em>metamathematics</em>—i.e., the formal study of axioms and\nderivations which would grow into the subject now known as\n<a href=\"https://plato.stanford.edu/entries/proof-theory/\"><em>proof theory</em></a>.</p>\n<p>\nIn one of his initial descriptions of this program Hilbert (1905)\nsketched the basic form which a metamathematical proof of consistency\nmight take. Suppose, for instance, that \\(\\mathsf{T}\\) is a\nmathematical theory about which it is possible to prove the following\nconditional:</p>\n<ol>\n<li>If \\(n\\) applications of rules of inference applied to the axioms\nof a system \\(\\mathsf{T}\\) do not lead to a contradiction, then\n\\(n+1\\) applications also do not lead to a contradiction.</li>\n</ol>\n<p>\nWere it possible to provide a mathematical demonstration of i), it\nmight seem possible to conclude</p>\n<ol>\n<li>\\(\\mathsf{T}\\) is consistent.</li>\n</ol>\n<p>\nHowever P",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "1. Historical BackgroundThe theory of recursive functions is often presented as a chapter in\nthe history of the subject originally known asrecursive function\ntheory. This subject has its roots in the foundational debates of\nthe first half of the twentieth century. Within this context, the need\narose to provide a precise analysis of what we would naturally\ndescribe as inductive or recursive modes of reasoning which play a\npart in the deductive machinery of axiomatic theories in mathematics.\nThis ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "1. Historical BackgroundThe theory of recursive functions is often presented as a chapter in\nthe history of the subject originally known asrecursive function\ntheory. This subject has its roots in the foundational debates of\nthe first half of the twentieth century. Within this context, the need\narose to provide a precise analysis of what we would naturally\ndescribe as inductive or recursive modes of reasoning which play a\npart in the deductive machinery of axiomatic theories in mathematics.\nThis ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "1. Historical Background",
              "id": ""
            },
            {
              "level": "h3",
              "text": "1.1 The Early History of Recursive Definitions",
              "id": ""
            },
            {
              "level": "h3",
              "text": "1.2 The Origins of Primitive Recursion",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://arxiv.org/pdf/1310.4401.pdf",
      "title": "",
      "author": "",
      "published_date": "2018-09-29T00:00:00.000Z",
      "content": {
        "text": "arXiv:1310.4401v2 [quant-ph] 4 Apr 2014\nRecursive encoding and decoding of the noiseless subsystem for qudits\nUtkan G¨ung¨ord¨u,1 Chi-Kwong Li,2 Mikio Nakahara,1, 3 Yiu-Tung Poon,4 and Nung-Sing Sze5\n1Research Center for Quantum Computing, Interdisciplinary Graduate School of Science and Engineering,\nKinki University, 3-4-1 Kowakae, Higashi-Osaka, Osaka 577-8502, Japan∗\n2Department of Mathematics, College of William & Mary, Williamsburg,\nVA 23187-8795, USA. (Year 2011: Department of Mathematics,\nHong Kong University of Science & Technology, Hong Kong.)†\n3Department of Physics, Kinki University, 3-4-1 Kowakae, Higashi-Osaka, Osaka 577-8502, Japan‡\n4Department of Mathematics, Iowa State University, Ames, IA 50011, USA.§\n5Department of Applied Mathematics, The Hong Kong Polytechnic University, Hung Hom, Hong Kong.¶\nWe give a full explanation of the noiseless subsystem that protects a single-qubit against collective\nerrors and the corresponding recursive scheme described by C.-K. Li et. al. [Phys. Rev. A 84,\n044301 (2011)] from a representation theory point of view. Furthermore, we extend the construction\nto qudits under the influence of collective SU(d) errors. We find that under this recursive scheme,\nthe asymptotic encoding rate is 1/d.\nPACS numbers: 03.67.-a,03.67.Pp\nI. INTRODUCTION\nQuantum computing and quantum information pro\u0002cessing make use of quantum systems as computational\nresources to outperform their classical counterparts. It is\nexpected that a quantum computer solves computation\u0002ally hard tasks for a classical computer, such as prime\nnumber factorization of a large number, in a practical\ntime and quantum key distribution realizes a 100% se\u0002cure classical information transmission. In spite of this\nexpectation, a working quantum computer has not be\u0002come a reality yet. One of the obstacles against its real\u0002ization is decoherence. Decoherence is a process caused\nby a coupling between a quantum system (a quantum\ncomputer in the present context) and its environment.\nA pure state to be used as a computational resource be\u0002comes a dirty mixed state due to decoherence and then\nthe computational outcome is not reliable any more.\nThere are several strategies to fight against decoher\u0002ence and quantum error correcting codes, abbreviated\nas QECC hereafter, is one of the best weapons to fight\nagainst decoherence. A pure state may be contaminated\ndue to the interaction between the system and the envi\u0002ronment. Then one may embed the quantum information\nto higher dimensional Hilbert space so that either (i) the\nerror acted on physical qubit may be identified by intro\u0002ducing the error syndrome measurement qubits so that\nthe initial quantum information is recovered after apply\u0002ing appropriate corrections or (ii) the error operator acts\nonly on a part of the Hilbert space keeping the initial\nquantum information intact. The second QECC scheme\nis often called the “error-avoiding” coding due to this\n∗ Corresponding author; utkan@alice.math.kindai.ac.jp\n†\nckli@math.wm.edu\n‡ nakahara@math.kindai.ac.jp\n§ ytpoon@iastate.edu\n¶ raymond.sze@inet.polyu.edu.hk\nreason. Decoherence free subspace (DFS) and noiseless\nsubsystem (NS) are two popular examples of the second\nkind [1–14].\nIn this paper, we consider the second approach to deal\nwith quantum channels in which all physical qubits in\u0002volved in coding suffer from the same error operators.\nThere are two relevant cases in which such error operators\nare in action; (1) when the size of a quantum computer\nis much smaller than the wavelength of the external dis\u0002turbances and (2) when photonic qubits are sent one by\none through an optical fiber with a fixed imperfection. In\nboth cases, the qubits suffer from the same errors leading\nto decoherence. Another instance in which such encoding\nis useful is that when Alice sends quantum information\nto Bob (possibly billions light years away) without know\u0002ing which basis vectors Bob employs. Then mismatching\nof the basis vectors is common for all qubits and such\nmismatching is regarded as collective noise.\nIn our previous publications, we reported the following\nresults:\n1. For a limited class of error operators\n{σ\n⊗n\nx\n, σ⊗n\ny\n, σ⊗n\nz\n}, it is possible to iteratively\nimplement encoding/decoding circuits which pro\u0002tects n − 1 logical qubits when n is odd and n − 2\nlogical qubits when n is even [15]. When n physical\nqubits protect k logical qubits, the encoding rate\nis defined by k/n. The asymptotic encoding rate\nobtained in [15] is 1 as n ≫ 1 for both cases.\n2. For general error operators W⊗n, where W ∈\nSU(2), we gave explicit recursive implementation\nof encoding/decoding circuits for arbitrary number\nn of physical qubits. We have shown that n = 2k+1\nphysical qubits protect k logical qubits, leading to\nthe asymptotic encoding rate of 1/2 [16].\n3. A qudit is a d-dimensional analogue of a qubit.\nIt transforms under the action of the fundamen\u0002tal representation of SU(d). (It should not be\n2\n|ui\nUE\nW\nU\n†\nE\n|ui\n|ψi W |ψi\n|vi W W|vi\nFIG. 1. Re-ordered version of the three qubit QECC from\n[16]. A circuit representation for UE is given is Fig. 2. |ψi\nrepresents the data qubit. |vi is the state of the ancillary\nqubit, which can be arbitrary.\nconfused with a vector transforming under the ac\u0002tion of a d-dimensional representation of SU(2).)\nIn [17], we identified the subspace with the maxi\u0002mal dimension of the total Hilbert space of physi\u0002cal qudits when d = 2 and 3, which is immune to\ncollective noise operators of the form W⊗n where\nW ∈ SU(d),(d = 2, 3). It was shown that the en\u0002coding rate approaches to 1 as n ≫ 1. The irre\u0002ducible representation (abbreviated as irrep, here\u0002after) giving the encoding subspace with the max\u0002imal dimension is given by an almost rectangular\nYoung tableau [17]. Identification of an irrep with\nthe maximal multiplicity for d > 3 is a highly non\u0002trivial open problem even though the decomposi\u0002tion of W⊗n into irreps is well established.\nIn the present paper, we demonstrate why the recur\u0002sion relation introduced in [16] works from representation\ntheory point of view and generalize this relation to qu\u0002dit case. We show how to implement encoding/decoding\ncircuits for n physical qudits, which results in the asymp\u0002totic encoding rate of 1/d. A natural question to raise\nfrom this statement must be “why do we do this anal\u0002ysis even though it is known that there is a DFS/NS\nwhich gives asymptotic encoding rate of 1?”. To imple\u0002ment encoding/decoding circuits, we need quantum cir\u0002cuits, which physically represent the encoding/decoding\nmatrix UE/U†\nE. Although it may be possible to find the\nquantum circuits for small n by some trial and error, it\nis totally impossible to find them if the number of qudits\nn is more than 100 or even 10. We believe recursive im\u0002plementation of the circuits is the only possible way to\nphysically realize proposed scheme.\nThe rest of the paper is organized as follows. In the\nnext section, we outline the results of [16] for qubits from\na representation theoretical viewpoint so that they can\nbe easily generalized to the qudits cases. In section 3, we\ngive the detailed analysis of recursive implementation of\nqudits encoding/decoding circuits and prove that this im\u0002plementation gives the asymptotic encoding rate of 1/d.\nSection 4 is devoted to summary and discussions.\nII. SU(2) RECURSION RELATION REVISITED\nIn this section, we review and give further explanation\nto the 3-qubit noiseless subsystem and recursion relation\n|ui YΘ •\n|ψi • Yπ/2\n|vi σz •\nFIG. 2. Re-ordered SU(2) encoding gate UE from [16], in\nterms of single-qubit and two qubit controlled-U gates. Above\nYθ = exp(iσyθ) and sin Θ = p2/3.\ndescribed in [16] from a representation theory point of\nview. This approach has the advantage of being general\nand applicable to systems with d levels.\nLet us denote the error acting on a single site as\nW ∈ SU(2) and the total collective noise on the system\nas E = W ⊗ W ⊗ W. Such an operation is totally sym\u0002metric under exchanges, and the resulting 8 × 8 matrix\nis reducible as 4 + 2 + 2. In the context of representa\u0002tion theory, irreps of groups are conveniently labeled by\nYoung tableau. The fundamental irrep of SU(2) is la\u0002beled as 1 . The form of the reduction is contained in\nthe expansion [18]\n1 ⊗ 1 ⊗ 1 = 1 2 3 ⊕\n1 2\n3\n⊕\n1 3\n2\n. (1)\nThe irreps on the RHS have the dimensions of 4, 2, 2\nrespectively. The two copies of the fundamental irrep\ngive rise to a noiseless subsystem. These irreps are more\ncommonly known as spin-3/2 and spin-1/2 representa\u0002tions of SU(2) respectively. The dimension of an irrep is\nthe number of vectors belonging to it whose entries are\nthe Clebsch-Gordan coefficients, and they are sometimes\ncalled Young-Yamanouchi vectors [19].\nIf we denote the elements of the fundamental irrep as\nu and d (or |ui, |di) which refer to the spin-up and spin\u0002down states, the vectors belonging to the irreps that ap\u0002pear in Eq. (1) can be written as\n1 2\n3\n\n\n\n1\n√\n6\n(−[ud + du]u + 2[uu]d)\n1\n√\n6\n([ud + du]d − 2[dd]u)\n1 3\n2\n\n\n\n1\n√\n2\n(ud − du)u\n1\n√\n2\n(ud − du)d\n1 2 3\n\n\n\nuuu\n1\n√\n3\n(uud + udu + duu)\n1\n√\n3\n(ddu + dud + udd)\nddd\n(2)\nThe unitary transformation UE that block-diagonalizes E\nas W ⊕ W ⊕ W(3/2) where W(3/2) is the spin-3/2 repre\u0002sentation of W is constructed by using these basis vectors\nas columns and grouping them in a proper fashion such\n3\nas [20]\nUE =\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n1 2\n3\n1 3\n2\n1 2 3\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n\n. (3)\nAn element of SU(2) is naturally expressed in an ex\u0002ponential form as e\ni(rxσx+ryσy+rzσz)\n. Different repre\u0002sentations can be obtained by replacing Pauli matri\u0002ces, which correspond to the fundamental representation,\nwith larger representations of the algebra su(2). In the\nparticular case of the 4-dimensional irrep, the generators\nare given as (see for example [21, 22])\nJ\n(3/2)\nx =\n\n\n0\n√\n3 0 0\n√\n3 0 2 0\n0 2 0 √\n3\n0 0 √\n3 0\n\n ,\nJ\n(3/2)\ny = i\n\n\n0 −\n√\n3 0 0\n√\n3 0 −2 0\n0 2 0 −\n√\n3\n0 0 √\n3 0\n\n ,\nJ\n(3/2)\nz =\n\n\n3 0 0 0\n0 1 0 0\n0 0 −1 0\n0 0 0 −3\n\n .\n(4)\nFigure 1 s",
        "html": "arXiv:1310.4401v2 [quant-ph] 4 Apr 2014\nRecursive encoding and decoding of the noiseless subsystem for qudits\nUtkan G¨ung¨ord¨u,1 Chi-Kwong Li,2 Mikio Nakahara,1, 3 Yiu-Tung Poon,4 and Nung-Sing Sze5\n1Research Center for Quantum Computing, Interdisciplinary Graduate School of Science and Engineering,\nKinki University, 3-4-1 Kowakae, Higashi-Osaka, Osaka 577-8502, Japan∗\n2Department of Mathematics, College of William & Mary, Williamsburg,\nVA 23187-8795, USA. (Year 2011: Department of Mathematics,\nHong Kong University of Science & Technology, Hong Kong.)†\n3Department of Physics, Kinki University, 3-4-1 Kowakae, Higashi-Osaka, Osaka 577-8502, Japan‡\n4Department of Mathematics, Iowa State University, Ames, IA 50011, USA.§\n5Department of Applied Mathematics, The Hong Kong Polytechnic University, Hung Hom, Hong Kong.¶\nWe give a full explanation of the noiseless subsystem that protects a single-qubit against collective\nerrors and the corresponding recursive scheme described by C.-K. Li et. al. [Phys. Rev. A 84,\n044301 (2011)] from a representation theory point of view. Furthermore, we extend the construction\nto qudits under the influence of collective SU(d) errors. We find that under this recursive scheme,\nthe asymptotic encoding rate is 1/d.\nPACS numbers: 03.67.-a,03.67.Pp\nI. INTRODUCTION\nQuantum computing and quantum information pro\u0002cessing make use of quantum systems as computational\nresources to outperform their classical counterparts. It is\nexpected that a quantum computer solves computation\u0002ally hard tasks for a classical computer, such as prime\nnumber factorization of a large number, in a practical\ntime and quantum key distribution realizes a 100% se\u0002cure classical information transmission. In spite of this\nexpectation, a working quantum computer has not be\u0002come a reality yet. One of the obstacles against its real\u0002ization is decoherence. Decoherence is a process caused\nby a coupling between a quantum system (a quantum\ncomputer in the present context) and its environment.\nA pure state to be used as a computational resource be\u0002comes a dirty mixed state due to decoherence and then\nthe computational outcome is not reliable any more.\nThere are several strategies to fight against decoher\u0002ence and quantum error correcting codes, abbreviated\nas QECC hereafter, is one of the best weapons to fight\nagainst decoherence. A pure state may be contaminated\ndue to the interaction between the system and the envi\u0002ronment. Then one may embed the quantum information\nto higher dimensional Hilbert space so that either (i) the\nerror acted on physical qubit may be identified by intro\u0002ducing the error syndrome measurement qubits so that\nthe initial quantum information is recovered after apply\u0002ing appropriate corrections or (ii) the error operator acts\nonly on a part of the Hilbert space keeping the initial\nquantum information intact. The second QECC scheme\nis often called the “error-avoiding” coding due to this\n∗ Corresponding author; utkan@alice.math.kindai.ac.jp\n†\nckli@math.wm.edu\n‡ nakahara@math.kindai.ac.jp\n§ ytpoon@iastate.edu\n¶ raymond.sze@inet.polyu.edu.hk\nreason. Decoherence free subspace (DFS) and noiseless\nsubsystem (NS) are two popular examples of the second\nkind [1–14].\nIn this paper, we consider the second approach to deal\nwith quantum channels in which all physical qubits in\u0002volved in coding suffer from the same error operators.\nThere are two relevant cases in which such error operators\nare in action; (1) when the size of a quantum computer\nis much smaller than the wavelength of the external dis\u0002turbances and (2) when photonic qubits are sent one by\none through an optical fiber with a fixed imperfection. In\nboth cases, the qubits suffer from the same errors leading\nto decoherence. Another instance in which such encoding\nis useful is that when Alice sends quantum information\nto Bob (possibly billions light years away) without know\u0002ing which basis vectors Bob employs. Then mismatching\nof the basis vectors is common for all qubits and such\nmismatching is regarded as collective noise.\nIn our previous publications, we reported the following\nresults:\n1. For a limited class of error operators\n{σ\n⊗n\nx\n, σ⊗n\ny\n, σ⊗n\nz\n}, it is possible to iteratively\nimplement encoding/decoding circuits which pro\u0002tects n − 1 logical qubits when n is odd and n − 2\nlogical qubits when n is even [15]. When n physical\nqubits protect k logical qubits, the encoding rate\nis defined by k/n. The asymptotic encoding rate\nobtained in [15] is 1 as n ≫ 1 for both cases.\n2. For general error operators W⊗n, where W ∈\nSU(2), we gave explicit recursive implementation\nof encoding/decoding circuits for arbitrary number\nn of physical qubits. We have shown that n = 2k+1\nphysical qubits protect k logical qubits, leading to\nthe asymptotic encoding rate of 1/2 [16].\n3. A qudit is a d-dimensional analogue of a qubit.\nIt transforms under the action of the fundamen\u0002tal representation of SU(d). (It should not be\n2\n|ui\nUE\nW\nU\n†\nE\n|ui\n|ψi W |ψi\n|vi W W|vi\nFIG. 1. Re-ordered version of the three qubit QECC from\n[16]. A circuit representation for UE is given is Fig. 2. |ψi\nrepresents the data qubit. |vi is the state of the ancillary\nqubit, which can be arbitrary.\nconfused with a vector transforming under the ac\u0002tion of a d-dimensional representation of SU(2).)\nIn [17], we identified the subspace with the maxi\u0002mal dimension of the total Hilbert space of physi\u0002cal qudits when d = 2 and 3, which is immune to\ncollective noise operators of the form W⊗n where\nW ∈ SU(d),(d = 2, 3). It was shown that the en\u0002coding rate approaches to 1 as n ≫ 1. The irre\u0002ducible representation (abbreviated as irrep, here\u0002after) giving the encoding subspace with the max\u0002imal dimension is given by an almost rectangular\nYoung tableau [17]. Identification of an irrep with\nthe maximal multiplicity for d > 3 is a highly non\u0002trivial open problem even though the decomposi\u0002tion of W⊗n into irreps is well established.\nIn the present paper, we demonstrate why the recur\u0002sion relation introduced in [16] works from representation\ntheory point of view and generalize this relation to qu\u0002dit case. We show how to implement encoding/decoding\ncircuits for n physical qudits, which results in the asymp\u0002totic encoding rate of 1/d. A natural question to raise\nfrom this statement must be “why do we do this anal\u0002ysis even though it is known that there is a DFS/NS\nwhich gives asymptotic encoding rate of 1?”. To imple\u0002ment encoding/decoding circuits, we need quantum cir\u0002cuits, which physically represent the encoding/decoding\nmatrix UE/U†\nE. Although it may be possible to find the\nquantum circuits for small n by some trial and error, it\nis totally impossible to find them if the number of qudits\nn is more than 100 or even 10. We believe recursive im\u0002plementation of the circuits is the only possible way to\nphysically realize proposed scheme.\nThe rest of the paper is organized as follows. In the\nnext section, we outline the results of [16] for qubits from\na representation theoretical viewpoint so that they can\nbe easily generalized to the qudits cases. In section 3, we\ngive the detailed analysis of recursive implementation of\nqudits encoding/decoding circuits and prove that this im\u0002plementation gives the asymptotic encoding rate of 1/d.\nSection 4 is devoted to summary and discussions.\nII. SU(2) RECURSION RELATION REVISITED\nIn this section, we review and give further explanation\nto the 3-qubit noiseless subsystem and recursion relation\n|ui YΘ •\n|ψi • Yπ/2\n|vi σz •\nFIG. 2. Re-ordered SU(2) encoding gate UE from [16], in\nterms of single-qubit and two qubit controlled-U gates. Above\nYθ = exp(iσyθ) and sin Θ = p2/3.\ndescribed in [16] from a representation theory point of\nview. This approach has the advantage of being general\nand applicable to systems with d levels.\nLet us denote the error acting on a single site as\nW ∈ SU(2) and the total collective noise on the system\nas E = W ⊗ W ⊗ W. Such an operation is totally sym\u0002metric under exchanges, and the resulting 8 × 8 matrix\nis reducible as 4 + 2 + 2. In the context of representa\u0002tion theory, irreps of groups are conveniently labeled by\nYoung tableau. The fundamental irrep of SU(2) is la\u0002beled as 1 . The form of the reduction is contained in\nthe expansion [18]\n1 ⊗ 1 ⊗ 1 = 1 2 3 ⊕\n1 2\n3\n⊕\n1 3\n2\n. (1)\nThe irreps on the RHS have the dimensions of 4, 2, 2\nrespectively. The two copies of the fundamental irrep\ngive rise to a noiseless subsystem. These irreps are more\ncommonly known as spin-3/2 and spin-1/2 representa\u0002tions of SU(2) respectively. The dimension of an irrep is\nthe number of vectors belonging to it whose entries are\nthe Clebsch-Gordan coefficients, and they are sometimes\ncalled Young-Yamanouchi vectors [19].\nIf we denote the elements of the fundamental irrep as\nu and d (or |ui, |di) which refer to the spin-up and spin\u0002down states, the vectors belonging to the irreps that ap\u0002pear in Eq. (1) can be written as\n1 2\n3\n\n\n\n1\n√\n6\n(−[ud + du]u + 2[uu]d)\n1\n√\n6\n([ud + du]d − 2[dd]u)\n1 3\n2\n\n\n\n1\n√\n2\n(ud − du)u\n1\n√\n2\n(ud − du)d\n1 2 3\n\n\n\nuuu\n1\n√\n3\n(uud + udu + duu)\n1\n√\n3\n(ddu + dud + udd)\nddd\n(2)\nThe unitary transformation UE that block-diagonalizes E\nas W ⊕ W ⊕ W(3/2) where W(3/2) is the spin-3/2 repre\u0002sentation of W is constructed by using these basis vectors\nas columns and grouping them in a proper fashion such\n3\nas [20]\nUE =\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n1 2\n3\n1 3\n2\n1 2 3\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n\n. (3)\nAn element of SU(2) is naturally expressed in an ex\u0002ponential form as e\ni(rxσx+ryσy+rzσz)\n. Different repre\u0002sentations can be obtained by replacing Pauli matri\u0002ces, which correspond to the fundamental representation,\nwith larger representations of the algebra su(2). In the\nparticular case of the 4-dimensional irrep, the generators\nare given as (see for example [21, 22])\nJ\n(3/2)\nx =\n\n\n0\n√\n3 0 0\n√\n3 0 2 0\n0 2 0 √\n3\n0 0 √\n3 0\n\n ,\nJ\n(3/2)\ny = i\n\n\n0 −\n√\n3 0 0\n√\n3 0 −2 0\n0 2 0 −\n√\n3\n0 0 √\n3 0\n\n ,\nJ\n(3/2)\nz =\n\n\n3 0 0 0\n0 1 0 0\n0 0 −1 0\n0 0 0 −3\n\n .\n(4)\nFigure 1 s",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://stackoverflow.com/questions/17428096/get-subsystems-recursively-in-simulink",
      "title": "Get subsystems recursively in Simulink",
      "author": "",
      "published_date": "2013-07-03T16:58:00.000Z",
      "content": {
        "text": "<div><div>\n<p>I want the function to return the \"root\" and the paths to all the subsystems below. I have yet no clue how to do it, this is my attempt, haven't run it yet because I need to find out all the functions to do lists and appending and getting subsystem paths and so on. But I just wanted to ask if this is the right way to do it so that i can proceed with my searching for these functions, or if there exists functions to do it or parts of it?</p>\n<pre><code>function dest,paths = SaveRootAndBelow(path)\nentitytosave = gcs;\nif strcmp(bdroot(entitytosave),entitytosave)\n% I'm the main model\ndest = save_system(entitytosave,path);\npaths = getPaths(entitytosave)\nelse\n% I'm a subsystem\nnewbd = new_system;\nopen_system(newbd);\n% copy the subsystem\nSimulink.SubSystem.copyContentsToBlockDiagram(entitytosave, newbd);\ndest = save_system(newbd,path);\npaths = getPaths(newbd)\n% close the new model\nclose_system(newbd, 0);\nend\nend\nfunction paths = getPaths(root)\npaths = []\nsubsystems = find_system(modelName, 'BlockType', 'SubSystem')\nforeach subsystem in subsystems\npaths.append(subsyspath)\npaths.append(getPaths(subsystem))\nend\nend\n</code></pre>\n</div></div>",
        "html": "<div><div>\n<p>I want the function to return the \"root\" and the paths to all the subsystems below. I have yet no clue how to do it, this is my attempt, haven't run it yet because I need to find out all the functions to do lists and appending and getting subsystem paths and so on. But I just wanted to ask if this is the right way to do it so that i can proceed with my searching for these functions, or if there exists functions to do it or parts of it?</p>\n<pre><code>function dest,paths = SaveRootAndBelow(path)\nentitytosave = gcs;\nif strcmp(bdroot(entitytosave),entitytosave)\n% I'm the main model\ndest = save_system(entitytosave,path);\npaths = getPaths(entitytosave)\nelse\n% I'm a subsystem\nnewbd = new_system;\nopen_system(newbd);\n% copy the subsystem\nSimulink.SubSystem.copyContentsToBlockDiagram(entitytosave, newbd);\ndest = save_system(newbd,path);\npaths = getPaths(newbd)\n% close the new model\nclose_system(newbd, 0);\nend\nend\nfunction paths = getPaths(root)\npaths = []\nsubsystems = find_system(modelName, 'BlockType', 'SubSystem')\nforeach subsystem in subsystems\npaths.append(subsyspath)\npaths.append(getPaths(subsystem))\nend\nend\n</code></pre>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "I want the function to return the \"root\" and the paths to all the subsystems below. I have yet no clue how to do it, this is my attempt, haven't run it yet because I need to find out all the functions to do lists and appending and getting subsystem paths and so on. But I just wanted to ask if this is the right way to do it so that i can proceed with my searching for these functions, or if there exists functions to do it or parts of it?function dest,paths = SaveRootAndBelow(path)\nentitytosave = g",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "I want the function to return the \"root\" and the paths to all the subsystems below. I have yet no clue how to do it, this is my attempt, haven't run it yet because I need to find out all the functions to do lists and appending and getting subsystem paths and so on. But I just wanted to ask if this is the right way to do it so that i can proceed with my searching for these functions, or if there exists functions to do it or parts of it?function dest,paths = SaveRootAndBelow(path)\nentitytosave = g",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://pages.hmc.edu/harris/cmosvlsi/4e/cmosvlsidesign_4e_ch11.pdf",
      "title": "Weste11.fm",
      "author": "Gillian",
      "published_date": "2010-02-01T00:00:00.000Z",
      "content": {
        "text": "11\n429\nDatapath\nSubsystems\n11.1 Introduction\nChip functions generally can be divided into the following categories:\n\u0002 Datapath operators\n\u0002 Memory elements\n\u0002 Control structures\n\u0002 Special-purpose cells\n○ I/O\n○ Power distribution\n○ Clock generation and distribution\n○ Analog and RF\nCMOS system design consists of partitioning the system into subsystems of the types\nlisted above. Many options exist that make trade-offs between speed, density, programma\u0002bility, ease of design, and other variables. This chapter addresses design options for com\u0002mon datapath operators. The next chapter addresses arrays, especially those used for\nmemory. Control structures are most commonly coded in a hardware description language\nand synthesized. Special-purpose subsystems are considered in Chapter 13.\nAs introduced in Chapter 1, datapath operators benefit from the structured design\nprinciples of hierarchy, regularity, modularity, and locality. They may use N identical cir\u0002cuits to process N-bit data. Related data operators are placed physically adjacent to each\nother to reduce wire length and delay. Generally, data is arranged to flow in one direction,\nwhile control signals are introduced in a direction orthogonal to the dataflow.\nCommon datapath operators considered in this chapter include adders, one/zero\ndetectors, comparators, counters, Boolean logic units, error-correcting code blocks,\nshifters, and multipliers.\n11.2 Addition/Subtraction\n“Multitudes of contrivances were designed, and almost endless drawings made, for the\npurpose of economizing the time and simplifying the mechanism of carriage.”\n—Charles Babbage, on Difference Engine No. 1, 1864 [Morrison61]\n430 Chapter 11 Datapath Subsystems\nAddition forms the basis for many processing operations, from ALUs to address genera\u0002tion to multiplication to filtering. As a result, adder circuits that add two binary numbers\nare of great interest to digital system designers. An extensive, almost endless, assortment\nof adder architectures serve different speed/power/area requirements. This section begins\nwith half adders and full adders for single-bit addition. It then considers a plethora of\ncarry-propagate adders (CPAs) for the addition of multibit words. Finally, related struc\u0002tures such as subtracters and multiple-input adders are discussed.\n11.2.1 Single-Bit Addition\nThe half adder of Figure 11.1(a) adds two single-bit inputs, A and B. The result is 0, 1, or\n2, so two bits are required to represent the value; they are called the sum S and carry-out\nCout. The carry-out is equivalent to a carry-in to the next more significant column of a\nmultibit adder, so it can be described as having double the weight of the other bits. If mul\u0002tiple adders are to be cascaded, each must be able to receive the carry-in. Such a full adder\nas shown in Figure 11.1(b) has a third input called C or Cin.\nThe truth tables for the half adder and full adder are given in Tables 11.1 and 11.2.\nFor a full adder, it is sometimes useful to define Generate (G), Propagate (P), and Kill (K)\nsignals. The adder generates a carry when Cout is true independent of Cin, so G = A · B.\nThe adder kills a carry when Cout is false independent of Cin, so K = A · B = A + B. The\nadder propagates a carry; i.e., it produces a carry-out if and only if it receives a carry-in,\nwhen exactly one input is true: P = A ⊕ B.\nFrom the truth table, the half adder logic is\n(11.1)\nTABLE 11.1 Truth table for half adder\nA B Cout S\n0 0 0 0\n0 1 0 1\n1 0 0 1\n1 1 1 0\nTABLE 11.2 Truth table for full adder\nA B C G P K Cout S\n0 0 0 0 0 1 0 0\n1 0 1\n0 1 0 0 1 0 0 1\n1 1 0\n1 0 0 0 1 0 0 1\n1 1 0\n1 1 0 1 0 0 1 0\n1 1 1\nSAB\nC AB\n= ⊕\n= out ·\nA B\nC\nS\nCout\nA B\nS\nCout\n(a) (b)\nFIGURE 11.1\nHalf and full adders\n11.2 Addition/Subtraction 431\nand the full adder logic is\n(11.2)\nThe most straightforward approach to designing an adder is with logic gates. Figure\n11.2 shows a half adder. Figure 11.3 shows a full adder at the gate (a) and transistor (b)\nlevels. The carry gate is also called a majority gate because it produces a 1 if at least two of\nthe three inputs are 1. Full adders are used most often, so they will receive the attention of\nthe remainder of this section.\nS ABC ABC ABC ABC\nAB CPC\nC AB AC BC\nAB C\n= +++\n= ( ) ⊕ ⊕ = ⊕\n=++\n= +\nout\nA B\nAB C A B\nABC\n( ) +\n=+ + ( ) = MAJ(, , )\nA\nB\nA\nB\nS\nCout\nFIGURE 11.2\nHalf adder design\nA\nB\nC\nS\nCout\n(a)\nMAJ\nA\nB\nC\nA\nB B B\nA\nC\nS\nC\nC C\nB B\nB\nA A\n(b)\nA B\nC\nB\nA\nA A B B C C\nCout\nC\nA\nA\nB B\nFIGURE 11.3 Full adder design\nThe full adder of Figure 11.3(b) employs 32 transistors (6 for the inverters, 10 for the\nmajority gate, and 16 for the 3-input XOR). A more compact design is based on the\nobservation that S can be factored to reuse the Cout term as follows:\n(11.3)\nSuch a design is shown at the gate (a) and transistor (b) levels in Figure 11.4 and uses\nonly 28 transistors. Note that the pMOS network is identical to the nMOS network\nrather than being the conduction complement, so the topology is called a mirror adder.\nThis simplification reduces the number of series transistors and makes the layout more\nuniform. It is possible because the addition function is symmetric; i.e., the function of com\u0002plemented inputs is the complement of the function.\nThe mirror adder has a greater delay to compute S than Cout. In carry-ripple adders\n(Section 11.2.2.1), the critical path goes from C to Cout through many full adders, so the\nS ABC A B C C = + ++ ( ) out\n432 Chapter 11 Datapath Subsystems\nextra delay computing S is unimportant. Figure 11.4(c) shows the adder with transistor\nsizes optimized to favor the critical path using a number of techniques:\n\u0002 Feed the carry-in signal (C) to the inner inputs so the internal capacitance is\nalready discharged.\n\u0002 Make all transistors in the sum logic whose gate signals are connected to the carry\u0002in and carry logic minimum size (1 unit, e.g., 4 λ). This minimizes the branching\neffort on the critical path. Keep routing on this signal as short as possible to reduce\ninterconnect capacitance.\n\u0002 Determine widths of series transistors by logical effort and simulation. Build an\nasymmetric gate that reduces the logical effort from C to Cout at the expense of\neffort to S.\nS\n(a)\n(b)\nS\nCout\nA B\nC\nB\nA\nCout\nC\nA\nA\nB B\nS\nABC\nABC\nA\nB\nC\nB\nC\nA\n8 8\n8\n4\n441\n1\n1\n1\n1\n1\n1\n1\n1 1\n111\n1\n1\n1\n1\n1\nA\nB\nC\nCout\nA MINORITY\nB\nC Cout\nCout\nS S\nA\nB\nC\n(c)\nMINORITY\nFIGURE 11.4 Full adder for carry-ripple operation\n11.2 Addition/Subtraction 433\n\u0002 Use relatively large transistors on the critical path so that stray wiring capacitance\nis a small fraction of the overall capacitance.\n\u0002 Remove the output inverters and alternate positive and negative logic to reduce\ndelay and transistor count to 24 (see Section 11.2.2.1).\nFigure 11.5 shows two layouts of the adder (see also the inside front cover). The\nchoice of the aspect ratio depends on the application. In a standard-cell environment, the\nlayout of Figure 11.5(a) might be appropriate when a single row of nMOS and pMOS\ntransistors is used. The routing for the A, B, and C inputs is shown inside the cell,\nalthough it could be placed outside the cell because external routing tracks have to be\nassigned to these signals anyway. Figure 11.5(b) shows a layout that might be appropriate\nfor a dense datapath (if horizontal polysilicon is legal). Here, the transistors are rotated\nand all of the wiring is completed in polysilicon and metal1. This allows metal2 bus lines\nto pass over the cell horizontally. Moreover, the widths of the transistors can increase\nA\nA\nBC S Cout\nVDD\nGND\n(a)\nVDD\nGND\nA\nB\nC\n(b)\nS\nCout\nFIGURE 11.5 Full adder layouts. Color version on inside front cover.\n434 Chapter 11 Datapath Subsystems\nwithout impacting the bit-pitch (height) of the datapath. In this case, the widths are\nselected to reduce the Cin to Cout delay that is on the critical path of a carry-ripple adder.\nA rather different full adder design uses transmission gates to form multiplexers and\nXORs. Figure 11.6(a) shows the transistor-level schematic using 24 transistors and pro\u0002viding buffered outputs of the proper polarity with equal delay. The design can be under\u0002stood by parsing the transmission gate structures into multiplexers and an “invertible\ninverter” XOR structure (see Section 11.7.4), as drawn in Figure 11.6(b).1 Note that the\nmultiplexer choosing S is configured to compute P ⊕ C, as given in EQ (11.2).\nFigure 11.7 shows a complementary pass-transistor logic (CPL) approach. In com\u0002parison to a poorly optimized 40-transistor static CMOS full adder, [Yano90] finds CPL\nis twice as fast, 30% lower in power, and slightly smaller. On the other hand, in compari\u0002son to a careful implementation of the mirror adder, [Zimmermann97] finds the CPL\ndelay slightly better, the power comparable, and the area much larger.\nDynamic full adders are widely used in fast multipliers when power is not a concern.\nAs the sum logic inherently requires true and complementary versions of the inputs, dual\u0002rail domino is necessary. Figure 11.8 shows such an adder using footless dual-rail domino\nXOR/XNOR and MAJORITY/MINORTY gates [Heikes94]. The delays to the two\noutputs are reasonably well balanced, which is important for multipliers where both paths\nare critical. It shares transistors in the sum gate to reduce transistor count and takes advan\u0002tage of the symmetric property to provide identical layouts for the two carry gates.\nStatic CMOS full adders typically have a delay of 2–3 FO4 inverters, while domino\nadders have a delay of about 1.5.\n11.2.2 Carry-Propagate Addition\nN-bit adders take inputs {AN, …, A1}, {BN, …, B1}, and carry-in Cin, and compute the sum\n{SN, …, S1} and the carry-out of the most significant bit Cout, as shown in Figure 11.9.\n1\nSome switch-level simulators, notably IRSIM, are confused by this XOR structure and may not simulate\nit correctly.\nB\nS\nCout\nA B C\nP\nP\nA\n1\n0\n1\n0\nP\nP\nC\nS\nCout\n(a) (b)\nFIGURE 11.6 Transmission gate full adder\n11.2 Addition/Subtraction 435\n(Ordinarily, this text calls the least significant bit A0 rather than A1. However, for ",
        "html": "11\n429\nDatapath\nSubsystems\n11.1 Introduction\nChip functions generally can be divided into the following categories:\n\u0002 Datapath operators\n\u0002 Memory elements\n\u0002 Control structures\n\u0002 Special-purpose cells\n○ I/O\n○ Power distribution\n○ Clock generation and distribution\n○ Analog and RF\nCMOS system design consists of partitioning the system into subsystems of the types\nlisted above. Many options exist that make trade-offs between speed, density, programma\u0002bility, ease of design, and other variables. This chapter addresses design options for com\u0002mon datapath operators. The next chapter addresses arrays, especially those used for\nmemory. Control structures are most commonly coded in a hardware description language\nand synthesized. Special-purpose subsystems are considered in Chapter 13.\nAs introduced in Chapter 1, datapath operators benefit from the structured design\nprinciples of hierarchy, regularity, modularity, and locality. They may use N identical cir\u0002cuits to process N-bit data. Related data operators are placed physically adjacent to each\nother to reduce wire length and delay. Generally, data is arranged to flow in one direction,\nwhile control signals are introduced in a direction orthogonal to the dataflow.\nCommon datapath operators considered in this chapter include adders, one/zero\ndetectors, comparators, counters, Boolean logic units, error-correcting code blocks,\nshifters, and multipliers.\n11.2 Addition/Subtraction\n“Multitudes of contrivances were designed, and almost endless drawings made, for the\npurpose of economizing the time and simplifying the mechanism of carriage.”\n—Charles Babbage, on Difference Engine No. 1, 1864 [Morrison61]\n430 Chapter 11 Datapath Subsystems\nAddition forms the basis for many processing operations, from ALUs to address genera\u0002tion to multiplication to filtering. As a result, adder circuits that add two binary numbers\nare of great interest to digital system designers. An extensive, almost endless, assortment\nof adder architectures serve different speed/power/area requirements. This section begins\nwith half adders and full adders for single-bit addition. It then considers a plethora of\ncarry-propagate adders (CPAs) for the addition of multibit words. Finally, related struc\u0002tures such as subtracters and multiple-input adders are discussed.\n11.2.1 Single-Bit Addition\nThe half adder of Figure 11.1(a) adds two single-bit inputs, A and B. The result is 0, 1, or\n2, so two bits are required to represent the value; they are called the sum S and carry-out\nCout. The carry-out is equivalent to a carry-in to the next more significant column of a\nmultibit adder, so it can be described as having double the weight of the other bits. If mul\u0002tiple adders are to be cascaded, each must be able to receive the carry-in. Such a full adder\nas shown in Figure 11.1(b) has a third input called C or Cin.\nThe truth tables for the half adder and full adder are given in Tables 11.1 and 11.2.\nFor a full adder, it is sometimes useful to define Generate (G), Propagate (P), and Kill (K)\nsignals. The adder generates a carry when Cout is true independent of Cin, so G = A · B.\nThe adder kills a carry when Cout is false independent of Cin, so K = A · B = A + B. The\nadder propagates a carry; i.e., it produces a carry-out if and only if it receives a carry-in,\nwhen exactly one input is true: P = A ⊕ B.\nFrom the truth table, the half adder logic is\n(11.1)\nTABLE 11.1 Truth table for half adder\nA B Cout S\n0 0 0 0\n0 1 0 1\n1 0 0 1\n1 1 1 0\nTABLE 11.2 Truth table for full adder\nA B C G P K Cout S\n0 0 0 0 0 1 0 0\n1 0 1\n0 1 0 0 1 0 0 1\n1 1 0\n1 0 0 0 1 0 0 1\n1 1 0\n1 1 0 1 0 0 1 0\n1 1 1\nSAB\nC AB\n= ⊕\n= out ·\nA B\nC\nS\nCout\nA B\nS\nCout\n(a) (b)\nFIGURE 11.1\nHalf and full adders\n11.2 Addition/Subtraction 431\nand the full adder logic is\n(11.2)\nThe most straightforward approach to designing an adder is with logic gates. Figure\n11.2 shows a half adder. Figure 11.3 shows a full adder at the gate (a) and transistor (b)\nlevels. The carry gate is also called a majority gate because it produces a 1 if at least two of\nthe three inputs are 1. Full adders are used most often, so they will receive the attention of\nthe remainder of this section.\nS ABC ABC ABC ABC\nAB CPC\nC AB AC BC\nAB C\n= +++\n= ( ) ⊕ ⊕ = ⊕\n=++\n= +\nout\nA B\nAB C A B\nABC\n( ) +\n=+ + ( ) = MAJ(, , )\nA\nB\nA\nB\nS\nCout\nFIGURE 11.2\nHalf adder design\nA\nB\nC\nS\nCout\n(a)\nMAJ\nA\nB\nC\nA\nB B B\nA\nC\nS\nC\nC C\nB B\nB\nA A\n(b)\nA B\nC\nB\nA\nA A B B C C\nCout\nC\nA\nA\nB B\nFIGURE 11.3 Full adder design\nThe full adder of Figure 11.3(b) employs 32 transistors (6 for the inverters, 10 for the\nmajority gate, and 16 for the 3-input XOR). A more compact design is based on the\nobservation that S can be factored to reuse the Cout term as follows:\n(11.3)\nSuch a design is shown at the gate (a) and transistor (b) levels in Figure 11.4 and uses\nonly 28 transistors. Note that the pMOS network is identical to the nMOS network\nrather than being the conduction complement, so the topology is called a mirror adder.\nThis simplification reduces the number of series transistors and makes the layout more\nuniform. It is possible because the addition function is symmetric; i.e., the function of com\u0002plemented inputs is the complement of the function.\nThe mirror adder has a greater delay to compute S than Cout. In carry-ripple adders\n(Section 11.2.2.1), the critical path goes from C to Cout through many full adders, so the\nS ABC A B C C = + ++ ( ) out\n432 Chapter 11 Datapath Subsystems\nextra delay computing S is unimportant. Figure 11.4(c) shows the adder with transistor\nsizes optimized to favor the critical path using a number of techniques:\n\u0002 Feed the carry-in signal (C) to the inner inputs so the internal capacitance is\nalready discharged.\n\u0002 Make all transistors in the sum logic whose gate signals are connected to the carry\u0002in and carry logic minimum size (1 unit, e.g., 4 λ). This minimizes the branching\neffort on the critical path. Keep routing on this signal as short as possible to reduce\ninterconnect capacitance.\n\u0002 Determine widths of series transistors by logical effort and simulation. Build an\nasymmetric gate that reduces the logical effort from C to Cout at the expense of\neffort to S.\nS\n(a)\n(b)\nS\nCout\nA B\nC\nB\nA\nCout\nC\nA\nA\nB B\nS\nABC\nABC\nA\nB\nC\nB\nC\nA\n8 8\n8\n4\n441\n1\n1\n1\n1\n1\n1\n1\n1 1\n111\n1\n1\n1\n1\n1\nA\nB\nC\nCout\nA MINORITY\nB\nC Cout\nCout\nS S\nA\nB\nC\n(c)\nMINORITY\nFIGURE 11.4 Full adder for carry-ripple operation\n11.2 Addition/Subtraction 433\n\u0002 Use relatively large transistors on the critical path so that stray wiring capacitance\nis a small fraction of the overall capacitance.\n\u0002 Remove the output inverters and alternate positive and negative logic to reduce\ndelay and transistor count to 24 (see Section 11.2.2.1).\nFigure 11.5 shows two layouts of the adder (see also the inside front cover). The\nchoice of the aspect ratio depends on the application. In a standard-cell environment, the\nlayout of Figure 11.5(a) might be appropriate when a single row of nMOS and pMOS\ntransistors is used. The routing for the A, B, and C inputs is shown inside the cell,\nalthough it could be placed outside the cell because external routing tracks have to be\nassigned to these signals anyway. Figure 11.5(b) shows a layout that might be appropriate\nfor a dense datapath (if horizontal polysilicon is legal). Here, the transistors are rotated\nand all of the wiring is completed in polysilicon and metal1. This allows metal2 bus lines\nto pass over the cell horizontally. Moreover, the widths of the transistors can increase\nA\nA\nBC S Cout\nVDD\nGND\n(a)\nVDD\nGND\nA\nB\nC\n(b)\nS\nCout\nFIGURE 11.5 Full adder layouts. Color version on inside front cover.\n434 Chapter 11 Datapath Subsystems\nwithout impacting the bit-pitch (height) of the datapath. In this case, the widths are\nselected to reduce the Cin to Cout delay that is on the critical path of a carry-ripple adder.\nA rather different full adder design uses transmission gates to form multiplexers and\nXORs. Figure 11.6(a) shows the transistor-level schematic using 24 transistors and pro\u0002viding buffered outputs of the proper polarity with equal delay. The design can be under\u0002stood by parsing the transmission gate structures into multiplexers and an “invertible\ninverter” XOR structure (see Section 11.7.4), as drawn in Figure 11.6(b).1 Note that the\nmultiplexer choosing S is configured to compute P ⊕ C, as given in EQ (11.2).\nFigure 11.7 shows a complementary pass-transistor logic (CPL) approach. In com\u0002parison to a poorly optimized 40-transistor static CMOS full adder, [Yano90] finds CPL\nis twice as fast, 30% lower in power, and slightly smaller. On the other hand, in compari\u0002son to a careful implementation of the mirror adder, [Zimmermann97] finds the CPL\ndelay slightly better, the power comparable, and the area much larger.\nDynamic full adders are widely used in fast multipliers when power is not a concern.\nAs the sum logic inherently requires true and complementary versions of the inputs, dual\u0002rail domino is necessary. Figure 11.8 shows such an adder using footless dual-rail domino\nXOR/XNOR and MAJORITY/MINORTY gates [Heikes94]. The delays to the two\noutputs are reasonably well balanced, which is important for multipliers where both paths\nare critical. It shares transistors in the sum gate to reduce transistor count and takes advan\u0002tage of the symmetric property to provide identical layouts for the two carry gates.\nStatic CMOS full adders typically have a delay of 2–3 FO4 inverters, while domino\nadders have a delay of about 1.5.\n11.2.2 Carry-Propagate Addition\nN-bit adders take inputs {AN, …, A1}, {BN, …, B1}, and carry-in Cin, and compute the sum\n{SN, …, S1} and the carry-out of the most significant bit Cout, as shown in Figure 11.9.\n1\nSome switch-level simulators, notably IRSIM, are confused by this XOR structure and may not simulate\nit correctly.\nB\nS\nCout\nA B C\nP\nP\nA\n1\n0\n1\n0\nP\nP\nC\nS\nCout\n(a) (b)\nFIGURE 11.6 Transmission gate full adder\n11.2 Addition/Subtraction 435\n(Ordinarily, this text calls the least significant bit A0 rather than A1. However, for ",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=820555",
      "title": "",
      "author": "drussell",
      "published_date": "1996-08-12T00:00:00.000Z",
      "content": {
        "text": "The Engineering of Mind\nJames S. Albus\nIntelligent Systems Division\nNational Institute of Standards and Technology\nGaithersburg, MD 20895\nalbus@cme.nist.gov\nAbstract\nWhile the mind remains a mysterious and\ninaccessible phenomenon, many of the components\nof mind, such as perception, behavior generation,\nknowledge representation, value judgment, reason,\nintention, emotion, memory, imagination,\nrecognition, learning, attention, and intelligence are\nbecoming well defined and amenable to analysis.\nProgress is rapid in the cognitive and neurosciences as\nwell as in artificial intelligence, control theory, and\nmany other fields related to the engineering of mind.\nA reference model architecture for intelligent systems\nis suggested to tie together concepts from all these\nseparate fields into a unified framework that includes\nboth biological and machine embodiments of the\ncomponents of mind. It is argued that such a\nreference model architecture will facilitate the\ndevelopment of scientific models of mind.\n1. Introduction\nWhat is mind? What is the relationship between the\nmind and the brain? What is thought? What are the\nmechanisms that give rise to imagination? What is\nperception and how is it related to the object perceived?\nWhat are emotions and why to we have them? What is will\nand how do we choose what we intend to do? How do we\nconvert intention into action? How do we plan and how do\nwe know what to expect from the future?\nUntil recently such questions could only be addressed\nindirectly by subjective introspection, or by psychological\nexperiments in which the majority of the critical variables\ncannot be measured or controlled. Only in the past half\ncentury, since the invention of the electronic computer has it\nbecome possible to approach these issues directly by\nbuilding machines and programs that exhibit some of the\nmind’s essential qualities; such as the ability to recognize\npatterns and relationships, to store and use knowledge, to\nreason and plan, to learn from experience, and to evaluate\nwhat is happening. This is a crucial step in the study of\nmind, for it makes it possible to build mathematical models,\nand conduct experiments where, at least in principle, all the\nvariables can be measured.\nResearch in neural nets, brain modeling, fuzzy systems,\nand genetic algorithms is providing insight into learning and\nthe similarities and differences between neuronal and\nelectronic computing. Artificial intelligence and linguistics\nare probing the nature of language. Image understanding has\ndeveloped into a field of its own. There has been significant\nprogress in rule based reasoning, planning, and problem\nsolving. Game theory and operations research have\ndeveloped methods for decision making in the face of\nuncertainty. Autonomous vehicle research has produced\nadvances in real-time sensory processing, world modeling,\nnavigation, and locomotion. Research in robotics and\nautomated manufacturing has produced intelligent\nhierarchical controls, distributed databases, representations of\nobject geometry, process plans, and material properties.\nControl theory has developed precise understanding of\nstability, adaptability, and controllability under various\nconditions of feedback and noise. Powerful mechanisms\nhave been developed for parallel processing, recursive\nestimation, and focusing of attention. Engineering\nsolutions exist for fusing sensory input from multiple\nsources, and assessing the believability of noisy data.\nSince the 1950’s, a wide variety of robotic systems have\nbeen designed and built -- from experimental laboratory\nvehicles that wander about, follow walls, and pick up sundry\nitems, to precision assembly systems that use vision to\nacquire parts and Computer Aided Design (CAD) models to\nplan motions. Many approaches have been explored and\nvarious architectures designed, from subsumption and neural\nnets, to SOAR [Rosenbloom et al. 93] and RCS [Albus\n96]. Entire factories have been automated and products as\ncomplex as the Boeing 777 aircraft containing over three\nmillion parts have been designed and engineered entirely in\nsoftware, without physical mockups.\nProgress is also rapid in the cognitive and neurosciences.\nNeuroanatomy is producing maps of the interconnecting\npathways of the brain. Neurophysiology is determining\nhow neurons compute functions and communicate\ninformation. Neuropharmacology is discovering many of\nthe transmitter substances that modify value judgments,\ncompute reward and punishment, motivate behavior, and\nproduce learning. Psychophysics provides clues as to how\nhumans and animals perceive objects, events, time, and\nspace, and reason about relationships. Behavioral\npsychology is creating models of mental and emotional\ndevelopment and behavior.\nWhile the mind itself remains a mysterious and\ninaccessible phenomena, many of the components of mind,\nsuch as perception, behavior generation, knowledge\nrepresentation, value judgment, reason, intention, emotion,\nmemory imagination, recognition, learning, and intelligence\nare becoming well defined and amenable to analysis.\nProgress is rapid, and there exists an enormous and rapidly\ngrowing literature in each of the above fields. What is\nlacking is a general theoretical model which ties all these\nseparate areas into a unified framework that includes both\nbiological and machine embodiments of the components of\nmind. In 1991, I published an outline for a general theory\nof intelligence [Albus 91]. This theory was expressed in the\nnotation of the Real-time Control System (RCS) developed\nat NIST and elsewhere for the design of intelligent control\nsystems [Albus 96]. In this paper, I will illustrate how\nmany of the concepts developed for intelligent machines\napply to biological intelligence and suggest how engineering\nprinciples might be developed for the design and analysis of\npractical intelligent systems.\n2. The Fundamental Elements\nIn any scientific endeavor, it is necessary to precisely\ndefine concepts and clearly state assumptions. I therefore\nbegin with some axioms and definitions.\nAxiom 1: The functional elements of an intelligent\nsystem are behavior generation, sensory perception, world\nmodeling, and value judgment.\nDf: behavior generation (BG)\nthe planning and control of action designed to achieve\nbehavioral goals.\nBehavior generation organizes the response of a\ncollection of agents to task commands. Behavior generation\naccepts task commands with goals, objects, and priorities.\nIt decomposes tasks into jobs and assigns jobs and resources\nto agents. It formulates and selects plans and develops\nschedules for possibly coordinated actions by agents. It\nexecutes plans and reacts to feedback so as to follow plans in\nspite of local perturbations and unexpected events. Finally,\nbehavior generation produces output commands that are\neither decomposed further, or act directly on the\nenvironment.\nDf: planning\na process that:\n1. assigns responsibility to agents for jobs, and\nallocates resources to agents for performing their\nassigned jobs,\n2. hypothesizes strings of actions (plans) for agents\nfrom a vocabulary of possible actions to accomplish\njobs,\n3. simulates and predicts the results of executing these\nhypothesized plans,\n4. evaluates the predicted results of the hypothesized\nplans,\n5. selects the hypothesized plan with the most\nfavorable results for execution.\nThe planning process may use either a heuristic or an\nexhaustive search strategy for synthesizing hypothesized\nplans. Heuristic strategies may include the selection of\npreviously generated plans from a library.\nDf: agent\na set of computational elements that plan and control the\nexecution of jobs, correcting for errors and perturbations\nalong the way.\nAn agent may servo its output to follow a planned\ntrajectory, or may sequence discrete actions and branch on\nconditions. An agent also assigns jobs and resources to\nsubordinates. The computational elements in an agent may\ninclude sensory perception, world modeling, and value\njudgment functions and a knowledge database.\nDf: sensory perception (SP)\nthe transformation of data from sensors into meaningful\nand useful representations of the world.\nSensory perception accepts input data from sensors that\nmeasure states of the external world as well as internal states\nof the system itself. Sensory perception scales and filters\ndata, computes observed features and attributes, and\ncompares observations with expectations generated from\ninternal models. Correlations between sensed observations\nand internally generated expectations are used to detect events\nand recognize entities and situations. Differences between\nsensed observations and internally generated expectations are\nsent to world modeling to update internal models. Sensory\nperception also classifies, generalizes, and clusters, or\ngroups, recognized entities and detected events into higher\norder entities and events, and computes attributes of entities\nand events.\nDf: value judgment (VJ)\na) the computation of cost, risk, and benefit of actions\nand plans,\nb) the estimation of the importance and value of\nobjects, events, and situations,\nc) the assessment of reliability of information,\nd) the calculation of reward or punishment resulting\nfrom perceived states and events.\nValue judgment evaluates perceived and planned\nsituations thereby enabling behavior generation to select\nadvantageous goals and set priorities among competing\nbehavioral possibilities. It computes what is important (for\nattention), and what is rewarding or punishing (for learning).\nValue judgment is performed in the brain by the limbic\nsystem.\nDf: world modeling (WM)\na process that performs four principal functions:\n1. Uses sensory input to construct, update, and maintain\na knowledge database, including iconic images,\nsymbolic lists, entity and event frames, and semantic\nand pragmatic relationships between entities, and\nlinks between symbolic and iconic representations.\nIn biological systems, this is the function of short\nterm and long term memory.\n2.",
        "html": "The Engineering of Mind\nJames S. Albus\nIntelligent Systems Division\nNational Institute of Standards and Technology\nGaithersburg, MD 20895\nalbus@cme.nist.gov\nAbstract\nWhile the mind remains a mysterious and\ninaccessible phenomenon, many of the components\nof mind, such as perception, behavior generation,\nknowledge representation, value judgment, reason,\nintention, emotion, memory, imagination,\nrecognition, learning, attention, and intelligence are\nbecoming well defined and amenable to analysis.\nProgress is rapid in the cognitive and neurosciences as\nwell as in artificial intelligence, control theory, and\nmany other fields related to the engineering of mind.\nA reference model architecture for intelligent systems\nis suggested to tie together concepts from all these\nseparate fields into a unified framework that includes\nboth biological and machine embodiments of the\ncomponents of mind. It is argued that such a\nreference model architecture will facilitate the\ndevelopment of scientific models of mind.\n1. Introduction\nWhat is mind? What is the relationship between the\nmind and the brain? What is thought? What are the\nmechanisms that give rise to imagination? What is\nperception and how is it related to the object perceived?\nWhat are emotions and why to we have them? What is will\nand how do we choose what we intend to do? How do we\nconvert intention into action? How do we plan and how do\nwe know what to expect from the future?\nUntil recently such questions could only be addressed\nindirectly by subjective introspection, or by psychological\nexperiments in which the majority of the critical variables\ncannot be measured or controlled. Only in the past half\ncentury, since the invention of the electronic computer has it\nbecome possible to approach these issues directly by\nbuilding machines and programs that exhibit some of the\nmind’s essential qualities; such as the ability to recognize\npatterns and relationships, to store and use knowledge, to\nreason and plan, to learn from experience, and to evaluate\nwhat is happening. This is a crucial step in the study of\nmind, for it makes it possible to build mathematical models,\nand conduct experiments where, at least in principle, all the\nvariables can be measured.\nResearch in neural nets, brain modeling, fuzzy systems,\nand genetic algorithms is providing insight into learning and\nthe similarities and differences between neuronal and\nelectronic computing. Artificial intelligence and linguistics\nare probing the nature of language. Image understanding has\ndeveloped into a field of its own. There has been significant\nprogress in rule based reasoning, planning, and problem\nsolving. Game theory and operations research have\ndeveloped methods for decision making in the face of\nuncertainty. Autonomous vehicle research has produced\nadvances in real-time sensory processing, world modeling,\nnavigation, and locomotion. Research in robotics and\nautomated manufacturing has produced intelligent\nhierarchical controls, distributed databases, representations of\nobject geometry, process plans, and material properties.\nControl theory has developed precise understanding of\nstability, adaptability, and controllability under various\nconditions of feedback and noise. Powerful mechanisms\nhave been developed for parallel processing, recursive\nestimation, and focusing of attention. Engineering\nsolutions exist for fusing sensory input from multiple\nsources, and assessing the believability of noisy data.\nSince the 1950’s, a wide variety of robotic systems have\nbeen designed and built -- from experimental laboratory\nvehicles that wander about, follow walls, and pick up sundry\nitems, to precision assembly systems that use vision to\nacquire parts and Computer Aided Design (CAD) models to\nplan motions. Many approaches have been explored and\nvarious architectures designed, from subsumption and neural\nnets, to SOAR [Rosenbloom et al. 93] and RCS [Albus\n96]. Entire factories have been automated and products as\ncomplex as the Boeing 777 aircraft containing over three\nmillion parts have been designed and engineered entirely in\nsoftware, without physical mockups.\nProgress is also rapid in the cognitive and neurosciences.\nNeuroanatomy is producing maps of the interconnecting\npathways of the brain. Neurophysiology is determining\nhow neurons compute functions and communicate\ninformation. Neuropharmacology is discovering many of\nthe transmitter substances that modify value judgments,\ncompute reward and punishment, motivate behavior, and\nproduce learning. Psychophysics provides clues as to how\nhumans and animals perceive objects, events, time, and\nspace, and reason about relationships. Behavioral\npsychology is creating models of mental and emotional\ndevelopment and behavior.\nWhile the mind itself remains a mysterious and\ninaccessible phenomena, many of the components of mind,\nsuch as perception, behavior generation, knowledge\nrepresentation, value judgment, reason, intention, emotion,\nmemory imagination, recognition, learning, and intelligence\nare becoming well defined and amenable to analysis.\nProgress is rapid, and there exists an enormous and rapidly\ngrowing literature in each of the above fields. What is\nlacking is a general theoretical model which ties all these\nseparate areas into a unified framework that includes both\nbiological and machine embodiments of the components of\nmind. In 1991, I published an outline for a general theory\nof intelligence [Albus 91]. This theory was expressed in the\nnotation of the Real-time Control System (RCS) developed\nat NIST and elsewhere for the design of intelligent control\nsystems [Albus 96]. In this paper, I will illustrate how\nmany of the concepts developed for intelligent machines\napply to biological intelligence and suggest how engineering\nprinciples might be developed for the design and analysis of\npractical intelligent systems.\n2. The Fundamental Elements\nIn any scientific endeavor, it is necessary to precisely\ndefine concepts and clearly state assumptions. I therefore\nbegin with some axioms and definitions.\nAxiom 1: The functional elements of an intelligent\nsystem are behavior generation, sensory perception, world\nmodeling, and value judgment.\nDf: behavior generation (BG)\nthe planning and control of action designed to achieve\nbehavioral goals.\nBehavior generation organizes the response of a\ncollection of agents to task commands. Behavior generation\naccepts task commands with goals, objects, and priorities.\nIt decomposes tasks into jobs and assigns jobs and resources\nto agents. It formulates and selects plans and develops\nschedules for possibly coordinated actions by agents. It\nexecutes plans and reacts to feedback so as to follow plans in\nspite of local perturbations and unexpected events. Finally,\nbehavior generation produces output commands that are\neither decomposed further, or act directly on the\nenvironment.\nDf: planning\na process that:\n1. assigns responsibility to agents for jobs, and\nallocates resources to agents for performing their\nassigned jobs,\n2. hypothesizes strings of actions (plans) for agents\nfrom a vocabulary of possible actions to accomplish\njobs,\n3. simulates and predicts the results of executing these\nhypothesized plans,\n4. evaluates the predicted results of the hypothesized\nplans,\n5. selects the hypothesized plan with the most\nfavorable results for execution.\nThe planning process may use either a heuristic or an\nexhaustive search strategy for synthesizing hypothesized\nplans. Heuristic strategies may include the selection of\npreviously generated plans from a library.\nDf: agent\na set of computational elements that plan and control the\nexecution of jobs, correcting for errors and perturbations\nalong the way.\nAn agent may servo its output to follow a planned\ntrajectory, or may sequence discrete actions and branch on\nconditions. An agent also assigns jobs and resources to\nsubordinates. The computational elements in an agent may\ninclude sensory perception, world modeling, and value\njudgment functions and a knowledge database.\nDf: sensory perception (SP)\nthe transformation of data from sensors into meaningful\nand useful representations of the world.\nSensory perception accepts input data from sensors that\nmeasure states of the external world as well as internal states\nof the system itself. Sensory perception scales and filters\ndata, computes observed features and attributes, and\ncompares observations with expectations generated from\ninternal models. Correlations between sensed observations\nand internally generated expectations are used to detect events\nand recognize entities and situations. Differences between\nsensed observations and internally generated expectations are\nsent to world modeling to update internal models. Sensory\nperception also classifies, generalizes, and clusters, or\ngroups, recognized entities and detected events into higher\norder entities and events, and computes attributes of entities\nand events.\nDf: value judgment (VJ)\na) the computation of cost, risk, and benefit of actions\nand plans,\nb) the estimation of the importance and value of\nobjects, events, and situations,\nc) the assessment of reliability of information,\nd) the calculation of reward or punishment resulting\nfrom perceived states and events.\nValue judgment evaluates perceived and planned\nsituations thereby enabling behavior generation to select\nadvantageous goals and set priorities among competing\nbehavioral possibilities. It computes what is important (for\nattention), and what is rewarding or punishing (for learning).\nValue judgment is performed in the brain by the limbic\nsystem.\nDf: world modeling (WM)\na process that performs four principal functions:\n1. Uses sensory input to construct, update, and maintain\na knowledge database, including iconic images,\nsymbolic lists, entity and event frames, and semantic\nand pragmatic relationships between entities, and\nlinks between symbolic and iconic representations.\nIn biological systems, this is the function of short\nterm and long term memory.\n2.",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.academia.edu/27483144/Recursive_encoding_and_decoding_of_the_noiseless_subsystem_for_qudits",
      "title": "Recursive encoding and decoding of the noiseless subsystem for qudits",
      "author": "Chi-Kwong Li",
      "published_date": "2016-08-02T23:42:46.000Z",
      "content": {
        "text": "<div><div><p>When the environmental disturbace to a quantum system has a wavelength much larger than the system size, all qubits localized within a small area are under action of the same error operators. Noiseless subsystem and decoherence free subspace are known to correct such collective errors. We construct simple quantum circuits, which implement these collective error correction codes, for a small number n of physical qubits. A single logical qubit is encoded with n = 3 and n = 4, while two logical qubits are encoded with n = 5. The recursive relations among the subspaces employed in noiseless subsystem and decoherence free subspace play essential rôles in our implementation. The recursive relations also show that the number of gates required to encode m logical qubits increases linearly in m.</p><div><div><p></p><h4>Sign up for access to the world's latest research.</h4></div><div><p><span>check</span><span>Get notified about relevant papers</span></p><p><span>check</span><span>Save papers to use in your research</span></p><p><span>check</span><span>Join the discussion with peers</span></p><p><span>check</span><span>Track your impact</span></p></div></div></div></div>",
        "html": "<div><div><p>When the environmental disturbace to a quantum system has a wavelength much larger than the system size, all qubits localized within a small area are under action of the same error operators. Noiseless subsystem and decoherence free subspace are known to correct such collective errors. We construct simple quantum circuits, which implement these collective error correction codes, for a small number n of physical qubits. A single logical qubit is encoded with n = 3 and n = 4, while two logical qubits are encoded with n = 5. The recursive relations among the subspaces employed in noiseless subsystem and decoherence free subspace play essential rôles in our implementation. The recursive relations also show that the number of gates required to encode m logical qubits increases linearly in m.</p><div><div><p></p><h4>Sign up for access to the world's latest research.</h4></div><div><p><span>check</span><span>Get notified about relevant papers</span></p><p><span>check</span><span>Save papers to use in your research</span></p><p><span>check</span><span>Join the discussion with peers</span></p><p><span>check</span><span>Track your impact</span></p></div></div></div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "When the environmental disturbace to a quantum system has a wavelength much larger than the system size, all qubits localized within a small area are under action of the same error operators. Noiseless subsystem and decoherence free subspace are known to correct such collective errors. We construct simple quantum circuits, which implement these collective error correction codes, for a small number n of physical qubits. A single logical qubit is encoded with n = 3 and n = 4, while two logical qub",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "When the environmental disturbace to a quantum system has a wavelength much larger than the system size, all qubits localized within a small area are under action of the same error operators. Noiseless subsystem and decoherence free subspace are known to correct such collective errors. We construct simple quantum circuits, which implement these collective error correction codes, for a small number n of physical qubits. A single logical qubit is encoded with n = 3 and n = 4, while two logical qub",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Sign up for access to the world's latest research.checkGet notified about relevant paperscheckSave papers to use in your researchcheckJoin the discussion with peerscheckTrack your impact",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Sign up for access to the world's latest research.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "checkGet notified about relevant paperscheckSave papers to use in your researchcheckJoin the discussion with peerscheckTrack your impact",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h4",
              "text": "Sign up for access to the world's latest research.",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.researchgate.net/publication/251385982_Cognitive_Task_Analysis_in_Interacting_Cognitive_Subsystems",
      "title": "(PDF) Cognitive Task Analysis in Interacting Cognitive Subsystems",
      "author": "",
      "published_date": "2004-01-01T00:00:00.000Z",
      "content": {
        "text": "<div><section><div><div><p>experiential, and abstracted memories influence the ease of processing, and the scope a design offers for their development,informs ease of learning and skill acquisition. The location of a particular form of buffered processing predicts subjective awareness of different aspects of the task, and of task complexity. Two notations supporting analysis are described. The close coupling of the analytic approach and the underlying theory enables a CTA in ICS to provide supportive evaluation, allowing iterative redesign. It is also allowing further research linking ICS to formal models of systems analysis (Syndetics) and to other methods of TA, namely TKS, to extend both techniques to collaborative and multiple task performance. 15.1 A RATIONALE FOR COGNITIVE TASK ANALYSIS</p><div><p>Figures - uploaded by <a href=\"https://www.researchgate.net/publication/profile/Jon-May\">Jon May</a></p><div><p><span>Author content</span></p><div><p>All figure content in this area was uploaded by Jon May</p></div></div></div><p>Content may be subject to copyright.</p></div><div><p><strong>Discover the world's research</strong></p><ul><li>25+ million members</li><li>160+ million publication pages</li><li>2.3+ billion citations</li></ul><p><a href=\"https://www.researchgate.net/publication/signup.SignUp.html\"><span>Join for free</span></a></p></div></div><section><span></span><a href=\"https://www.researchgate.net/publication/publication/251385982_Cognitive_Task_Analysis_in_Interacting_Cognitive_Subsystems#read-preview\"></a><div>\n<div><p>THE HANDBOOK OF T<span></span>ASK ANAL<span></span>YSIS</p><p>FOR HUMAN-COMPUTER INTERACTION</p><p>Edited by</p><p>Dan Diaper</p><p>Bournemouth<span> </span>University</p><p>Neville A. Stanton</p><p>Brunel<span> </span>University</p><p>LA<span></span>WRENCE ERLBAUM ASSOCIA<span></span>TES, PUBLISHERS</p><p>2004<span> </span><span>Mahwah, New Jersey<span> </span>London</span></p></div>\n<div><p>15</p><p>Cognitive T<span></span>ask Analysis</p><p>in Interacting Cognitive</p><p>Subsystems</p><p>Jon May</p><p>University<span> </span>of<span> </span>Shefﬁeld</p><p>Philip J. Barnard</p><p>MRC-CBU</p><p>Cognitiv<span></span>e task<span> </span>analysis (CT<span></span>A) techniques seek<span> </span>to model<span> </span>the mental<span> </span>activity<span> </span>of a<span> </span>task operator<span></span>.</p><p>W<span></span>ith<span> </span>the<span> </span>rise<span> </span>of<span> </span>computing<span> </span>artifacts,<span> </span>the<span> </span>focus<span> </span>of<span> </span>CT<span></span>A<span> </span>has<span> </span>changed<span> </span>from<span> </span>supporting<span> </span>the<span> </span>tutoring</p><p>of<span> </span>operators,<span> </span>to<span> </span>modeling<span> </span>knowledge<span></span>application,<span></span>to<span> </span>modeling<span> </span>cognitiv<span></span>e<span> </span>processes.<span> </span>Descendants</p><p>of<span> </span>knowledge-based<span> </span>approaches<span> </span>include<span> </span>GOMS,<span> </span>and<span> </span>produce<span> </span>quantitative<span> </span>temporal<span> </span>behavioral</p><p>predictions<span> </span>for<span> </span>well<span> </span>deﬁned<span> </span>interfaces.<span> </span>The<span> </span>increasing<span> </span>pace<span> </span>of<span> </span>design,<span> </span>and<span> </span>the<span> </span>dominance<span> </span>of</p><p>small design<span> </span>teams has led<span> </span>to a demand<span> </span>for more<span> </span>ﬂexible techniques.<span> </span>This chapter<span> </span>describes a</p><p>particular approach to CT<span></span>A using a cognitive theory called Interacting Cognitiv<span></span>e Subsystems</p><p>(ICS).<span> </span>A<span> </span>CT<span></span>A<span> </span>in<span> </span>ICS<span> </span>requires<span> </span>a<span> </span>prior<span> </span>task<span> </span>analysis<span> </span>to<span> </span>have<span> </span>been<span> </span>conducted,<span> </span>b<span></span>ut<span> </span>the<span> </span>analyst<span> </span>then</p><p>identiﬁes<span> </span>the<span> </span>conﬁguration<span> </span>of<span> </span>cognitiv<span></span>e<span> </span>processes<span> </span>necessary<span> </span>to<span> </span>transform<span> </span>information<span> </span>about</p><p>the task,<span> </span>through the phases<span> </span>of goal formation,<span> </span>action speciﬁcation,<span> </span>and action execution; for</p><p>novices,<span> </span>occasional (normal),<span> </span>and e<span></span>xpert operators.<span> </span>The av<span></span>ailability of procedural<span> </span>knowledge,</p><p>experiential,<span> </span>and<span> </span>abstracted<span> </span>memories inﬂuence<span> </span>the ease<span> </span>of<span> </span>processing,<span> </span>and the<span> </span>scope a<span> </span>design</p><p>offers<span> </span>for<span> </span>their<span> </span>de<span></span>velopment<span> </span>informs<span> </span>ease<span> </span>of<span> </span>learning<span> </span>and<span> </span>skill<span> </span>acquisition.<span> </span>The<span> </span>location<span> </span>of</p><p>a particular<span> </span>form<span> </span>of buffered processing<span> </span>predicts subjective awareness of different aspects<span> </span>of</p><p>the<span> </span>task,<span> </span>and<span> </span>of<span> </span>task<span> </span>complexity<span></span>.<span> </span>T<span></span>wo notations<span> </span>supporting<span> </span>analysis<span> </span>are<span> </span>described.<span> </span>The<span> </span>close</p><p>coupling of the analytic approach and the underlying theory enables a CT<span></span>A in ICS to provide</p><p>supportiv<span></span>e<span> </span>e<span></span>valuation, allowing iterativ<span></span>e<span> </span>redesign.<span> </span>It is<span> </span>also<span> </span>allowing further<span> </span>research<span> </span>linking</p><p>ICS<span> </span>to<span> </span>formal<span> </span>models<span> </span>of<span> </span>systems<span> </span>analysis<span> </span>(Syndetics)<span> </span>and<span> </span>to<span> </span>other<span> </span>methods<span> </span>of<span> </span>T<span></span>A,<span> </span>namely</p><p>TKS, to extend both techniques to collaborati<span></span>ve and multiple task performance.</p><p>15.1<span> </span>A RATIONALE FOR COGNITIVE T<span></span>ASK ANALYSIS</p><p>The<span> </span>pace<span> </span>of<span> </span>technological<span> </span>change<span> </span>and<span> </span>the<span> </span>ubiquity<span> </span>of<span> </span>computer-based<span> </span>devices<span> </span>has<span> </span>brought</p><p>about<span> </span>a<span> </span>signiﬁcant<span> </span>change<span> </span>in<span> </span>the<span> </span>focus<span> </span>of<span> </span>task<span> </span>analysis<span> </span>over<span> </span>the<span> </span>past<span> </span>20<span> </span>years.<span> </span>As<span> </span>Annett</p><p>describes<span> </span>in<span> </span>chapter<span> </span>3<span> </span>of<span> </span>this<span> </span>volume,<span> </span>the<span> </span>early<span> </span>time-and-motion<span> </span>focus<span> </span>on<span> </span>physical<span> </span>units<span> </span>of</p><p>task<span> </span>performance<span> </span>has<span> </span>been<span> </span>superseded<span> </span>by<span> </span>an<span> </span>emphasis<span> </span>on<span> </span>the<span> </span>mental<span> </span>operations<span> </span>required<span> </span>of</p><p>an<span> </span>operator<span> </span>of<span> </span>a<span> </span>de<span></span>vice.<span> </span>Cognitiv<span></span>e<span> </span>task<span> </span>analysis<span> </span>(CT<span></span>A)<span> </span>began<span> </span>by<span> </span>recognizing<span> </span>that<span> </span>the<span> </span>key<span> </span>to</p><p>291</p></div>\n<div><p>292<span> </span><span>MAY AND BARNARD</span></p><p>skilled<span> </span>task<span> </span>performance<span> </span>lay<span> </span>in<span> </span>the<span> </span>possession<span> </span>and<span> </span>appropriate<span> </span>use<span> </span>by<span> </span>the<span> </span>operator<span> </span>of<span> </span>task-</p><p>relev<span></span>ant<span> </span>knowledge<span> </span>and<span> </span>sought<span> </span>to<span> </span>de<span></span>velop<span> </span>models<span> </span>of<span> </span>the<span> </span>required<span> </span>kno<span></span>wledge<span> </span>to<span> </span>improve the</p><p>tutoring<span> </span>of<span> </span>operators<span> </span>and<span> </span>speed<span> </span>the<span> </span>progression<span> </span>of<span> </span>an<span> </span>individual<span> </span>from<span> </span>task<span> </span>novice<span> </span>to<span> </span>task</p><p>expert.<span> </span>Psychological<span> </span>theories<span> </span>of<span> </span>learning<span> </span>and<span> </span>knowledge<span> </span>structuring,<span> </span>such<span> </span>as<span> </span>Newell’<span></span>s<span> </span>SO<span></span>AR</p><p>architecture<span> </span>(Ne<span></span>well,<span> </span>1990),<span> </span>ga<span></span>ve rise<span> </span>to<span> </span>the<span> </span>realization that<span> </span>the<span> </span>task<span> </span>could itself<span> </span>be<span> </span>designed</p><p>to<span> </span>facilitate<span> </span>knowledge<span> </span>acquisition,<span> </span>and<span> </span>so<span> </span>CT<span></span>A<span> </span>began<span> </span>to<span> </span>be<span> </span>seen<span> </span>as<span> </span>a<span> </span>stage<span> </span>in<span> </span>task<span> </span>design,</p><p>modifying<span> </span>the<span> </span>task<span> </span>device<span> </span>or<span> </span>structure,<span> </span>rather<span> </span>than<span> </span>as<span> </span>something<span> </span>to<span> </span>be<span> </span>done<span> </span>to<span> </span>modify<span> </span>the</p><p>operators’ knowledge.</p><p>The<span> </span>descendants<span> </span>of<span> </span>knowledge-based<span> </sp",
        "html": "<div><section><div><div><p>experiential, and abstracted memories influence the ease of processing, and the scope a design offers for their development,informs ease of learning and skill acquisition. The location of a particular form of buffered processing predicts subjective awareness of different aspects of the task, and of task complexity. Two notations supporting analysis are described. The close coupling of the analytic approach and the underlying theory enables a CTA in ICS to provide supportive evaluation, allowing iterative redesign. It is also allowing further research linking ICS to formal models of systems analysis (Syndetics) and to other methods of TA, namely TKS, to extend both techniques to collaborative and multiple task performance. 15.1 A RATIONALE FOR COGNITIVE TASK ANALYSIS</p><div><p>Figures - uploaded by <a href=\"https://www.researchgate.net/publication/profile/Jon-May\">Jon May</a></p><div><p><span>Author content</span></p><div><p>All figure content in this area was uploaded by Jon May</p></div></div></div><p>Content may be subject to copyright.</p></div><div><p><strong>Discover the world's research</strong></p><ul><li>25+ million members</li><li>160+ million publication pages</li><li>2.3+ billion citations</li></ul><p><a href=\"https://www.researchgate.net/publication/signup.SignUp.html\"><span>Join for free</span></a></p></div></div><section><span></span><a href=\"https://www.researchgate.net/publication/publication/251385982_Cognitive_Task_Analysis_in_Interacting_Cognitive_Subsystems#read-preview\"></a><div>\n<div><p>THE HANDBOOK OF T<span></span>ASK ANAL<span></span>YSIS</p><p>FOR HUMAN-COMPUTER INTERACTION</p><p>Edited by</p><p>Dan Diaper</p><p>Bournemouth<span> </span>University</p><p>Neville A. Stanton</p><p>Brunel<span> </span>University</p><p>LA<span></span>WRENCE ERLBAUM ASSOCIA<span></span>TES, PUBLISHERS</p><p>2004<span> </span><span>Mahwah, New Jersey<span> </span>London</span></p></div>\n<div><p>15</p><p>Cognitive T<span></span>ask Analysis</p><p>in Interacting Cognitive</p><p>Subsystems</p><p>Jon May</p><p>University<span> </span>of<span> </span>Shefﬁeld</p><p>Philip J. Barnard</p><p>MRC-CBU</p><p>Cognitiv<span></span>e task<span> </span>analysis (CT<span></span>A) techniques seek<span> </span>to model<span> </span>the mental<span> </span>activity<span> </span>of a<span> </span>task operator<span></span>.</p><p>W<span></span>ith<span> </span>the<span> </span>rise<span> </span>of<span> </span>computing<span> </span>artifacts,<span> </span>the<span> </span>focus<span> </span>of<span> </span>CT<span></span>A<span> </span>has<span> </span>changed<span> </span>from<span> </span>supporting<span> </span>the<span> </span>tutoring</p><p>of<span> </span>operators,<span> </span>to<span> </span>modeling<span> </span>knowledge<span></span>application,<span></span>to<span> </span>modeling<span> </span>cognitiv<span></span>e<span> </span>processes.<span> </span>Descendants</p><p>of<span> </span>knowledge-based<span> </span>approaches<span> </span>include<span> </span>GOMS,<span> </span>and<span> </span>produce<span> </span>quantitative<span> </span>temporal<span> </span>behavioral</p><p>predictions<span> </span>for<span> </span>well<span> </span>deﬁned<span> </span>interfaces.<span> </span>The<span> </span>increasing<span> </span>pace<span> </span>of<span> </span>design,<span> </span>and<span> </span>the<span> </span>dominance<span> </span>of</p><p>small design<span> </span>teams has led<span> </span>to a demand<span> </span>for more<span> </span>ﬂexible techniques.<span> </span>This chapter<span> </span>describes a</p><p>particular approach to CT<span></span>A using a cognitive theory called Interacting Cognitiv<span></span>e Subsystems</p><p>(ICS).<span> </span>A<span> </span>CT<span></span>A<span> </span>in<span> </span>ICS<span> </span>requires<span> </span>a<span> </span>prior<span> </span>task<span> </span>analysis<span> </span>to<span> </span>have<span> </span>been<span> </span>conducted,<span> </span>b<span></span>ut<span> </span>the<span> </span>analyst<span> </span>then</p><p>identiﬁes<span> </span>the<span> </span>conﬁguration<span> </span>of<span> </span>cognitiv<span></span>e<span> </span>processes<span> </span>necessary<span> </span>to<span> </span>transform<span> </span>information<span> </span>about</p><p>the task,<span> </span>through the phases<span> </span>of goal formation,<span> </span>action speciﬁcation,<span> </span>and action execution; for</p><p>novices,<span> </span>occasional (normal),<span> </span>and e<span></span>xpert operators.<span> </span>The av<span></span>ailability of procedural<span> </span>knowledge,</p><p>experiential,<span> </span>and<span> </span>abstracted<span> </span>memories inﬂuence<span> </span>the ease<span> </span>of<span> </span>processing,<span> </span>and the<span> </span>scope a<span> </span>design</p><p>offers<span> </span>for<span> </span>their<span> </span>de<span></span>velopment<span> </span>informs<span> </span>ease<span> </span>of<span> </span>learning<span> </span>and<span> </span>skill<span> </span>acquisition.<span> </span>The<span> </span>location<span> </span>of</p><p>a particular<span> </span>form<span> </span>of buffered processing<span> </span>predicts subjective awareness of different aspects<span> </span>of</p><p>the<span> </span>task,<span> </span>and<span> </span>of<span> </span>task<span> </span>complexity<span></span>.<span> </span>T<span></span>wo notations<span> </span>supporting<span> </span>analysis<span> </span>are<span> </span>described.<span> </span>The<span> </span>close</p><p>coupling of the analytic approach and the underlying theory enables a CT<span></span>A in ICS to provide</p><p>supportiv<span></span>e<span> </span>e<span></span>valuation, allowing iterativ<span></span>e<span> </span>redesign.<span> </span>It is<span> </span>also<span> </span>allowing further<span> </span>research<span> </span>linking</p><p>ICS<span> </span>to<span> </span>formal<span> </span>models<span> </span>of<span> </span>systems<span> </span>analysis<span> </span>(Syndetics)<span> </span>and<span> </span>to<span> </span>other<span> </span>methods<span> </span>of<span> </span>T<span></span>A,<span> </span>namely</p><p>TKS, to extend both techniques to collaborati<span></span>ve and multiple task performance.</p><p>15.1<span> </span>A RATIONALE FOR COGNITIVE T<span></span>ASK ANALYSIS</p><p>The<span> </span>pace<span> </span>of<span> </span>technological<span> </span>change<span> </span>and<span> </span>the<span> </span>ubiquity<span> </span>of<span> </span>computer-based<span> </span>devices<span> </span>has<span> </span>brought</p><p>about<span> </span>a<span> </span>signiﬁcant<span> </span>change<span> </span>in<span> </span>the<span> </span>focus<span> </span>of<span> </span>task<span> </span>analysis<span> </span>over<span> </span>the<span> </span>past<span> </span>20<span> </span>years.<span> </span>As<span> </span>Annett</p><p>describes<span> </span>in<span> </span>chapter<span> </span>3<span> </span>of<span> </span>this<span> </span>volume,<span> </span>the<span> </span>early<span> </span>time-and-motion<span> </span>focus<span> </span>on<span> </span>physical<span> </span>units<span> </span>of</p><p>task<span> </span>performance<span> </span>has<span> </span>been<span> </span>superseded<span> </span>by<span> </span>an<span> </span>emphasis<span> </span>on<span> </span>the<span> </span>mental<span> </span>operations<span> </span>required<span> </span>of</p><p>an<span> </span>operator<span> </span>of<span> </span>a<span> </span>de<span></span>vice.<span> </span>Cognitiv<span></span>e<span> </span>task<span> </span>analysis<span> </span>(CT<span></span>A)<span> </span>began<span> </span>by<span> </span>recognizing<span> </span>that<span> </span>the<span> </span>key<span> </span>to</p><p>291</p></div>\n<div><p>292<span> </span><span>MAY AND BARNARD</span></p><p>skilled<span> </span>task<span> </span>performance<span> </span>lay<span> </span>in<span> </span>the<span> </span>possession<span> </span>and<span> </span>appropriate<span> </span>use<span> </span>by<span> </span>the<span> </span>operator<span> </span>of<span> </span>task-</p><p>relev<span></span>ant<span> </span>knowledge<span> </span>and<span> </span>sought<span> </span>to<span> </span>de<span></span>velop<span> </span>models<span> </span>of<span> </span>the<span> </span>required<span> </span>kno<span></span>wledge<span> </span>to<span> </span>improve the</p><p>tutoring<span> </span>of<span> </span>operators<span> </span>and<span> </span>speed<span> </span>the<span> </span>progression<span> </span>of<span> </span>an<span> </span>individual<span> </span>from<span> </span>task<span> </span>novice<span> </span>to<span> </span>task</p><p>expert.<span> </span>Psychological<span> </span>theories<span> </span>of<span> </span>learning<span> </span>and<span> </span>knowledge<span> </span>structuring,<span> </span>such<span> </span>as<span> </span>Newell’<span></span>s<span> </span>SO<span></span>AR</p><p>architecture<span> </span>(Ne<span></span>well,<span> </span>1990),<span> </span>ga<span></span>ve rise<span> </span>to<span> </span>the<span> </span>realization that<span> </span>the<span> </span>task<span> </span>could itself<span> </span>be<span> </span>designed</p><p>to<span> </span>facilitate<span> </span>knowledge<span> </span>acquisition,<span> </span>and<span> </span>so<span> </span>CT<span></span>A<span> </span>began<span> </span>to<span> </span>be<span> </span>seen<span> </span>as<span> </span>a<span> </span>stage<span> </span>in<span> </span>task<span> </span>design,</p><p>modifying<span> </span>the<span> </span>task<span> </span>device<span> </span>or<span> </span>structure,<span> </span>rather<span> </span>than<span> </span>as<span> </span>something<span> </span>to<span> </span>be<span> </span>done<span> </span>to<span> </span>modify<span> </span>the</p><p>operators’ knowledge.</p><p>The<span> </span>descendants<span> </span>of<span> </span>knowledge-based<span> </sp",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "experiential, and abstracted memories influence the ease of processing, and the scope a design offers for their development,informs ease of learning and skill acquisition. The location of a particular form of buffered processing predicts subjective awareness of different aspects of the task, and of task complexity. Two notations supporting analysis are described. The close coupling of the analytic approach and the underlying theory enables a CTA in ICS to provide supportive evaluation, allowing ",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "experiential, and abstracted memories influence the ease of processing, and the scope a design offers for their development,informs ease of learning and skill acquisition. The location of a particular form of buffered processing predicts subjective awareness of different aspects of the task, and of task complexity. Two notations supporting analysis are described. The close coupling of the analytic approach and the underlying theory enables a CTA in ICS to provide supportive evaluation, allowing ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "experiential, and abstracted memories influence the ease of processing, and the scope a design offers for their development,informs ease of learning and skill acquisition. The location of a particular form of buffered processing predicts subjective awareness of different aspects of the task, and of task complexity. Two notations supporting analysis are described. The close coupling of the analytic approach and the underlying theory enables a CTA in ICS to provide supportive evaluation, allowing ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "experiential, and abstracted memories influence the ease of processing, and the scope a design offers for their development,informs ease of learning and skill acquisition. The location of a particular form of buffered processing predicts subjective awareness of different aspects of the task, and of task complexity. Two notations supporting analysis are described. The close coupling of the analytic approach and the underlying theory enables a CTA in ICS to provide supportive evaluation, allowing ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figures - uploaded byJon MayAuthor contentAll figure content in this area was uploaded by Jon May",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Author contentAll figure content in this area was uploaded by Jon May",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "All figure content in this area was uploaded by Jon May",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Discover the world's research25+ million members160+ million publication pages2.3+ billion citationsJoin for free",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "THE HANDBOOK OF TASK ANALYSISFOR HUMAN-COMPUTER INTERACTIONEdited byDan DiaperBournemouthUniversityNeville A. StantonBrunelUniversityLAWRENCE ERLBAUM ASSOCIATES, PUBLISHERS2004Mahwah, New JerseyLondon15Cognitive Task Analysisin Interacting CognitiveSubsystemsJon MayUniversityofShefﬁeldPhilip J. BarnardMRC-CBUCognitive taskanalysis (CTA) techniques seekto modelthe mentalactivityof atask operator.Withtheriseofcomputingartifacts,thefocusofCTAhaschangedfromsupportingthetutoringofoperators,tomodeling",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "THE HANDBOOK OF TASK ANALYSISFOR HUMAN-COMPUTER INTERACTIONEdited byDan DiaperBournemouthUniversityNeville A. StantonBrunelUniversityLAWRENCE ERLBAUM ASSOCIATES, PUBLISHERS2004Mahwah, New JerseyLondon15Cognitive Task Analysisin Interacting CognitiveSubsystemsJon MayUniversityofShefﬁeldPhilip J. BarnardMRC-CBUCognitive taskanalysis (CTA) techniques seekto modelthe mentalactivityof atask operator.Withtheriseofcomputingartifacts,thefocusofCTAhaschangedfromsupportingthetutoringofoperators,tomodeling",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "THE HANDBOOK OF TASK ANALYSISFOR HUMAN-COMPUTER INTERACTIONEdited byDan DiaperBournemouthUniversityNeville A. StantonBrunelUniversityLAWRENCE ERLBAUM ASSOCIATES, PUBLISHERS2004Mahwah, New JerseyLondon",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "15Cognitive Task Analysisin Interacting CognitiveSubsystemsJon MayUniversityofShefﬁeldPhilip J. BarnardMRC-CBUCognitive taskanalysis (CTA) techniques seekto modelthe mentalactivityof atask operator.Withtheriseofcomputingartifacts,thefocusofCTAhaschangedfromsupportingthetutoringofoperators,tomodelingknowledgeapplication,tomodelingcognitiveprocesses.Descendantsofknowledge-basedapproachesincludeGOMS,andproducequantitativetemporalbehavioralpredictionsforwelldeﬁnedinterfaces.Theincreasingpaceofdesign",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "292MAY AND BARNARDskilledtaskperformancelayinthepossessionandappropriateusebytheoperatoroftask-relevantknowledgeandsoughttodevelopmodelsoftherequiredknowledgetoimprove thetutoringofoperatorsandspeedtheprogressionofanindividualfromtasknovicetotaskexpert.Psychologicaltheoriesoflearningandknowledgestructuring,suchasNewell’sSOARarchitecture(Newell,1990),gave risetotherealization thatthetaskcould itselfbedesignedtofacilitateknowledgeacquisition,andsoCTAbegantobeseenasastageintaskdesign,modifyingtheta",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://ocastaengage.com/internal-comms-explained/what-is-a-knowledge-management-system-kms",
      "title": "What is a Knowledge Management System (KMS)? Internal Communications Explained | Ocasta Engage",
      "author": "15 Mar Written By Hayley Biggs",
      "published_date": "2024-05-10T10:47:02.000Z",
      "content": {
        "text": "<div><div>\n<p>A <a href=\"https://ocastaengage.com/knowledge\">Knowledge</a> Management System (KMS) is a technology-based system designed to facilitate the capturing, organizing, sharing, and analyzing of information within an organisation. This system enables employees to access collective knowledge, expertise, and experiences, making it easier to find solutions, learn from past projects, and collaborate more effectively.</p><h3><strong>Why is a Knowledge Management System relevant to internal comms?</strong></h3><p>A KMS is highly relevant to <a href=\"https://ocastaengage.com/internal-comms\">internal communications</a> as it serves as a central repository for organisational knowledge, including policies, procedures, best practices, and lessons learned. It supports effective communication by ensuring that all employees have access to the information they need to perform their roles efficiently, fostering a <a href=\"https://ocastaengage.com/blog/employee-training-plan-template-download-2021-ddsyp\">culture of learning and continuous improvement</a>.</p><h3><strong>Examples of a Knowledge Management System in internal comms</strong></h3><p>Examples include a centralised digital library where employees can access training materials, company policies, or industry research. Another example is a community forum within the KMS where employees can ask questions, share insights, and learn from each other's experiences, promoting a collaborative learning environment.</p><h3><strong>Best practices for a Knowledge Management System</strong></h3><p>Implementing a KMS effectively involves ensuring the system is user-friendly and accessible to all employees. Regular updates, clear categorisation of information, and encouraging a culture of knowledge sharing are also key. Additionally, integrating the KMS with other tools and systems used within the organisation can enhance its utility and adoption.</p><h3><strong>Common challenges for a Knowledge Management System</strong></h3><ul><li><p>Ensuring the quality and relevance of the information stored</p></li><li><p>Encouraging consistent use and contribution by all employees</p></li><li><p>Integrating the KMS with existing workflows and systems</p></li><li><p>Keeping the system up-to-date with the latest knowledge and information</p></li></ul><h3><strong>What does a Knowledge Management System mean for frontline teams?</strong></h3><p>For <a href=\"https://ocastaengage.com/internal-comms\">frontline teams</a>, a KMS can be particularly valuable for quickly accessing up-to-date information and solutions that enhance customer service and operational efficiency. It enables these teams to share frontline insights and feedback, which can be vital for organisational learning and improvement.</p><h3><strong>Knowledge Management System FAQs</strong></h3><p><strong>Q: How does a KMS differ from a simple document storage system?</strong><br/>A: Unlike basic document storage, a KMS offers advanced features for categorising, searching, and collaborating on knowledge, making it easier to find and utilise information.</p><p><strong>Q: Can a KMS support decision-making?</strong><br/>A: Yes, by providing easy access to relevant information and insights, a KMS can significantly support and improve decision-making processes within an organisation.</p><p><strong>Q: What role does employee engagement play in the success of a KMS?</strong><br/>A: Employee engagement is crucial; the more actively employees contribute to and use the system, the more valuable and effective it becomes as a repository of organisational knowledge.</p>\n</div></div>",
        "html": "<div><div>\n<p>A <a href=\"https://ocastaengage.com/knowledge\">Knowledge</a> Management System (KMS) is a technology-based system designed to facilitate the capturing, organizing, sharing, and analyzing of information within an organisation. This system enables employees to access collective knowledge, expertise, and experiences, making it easier to find solutions, learn from past projects, and collaborate more effectively.</p><h3><strong>Why is a Knowledge Management System relevant to internal comms?</strong></h3><p>A KMS is highly relevant to <a href=\"https://ocastaengage.com/internal-comms\">internal communications</a> as it serves as a central repository for organisational knowledge, including policies, procedures, best practices, and lessons learned. It supports effective communication by ensuring that all employees have access to the information they need to perform their roles efficiently, fostering a <a href=\"https://ocastaengage.com/blog/employee-training-plan-template-download-2021-ddsyp\">culture of learning and continuous improvement</a>.</p><h3><strong>Examples of a Knowledge Management System in internal comms</strong></h3><p>Examples include a centralised digital library where employees can access training materials, company policies, or industry research. Another example is a community forum within the KMS where employees can ask questions, share insights, and learn from each other's experiences, promoting a collaborative learning environment.</p><h3><strong>Best practices for a Knowledge Management System</strong></h3><p>Implementing a KMS effectively involves ensuring the system is user-friendly and accessible to all employees. Regular updates, clear categorisation of information, and encouraging a culture of knowledge sharing are also key. Additionally, integrating the KMS with other tools and systems used within the organisation can enhance its utility and adoption.</p><h3><strong>Common challenges for a Knowledge Management System</strong></h3><ul><li><p>Ensuring the quality and relevance of the information stored</p></li><li><p>Encouraging consistent use and contribution by all employees</p></li><li><p>Integrating the KMS with existing workflows and systems</p></li><li><p>Keeping the system up-to-date with the latest knowledge and information</p></li></ul><h3><strong>What does a Knowledge Management System mean for frontline teams?</strong></h3><p>For <a href=\"https://ocastaengage.com/internal-comms\">frontline teams</a>, a KMS can be particularly valuable for quickly accessing up-to-date information and solutions that enhance customer service and operational efficiency. It enables these teams to share frontline insights and feedback, which can be vital for organisational learning and improvement.</p><h3><strong>Knowledge Management System FAQs</strong></h3><p><strong>Q: How does a KMS differ from a simple document storage system?</strong><br/>A: Unlike basic document storage, a KMS offers advanced features for categorising, searching, and collaborating on knowledge, making it easier to find and utilise information.</p><p><strong>Q: Can a KMS support decision-making?</strong><br/>A: Yes, by providing easy access to relevant information and insights, a KMS can significantly support and improve decision-making processes within an organisation.</p><p><strong>Q: What role does employee engagement play in the success of a KMS?</strong><br/>A: Employee engagement is crucial; the more actively employees contribute to and use the system, the more valuable and effective it becomes as a repository of organisational knowledge.</p>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AKnowledgeManagement System (KMS) is a technology-based system designed to facilitate the capturing, organizing, sharing, and analyzing of information within an organisation. This system enables employees to access collective knowledge, expertise, and experiences, making it easier to find solutions, learn from past projects, and collaborate more effectively.Why is a Knowledge Management System relevant to internal comms?A KMS is highly relevant tointernal communicationsas it serves as a central ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AKnowledgeManagement System (KMS) is a technology-based system designed to facilitate the capturing, organizing, sharing, and analyzing of information within an organisation. This system enables employees to access collective knowledge, expertise, and experiences, making it easier to find solutions, learn from past projects, and collaborate more effectively.Why is a Knowledge Management System relevant to internal comms?A KMS is highly relevant tointernal communicationsas it serves as a central ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "Why is a Knowledge Management System relevant to internal comms?",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Examples of a Knowledge Management System in internal comms",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Best practices for a Knowledge Management System",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Common challenges for a Knowledge Management System",
              "id": ""
            },
            {
              "level": "h3",
              "text": "What does a Knowledge Management System mean for frontline teams?",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Knowledge Management System FAQs",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://pubmed.ncbi.nlm.nih.gov/35599568/",
      "title": "Emergence and algorithmic information dynamics of systems and observers - PubMed",
      "author": "Felipe S Abrahão 1 2 ,",
      "published_date": "2022-11-07T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<header>\n<div>\n<h2>\nEmergence and algorithmic information dynamics of systems and observers\n</h2>\n<p><span>\n<span><span>Felipe S Abrahão</span><span> et al.</span></span>\n</span>\n<span>\nPhilos Trans A Math Phys Eng Sci<span>.</span>\n</span>\n<span>\n<time>2022</time><span>.</span>\n</span>\n</p>\n</div>\n</header>\n<div>\n<h2>\nAbstract\n</h2>\n<p>\nOne of the challenges of defining emergence is that one observer's prior knowledge may cause a phenomenon to present itself as emergent that to another observer appears reducible. By formalizing the act of observing as mutual perturbations between dynamical systems, we demonstrate that the emergence of algorithmic information does depend on the observer's formal knowledge, while being robust vis-a-vis other subjective factors, particularly: the choice of programming language and method of measurement; errors or distortions during the observation; and the informational cost of processing. This is called observer-dependent emergence (ODE). In addition, we demonstrate that the unbounded and rapid increase of emergent algorithmic information implies asymptotically observer-independent emergence (AOIE). Unlike ODE, AOIE is a type of emergence for which emergent phenomena will be considered emergent no matter what formal theory an observer might bring to bear. We demonstrate the existence of an evolutionary model that displays the diachronic variant of AOIE and a network model that displays the holistic variant of AOIE. Our results show that, restricted to the context of finite discrete deterministic dynamical systems, computable systems and irreducible information content measures, AOIE is the strongest form of emergence that formal theories can attain. This article is part of the theme issue 'Emergent phenomena in complex physical and socio-technical systems: from cells to societies'.\n</p>\n<p>\n<strong>\nKeywords:\n</strong>\nalgorithmic information dynamics; dynamical systems; emergence; observers.\n</p>\n</div>\n<p>\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/disclaimer/\">PubMed Disclaimer</a>\n</p>\n<div>\n<h2>\nSimilar articles\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599559/\">\nFrom the origin of life to pandemics: emergent phenomena in complex systems.\n</a></p><p><span>Artime O, De Domenico M.</span>\n<span>Artime O, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599559</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599561/\">\nEmergence as the conversion of information: a unifying theory.\n</a></p><p><span>Varley TF, Hoel E.</span>\n<span>Varley TF, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210150. doi: 10.1098/rsta.2021.0150. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599561</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599558/\">\nGreater than the parts: a review of the information decomposition approach to causal emergence.\n</a></p><p><span>Mediano PAM, Rosas FE, Luppi AI, Jensen HJ, Seth AK, Barrett AB, Carhart-Harris RL, Bor D.</span>\n<span>Mediano PAM, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210246. doi: 10.1098/rsta.2021.0246. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599558</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/23912807/\">\nMacromolecular crowding: chemistry and physics meet biology (Ascona, Switzerland, 10-14 June 2012).\n</a></p><p><span>Foffi G, Pastore A, Piazza F, Temussi PA.</span>\n<span>Foffi G, et al.</span>\n<span>Phys Biol. 2013 Aug;10(4):040301. doi: 10.1088/1478-3975/10/4/040301. Epub 2013 Aug 2.</span>\n<span>Phys Biol. 2013.</span>\n<span>PMID: <span>23912807</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599566/\">\nThe simple emergence of complex molecular function.\n</a></p><p><span>Manrubia S.</span>\n<span>Manrubia S.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200422. doi: 10.1098/rsta.2020.0422. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599566</span></span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nCited by\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/39112510/\">\nOn the salient limitations of the methods of assembly theory and their classification of molecular biosignatures.\n</a></p><p><span>Uthamacumaran A, Abrahão FS, Kiani NA, Zenil H.</span>\n<span>Uthamacumaran A, et al.</span>\n<span>NPJ Syst Biol Appl. 2024 Aug 7;10(1):82. doi: 10.1038/s41540-024-00403-y.</span>\n<span>NPJ Syst Biol Appl. 2024.</span>\n<span>PMID: <span>39112510</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/36673195/\">\nFlickering Emergences: The Question of Locality in Information-Theoretic Approaches to Emergence.\n</a></p><p><span>Varley TF.</span>\n<span>Varley TF.</span>\n<span>Entropy (Basel). 2022 Dec 28;25(1):54. doi: 10.3390/e25010054.</span>\n<span>Entropy (Basel). 2022.</span>\n<span>PMID: <span>36673195</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599559/\">\nFrom the origin of life to pandemics: emergent phenomena in complex systems.\n</a></p><p><span>Artime O, De Domenico M.</span>\n<span>Artime O, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599559</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/36832676/\">\nDiscussion on the Relationship between Computation, Information, Cognition, and Their Embodiment.\n</a></p><p><span>Dodig-Crnkovic G, Miłkowski M.</span>\n<span>Dodig-Crnkovic G, et al.</span>\n<span>Entropy (Basel). 2023 Feb 8;25(2):310. doi: 10.3390/e25020310.</span>\n<span>Entropy (Basel). 2023.</span>\n<span>PMID: <span>36832676</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nReferences\n</h2>\n<div>\n<ol>\n<li>\n<ol>\n<li>\nAbrahão FS, Zenil H. 2022. Emergence and algorithmic information dynamics of systems and observers. Figshare. (10.6084/m9.figshare.c.5901204)\n-\n<a href=\"https://doi.org/10.6084/m9.figshare.c.5901204\">\nDOI\n</a>\n-\n<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9125223/\">\nPMC\n</a>\n-\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/35599568/\">\nPubMed\n</a>\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nAbrahão FS, Wehmuth K, Ziviani A. 2019. Algorithmic networks: central time to trigger expected emergent open-endedness. Theor. Comput. Sci. 785, 83-116. (10.1016/j.tcs.2019.03.008)\n-\n<a href=\"https://doi.org/10.1016/j.tcs.2019.03.008\">\nDOI\n</a>\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nAdams A, Zenil H, Davies PCW, Walker SI. 2017. Formal definitions of unbounded evolution and innovation reveal universal mechanisms for open-ended evolution in dynamical systems. Sci. Rep. 7, 997. (10.1038/s41598-017-00810-8)\n-\n<a href=\"https://doi.org/10.1038/s41598-017-00810-8\">\nDOI\n</a>\n-\n<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5430523/\">\nPMC\n</a>\n-\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/28428620/\">\nPubMed\n</a>\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nBedau MA. 1997. Weak emergence. Philos. Perspect. 11, 375-399.\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nHernández-Orozco S, Hernández-Quiroz F, Zenil H. 2018. Undecidability and irreducibility conditions for open-ended evolution and emergence. Artif. Life 24, 56-70. (10.1162/ARTL_a_00254)\n-\n<a href=\"https://doi.org/10.1162/artl_a_00254\">\nDOI\n</a>\n-\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/29369710/\">\nPubMed\n</a>\n</li>\n</ol>\n</li>\n</ol>\n</div>\n</div>\n<div>\n<h2>\nMeSH terms\n</h2>\n<ul><li></li><li></li></ul>\n</div>\n<div>\n<h2>\nLinkOut - more resources\n</h2>\n<ul><li><h3>Full Text Sources</h3><ul><li><a href=\"https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2020.0429?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub 0pubmed\">\nAtypon\n</a></li><li><a href=\"https://europepmc.org/abstract/MED/35599568\">\nEurope PubMed Central\n</a></li><li><a href=\"https://pmc.ncbi.nlm.nih.gov/articles/pmid/35599568/\">\nPubMed Central\n</a></li></ul></li></ul>\n</div>\n</main>\n</div></div>",
        "html": "<div><div>\n<main>\n<header>\n<div>\n<h2>\nEmergence and algorithmic information dynamics of systems and observers\n</h2>\n<p><span>\n<span><span>Felipe S Abrahão</span><span> et al.</span></span>\n</span>\n<span>\nPhilos Trans A Math Phys Eng Sci<span>.</span>\n</span>\n<span>\n<time>2022</time><span>.</span>\n</span>\n</p>\n</div>\n</header>\n<div>\n<h2>\nAbstract\n</h2>\n<p>\nOne of the challenges of defining emergence is that one observer's prior knowledge may cause a phenomenon to present itself as emergent that to another observer appears reducible. By formalizing the act of observing as mutual perturbations between dynamical systems, we demonstrate that the emergence of algorithmic information does depend on the observer's formal knowledge, while being robust vis-a-vis other subjective factors, particularly: the choice of programming language and method of measurement; errors or distortions during the observation; and the informational cost of processing. This is called observer-dependent emergence (ODE). In addition, we demonstrate that the unbounded and rapid increase of emergent algorithmic information implies asymptotically observer-independent emergence (AOIE). Unlike ODE, AOIE is a type of emergence for which emergent phenomena will be considered emergent no matter what formal theory an observer might bring to bear. We demonstrate the existence of an evolutionary model that displays the diachronic variant of AOIE and a network model that displays the holistic variant of AOIE. Our results show that, restricted to the context of finite discrete deterministic dynamical systems, computable systems and irreducible information content measures, AOIE is the strongest form of emergence that formal theories can attain. This article is part of the theme issue 'Emergent phenomena in complex physical and socio-technical systems: from cells to societies'.\n</p>\n<p>\n<strong>\nKeywords:\n</strong>\nalgorithmic information dynamics; dynamical systems; emergence; observers.\n</p>\n</div>\n<p>\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/disclaimer/\">PubMed Disclaimer</a>\n</p>\n<div>\n<h2>\nSimilar articles\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599559/\">\nFrom the origin of life to pandemics: emergent phenomena in complex systems.\n</a></p><p><span>Artime O, De Domenico M.</span>\n<span>Artime O, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599559</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599561/\">\nEmergence as the conversion of information: a unifying theory.\n</a></p><p><span>Varley TF, Hoel E.</span>\n<span>Varley TF, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210150. doi: 10.1098/rsta.2021.0150. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599561</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599558/\">\nGreater than the parts: a review of the information decomposition approach to causal emergence.\n</a></p><p><span>Mediano PAM, Rosas FE, Luppi AI, Jensen HJ, Seth AK, Barrett AB, Carhart-Harris RL, Bor D.</span>\n<span>Mediano PAM, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210246. doi: 10.1098/rsta.2021.0246. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599558</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/23912807/\">\nMacromolecular crowding: chemistry and physics meet biology (Ascona, Switzerland, 10-14 June 2012).\n</a></p><p><span>Foffi G, Pastore A, Piazza F, Temussi PA.</span>\n<span>Foffi G, et al.</span>\n<span>Phys Biol. 2013 Aug;10(4):040301. doi: 10.1088/1478-3975/10/4/040301. Epub 2013 Aug 2.</span>\n<span>Phys Biol. 2013.</span>\n<span>PMID: <span>23912807</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599566/\">\nThe simple emergence of complex molecular function.\n</a></p><p><span>Manrubia S.</span>\n<span>Manrubia S.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200422. doi: 10.1098/rsta.2020.0422. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599566</span></span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nCited by\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/39112510/\">\nOn the salient limitations of the methods of assembly theory and their classification of molecular biosignatures.\n</a></p><p><span>Uthamacumaran A, Abrahão FS, Kiani NA, Zenil H.</span>\n<span>Uthamacumaran A, et al.</span>\n<span>NPJ Syst Biol Appl. 2024 Aug 7;10(1):82. doi: 10.1038/s41540-024-00403-y.</span>\n<span>NPJ Syst Biol Appl. 2024.</span>\n<span>PMID: <span>39112510</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/36673195/\">\nFlickering Emergences: The Question of Locality in Information-Theoretic Approaches to Emergence.\n</a></p><p><span>Varley TF.</span>\n<span>Varley TF.</span>\n<span>Entropy (Basel). 2022 Dec 28;25(1):54. doi: 10.3390/e25010054.</span>\n<span>Entropy (Basel). 2022.</span>\n<span>PMID: <span>36673195</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35599559/\">\nFrom the origin of life to pandemics: emergent phenomena in complex systems.\n</a></p><p><span>Artime O, De Domenico M.</span>\n<span>Artime O, et al.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.</span>\n<span>Philos Trans A Math Phys Eng Sci. 2022.</span>\n<span>PMID: <span>35599559</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/36832676/\">\nDiscussion on the Relationship between Computation, Information, Cognition, and Their Embodiment.\n</a></p><p><span>Dodig-Crnkovic G, Miłkowski M.</span>\n<span>Dodig-Crnkovic G, et al.</span>\n<span>Entropy (Basel). 2023 Feb 8;25(2):310. doi: 10.3390/e25020310.</span>\n<span>Entropy (Basel). 2023.</span>\n<span>PMID: <span>36832676</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nReferences\n</h2>\n<div>\n<ol>\n<li>\n<ol>\n<li>\nAbrahão FS, Zenil H. 2022. Emergence and algorithmic information dynamics of systems and observers. Figshare. (10.6084/m9.figshare.c.5901204)\n-\n<a href=\"https://doi.org/10.6084/m9.figshare.c.5901204\">\nDOI\n</a>\n-\n<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9125223/\">\nPMC\n</a>\n-\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/35599568/\">\nPubMed\n</a>\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nAbrahão FS, Wehmuth K, Ziviani A. 2019. Algorithmic networks: central time to trigger expected emergent open-endedness. Theor. Comput. Sci. 785, 83-116. (10.1016/j.tcs.2019.03.008)\n-\n<a href=\"https://doi.org/10.1016/j.tcs.2019.03.008\">\nDOI\n</a>\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nAdams A, Zenil H, Davies PCW, Walker SI. 2017. Formal definitions of unbounded evolution and innovation reveal universal mechanisms for open-ended evolution in dynamical systems. Sci. Rep. 7, 997. (10.1038/s41598-017-00810-8)\n-\n<a href=\"https://doi.org/10.1038/s41598-017-00810-8\">\nDOI\n</a>\n-\n<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5430523/\">\nPMC\n</a>\n-\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/28428620/\">\nPubMed\n</a>\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nBedau MA. 1997. Weak emergence. Philos. Perspect. 11, 375-399.\n</li>\n</ol>\n</li>\n<li>\n<ol>\n<li>\nHernández-Orozco S, Hernández-Quiroz F, Zenil H. 2018. Undecidability and irreducibility conditions for open-ended evolution and emergence. Artif. Life 24, 56-70. (10.1162/ARTL_a_00254)\n-\n<a href=\"https://doi.org/10.1162/artl_a_00254\">\nDOI\n</a>\n-\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/29369710/\">\nPubMed\n</a>\n</li>\n</ol>\n</li>\n</ol>\n</div>\n</div>\n<div>\n<h2>\nMeSH terms\n</h2>\n<ul><li></li><li></li></ul>\n</div>\n<div>\n<h2>\nLinkOut - more resources\n</h2>\n<ul><li><h3>Full Text Sources</h3><ul><li><a href=\"https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2020.0429?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub 0pubmed\">\nAtypon\n</a></li><li><a href=\"https://europepmc.org/abstract/MED/35599568\">\nEurope PubMed Central\n</a></li><li><a href=\"https://pmc.ncbi.nlm.nih.gov/articles/pmid/35599568/\">\nPubMed Central\n</a></li></ul></li></ul>\n</div>\n</main>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Emergence and algorithmic information dynamics of systems and observersFelipe S Abrahãoet al.Philos Trans A Math Phys Eng Sci.2022.AbstractOne of the challenges of defining emergence is that one observer's prior knowledge may cause a phenomenon to present itself as emergent that to another observer appears reducible. By formalizing the act of observing as mutual perturbations between dynamical systems, we demonstrate that the emergence of algorithmic information does depend on the observer's for",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Emergence and algorithmic information dynamics of systems and observersFelipe S Abrahãoet al.Philos Trans A Math Phys Eng Sci.2022.AbstractOne of the challenges of defining emergence is that one observer's prior knowledge may cause a phenomenon to present itself as emergent that to another observer appears reducible. By formalizing the act of observing as mutual perturbations between dynamical systems, we demonstrate that the emergence of algorithmic information does depend on the observer's for",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Emergence and algorithmic information dynamics of systems and observersFelipe S Abrahãoet al.Philos Trans A Math Phys Eng Sci.2022.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractOne of the challenges of defining emergence is that one observer's prior knowledge may cause a phenomenon to present itself as emergent that to another observer appears reducible. By formalizing the act of observing as mutual perturbations between dynamical systems, we demonstrate that the emergence of algorithmic information does depend on the observer's formal knowledge, while being robust vis-a-vis other subjective factors, particularly: the choice of programming language and method o",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Similar articlesFrom the origin of life to pandemics: emergent phenomena in complex systems.Artime O, De Domenico M.Artime O, et al.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.Philos Trans A Math Phys Eng Sci. 2022.PMID:35599559Free PMC article.Emergence as the conversion of information: a unifying theory.Varley TF, Hoel E.Varley TF, et al.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210150. doi: 10.1098/rsta.2021.0",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "From the origin of life to pandemics: emergent phenomena in complex systems.Artime O, De Domenico M.Artime O, et al.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.Philos Trans A Math Phys Eng Sci. 2022.PMID:35599559Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Emergence as the conversion of information: a unifying theory.Varley TF, Hoel E.Varley TF, et al.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210150. doi: 10.1098/rsta.2021.0150. Epub 2022 May 23.Philos Trans A Math Phys Eng Sci. 2022.PMID:35599561Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Greater than the parts: a review of the information decomposition approach to causal emergence.Mediano PAM, Rosas FE, Luppi AI, Jensen HJ, Seth AK, Barrett AB, Carhart-Harris RL, Bor D.Mediano PAM, et al.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20210246. doi: 10.1098/rsta.2021.0246. Epub 2022 May 23.Philos Trans A Math Phys Eng Sci. 2022.PMID:35599558Free PMC article.Review.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Macromolecular crowding: chemistry and physics meet biology (Ascona, Switzerland, 10-14 June 2012).Foffi G, Pastore A, Piazza F, Temussi PA.Foffi G, et al.Phys Biol. 2013 Aug;10(4):040301. doi: 10.1088/1478-3975/10/4/040301. Epub 2013 Aug 2.Phys Biol. 2013.PMID:23912807",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The simple emergence of complex molecular function.Manrubia S.Manrubia S.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200422. doi: 10.1098/rsta.2020.0422. Epub 2022 May 23.Philos Trans A Math Phys Eng Sci. 2022.PMID:35599566Review.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Cited byOn the salient limitations of the methods of assembly theory and their classification of molecular biosignatures.Uthamacumaran A, Abrahão FS, Kiani NA, Zenil H.Uthamacumaran A, et al.NPJ Syst Biol Appl. 2024 Aug 7;10(1):82. doi: 10.1038/s41540-024-00403-y.NPJ Syst Biol Appl. 2024.PMID:39112510Free PMC article.Review.Flickering Emergences: The Question of Locality in Information-Theoretic Approaches to Emergence.Varley TF.Varley TF.Entropy (Basel). 2022 Dec 28;25(1):54. doi: 10.3390/e2501",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "On the salient limitations of the methods of assembly theory and their classification of molecular biosignatures.Uthamacumaran A, Abrahão FS, Kiani NA, Zenil H.Uthamacumaran A, et al.NPJ Syst Biol Appl. 2024 Aug 7;10(1):82. doi: 10.1038/s41540-024-00403-y.NPJ Syst Biol Appl. 2024.PMID:39112510Free PMC article.Review.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Flickering Emergences: The Question of Locality in Information-Theoretic Approaches to Emergence.Varley TF.Varley TF.Entropy (Basel). 2022 Dec 28;25(1):54. doi: 10.3390/e25010054.Entropy (Basel). 2022.PMID:36673195Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "From the origin of life to pandemics: emergent phenomena in complex systems.Artime O, De Domenico M.Artime O, et al.Philos Trans A Math Phys Eng Sci. 2022 Jul 11;380(2227):20200410. doi: 10.1098/rsta.2020.0410. Epub 2022 May 23.Philos Trans A Math Phys Eng Sci. 2022.PMID:35599559Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Discussion on the Relationship between Computation, Information, Cognition, and Their Embodiment.Dodig-Crnkovic G, Miłkowski M.Dodig-Crnkovic G, et al.Entropy (Basel). 2023 Feb 8;25(2):310. doi: 10.3390/e25020310.Entropy (Basel). 2023.PMID:36832676Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "ReferencesAbrahão FS, Zenil H. 2022. Emergence and algorithmic information dynamics of systems and observers. Figshare. (10.6084/m9.figshare.c.5901204)\n-DOI-PMC-PubMedAbrahão FS, Wehmuth K, Ziviani A. 2019. Algorithmic networks: central time to trigger expected emergent open-endedness. Theor. Comput. Sci. 785, 83-116. (10.1016/j.tcs.2019.03.008)\n-DOIAdams A, Zenil H, Davies PCW, Walker SI. 2017. Formal definitions of unbounded evolution and innovation reveal universal mechanisms for open-ended e",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Abrahão FS, Zenil H. 2022. Emergence and algorithmic information dynamics of systems and observers. Figshare. (10.6084/m9.figshare.c.5901204)\n-DOI-PMC-PubMedAbrahão FS, Wehmuth K, Ziviani A. 2019. Algorithmic networks: central time to trigger expected emergent open-endedness. Theor. Comput. Sci. 785, 83-116. (10.1016/j.tcs.2019.03.008)\n-DOIAdams A, Zenil H, Davies PCW, Walker SI. 2017. Formal definitions of unbounded evolution and innovation reveal universal mechanisms for open-ended evolution i",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "MeSH terms",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "LinkOut - more resourcesFull Text SourcesAtyponEurope PubMed CentralPubMed Central",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Emergence and algorithmic information dynamics of systems and observers",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Similar articles",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Cited by",
              "id": ""
            },
            {
              "level": "h2",
              "text": "References",
              "id": ""
            },
            {
              "level": "h2",
              "text": "MeSH terms",
              "id": ""
            },
            {
              "level": "h2",
              "text": "LinkOut - more resources",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Full Text Sources",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC8645346/",
      "title": "Assessing the impact of knowledge communication and dissemination strategies targeted at health policy-makers and managers: an overview of systematic reviews",
      "author": "",
      "published_date": "2021-12-06T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<section><h3>Background</h3>\n<p>The use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.</p></section><section><h3>Methods</h3>\n<p>This overview of systematic reviews used systematic review methods and was conducted according to a predefined and published protocol. A comprehensive electronic search of 13 databases and a manual search in four websites were conducted. Both published and unpublished reviews in English, Spanish or Portuguese were included. A narrative synthesis was undertaken, and effectiveness statements were developed, informed by the evidence identified.</p></section><section><h3>Results</h3>\n<p>We included 27 systematic reviews. Three studies included only a communication strategy, while eight only included dissemination strategies, and the remaining 16 included both. None of the selected reviews provided “sufficient evidence” for any of the strategies, while four provided some evidence for three communication and four dissemination strategies. Regarding communication strategies, the use of tailored and targeted messages seemed to successfully lead to changes in the decision-making practices of the target audience. Regarding dissemination strategies, interventions that aimed at improving only the reach of evidence did not have an impact on its use in decisions, while interventions aimed at enhancing users’ ability to use and apply evidence had a positive effect on decision-making processes. Multifaceted dissemination strategies also demonstrated the potential for changing knowledge about evidence but not its implementation in decision-making.</p></section><section><h3>Conclusions</h3>\n<p>There is limited evidence regarding the effectiveness of interventions targeting health managers and policy-makers, as well as the mechanisms required for achieving impact. More studies are needed that are informed by theoretical frameworks or specific tools and using robust methods, standardized outcome measures and clear descriptions of the interventions. We found that passive communication increased access to evidence but had no effect on uptake. Some evidence indicated that the use of targeted messages, knowledge-brokering and user training was effective in promoting evidence use by managers and policy-makers.</p></section><section><h3>Supplementary Information</h3>\n<p>The online version contains supplementary material available at 10.1186/s12961-021-00780-4.</p></section><section><p><strong>Keywords:</strong> Knowledge translation, Evidence-informed policy-making/makers, Decision-making/makers, Manager</p></section></section><section><h2>Background</h2>\n<p>Knowledge translation (KT) seeks to address the challenges involved in the use of research evidence by different and diverse stakeholders, in order to close the gap between the evidence generated and the decisions made by these stakeholders (KT for action). In recent years, KT processes targeted at healthcare providers and patients have been addressed by a number of publications [<a href=\"#CR1\">1</a>–<a href=\"#CR3\">3</a>]. However, such processes targeted at managers or policy-makers have been less researched. Therefore, our overview was aimed at better understanding the impact of KT processes targeted at managers or policy decision-makers.</p>\n<p>Despite conceptual differences, the term “knowledge translation” has frequently been used interchangeably with the term “evidence-informed decision-making” [<a href=\"#CR4\">4</a>], as well as other terms such as “knowledge transfer”, “knowledge exchange”, “research utilization” and “implementation” [<a href=\"#CR5\">5</a>]. KT has also been conceptualized as a term to describe the range of strategies to address the barriers to evidence-informed decision-making [<a href=\"#CR6\">6</a>]. According to WHO, KT is defined as “the exchange, synthesis, and effective communication of reliable and relevant research results. The focus is on promoting interaction among the producers and users of research, removing the barriers to research use, and tailoring information to different target audiences so that effective interventions are used more widely” [<a href=\"#CR7\">7</a>].</p>\n<p>In this context, diffusion, dissemination and implementation have been described in research findings by identifying and overcoming barriers through specific multifaceted interventions (“make it happen”) [<a href=\"#CR8\">8</a>, <a href=\"#CR9\">9</a>] along a continuum of intensity for KT activities designed to promote the use of research evidence in decision-making processes [<a href=\"#CR8\">8</a>]. Diffusion or communication activities are those that are passive and largely unplanned, uncontrolled, and primarily horizontal or mediated by peers (“let it happen”).</p>\n<p>Dissemination focuses primarily on communicating research results by targeting and tailoring the findings and the message to a particular target audience (“helping it happen”). Finally, in this taxonomy, implementation involves systematic efforts to encourage the adoption of the research findings by identifying and overcoming barriers through specific multifaceted interventions (“make it happen”) [<a href=\"#CR8\">8</a>, <a href=\"#CR9\">9</a>].</p>\n<p>For the purposes of this review, we focused on communication and dissemination interventions/strategies/approaches (although these terms are used for different purposes in the literature, we will use them interchangeably to be inclusive) targeted towards policy-makers and health managers. As mentioned before, dissemination refers to identifying the appropriate audience and tailoring, targeting or framing the message to that audience. This could include different research products such as evidence-based guidelines, publications, research reports, pamphlets, videos and websites, disseminated through different interventions/strategies/approaches depending on the target group. Furthermore, conceptual frameworks underlying each intervention/strategy/approach and tools used in its implementation could be identified.</p>\n<section><h3>Review question</h3>\n<p>What is the effectiveness/impact of the different knowledge communication and dissemination interventions/strategies/approaches targeted to health policy-makers and managers?</p></section></section><section><h2>Methods</h2>\n<p>This overview of systematic reviews (SRs) adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement [<a href=\"#CR10\">10</a>]. An SR protocol was developed and registered in PROSPERO (CRD42021237214) prior to undertaking the searches.</p>\n<section><h3>Inclusion criteria for studies</h3>\n<p>Studies were selected based on the following inclusion criteria:</p>\n<section><h4>Types of studies</h4>\n<p>SRs including primary studies of any design providing information on the effectiveness of dissemination strategies were included. When no SRs were identified for a specific intervention/strategy, a focused search for primary studies in PubMed was conducted.</p>\n<p>As no relevant primary studies were located , SRs focused on a different audience (health professionals or recipients of care) were assessed as indirect evidence, which means this study remained focused on SRs only.</p></section><section><h4>Types of participants</h4>\n<p>Studies including only managers or policy-makers as the target audience or studies including a larger group (e.g. also healthcare providers and patients) but in which data for different target audiences was reported separately were included. Because the definitions of managers and policy-makers are not always precise, we used a broad definition including all types of decision-makers such as hospital directors or administrators, health administrators, department chiefs, health planners, and programme directors or managers.</p>\n<p>Intervention(s), exposure(s): The definitions of KT communication and dissemination strategies were adapted from the classification proposed by McCormack et al. [<a href=\"#CR11\">11</a>] and are described in greater detail in Additional file <a href=\"#MOESM4\">4</a>: Tables S2 and S3:</p>\n<ul>\n<li><p>Techniques to communicate evidence through (1) tailoring the message, (2) targeting the message, (3) using narratives, (4) framing the message and (5) using a multicomponent approach.</p></li>\n<li><p>Strategies for disseminating evidence to (1) increase the reach of the evidence, (2) increase people’s motivation to use and apply the evidence, (3) increase people’s ability to use and apply the evidence, and (4) use a multipronged approach with any of the dissemination strategies described above.</p></li>\n</ul>\n<p>The communication or dissemination support could be physical materials (i.e. pamphlets, flyers, board games, policy briefs), electronic (i.e. video, audio-drama), Internet-based (i.e. databases, information services, discussion lists, registries of preprocessed research evidence or online-tailored and targeted messaging, online training, range of epidemiological and demographic data to inform public health policy and programme decisions, etc.), interpersonal (workshops, knowledge brokers, dialogues), through media (radio, TV) or social media (Twitter, Facebook, YouTube, including blogs and forums, etc.), and others (i.e. visual arts, literary arts, performing arts and applied arts).</p>\n<p>The strategies could be defined as single or combined. The combined or multicomponent strategies refer to different combinations of single strategies—targeted messages + knowledge brokers; education + information service + free acce",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<section><h3>Background</h3>\n<p>The use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.</p></section><section><h3>Methods</h3>\n<p>This overview of systematic reviews used systematic review methods and was conducted according to a predefined and published protocol. A comprehensive electronic search of 13 databases and a manual search in four websites were conducted. Both published and unpublished reviews in English, Spanish or Portuguese were included. A narrative synthesis was undertaken, and effectiveness statements were developed, informed by the evidence identified.</p></section><section><h3>Results</h3>\n<p>We included 27 systematic reviews. Three studies included only a communication strategy, while eight only included dissemination strategies, and the remaining 16 included both. None of the selected reviews provided “sufficient evidence” for any of the strategies, while four provided some evidence for three communication and four dissemination strategies. Regarding communication strategies, the use of tailored and targeted messages seemed to successfully lead to changes in the decision-making practices of the target audience. Regarding dissemination strategies, interventions that aimed at improving only the reach of evidence did not have an impact on its use in decisions, while interventions aimed at enhancing users’ ability to use and apply evidence had a positive effect on decision-making processes. Multifaceted dissemination strategies also demonstrated the potential for changing knowledge about evidence but not its implementation in decision-making.</p></section><section><h3>Conclusions</h3>\n<p>There is limited evidence regarding the effectiveness of interventions targeting health managers and policy-makers, as well as the mechanisms required for achieving impact. More studies are needed that are informed by theoretical frameworks or specific tools and using robust methods, standardized outcome measures and clear descriptions of the interventions. We found that passive communication increased access to evidence but had no effect on uptake. Some evidence indicated that the use of targeted messages, knowledge-brokering and user training was effective in promoting evidence use by managers and policy-makers.</p></section><section><h3>Supplementary Information</h3>\n<p>The online version contains supplementary material available at 10.1186/s12961-021-00780-4.</p></section><section><p><strong>Keywords:</strong> Knowledge translation, Evidence-informed policy-making/makers, Decision-making/makers, Manager</p></section></section><section><h2>Background</h2>\n<p>Knowledge translation (KT) seeks to address the challenges involved in the use of research evidence by different and diverse stakeholders, in order to close the gap between the evidence generated and the decisions made by these stakeholders (KT for action). In recent years, KT processes targeted at healthcare providers and patients have been addressed by a number of publications [<a href=\"#CR1\">1</a>–<a href=\"#CR3\">3</a>]. However, such processes targeted at managers or policy-makers have been less researched. Therefore, our overview was aimed at better understanding the impact of KT processes targeted at managers or policy decision-makers.</p>\n<p>Despite conceptual differences, the term “knowledge translation” has frequently been used interchangeably with the term “evidence-informed decision-making” [<a href=\"#CR4\">4</a>], as well as other terms such as “knowledge transfer”, “knowledge exchange”, “research utilization” and “implementation” [<a href=\"#CR5\">5</a>]. KT has also been conceptualized as a term to describe the range of strategies to address the barriers to evidence-informed decision-making [<a href=\"#CR6\">6</a>]. According to WHO, KT is defined as “the exchange, synthesis, and effective communication of reliable and relevant research results. The focus is on promoting interaction among the producers and users of research, removing the barriers to research use, and tailoring information to different target audiences so that effective interventions are used more widely” [<a href=\"#CR7\">7</a>].</p>\n<p>In this context, diffusion, dissemination and implementation have been described in research findings by identifying and overcoming barriers through specific multifaceted interventions (“make it happen”) [<a href=\"#CR8\">8</a>, <a href=\"#CR9\">9</a>] along a continuum of intensity for KT activities designed to promote the use of research evidence in decision-making processes [<a href=\"#CR8\">8</a>]. Diffusion or communication activities are those that are passive and largely unplanned, uncontrolled, and primarily horizontal or mediated by peers (“let it happen”).</p>\n<p>Dissemination focuses primarily on communicating research results by targeting and tailoring the findings and the message to a particular target audience (“helping it happen”). Finally, in this taxonomy, implementation involves systematic efforts to encourage the adoption of the research findings by identifying and overcoming barriers through specific multifaceted interventions (“make it happen”) [<a href=\"#CR8\">8</a>, <a href=\"#CR9\">9</a>].</p>\n<p>For the purposes of this review, we focused on communication and dissemination interventions/strategies/approaches (although these terms are used for different purposes in the literature, we will use them interchangeably to be inclusive) targeted towards policy-makers and health managers. As mentioned before, dissemination refers to identifying the appropriate audience and tailoring, targeting or framing the message to that audience. This could include different research products such as evidence-based guidelines, publications, research reports, pamphlets, videos and websites, disseminated through different interventions/strategies/approaches depending on the target group. Furthermore, conceptual frameworks underlying each intervention/strategy/approach and tools used in its implementation could be identified.</p>\n<section><h3>Review question</h3>\n<p>What is the effectiveness/impact of the different knowledge communication and dissemination interventions/strategies/approaches targeted to health policy-makers and managers?</p></section></section><section><h2>Methods</h2>\n<p>This overview of systematic reviews (SRs) adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement [<a href=\"#CR10\">10</a>]. An SR protocol was developed and registered in PROSPERO (CRD42021237214) prior to undertaking the searches.</p>\n<section><h3>Inclusion criteria for studies</h3>\n<p>Studies were selected based on the following inclusion criteria:</p>\n<section><h4>Types of studies</h4>\n<p>SRs including primary studies of any design providing information on the effectiveness of dissemination strategies were included. When no SRs were identified for a specific intervention/strategy, a focused search for primary studies in PubMed was conducted.</p>\n<p>As no relevant primary studies were located , SRs focused on a different audience (health professionals or recipients of care) were assessed as indirect evidence, which means this study remained focused on SRs only.</p></section><section><h4>Types of participants</h4>\n<p>Studies including only managers or policy-makers as the target audience or studies including a larger group (e.g. also healthcare providers and patients) but in which data for different target audiences was reported separately were included. Because the definitions of managers and policy-makers are not always precise, we used a broad definition including all types of decision-makers such as hospital directors or administrators, health administrators, department chiefs, health planners, and programme directors or managers.</p>\n<p>Intervention(s), exposure(s): The definitions of KT communication and dissemination strategies were adapted from the classification proposed by McCormack et al. [<a href=\"#CR11\">11</a>] and are described in greater detail in Additional file <a href=\"#MOESM4\">4</a>: Tables S2 and S3:</p>\n<ul>\n<li><p>Techniques to communicate evidence through (1) tailoring the message, (2) targeting the message, (3) using narratives, (4) framing the message and (5) using a multicomponent approach.</p></li>\n<li><p>Strategies for disseminating evidence to (1) increase the reach of the evidence, (2) increase people’s motivation to use and apply the evidence, (3) increase people’s ability to use and apply the evidence, and (4) use a multipronged approach with any of the dissemination strategies described above.</p></li>\n</ul>\n<p>The communication or dissemination support could be physical materials (i.e. pamphlets, flyers, board games, policy briefs), electronic (i.e. video, audio-drama), Internet-based (i.e. databases, information services, discussion lists, registries of preprocessed research evidence or online-tailored and targeted messaging, online training, range of epidemiological and demographic data to inform public health policy and programme decisions, etc.), interpersonal (workshops, knowledge brokers, dialogues), through media (radio, TV) or social media (Twitter, Facebook, YouTube, including blogs and forums, etc.), and others (i.e. visual arts, literary arts, performing arts and applied arts).</p>\n<p>The strategies could be defined as single or combined. The combined or multicomponent strategies refer to different combinations of single strategies—targeted messages + knowledge brokers; education + information service + free acce",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractBackgroundThe use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.MethodsThis overview of syste",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractBackgroundThe use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.MethodsThis overview of syste",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractBackgroundThe use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.MethodsThis overview of syste",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractBackgroundThe use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.MethodsThis overview of syste",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractBackgroundThe use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.MethodsThis overview of syste",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "BackgroundThe use of research evidence as an input for health decision-making is a need for most health systems. There are a number of approaches for promoting evidence use at different levels of the health system, but knowledge of their effectiveness is still scarce. The objective of this overview was to evaluate the effectiveness of knowledge communication and dissemination interventions, strategies or approaches targeting policy-makers and health managers.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "MethodsThis overview of systematic reviews used systematic review methods and was conducted according to a predefined and published protocol. A comprehensive electronic search of 13 databases and a manual search in four websites were conducted. Both published and unpublished reviews in English, Spanish or Portuguese were included. A narrative synthesis was undertaken, and effectiveness statements were developed, informed by the evidence identified.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "ResultsWe included 27 systematic reviews. Three studies included only a communication strategy, while eight only included dissemination strategies, and the remaining 16 included both. None of the selected reviews provided “sufficient evidence” for any of the strategies, while four provided some evidence for three communication and four dissemination strategies. Regarding communication strategies, the use of tailored and targeted messages seemed to successfully lead to changes in the decision-mak",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "ConclusionsThere is limited evidence regarding the effectiveness of interventions targeting health managers and policy-makers, as well as the mechanisms required for achieving impact. More studies are needed that are informed by theoretical frameworks or specific tools and using robust methods, standardized outcome measures and clear descriptions of the interventions. We found that passive communication increased access to evidence but had no effect on uptake. Some evidence indicated that the us",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Supplementary InformationThe online version contains supplementary material available at 10.1186/s12961-021-00780-4.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:Knowledge translation, Evidence-informed policy-making/makers, Decision-making/makers, Manager",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "BackgroundKnowledge translation (KT) seeks to address the challenges involved in the use of research evidence by different and diverse stakeholders, in order to close the gap between the evidence generated and the decisions made by these stakeholders (KT for action). In recent years, KT processes targeted at healthcare providers and patients have been addressed by a number of publications [1–3]. However, such processes targeted at managers or policy-makers have been less researched. Therefore, o",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Review questionWhat is the effectiveness/impact of the different knowledge communication and dissemination interventions/strategies/approaches targeted to health policy-makers and managers?",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "MethodsThis overview of systematic reviews (SRs) adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement [10]. An SR protocol was developed and registered in PROSPERO (CRD42021237214) prior to undertaking the searches.Inclusion criteria for studiesStudies were selected based on the following inclusion criteria:Types of studiesSRs including primary studies of any design providing information on the effectiveness of dissemination strategies were include",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Inclusion criteria for studiesStudies were selected based on the following inclusion criteria:Types of studiesSRs including primary studies of any design providing information on the effectiveness of dissemination strategies were included. When no SRs were identified for a specific intervention/strategy, a focused search for primary studies in PubMed was conducted.As no relevant primary studies were located , SRs focused on a different audience (health professionals or recipients of care) were a",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Types of studiesSRs including primary studies of any design providing information on the effectiveness of dissemination strategies were included. When no SRs were identified for a specific intervention/strategy, a focused search for primary studies in PubMed was conducted.As no relevant primary studies were located , SRs focused on a different audience (health professionals or recipients of care) were assessed as indirect evidence, which means this study remained focused on SRs only.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Types of participantsStudies including only managers or policy-makers as the target audience or studies including a larger group (e.g. also healthcare providers and patients) but in which data for different target audiences was reported separately were included. Because the definitions of managers and policy-makers are not always precise, we used a broad definition including all types of decision-makers such as hospital directors or administrators, health administrators, department chiefs, healt",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Background",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Methods",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Results",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Conclusions",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Supplementary Information",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Background",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Review question",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Methods",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Inclusion criteria for studies",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Types of studies",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Types of participants",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.kmworld.com/Articles/White-Paper/Article/Contextual-KnowledgeYour-Key-to-Building-Effective-Knowledge-Tools-131222.aspx",
      "title": "Contextual Knowledge: Your Key to Building Effective Knowledge Tools",
      "author": "",
      "published_date": "2019-04-19T04:00:00.000Z",
      "content": {
        "text": "<div><div>\n<div>\n<p>\n</p>\n<ul>\n<li>\nApril 19, 2019</li>\n<li>By\n<a href=\"https://www.kmworld.com/Authors/7247-John-Chmaj.htm\">John Chmaj</a> Senior Practice Director of Knowledge Management, Verint Global Consulting Services\n</li>\n<li>\n<a href=\"https://www.kmworld.com/Articles/MoreNews.aspx?ContextSubtypeID=89\">Article</a>\n</li>\n</ul>\n</div>\n<div>\n<p>Knowledge has been defined as “information provided in the context of a specific need.” As such, context is the driving force behind targeted, personalized answers that make knowledge delivery systems efficient and accurate.</p><p>Increasingly, knowledge users expect the context of who they are, what they are doing, and what they need to drive the information and actions presented to them. “Contextual knowledge” is critical for delivering KM value by facilitating faster, better answers and information, dynamically presented in the context of the user’s work. Let’s take a look at how contextual knowledge can turbocharge customer support and the overall customer experience.</p><p><strong><span>Defining Context</span></strong></p><p>In the realm of knowledge management, “context” refers to the properties of both the requestor and the information requested that frame and scope the knowledge need. Context can be any information property, fielded information, or text that can contribute in a meaningful, predictable way to help assess information requests. Context can include a variety of criteria:</p>\n<p>♦ Identity: Who is asking?</p><p>♦ Issue: What they are asking about?</p><p>♦ Actions: What they are doing?</p><p>♦ Location: Where are they situated?</p><p>♦ Application: How they are interacting?</p><p>♦ Information Type: What types of information would serve them best?</p><p><span><strong>Enabling Context</strong></span></p><p>Context can help drive the best knowledge forward in several ways. Depending on the tools and working environment, context can arise from and be processed through:</p><p>♦ Customer account systems</p><p>♦ Actions and locations in digital workspaces (web, chat, email, intelligent virtual assistants, and social channels)</p><p>♦ IVRs or call management tools (including real-time speech analytics)</p><p>♦ Agent desktop metadata, forms, and workflow states</p><p>Context gathered from these environments can be linked to appropriate knowledge through metadata scoping, search string generation, direct content identification, natural language processing, and/or machine learning.</p><p>The output of context can influence what is delivered in different ways, depending on the capabilities of the KM system:</p><p>♦ Specific objects can be returned that directly match the context of the request.</p><p>♦ Groups of information that match the context can be presented in a results list.</p><p>♦ Some objects can be promoted or preferred in relation to others in a knowledge list.</p><p>♦ Activities can be triggered based on context, such as fetching additional context from other tools, initiating specific functions in a knowledge tool, or presenting requests for additional information to further refine the knowledge request.</p><p>Depending on the audience for the content, these enabling methods and their results can be broadly or narrowly focused. The key to enabling context effectively is to have a clear understanding of how each element of context can best scope information in the tools and knowledge base in play.</p>\n<div>\n<p>\n</p>\n</div>\n</div>\n</div></div>",
        "html": "<div><div>\n<div>\n<p>\n</p>\n<ul>\n<li>\nApril 19, 2019</li>\n<li>By\n<a href=\"https://www.kmworld.com/Authors/7247-John-Chmaj.htm\">John Chmaj</a> Senior Practice Director of Knowledge Management, Verint Global Consulting Services\n</li>\n<li>\n<a href=\"https://www.kmworld.com/Articles/MoreNews.aspx?ContextSubtypeID=89\">Article</a>\n</li>\n</ul>\n</div>\n<div>\n<p>Knowledge has been defined as “information provided in the context of a specific need.” As such, context is the driving force behind targeted, personalized answers that make knowledge delivery systems efficient and accurate.</p><p>Increasingly, knowledge users expect the context of who they are, what they are doing, and what they need to drive the information and actions presented to them. “Contextual knowledge” is critical for delivering KM value by facilitating faster, better answers and information, dynamically presented in the context of the user’s work. Let’s take a look at how contextual knowledge can turbocharge customer support and the overall customer experience.</p><p><strong><span>Defining Context</span></strong></p><p>In the realm of knowledge management, “context” refers to the properties of both the requestor and the information requested that frame and scope the knowledge need. Context can be any information property, fielded information, or text that can contribute in a meaningful, predictable way to help assess information requests. Context can include a variety of criteria:</p>\n<p>♦ Identity: Who is asking?</p><p>♦ Issue: What they are asking about?</p><p>♦ Actions: What they are doing?</p><p>♦ Location: Where are they situated?</p><p>♦ Application: How they are interacting?</p><p>♦ Information Type: What types of information would serve them best?</p><p><span><strong>Enabling Context</strong></span></p><p>Context can help drive the best knowledge forward in several ways. Depending on the tools and working environment, context can arise from and be processed through:</p><p>♦ Customer account systems</p><p>♦ Actions and locations in digital workspaces (web, chat, email, intelligent virtual assistants, and social channels)</p><p>♦ IVRs or call management tools (including real-time speech analytics)</p><p>♦ Agent desktop metadata, forms, and workflow states</p><p>Context gathered from these environments can be linked to appropriate knowledge through metadata scoping, search string generation, direct content identification, natural language processing, and/or machine learning.</p><p>The output of context can influence what is delivered in different ways, depending on the capabilities of the KM system:</p><p>♦ Specific objects can be returned that directly match the context of the request.</p><p>♦ Groups of information that match the context can be presented in a results list.</p><p>♦ Some objects can be promoted or preferred in relation to others in a knowledge list.</p><p>♦ Activities can be triggered based on context, such as fetching additional context from other tools, initiating specific functions in a knowledge tool, or presenting requests for additional information to further refine the knowledge request.</p><p>Depending on the audience for the content, these enabling methods and their results can be broadly or narrowly focused. The key to enabling context effectively is to have a clear understanding of how each element of context can best scope information in the tools and knowledge base in play.</p>\n<div>\n<p>\n</p>\n</div>\n</div>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "April 19, 2019ByJohn ChmajSenior Practice Director of Knowledge Management, Verint Global Consulting ServicesArticleKnowledge has been defined as “information provided in the context of a specific need.” As such, context is the driving force behind targeted, personalized answers that make knowledge delivery systems efficient and accurate.Increasingly, knowledge users expect the context of who they are, what they are doing, and what they need to drive the information and actions presented to them",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "April 19, 2019ByJohn ChmajSenior Practice Director of Knowledge Management, Verint Global Consulting ServicesArticleKnowledge has been defined as “information provided in the context of a specific need.” As such, context is the driving force behind targeted, personalized answers that make knowledge delivery systems efficient and accurate.Increasingly, knowledge users expect the context of who they are, what they are doing, and what they need to drive the information and actions presented to them",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "April 19, 2019ByJohn ChmajSenior Practice Director of Knowledge Management, Verint Global Consulting ServicesArticle",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Knowledge has been defined as “information provided in the context of a specific need.” As such, context is the driving force behind targeted, personalized answers that make knowledge delivery systems efficient and accurate.Increasingly, knowledge users expect the context of who they are, what they are doing, and what they need to drive the information and actions presented to them. “Contextual knowledge” is critical for delivering KM value by facilitating faster, better answers and information,",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://investigationsquality.com/2022/01/30/the-epistemic-interactions-of-knowledge-management/",
      "title": "The Epistemic Interactions of Knowledge Management",
      "author": "Jeremiah Genest",
      "published_date": "2022-01-30T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article>\n<div>\n<figure></figure>\n<p>The first four phases of knowledge management are all about identifying and creating meaning and then making that meaning usable. Knowledge management is a set of epistemic actions, creating knowledge through interaction. This interaction is a way of creating a partnership between what happens in the head with everything in the world – <a href=\"https://investigationsquality.com/2021/03/25/quality-as-imagined-versus-quality-as-done/\">Work-as-Imagined</a> and <a href=\"https://investigationsquality.com/tag/work-as-done/\">Work-as-Done</a>. </p>\n<figure></figure>\n<p>There are really four themes to a set of epistemic actions: </p>\n<ul><li><strong>Foraging</strong>: Locating resources that will lead to understanding</li><li><strong>Tuning</strong>: Adjusting resources to align with desired understanding</li><li><strong>Externalizing</strong>: Moving resources out of the head and into the world</li><li><strong>Constructing</strong>: Forming new knowledge structures in the world</li></ul>\n<p>These epistemic actions are al<a href=\"https://investigationsquality.com/2022/01/29/the-building-blocks-of-work-as-prescribed/\">l about moving from Work-as-Imagined through Work-as-Prescribed </a>to enable <a href=\"https://investigationsquality.com/tag/work-as-done/\">Work-as-Done</a>.</p>\n<p><a href=\"https://investigationsquality.com/2021/04/03/knowledge-transfer/\">Knowledge Management</a> is really about the embodiment of <a href=\"https://investigationsquality.com/2021/04/18/information-gaps/\">information</a>, <a href=\"https://investigationsquality.com/2019/04/03/knowledge-management-effective-change-management/\">knowledge, </a>and even <a href=\"https://investigationsquality.com/2020/01/21/building-experts/\">wisdom </a>through these epistemic actions to apply <a href=\"https://investigationsquality.com/2021/05/06/change-strategies-for-accelerating-changes/\">change </a>upon the world. </p>\n<figure><figcaption>Four Themes Mapped to Firts 4 Phases of Knowledge Management</figcaption></figure>\n<div>\n<table>\n<tbody><tr>\n<td>\n<p><b><span>Theme</span></b></p>\n</td>\n<td>\n<p><b><span>Epistemic Interaction</span></b></p>\n</td>\n<td>\n<p><b><span>Means</span></b></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Foraging</span></p>\n<p><b><span>Locating resources that will lead to understanding</span></b></p>\n</td>\n<td>\n<p><span>Searching</span></p>\n</td>\n<td>\n<p><span>Searching happens when you need information and\nbelieve it exists somewhere. </span></p>\n<p><span>Searching depends on how we articulate or\ninformation needs.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Probing</span></p>\n</td>\n<td>\n<p><span>“Tell me more.” Probing happens when the information\nyou have isn’t quite enough. You are probing when you take the next step,\nmove to the next level, and obtain more salient specifics. Probing is about\ndrilling down and saying “show, explain, and reveal more about this.”</span></p>\n<p><span>We can probe to reveal new patterns, structures and\nrelationships. It brings to light new information that helps us to reconsider\nwhat we already know.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Animating</span></p>\n</td>\n<td>\n<p><span>Animating is when we initiate and control motion in\nan information source. It includes learning-by-doing.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Collecting</span></p>\n</td>\n<td>\n<p><span>Collecting is how we gather foraged information and\ntuck it away for future use. </span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Tuning</span></p>\n<p><b><span>Adjusting resources to align with desired\nunderstanding</span></b></p>\n</td>\n<td>\n<p><span>Collecting</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Cloning</span></p>\n</td>\n<td>\n<p><span>Cloning lets us take information from one situation\nand use it in another.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Cutting</span></p>\n</td>\n<td>\n<p><span>Cutting is the way we say “this matters”, that “I\nneed this part, but not the rest.”</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Filtering</span></p>\n</td>\n<td>\n<p><span>Filtering reduces complexity by reducing clutter to\nexpose salient details.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Externalizing </span></p>\n<p><b><span>Moving resources out of the head and into the world</span></b></p>\n</td>\n<td>\n<p><span>Annotating</span></p>\n</td>\n<td>\n<p><span>Annotating is how we add context to information. How\nwe adapt and modify the information to the needed context.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Linking</span></p>\n</td>\n<td>\n<p><span>Connecting bits of information together. Forming\nconceptual maps.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Generating</span></p>\n</td>\n<td>\n<p><span>Introducing new knowledge into the world.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Chunking</span></p>\n</td>\n<td>\n<p><span>Grouping idenpendent yet related information together.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Constructing</span></p>\n<p><b><span>Forming new knowledge structures in the world</span></b></p>\n</td>\n<td>\n<p><span>Chunking</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Composing</span></p>\n</td>\n<td>\n<p><span>Producing a new, separate structure from the\ninformation that has its own meaning and purpose.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Fragmenting</span></p>\n</td>\n<td>\n<p><span>Taking information and breaking it apart into usable\ncomponents.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Rearranging</span></p>\n</td>\n<td>\n<p><span>The art of creating meaningful order.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Repicturing</span></p>\n</td>\n<td>\n<p><span>Changing the way the information is represented to\ncreate understanding.</span></p>\n</td>\n</tr>\n</tbody></table>\n</div>\n</div>\n<div>\n<div>\n<p>\t</p>\n<p>\n</p><h2>\nPublished by <span>Jeremiah Genest</span>\t</h2>\n<p></p>\n<p>\nQuality professional with over 20 years of experience. Gamer and storyteller with forty years of practice.\t<a href=\"https://investigationsquality.com/author/jeregenest/\">\nView all posts by Jeremiah Genest\t</a>\n</p>\n</div>\n<p><strong>Published</strong>\n<time>January 30, 2022</time><time>January 30, 2022</time>\t</p>\n</div>\n</article>\n<nav>\n<h2>Post navigation</h2>\n</nav>\n</main>\n</div></div>",
        "html": "<div><div>\n<main>\n<article>\n<div>\n<figure></figure>\n<p>The first four phases of knowledge management are all about identifying and creating meaning and then making that meaning usable. Knowledge management is a set of epistemic actions, creating knowledge through interaction. This interaction is a way of creating a partnership between what happens in the head with everything in the world – <a href=\"https://investigationsquality.com/2021/03/25/quality-as-imagined-versus-quality-as-done/\">Work-as-Imagined</a> and <a href=\"https://investigationsquality.com/tag/work-as-done/\">Work-as-Done</a>. </p>\n<figure></figure>\n<p>There are really four themes to a set of epistemic actions: </p>\n<ul><li><strong>Foraging</strong>: Locating resources that will lead to understanding</li><li><strong>Tuning</strong>: Adjusting resources to align with desired understanding</li><li><strong>Externalizing</strong>: Moving resources out of the head and into the world</li><li><strong>Constructing</strong>: Forming new knowledge structures in the world</li></ul>\n<p>These epistemic actions are al<a href=\"https://investigationsquality.com/2022/01/29/the-building-blocks-of-work-as-prescribed/\">l about moving from Work-as-Imagined through Work-as-Prescribed </a>to enable <a href=\"https://investigationsquality.com/tag/work-as-done/\">Work-as-Done</a>.</p>\n<p><a href=\"https://investigationsquality.com/2021/04/03/knowledge-transfer/\">Knowledge Management</a> is really about the embodiment of <a href=\"https://investigationsquality.com/2021/04/18/information-gaps/\">information</a>, <a href=\"https://investigationsquality.com/2019/04/03/knowledge-management-effective-change-management/\">knowledge, </a>and even <a href=\"https://investigationsquality.com/2020/01/21/building-experts/\">wisdom </a>through these epistemic actions to apply <a href=\"https://investigationsquality.com/2021/05/06/change-strategies-for-accelerating-changes/\">change </a>upon the world. </p>\n<figure><figcaption>Four Themes Mapped to Firts 4 Phases of Knowledge Management</figcaption></figure>\n<div>\n<table>\n<tbody><tr>\n<td>\n<p><b><span>Theme</span></b></p>\n</td>\n<td>\n<p><b><span>Epistemic Interaction</span></b></p>\n</td>\n<td>\n<p><b><span>Means</span></b></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Foraging</span></p>\n<p><b><span>Locating resources that will lead to understanding</span></b></p>\n</td>\n<td>\n<p><span>Searching</span></p>\n</td>\n<td>\n<p><span>Searching happens when you need information and\nbelieve it exists somewhere. </span></p>\n<p><span>Searching depends on how we articulate or\ninformation needs.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Probing</span></p>\n</td>\n<td>\n<p><span>“Tell me more.” Probing happens when the information\nyou have isn’t quite enough. You are probing when you take the next step,\nmove to the next level, and obtain more salient specifics. Probing is about\ndrilling down and saying “show, explain, and reveal more about this.”</span></p>\n<p><span>We can probe to reveal new patterns, structures and\nrelationships. It brings to light new information that helps us to reconsider\nwhat we already know.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Animating</span></p>\n</td>\n<td>\n<p><span>Animating is when we initiate and control motion in\nan information source. It includes learning-by-doing.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Collecting</span></p>\n</td>\n<td>\n<p><span>Collecting is how we gather foraged information and\ntuck it away for future use. </span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Tuning</span></p>\n<p><b><span>Adjusting resources to align with desired\nunderstanding</span></b></p>\n</td>\n<td>\n<p><span>Collecting</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Cloning</span></p>\n</td>\n<td>\n<p><span>Cloning lets us take information from one situation\nand use it in another.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Cutting</span></p>\n</td>\n<td>\n<p><span>Cutting is the way we say “this matters”, that “I\nneed this part, but not the rest.”</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Filtering</span></p>\n</td>\n<td>\n<p><span>Filtering reduces complexity by reducing clutter to\nexpose salient details.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Externalizing </span></p>\n<p><b><span>Moving resources out of the head and into the world</span></b></p>\n</td>\n<td>\n<p><span>Annotating</span></p>\n</td>\n<td>\n<p><span>Annotating is how we add context to information. How\nwe adapt and modify the information to the needed context.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Linking</span></p>\n</td>\n<td>\n<p><span>Connecting bits of information together. Forming\nconceptual maps.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Generating</span></p>\n</td>\n<td>\n<p><span>Introducing new knowledge into the world.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Chunking</span></p>\n</td>\n<td>\n<p><span>Grouping idenpendent yet related information together.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Constructing</span></p>\n<p><b><span>Forming new knowledge structures in the world</span></b></p>\n</td>\n<td>\n<p><span>Chunking</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Composing</span></p>\n</td>\n<td>\n<p><span>Producing a new, separate structure from the\ninformation that has its own meaning and purpose.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Fragmenting</span></p>\n</td>\n<td>\n<p><span>Taking information and breaking it apart into usable\ncomponents.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Rearranging</span></p>\n</td>\n<td>\n<p><span>The art of creating meaningful order.</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Repicturing</span></p>\n</td>\n<td>\n<p><span>Changing the way the information is represented to\ncreate understanding.</span></p>\n</td>\n</tr>\n</tbody></table>\n</div>\n</div>\n<div>\n<div>\n<p>\t</p>\n<p>\n</p><h2>\nPublished by <span>Jeremiah Genest</span>\t</h2>\n<p></p>\n<p>\nQuality professional with over 20 years of experience. Gamer and storyteller with forty years of practice.\t<a href=\"https://investigationsquality.com/author/jeregenest/\">\nView all posts by Jeremiah Genest\t</a>\n</p>\n</div>\n<p><strong>Published</strong>\n<time>January 30, 2022</time><time>January 30, 2022</time>\t</p>\n</div>\n</article>\n<nav>\n<h2>Post navigation</h2>\n</nav>\n</main>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "The first four phases of knowledge management are all about identifying and creating meaning and then making that meaning usable. Knowledge management is a set of epistemic actions, creating knowledge through interaction. This interaction is a way of creating a partnership between what happens in the head with everything in the world –Work-as-ImaginedandWork-as-Done.There are really four themes to a set of epistemic actions:Foraging: Locating resources that will lead to understandingTuning: Adju",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The first four phases of knowledge management are all about identifying and creating meaning and then making that meaning usable. Knowledge management is a set of epistemic actions, creating knowledge through interaction. This interaction is a way of creating a partnership between what happens in the head with everything in the world –Work-as-ImaginedandWork-as-Done.There are really four themes to a set of epistemic actions:Foraging: Locating resources that will lead to understandingTuning: Adju",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "The first four phases of knowledge management are all about identifying and creating meaning and then making that meaning usable. Knowledge management is a set of epistemic actions, creating knowledge through interaction. This interaction is a way of creating a partnership between what happens in the head with everything in the world –Work-as-ImaginedandWork-as-Done.There are really four themes to a set of epistemic actions:Foraging: Locating resources that will lead to understandingTuning: Adju",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The first four phases of knowledge management are all about identifying and creating meaning and then making that meaning usable. Knowledge management is a set of epistemic actions, creating knowledge through interaction. This interaction is a way of creating a partnership between what happens in the head with everything in the world –Work-as-ImaginedandWork-as-Done.There are really four themes to a set of epistemic actions:Foraging: Locating resources that will lead to understandingTuning: Adju",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "ThemeEpistemic InteractionMeansForagingLocating resources that will lead to understandingSearchingSearching happens when you need information and\nbelieve it exists somewhere.Searching depends on how we articulate or\ninformation needs.Probing“Tell me more.” Probing happens when the information\nyou have isn’t quite enough. You are probing when you take the next step,\nmove to the next level, and obtain more salient specifics. Probing is about\ndrilling down and saying “show, explain, and reveal more",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Published byJeremiah GenestQuality professional with over 20 years of experience. Gamer and storyteller with forty years of practice.View all posts by Jeremiah GenestPublishedJanuary 30, 2022January 30, 2022",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Published byJeremiah GenestQuality professional with over 20 years of experience. Gamer and storyteller with forty years of practice.View all posts by Jeremiah Genest",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Published byJeremiah Genest",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Post navigation",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "http://www.nickmilton.com/2018/02/feedback-loops-in-knowledge-cycle.html",
      "title": "Feedback loops in the Knowledge cycle",
      "author": "",
      "published_date": "2018-02-07T07:37:00.000Z",
      "content": {
        "text": "<div><div><div>\n<h3>\n<a href=\"http://www.nickmilton.com/2018/02/feedback-loops-in-knowledge-cycle.html\">Feedback loops in the Knowledge cycle</a>\n</h3>\n<div>\n<h3>\nLast week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.</h3>\n<p><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9vjQXtvrrpsy-BYNnn2aTOhxXn2-MBLGQwPBPTSQb8IOadw_2fim8pH4vUv30FUn8jGvU-50ZGgVKbGTMbLrE9Pvw1KmXLeWGT8NNoBlxC2-Gr_gNTKTQm-IhhXh9iCaYAD7Jj0Z2uegX/s1600/Untitled.png\"></a></p>\n<div><p>\nYou can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;</p><ul>\n<li>The cycle starts with a <b>problem</b>, and the identification of the need for knowledge to solve the problem (the \"need to know\")</li>\n<li>The first step is to <b>seek</b> for that knowledge - to search online, and to<b> ask</b> others</li>\n<li>Seeking/asking is followed by <b>finding</b></li>\n<li>However generally we tend to \"over-find\". Unless we are lucky, or there is a very good KM system, we find more than we need, so the next step is to <b>review </b>the results and<b> select</b> those which seem most relevant in the context of the problem.</li>\n<li>This found knowledge then needs to be <b>integrated</b> into what is already known about the problem, and integrated into solutions, approaches, procedures and plans.</li>\n<li>Finally the integrated knowledge needs to be <b>applied</b> to the problem.</li>\n</ul>\n</div>\n<p>\nIn the picture above, I have added the monitoring and feedback loops to each step, which work like this:</p>\n<div>\n<ul>\n<li>After the behaviour of asking/seeking, you feedback firstly whether there was any asking/seeking (so the organisation can track the behaviours of knowledge seeking) and you monitor and feed back the topics that people are asking about or searching for. You can for example <a href=\"http://www.nickmilton.com/2012/10/analysing-searches-in-community-of.html\">analyse questions in a community of practice</a>, or queries to a helpdesk, and you can analyse search terms from the corporate search engine logs. These will give you some ideas of the knowledge needs in the organisation, which knowledge supply has to match. </li>\n</ul>\n<ul>\n<li>After the finding step you feedback whether you found the knowledge you needed, or not. This feedback will help identify gaps in the knowledge base where the knowledge needs are not being met, and can trigger the creation of new knowledge assets of articles.</li>\n<li>After the review step you feed back whether the knowledge was relevant or not. In reality this feedback will be merged with the previous step. </li>\n</ul>\n<ul>\n<li>After the Integration step you feed back on the quality of the knowledge you found. This feedback will identify knowledge assets or knowledge articles which need to be updated.</li>\n</ul>\n<ul>\n<li>After the Apply step, you feed back whether the knowledge was actually applied. This will help identify the most applicable and useful knowledge assets and articles. </li>\n</ul>\n<ul>\n<li>Finally, after the problem solution step, you feed back how much difference the knowledge made, and how much value was realised through problem solution. This allows you to track the value of the entire pull cycle and the entire <a href=\"https://www.knoco.com/knowledge-management-framework-design.htm\">knowledge management framework</a>. </li>\n</ul>\n<p>\nMany of these monitoring and feedback loops are well developed in the customer-focused KM approaches such as KCS (Knowledge Centred Support), but any KM approach can apply these as part of their own KM metrics framework.</p>\n<p><b>It is through the feedback associated with the steps that you can tell whether KM is actually working.</b></p>\n<ul>\n</ul>\n</div>\n</div>\n</div><div>\n<h2>Blog Archive</h2>\n</div></div></div>",
        "html": "<div><div><div>\n<h3>\n<a href=\"http://www.nickmilton.com/2018/02/feedback-loops-in-knowledge-cycle.html\">Feedback loops in the Knowledge cycle</a>\n</h3>\n<div>\n<h3>\nLast week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.</h3>\n<p><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9vjQXtvrrpsy-BYNnn2aTOhxXn2-MBLGQwPBPTSQb8IOadw_2fim8pH4vUv30FUn8jGvU-50ZGgVKbGTMbLrE9Pvw1KmXLeWGT8NNoBlxC2-Gr_gNTKTQm-IhhXh9iCaYAD7Jj0Z2uegX/s1600/Untitled.png\"></a></p>\n<div><p>\nYou can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;</p><ul>\n<li>The cycle starts with a <b>problem</b>, and the identification of the need for knowledge to solve the problem (the \"need to know\")</li>\n<li>The first step is to <b>seek</b> for that knowledge - to search online, and to<b> ask</b> others</li>\n<li>Seeking/asking is followed by <b>finding</b></li>\n<li>However generally we tend to \"over-find\". Unless we are lucky, or there is a very good KM system, we find more than we need, so the next step is to <b>review </b>the results and<b> select</b> those which seem most relevant in the context of the problem.</li>\n<li>This found knowledge then needs to be <b>integrated</b> into what is already known about the problem, and integrated into solutions, approaches, procedures and plans.</li>\n<li>Finally the integrated knowledge needs to be <b>applied</b> to the problem.</li>\n</ul>\n</div>\n<p>\nIn the picture above, I have added the monitoring and feedback loops to each step, which work like this:</p>\n<div>\n<ul>\n<li>After the behaviour of asking/seeking, you feedback firstly whether there was any asking/seeking (so the organisation can track the behaviours of knowledge seeking) and you monitor and feed back the topics that people are asking about or searching for. You can for example <a href=\"http://www.nickmilton.com/2012/10/analysing-searches-in-community-of.html\">analyse questions in a community of practice</a>, or queries to a helpdesk, and you can analyse search terms from the corporate search engine logs. These will give you some ideas of the knowledge needs in the organisation, which knowledge supply has to match. </li>\n</ul>\n<ul>\n<li>After the finding step you feedback whether you found the knowledge you needed, or not. This feedback will help identify gaps in the knowledge base where the knowledge needs are not being met, and can trigger the creation of new knowledge assets of articles.</li>\n<li>After the review step you feed back whether the knowledge was relevant or not. In reality this feedback will be merged with the previous step. </li>\n</ul>\n<ul>\n<li>After the Integration step you feed back on the quality of the knowledge you found. This feedback will identify knowledge assets or knowledge articles which need to be updated.</li>\n</ul>\n<ul>\n<li>After the Apply step, you feed back whether the knowledge was actually applied. This will help identify the most applicable and useful knowledge assets and articles. </li>\n</ul>\n<ul>\n<li>Finally, after the problem solution step, you feed back how much difference the knowledge made, and how much value was realised through problem solution. This allows you to track the value of the entire pull cycle and the entire <a href=\"https://www.knoco.com/knowledge-management-framework-design.htm\">knowledge management framework</a>. </li>\n</ul>\n<p>\nMany of these monitoring and feedback loops are well developed in the customer-focused KM approaches such as KCS (Knowledge Centred Support), but any KM approach can apply these as part of their own KM metrics framework.</p>\n<p><b>It is through the feedback associated with the steps that you can tell whether KM is actually working.</b></p>\n<ul>\n</ul>\n</div>\n</div>\n</div><div>\n<h2>Blog Archive</h2>\n</div></div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Feedback loops in the Knowledge cycleLast week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.You can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;The cycle starts with aproblem, and the identification of the need for knowledge to solve the problem (the \"need to know\")The first step is toseekfor that knowledge - to search online, and to",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Feedback loops in the Knowledge cycleLast week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.You can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;The cycle starts with aproblem, and the identification of the need for knowledge to solve the problem (the \"need to know\")The first step is toseekfor that knowledge - to search online, and to",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Feedback loops in the Knowledge cycleLast week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.You can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;The cycle starts with aproblem, and the identification of the need for knowledge to solve the problem (the \"need to know\")The first step is toseekfor that knowledge - to search online, and to",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Last week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.You can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;The cycle starts with aproblem, and the identification of the need for knowledge to solve the problem (the \"need to know\")The first step is toseekfor that knowledge - to search online, and toaskothersSeeking/asking is followed b",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "You can find description of the cycle here. This is a cycle based on knowledge demand (unlike the supply-side cycles you normally see) and includes the following steps;The cycle starts with aproblem, and the identification of the need for knowledge to solve the problem (the \"need to know\")The first step is toseekfor that knowledge - to search online, and toaskothersSeeking/asking is followed byfindingHowever generally we tend to \"over-find\". Unless we are lucky, or there is a very good KM system",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "After the behaviour of asking/seeking, you feedback firstly whether there was any asking/seeking (so the organisation can track the behaviours of knowledge seeking) and you monitor and feed back the topics that people are asking about or searching for. You can for exampleanalyse questions in a community of practice, or queries to a helpdesk, and you can analyse search terms from the corporate search engine logs. These will give you some ideas of the knowledge needs in the organisation, which kno",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Blog Archive",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "Feedback loops in the Knowledge cycle",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Last week I described a \"Pull cycle\" for knowledge - let's now look at the feedback loops in that cycle.",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Blog Archive",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://oxfordre.com/communication/abstract/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-17?d=%2F10.1093%2Facrefore%2F9780190228613.001.0001%2Facrefore-9780190228613-e-17&p=emailAApI1eK16tu.2",
      "title": "Communication Technology and Knowledge Management",
      "author": "Jeffrey Treem",
      "published_date": "2018-04-26T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<div>\n<ul>\n<li>\n</li><li>\n<a href=\"https://oxfordre.com/communication/login?t:state:client=QY25KZQl07DvdWARkMpweXPGdLg=:H4sIAAAAAAAAAK2Ou0pDQRCGJ15QCTY2voDYZS8J5oIECaIQchAhaL+cMzmu7NldZyeJaWwtfRFr38Xa2s7KymMTsLcYmOH7+eZ//YTt5RYANBLBJFApTDT5HQo2ERPT6kRYz0jeOJGQFjbHJM6dRc/XSMkmrrdLi66YciBT4riK7miCq/evw5edj+/nDdjMoJmHKgZfR8cFw0F2bxZGOuNLOWWyvjzNYG/2K7kyFT7AEzQy2I21bX0/xsjQJCwsYc435Bj2Qwry1uLywtc9Gd5k/aWae5sbtsHLwqbozEpqJbQadKTJCWeBUA56faUHqt3ud3VHKKXrUXrNW394C1u6d1YM/0NzHIdYGetGozjWONFdnov2D1DbCHyCAQAA\">\n<span>Bookmark</span>\n</a>\n</li><li>\n<div>\n<h2>Share Link</h2>\n<hr/>\n<p>Copy this link, or click below to email it to a friend</p>\n<p><a href=\"mailto:?subject=Link%20to%20Communication%20Technology%20and%20Knowledge%20Management&amp;body=https%3A%2F%2Foxfordre.com%2Fcommunication%2Fdisplay%2F10.1093%2Facrefore%2F9780190228613.001.0001%2Facrefore-9780190228613-e-17\">Email\n</a></p><p>or copy the link directly:</p>\n<div>\n<p>The link was not copied. Your current browser may not support copying via this button.</p>\n</div>\n<hr/>\n</div>\n</li></ul>\n</div>\n<div>\n<h2>Article contents</h2>\n<nav><ul><li><a href=\"#acrefore-9780190228613-e-17-div1-1\">Introduction</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-2\">The Nature of Knowledge and Information in Knowledge Management</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-3\">Communication Technology and Knowledge Management</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-4\">Conceptualizations of Communication Technology and Knowledge Management</a><ul><li><a href=\"#acrefore-9780190228613-e-17-div2-2\">Communication Technologies as Public Goods</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-3\">Communication Technologies as Facilitating Communities of Practice</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-4\">Communication Technologies and Transactive Memory Systems</a></li></ul></li><li><a href=\"#acrefore-9780190228613-e-17-div1-5\">The Communicative Challenges of Knowledge Management Systems</a><ul><li><a href=\"#acrefore-9780190228613-e-17-div2-6\">Knowledge Creation</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-7\">Knowledge Sharing</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-8\">Knowledge Transfer</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-9\">Knowledge Storage</a></li></ul></li><li><a href=\"#acrefore-9780190228613-e-17-div1-6\">Future Directions for Communication Technology and Knowledge Management</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-7\">Historiography</a></li><li><a href=\"#acrefore-9780190228613-e-17-bibliography-0001\">Further Reading</a></li><li><a href=\"#acrefore-9780190228613-e-17-bibliography-0002\">References</a></li></ul><ul><li><a href=\"#RelatedArticles\">Related Articles</a></li></ul></nav>\n</div>\n<div>\n<p><a href=\"#\"><span>Show Summary Details</span></a></p>\n<div><div><h2>Communication Technology and Knowledge Management</h2></div><div><ul><li><span><span>Jeffrey Treem</span><span><span>Jeffrey Treem</span><span>Department of Communication Studies, University of Texas at Austin</span></span></span></li></ul></div></div>\n<div>\n<p>You do not currently have access to this article</p> <div> <h4>Login</h4> <p>Please <a href=\"https://oxfordre.com/communication/?url=%2Fcommunication%2Fdisplay%2F10.1093%2Facrefore%2F9780190228613.001.0001%2Facrefore-9780190228613-e-17\">login</a> to access the full content.</p> </div> <div> <h4>Subscribe</h4> <p>Access to the full content requires a <a href=\"https://oxfordre.com/page/subscriber-services/subscribe\">subscription</a></p> </div>\n</div>\n</div>\n</div></div>",
        "html": "<div><div>\n<div>\n<ul>\n<li>\n</li><li>\n<a href=\"https://oxfordre.com/communication/login?t:state:client=QY25KZQl07DvdWARkMpweXPGdLg=:H4sIAAAAAAAAAK2Ou0pDQRCGJ15QCTY2voDYZS8J5oIECaIQchAhaL+cMzmu7NldZyeJaWwtfRFr38Xa2s7KymMTsLcYmOH7+eZ//YTt5RYANBLBJFApTDT5HQo2ERPT6kRYz0jeOJGQFjbHJM6dRc/XSMkmrrdLi66YciBT4riK7miCq/evw5edj+/nDdjMoJmHKgZfR8cFw0F2bxZGOuNLOWWyvjzNYG/2K7kyFT7AEzQy2I21bX0/xsjQJCwsYc435Bj2Qwry1uLywtc9Gd5k/aWae5sbtsHLwqbozEpqJbQadKTJCWeBUA56faUHqt3ud3VHKKXrUXrNW394C1u6d1YM/0NzHIdYGetGozjWONFdnov2D1DbCHyCAQAA\">\n<span>Bookmark</span>\n</a>\n</li><li>\n<div>\n<h2>Share Link</h2>\n<hr/>\n<p>Copy this link, or click below to email it to a friend</p>\n<p><a href=\"mailto:?subject=Link%20to%20Communication%20Technology%20and%20Knowledge%20Management&amp;body=https%3A%2F%2Foxfordre.com%2Fcommunication%2Fdisplay%2F10.1093%2Facrefore%2F9780190228613.001.0001%2Facrefore-9780190228613-e-17\">Email\n</a></p><p>or copy the link directly:</p>\n<div>\n<p>The link was not copied. Your current browser may not support copying via this button.</p>\n</div>\n<hr/>\n</div>\n</li></ul>\n</div>\n<div>\n<h2>Article contents</h2>\n<nav><ul><li><a href=\"#acrefore-9780190228613-e-17-div1-1\">Introduction</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-2\">The Nature of Knowledge and Information in Knowledge Management</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-3\">Communication Technology and Knowledge Management</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-4\">Conceptualizations of Communication Technology and Knowledge Management</a><ul><li><a href=\"#acrefore-9780190228613-e-17-div2-2\">Communication Technologies as Public Goods</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-3\">Communication Technologies as Facilitating Communities of Practice</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-4\">Communication Technologies and Transactive Memory Systems</a></li></ul></li><li><a href=\"#acrefore-9780190228613-e-17-div1-5\">The Communicative Challenges of Knowledge Management Systems</a><ul><li><a href=\"#acrefore-9780190228613-e-17-div2-6\">Knowledge Creation</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-7\">Knowledge Sharing</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-8\">Knowledge Transfer</a></li><li><a href=\"#acrefore-9780190228613-e-17-div2-9\">Knowledge Storage</a></li></ul></li><li><a href=\"#acrefore-9780190228613-e-17-div1-6\">Future Directions for Communication Technology and Knowledge Management</a></li><li><a href=\"#acrefore-9780190228613-e-17-div1-7\">Historiography</a></li><li><a href=\"#acrefore-9780190228613-e-17-bibliography-0001\">Further Reading</a></li><li><a href=\"#acrefore-9780190228613-e-17-bibliography-0002\">References</a></li></ul><ul><li><a href=\"#RelatedArticles\">Related Articles</a></li></ul></nav>\n</div>\n<div>\n<p><a href=\"#\"><span>Show Summary Details</span></a></p>\n<div><div><h2>Communication Technology and Knowledge Management</h2></div><div><ul><li><span><span>Jeffrey Treem</span><span><span>Jeffrey Treem</span><span>Department of Communication Studies, University of Texas at Austin</span></span></span></li></ul></div></div>\n<div>\n<p>You do not currently have access to this article</p> <div> <h4>Login</h4> <p>Please <a href=\"https://oxfordre.com/communication/?url=%2Fcommunication%2Fdisplay%2F10.1093%2Facrefore%2F9780190228613.001.0001%2Facrefore-9780190228613-e-17\">login</a> to access the full content.</p> </div> <div> <h4>Subscribe</h4> <p>Access to the full content requires a <a href=\"https://oxfordre.com/page/subscriber-services/subscribe\">subscription</a></p> </div>\n</div>\n</div>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "BookmarkShare LinkCopy this link, or click below to email it to a friendEmailor copy the link directly:The link was not copied. Your current browser may not support copying via this button.Article contentsIntroductionThe Nature of Knowledge and Information in Knowledge ManagementCommunication Technology and Knowledge ManagementConceptualizations of Communication Technology and Knowledge ManagementCommunication Technologies as Public GoodsCommunication Technologies as Facilitating Communities of ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "BookmarkShare LinkCopy this link, or click below to email it to a friendEmailor copy the link directly:The link was not copied. Your current browser may not support copying via this button.Article contentsIntroductionThe Nature of Knowledge and Information in Knowledge ManagementCommunication Technology and Knowledge ManagementConceptualizations of Communication Technology and Knowledge ManagementCommunication Technologies as Public GoodsCommunication Technologies as Facilitating Communities of ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "BookmarkShare LinkCopy this link, or click below to email it to a friendEmailor copy the link directly:The link was not copied. Your current browser may not support copying via this button.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Share LinkCopy this link, or click below to email it to a friendEmailor copy the link directly:The link was not copied. Your current browser may not support copying via this button.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The link was not copied. Your current browser may not support copying via this button.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Article contentsIntroductionThe Nature of Knowledge and Information in Knowledge ManagementCommunication Technology and Knowledge ManagementConceptualizations of Communication Technology and Knowledge ManagementCommunication Technologies as Public GoodsCommunication Technologies as Facilitating Communities of PracticeCommunication Technologies and Transactive Memory SystemsThe Communicative Challenges of Knowledge Management SystemsKnowledge CreationKnowledge SharingKnowledge TransferKnowledge S",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Show Summary DetailsCommunication Technology and Knowledge ManagementJeffrey TreemJeffrey TreemDepartment of Communication Studies, University of Texas at AustinYou do not currently have access to this articleLoginPleaseloginto access the full content.SubscribeAccess to the full content requires asubscription",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Communication Technology and Knowledge ManagementJeffrey TreemJeffrey TreemDepartment of Communication Studies, University of Texas at Austin",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Communication Technology and Knowledge Management",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jeffrey TreemJeffrey TreemDepartment of Communication Studies, University of Texas at Austin",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "You do not currently have access to this articleLoginPleaseloginto access the full content.SubscribeAccess to the full content requires asubscription",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "LoginPleaseloginto access the full content.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "SubscribeAccess to the full content requires asubscription",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Share Link",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Article contents",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Communication Technology and Knowledge Management",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Login",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Subscribe",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://www.nature.com/articles/srep12197",
      "title": "The dynamics of meaningful social interactions and the emergence of collective knowledge - Scientific Reports",
      "author": "Dankulov; Marija Mitrović; Melnik; Roderick; Tadić; Bosiljka",
      "published_date": "2023-02-27T02:44:45.000Z",
      "content": {
        "text": "<div><div>\n<div><h2>Introduction</h2><div><p>In modern statistical mechanics<sup><a href=\"/articles/srep12197#ref-CR1\">1</a></sup>, it has been recognized that the collective phenomena arise from interactions among the elementary units via a spontaneous transition to an organized state, which can be identified at a larger scale<sup><a href=\"/articles/srep12197#ref-CR2\">2</a>,<a href=\"/articles/srep12197#ref-CR3\">3</a></sup>. Recently, this unifying principle is gaining importance in other natural sciences, for instance for elucidating organization in living systems<sup><a href=\"/articles/srep12197#ref-CR4\">4</a>,<a href=\"/articles/srep12197#ref-CR5\">5</a>,<a href=\"/articles/srep12197#ref-CR6\">6</a>,<a href=\"/articles/srep12197#ref-CR7\">7</a>,<a href=\"/articles/srep12197#ref-CR8\">8</a></sup>, emergence of coherent activity in neuronal cultures<sup><a href=\"/articles/srep12197#ref-CR9\">9</a></sup> and developing computational social science<sup><a href=\"/articles/srep12197#ref-CR10\">10</a></sup>. In social systems, interactions and cooperations among actors can lead to the recognizable collective behavior, for instance, the development of collective knowledge<sup><a href=\"/articles/srep12197#ref-CR11\">11</a></sup>, appearance of common norms<sup><a href=\"/articles/srep12197#ref-CR12\">12</a></sup> or language<sup><a href=\"/articles/srep12197#ref-CR13\">13</a></sup>. The quantitative study of the stochastic processes underlying these social phenomena utilizes the methods of statistical physics supported by analysis of the plethora of online empirical data. Some illustrative examples are the appearance of good and bad conduct in online games<sup><a href=\"/articles/srep12197#ref-CR14\">14</a></sup> and groupings induced by the exchange of emotional messages on social sites<sup><a href=\"/articles/srep12197#ref-CR15\">15</a>,<a href=\"/articles/srep12197#ref-CR16\">16</a>,<a href=\"/articles/srep12197#ref-CR17\">17</a>,<a href=\"/articles/srep12197#ref-CR18\">18</a></sup>. However, a deeper understanding of the mechanisms of collaborative social endeavors<sup><a href=\"/articles/srep12197#ref-CR11\">11</a>,<a href=\"/articles/srep12197#ref-CR19\">19</a>,<a href=\"/articles/srep12197#ref-CR20\">20</a></sup> remains a serious challenging problem in physics and social dynamics modeling.</p><p>The building of collective knowledge via social interactions is a subtle phenomenon that requires both cognitive elements and an organized effort to solve a particular query. In this stochastic process, the social system that enables transfer of knowledge and the cognitive subsystem are dynamically interlinked and influence each other at a microscopic scale<sup><a href=\"/articles/srep12197#ref-CR21\">21</a></sup>. In the relational epistemology, the exchange of values is an essential factor that permits the emergence of a collective value via interaction and cooperation among equal individuals<sup><a href=\"/articles/srep12197#ref-CR22\">22</a></sup>. In this concept, the collective knowledge is neither an entity over individuals nor their sum, rather, it is a property of the particular relations among the interacting actors. It reflects the actions of each individual as a <i>meaningful, adjusted to the actions of others by means of new operation</i>; its reciprocity and the acceptance of the confirmed values lead to a cooperation “that has a logical structure isomorphic to logical thought”<sup><a href=\"/articles/srep12197#ref-CR22\">22</a></sup>. On the practical side, modern information communication technologies (ICT) provide a suitable platform for knowledge building via social dynamics<sup><a href=\"/articles/srep12197#ref-CR23\">23</a>,<a href=\"/articles/srep12197#ref-CR24\">24</a></sup>. These systems aim at transferring the expertise and tacit knowledge that reside in the minds of individuals into a form of collective knowledge. Through ICT, the individual’s knowledge is shared or “externalized”<sup><a href=\"/articles/srep12197#ref-CR21\">21</a></sup>. Also, the fragile relational state, where the knowledge is dynamically experienced within a community, is actualized as a collection of mutually related digital artifacts. When a systematic tagging is applied to these artifacts, a form of “explicit” knowledge appears, from which others can learn<sup><a href=\"/articles/srep12197#ref-CR21\">21</a></sup>. For this reason, the emergence and quality of the collective knowledge crucially depend on the microscopic mechanisms, by which a particular cognitive element and an individual actor’s expertise contribute to the self-organized process.</p><p>We develop a new approach that explains how the collective knowledge emerges in Questions &amp; Answers (Q&amp;A) communications. We utilize the concept of two-scale dynamics that enables defining a correct microscopic model of interactions between social and cognitive elements and confirm its predictions by quantitative analysis of the empirical data from a well-known Q&amp;A system. The elementary units in the process, actors and questions that they post or answer contain sub-elementary units—cognitive elements, which describe the actor’s expertise and the questions’ cognitive contents. Their dynamics strictly obeys the cognitive recognition rules, thus influencing the dynamics at the social level of actors. We quantitatively describe the knowledge-creation process from the elementary interactions to mesoscopic and global level. The statistical signatures of the collective dynamics depend on the range of the actors’ expertise, which can be extracted from the empirical data and varied in the simulations. The impact of cognitive elements in the empirical data is further confirmed by methods of information theory while the occurrence and structure of communities are visualized by graph theoretic techniques.</p></div></div><div><h2>Results</h2><div><h3>Fine-grained dynamics and cooperation</h3><p>All our exemplifications are provided based on the analysis of data in mathematics from the system known as <b>Mathematics</b> which has become a universal clearinghouse for Q&amp;A in the field<sup><a href=\"/articles/srep12197#ref-CR25\">25</a></sup>. In the data, the cognitive element of each artifact (question, answer or comment) has been systematically tagged according to the standard mathematics classification scheme. In addition, the fact that a unique identity is known for each actor (user) and each artifact together with the high temporal resolution of the data enable a detailed analysis of the underlying stochastic process. Assuming that the cognition-driven events occurred, we determine a set of tags as expertise of each user in the considered dataset. The dataset and the procedure are described in Methods. In the model (<a href=\"/articles/srep12197#MOESM1\">Supplementary information, SI</a>), the actors (agents) have a defined range of expertise. Minimal matching of the expertise of an answering agent with the tags of the answered question is strictly obeyed. The considered agents have the activity patterns statistically similar with the patterns of users in the empirical data while their expertise is varied.</p><p>In the process, which is schematically depicted in <a href=\"/articles/srep12197#Fig1\">Fig. 1a</a>, an actor (U) posts a question (Q), which may receive answers or comments (A) by other actors over time. Subsequently, new Q and the already present Q&amp;A are subject to further answers and so on. Representing each action by a directed link, this process co-evolves a bipartite network, where actors are one partition and Q&amp;A form another partition. An example of a single-question network from the empirical data is shown in <a href=\"/articles/srep12197#Fig1\">Fig. 1b</a>. The cognitive content of each question is marked by up to 5 different tags, which thus specify the required expertise of the answering actors. Matching by at least one tag is required. The actor’s expertise is transferred to its answer. The excess expertise of the involved actors leads to the innovation<sup><a href=\"/articles/srep12197#ref-CR26\">26</a>,<a href=\"/articles/srep12197#ref-CR27\">27</a>,<a href=\"/articles/srep12197#ref-CR28\">28</a></sup> and an accumulation of expertise around a particular question. At the same time, it extends the sample space of matching events, thus accelerating the process in a self-organized manner.</p><div><figure><figcaption><b>Figure 1</b></figcaption><div><div><a href=\"/articles/srep12197/figures/1\"></a></div><div><p>Tags-matching illustration and the activity patterns of users and tags in Mathematics.</p><p>(<b>a</b>) Schematically shown a sequence of events with matching of tags (colored boxes) between actors’ expertise (displayed as a particular set of tags above blue circles—actors, <i>U</i><sub><i>i</i></sub>), the answers <i>A</i><sub><i>j</i></sub> and questions <i>Q</i><sub><i>j</i></sub> containing the tags of the related actor’s expertise. The direction of lines towards/outwards each actor indicates the process of reading/posting event. (<b>b</b>) Bipartite network of users (blue) and answers (red) at a favorite question (big red node). (<b>c</b>) Probability <i>g</i><sub><i>i</i></sub> of posting a new question by the user <i>i</i> plotted against its total activity <i>N</i><sub><i>i</i></sub>, averaged over all users in the dataset. (<b>d</b>) The distributions of the interactivity time Δ<i>T</i> for users and tags. (<b>e</b>) The distribution of the user’s expertise entropy <i>S</i><sub><i>i</i></sub> averaged over all users in the data. (<b>f</b>) Each point indicates the entropy related with the probability of the appearance of a particular tag along a sequence of <i>m</i> time intervals, where <i>m</i> is the tag’s frequency. Lower set of points represents the entropies for all tags computed from the sequence of events in the empirical data while the upper set is obtained from its randomized version.</p></div></div><p><a href=\"/articles/srep12197/figures/1\">Full size image</a></p></fi",
        "html": "<div><div>\n<div><h2>Introduction</h2><div><p>In modern statistical mechanics<sup><a href=\"/articles/srep12197#ref-CR1\">1</a></sup>, it has been recognized that the collective phenomena arise from interactions among the elementary units via a spontaneous transition to an organized state, which can be identified at a larger scale<sup><a href=\"/articles/srep12197#ref-CR2\">2</a>,<a href=\"/articles/srep12197#ref-CR3\">3</a></sup>. Recently, this unifying principle is gaining importance in other natural sciences, for instance for elucidating organization in living systems<sup><a href=\"/articles/srep12197#ref-CR4\">4</a>,<a href=\"/articles/srep12197#ref-CR5\">5</a>,<a href=\"/articles/srep12197#ref-CR6\">6</a>,<a href=\"/articles/srep12197#ref-CR7\">7</a>,<a href=\"/articles/srep12197#ref-CR8\">8</a></sup>, emergence of coherent activity in neuronal cultures<sup><a href=\"/articles/srep12197#ref-CR9\">9</a></sup> and developing computational social science<sup><a href=\"/articles/srep12197#ref-CR10\">10</a></sup>. In social systems, interactions and cooperations among actors can lead to the recognizable collective behavior, for instance, the development of collective knowledge<sup><a href=\"/articles/srep12197#ref-CR11\">11</a></sup>, appearance of common norms<sup><a href=\"/articles/srep12197#ref-CR12\">12</a></sup> or language<sup><a href=\"/articles/srep12197#ref-CR13\">13</a></sup>. The quantitative study of the stochastic processes underlying these social phenomena utilizes the methods of statistical physics supported by analysis of the plethora of online empirical data. Some illustrative examples are the appearance of good and bad conduct in online games<sup><a href=\"/articles/srep12197#ref-CR14\">14</a></sup> and groupings induced by the exchange of emotional messages on social sites<sup><a href=\"/articles/srep12197#ref-CR15\">15</a>,<a href=\"/articles/srep12197#ref-CR16\">16</a>,<a href=\"/articles/srep12197#ref-CR17\">17</a>,<a href=\"/articles/srep12197#ref-CR18\">18</a></sup>. However, a deeper understanding of the mechanisms of collaborative social endeavors<sup><a href=\"/articles/srep12197#ref-CR11\">11</a>,<a href=\"/articles/srep12197#ref-CR19\">19</a>,<a href=\"/articles/srep12197#ref-CR20\">20</a></sup> remains a serious challenging problem in physics and social dynamics modeling.</p><p>The building of collective knowledge via social interactions is a subtle phenomenon that requires both cognitive elements and an organized effort to solve a particular query. In this stochastic process, the social system that enables transfer of knowledge and the cognitive subsystem are dynamically interlinked and influence each other at a microscopic scale<sup><a href=\"/articles/srep12197#ref-CR21\">21</a></sup>. In the relational epistemology, the exchange of values is an essential factor that permits the emergence of a collective value via interaction and cooperation among equal individuals<sup><a href=\"/articles/srep12197#ref-CR22\">22</a></sup>. In this concept, the collective knowledge is neither an entity over individuals nor their sum, rather, it is a property of the particular relations among the interacting actors. It reflects the actions of each individual as a <i>meaningful, adjusted to the actions of others by means of new operation</i>; its reciprocity and the acceptance of the confirmed values lead to a cooperation “that has a logical structure isomorphic to logical thought”<sup><a href=\"/articles/srep12197#ref-CR22\">22</a></sup>. On the practical side, modern information communication technologies (ICT) provide a suitable platform for knowledge building via social dynamics<sup><a href=\"/articles/srep12197#ref-CR23\">23</a>,<a href=\"/articles/srep12197#ref-CR24\">24</a></sup>. These systems aim at transferring the expertise and tacit knowledge that reside in the minds of individuals into a form of collective knowledge. Through ICT, the individual’s knowledge is shared or “externalized”<sup><a href=\"/articles/srep12197#ref-CR21\">21</a></sup>. Also, the fragile relational state, where the knowledge is dynamically experienced within a community, is actualized as a collection of mutually related digital artifacts. When a systematic tagging is applied to these artifacts, a form of “explicit” knowledge appears, from which others can learn<sup><a href=\"/articles/srep12197#ref-CR21\">21</a></sup>. For this reason, the emergence and quality of the collective knowledge crucially depend on the microscopic mechanisms, by which a particular cognitive element and an individual actor’s expertise contribute to the self-organized process.</p><p>We develop a new approach that explains how the collective knowledge emerges in Questions &amp; Answers (Q&amp;A) communications. We utilize the concept of two-scale dynamics that enables defining a correct microscopic model of interactions between social and cognitive elements and confirm its predictions by quantitative analysis of the empirical data from a well-known Q&amp;A system. The elementary units in the process, actors and questions that they post or answer contain sub-elementary units—cognitive elements, which describe the actor’s expertise and the questions’ cognitive contents. Their dynamics strictly obeys the cognitive recognition rules, thus influencing the dynamics at the social level of actors. We quantitatively describe the knowledge-creation process from the elementary interactions to mesoscopic and global level. The statistical signatures of the collective dynamics depend on the range of the actors’ expertise, which can be extracted from the empirical data and varied in the simulations. The impact of cognitive elements in the empirical data is further confirmed by methods of information theory while the occurrence and structure of communities are visualized by graph theoretic techniques.</p></div></div><div><h2>Results</h2><div><h3>Fine-grained dynamics and cooperation</h3><p>All our exemplifications are provided based on the analysis of data in mathematics from the system known as <b>Mathematics</b> which has become a universal clearinghouse for Q&amp;A in the field<sup><a href=\"/articles/srep12197#ref-CR25\">25</a></sup>. In the data, the cognitive element of each artifact (question, answer or comment) has been systematically tagged according to the standard mathematics classification scheme. In addition, the fact that a unique identity is known for each actor (user) and each artifact together with the high temporal resolution of the data enable a detailed analysis of the underlying stochastic process. Assuming that the cognition-driven events occurred, we determine a set of tags as expertise of each user in the considered dataset. The dataset and the procedure are described in Methods. In the model (<a href=\"/articles/srep12197#MOESM1\">Supplementary information, SI</a>), the actors (agents) have a defined range of expertise. Minimal matching of the expertise of an answering agent with the tags of the answered question is strictly obeyed. The considered agents have the activity patterns statistically similar with the patterns of users in the empirical data while their expertise is varied.</p><p>In the process, which is schematically depicted in <a href=\"/articles/srep12197#Fig1\">Fig. 1a</a>, an actor (U) posts a question (Q), which may receive answers or comments (A) by other actors over time. Subsequently, new Q and the already present Q&amp;A are subject to further answers and so on. Representing each action by a directed link, this process co-evolves a bipartite network, where actors are one partition and Q&amp;A form another partition. An example of a single-question network from the empirical data is shown in <a href=\"/articles/srep12197#Fig1\">Fig. 1b</a>. The cognitive content of each question is marked by up to 5 different tags, which thus specify the required expertise of the answering actors. Matching by at least one tag is required. The actor’s expertise is transferred to its answer. The excess expertise of the involved actors leads to the innovation<sup><a href=\"/articles/srep12197#ref-CR26\">26</a>,<a href=\"/articles/srep12197#ref-CR27\">27</a>,<a href=\"/articles/srep12197#ref-CR28\">28</a></sup> and an accumulation of expertise around a particular question. At the same time, it extends the sample space of matching events, thus accelerating the process in a self-organized manner.</p><div><figure><figcaption><b>Figure 1</b></figcaption><div><div><a href=\"/articles/srep12197/figures/1\"></a></div><div><p>Tags-matching illustration and the activity patterns of users and tags in Mathematics.</p><p>(<b>a</b>) Schematically shown a sequence of events with matching of tags (colored boxes) between actors’ expertise (displayed as a particular set of tags above blue circles—actors, <i>U</i><sub><i>i</i></sub>), the answers <i>A</i><sub><i>j</i></sub> and questions <i>Q</i><sub><i>j</i></sub> containing the tags of the related actor’s expertise. The direction of lines towards/outwards each actor indicates the process of reading/posting event. (<b>b</b>) Bipartite network of users (blue) and answers (red) at a favorite question (big red node). (<b>c</b>) Probability <i>g</i><sub><i>i</i></sub> of posting a new question by the user <i>i</i> plotted against its total activity <i>N</i><sub><i>i</i></sub>, averaged over all users in the dataset. (<b>d</b>) The distributions of the interactivity time Δ<i>T</i> for users and tags. (<b>e</b>) The distribution of the user’s expertise entropy <i>S</i><sub><i>i</i></sub> averaged over all users in the data. (<b>f</b>) Each point indicates the entropy related with the probability of the appearance of a particular tag along a sequence of <i>m</i> time intervals, where <i>m</i> is the tag’s frequency. Lower set of points represents the entropies for all tags computed from the sequence of events in the empirical data while the upper set is obtained from its randomized version.</p></div></div><p><a href=\"/articles/srep12197/figures/1\">Full size image</a></p></fi",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "IntroductionIn modern statistical mechanics1, it has been recognized that the collective phenomena arise from interactions among the elementary units via a spontaneous transition to an organized state, which can be identified at a larger scale2,3. Recently, this unifying principle is gaining importance in other natural sciences, for instance for elucidating organization in living systems4,5,6,7,8, emergence of coherent activity in neuronal cultures9and developing computational social science10. ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionIn modern statistical mechanics1, it has been recognized that the collective phenomena arise from interactions among the elementary units via a spontaneous transition to an organized state, which can be identified at a larger scale2,3. Recently, this unifying principle is gaining importance in other natural sciences, for instance for elucidating organization in living systems4,5,6,7,8, emergence of coherent activity in neuronal cultures9and developing computational social science10. ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionIn modern statistical mechanics1, it has been recognized that the collective phenomena arise from interactions among the elementary units via a spontaneous transition to an organized state, which can be identified at a larger scale2,3. Recently, this unifying principle is gaining importance in other natural sciences, for instance for elucidating organization in living systems4,5,6,7,8, emergence of coherent activity in neuronal cultures9and developing computational social science10. ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "In modern statistical mechanics1, it has been recognized that the collective phenomena arise from interactions among the elementary units via a spontaneous transition to an organized state, which can be identified at a larger scale2,3. Recently, this unifying principle is gaining importance in other natural sciences, for instance for elucidating organization in living systems4,5,6,7,8, emergence of coherent activity in neuronal cultures9and developing computational social science10. In social sy",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "ResultsFine-grained dynamics and cooperationAll our exemplifications are provided based on the analysis of data in mathematics from the system known asMathematicswhich has become a universal clearinghouse for Q&A in the field25. In the data, the cognitive element of each artifact (question, answer or comment) has been systematically tagged according to the standard mathematics classification scheme. In addition, the fact that a unique identity is known for each actor (user) and each artifact tog",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Fine-grained dynamics and cooperationAll our exemplifications are provided based on the analysis of data in mathematics from the system known asMathematicswhich has become a universal clearinghouse for Q&A in the field25. In the data, the cognitive element of each artifact (question, answer or comment) has been systematically tagged according to the standard mathematics classification scheme. In addition, the fact that a unique identity is known for each actor (user) and each artifact together w",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 1Tags-matching illustration and the activity patterns of users and tags in Mathematics.(a) Schematically shown a sequence of events with matching of tags (colored boxes) between actors’ expertise (displayed as a particular set of tags above blue circles—actors,Ui), the answersAjand questionsQjcontaining the tags of the related actor’s expertise. The direction of lines towards/outwards each actor indicates the process of reading/posting event. (b) Bipartite network of users (blue) and answ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Tags-matching illustration and the activity patterns of users and tags in Mathematics.(a) Schematically shown a sequence of events with matching of tags (colored boxes) between actors’ expertise (displayed as a particular set of tags above blue circles—actors,Ui), the answersAjand questionsQjcontaining the tags of the related actor’s expertise. The direction of lines towards/outwards each actor indicates the process of reading/posting event. (b) Bipartite network of users (blue) and answers (red",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Tags-matching illustration and the activity patterns of users and tags in Mathematics.(a) Schematically shown a sequence of events with matching of tags (colored boxes) between actors’ expertise (displayed as a particular set of tags above blue circles—actors,Ui), the answersAjand questionsQjcontaining the tags of the related actor’s expertise. The direction of lines towards/outwards each actor indicates the process of reading/posting event. (b) Bipartite network of users (blue) and answers (red",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Results",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Fine-grained dynamics and cooperation",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3063609/",
      "title": "The dynamic nature of knowledge: insights from a dynamic field model of children's novel noun generalization",
      "author": "",
      "published_date": "2009-01-07T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section><div>\n<p>. Author manuscript; available in PMC: 2011 Mar 24.</p></div></section><section><section><h2>Abstract</h2>\n<p>The present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decision processes in these tasks were instantiated in a dynamic field model. The model captures both qualitative and quantitative differences in performance across tasks and reveals constraints on the nature of children's accumulated knowledge. Additional simulations of developmental change in the yes/no task between 2 and 4 years of age illustrate how changes in children's representations translate into developmental changes in behavior. Together, the empirical data and model demonstrate the dynamic nature of knowledge and are consistent with the perspective that knowledge cannot be separated from the task-specific processes that create behavior in the moment.</p></section><hr/>\n<p>There are numerous examples in the cognitive development literature where children's abilities appear to shift across ages and tasks in seemingly paradoxical ways. For example, studies with young infants suggest that three- and four-month-old children can use knowledge of physical laws of continuity and solidity to determine where a ball rolled down a ramp should stop (<a href=\"#R73\">Spelke, Breinlinger, Macomber, &amp; Jacobson, 1992</a>). Yet, when tested in similar paradigms, 2- and 3-year-old children do not seem to have this same knowledge (<a href=\"#R5\">Berthier, DeBlois, Poirier, Novak, &amp; Clifton, 2000</a>). Similarly, research suggests that 6- to 8-month-old infants can detect the numerical equivalence between sets of auditory and visual stimuli (<a href=\"#R79\">Starkey, Spelke, &amp; Gelman, 1990</a>); yet, 3-year-old children fail at a similar task (<a href=\"#R42\">Mix, Huttenlocher, &amp; Levine, 1996</a>). Such examples leave the field in a difficult position: how are we to know when a child possesses some bit of knowledge?</p>\n<p>This question comes from a view of cognition that separates knowledge from process. By this view, knowledge resides in the head of the child, waiting to be accessed by the appropriate stimuli or task. Thus, developmentalists design tasks to tap into children's knowledge; if children perform competently they are said to have the requisite knowledge, if children fail they are said to lack the knowledge. One problem with this view is that it pits children's competence (i.e., knowledge) against their performance (i.e., behavior). Consequently, when children fail at a task it can always be claimed that they have the knowledge, but that the task did not effectively elicit that knowledge (see <a href=\"#R72\">Sophian, 1997</a>, and commentaries for discussion). A second problem with this view is that it leaves unexplained what is critical for acting in the world and for the unfolding of developmental process—how knowledge is created and how it is brought to bear in a task.</p>\n<p>An alternative and growing view is that knowledge is not separate from the processes that create behavior in a task. That is, knowledge is not a unitary thing that can be had, rather, it is distributed in and across many processes (e.g. <a href=\"#R2\">Barsalou, 1999</a>; <a href=\"#R47\">Plumert, in press</a>; <a href=\"#R48\">Port &amp; VanGelder, 1995</a>; <a href=\"#R57\">Samuelson &amp; Smith, 2000b</a>; <a href=\"#R64\">Skarda &amp; Freeman, 1987</a>; <a href=\"#R75\">Spencer &amp; Schöner, 2003</a>; <a href=\"#R78\">Spivey &amp; Dale, 2006</a>; <a href=\"#R81\">Thelen &amp; Smith, 1994</a>). By this view, one cannot ask about knowledge independent of the task that brings that knowledge to bear in a moment in time. Rather, the question to be asked is how the specifics of the task cohere with the child's prior history of perceiving, thinking, and acting to create behavior in the moment.</p>\n<p>Direct support for this view in developmental science comes from work by Esther Thelen, Linda Smith, and their colleagues showing how infants’ performance in the classic Piagetian A-not-B task is influenced by a host of intrinsic and extrinsic factors (<a href=\"#R10\">Clearfield, Diedrich, Smith, &amp; Thelen, 2006</a>; <a href=\"#R13\">Diedrich, Highlands, Thelen, &amp; Smith, 2001</a>; <a href=\"#R14\">Diedrich, Thelen, Smith, &amp; Corbetta, 2000</a>; <a href=\"#R70\">Smith, Thelen, Titzer, &amp; McLin, 1999</a>; <a href=\"#R80\">Thelen, Schöner, Scheier, &amp; Smith, 2001</a>; <a href=\"#R82\">Thelen &amp; Smith, 1997</a>). Although such studies have contributed foundational support for the idea that knowledge is bound to behavior in a particular task, the implications of this work for cognition more generally have been called into question given that the A-not-B phenomenon is largely grounded in sensori-motor activity (<a href=\"#R21\">Freeman, 2001</a>; <a href=\"#R29\">Glenberg, Cowart, &amp; Kaschak, 2001</a>; <a href=\"#R41\">Markman, 2001</a>; <a href=\"#R43\">Munakata &amp; McClelland, 2003</a>; but see <a href=\"#R75\">Spencer &amp; Schöner, 2003</a>). An important question, then, is whether this view has implications for higher-order cognition.</p>\n<p>This question is well illustrated by a current debate in the word learning literature (see <a href=\"#R51\">Samuelson &amp; Bloom, 2008</a>). In a typical experimental procedure, a young child shown a novel solid, rigid object and told a novel name (e.g., “this is a dax”) will most likely say that only other objects that share the same shape as the exemplar can be called by the same name (<a href=\"#R32\">Imai, Gentner, &amp; Uchida, 1994</a>; <a href=\"#R37\">Landau, Smith, &amp; Jones, 1988</a>; <a href=\"#R55\">Samuelson &amp; Smith, 1999</a>). Young children are thus said to show a “shape bias” when generalizing novel names for solid objects. Importantly, however, children do not always generalize novel names by shape similarity. Rather, attention to shape and other object dimensions has been shown to be context, stimulus, and language specific, and thus exquisitely tuned to the language being learned (see, <a href=\"#R69\">Smith &amp; Samuelson, 2006</a>; <a href=\"#R83\">Yoshida &amp; Smith, 2003</a>). Furthermore, recent studies suggest that children who learn to attend to shape when naming novel objects subsequently show accelerated vocabulary development (<a href=\"#R50\">Samuelson, 2002</a>; <a href=\"#R68\">Smith, Jones, Landau, Gershkoff-Stowe, &amp; Samuelson, 2002</a>) and that development of a shape bias is related to the development of the early noun vocabulary (<a href=\"#R27\">Gershkoff-Stowe &amp; Smith, 2004</a>; <a href=\"#R55\">Samuelson &amp; Smith, 1999</a>).</p>\n<p>Nevertheless, there has been sharp debate regarding the origin of the shape bias (<a href=\"#R8\">Booth &amp; Waxman, 2002</a>; <a href=\"#R15\">Diesendruck &amp; Bloom, 2003</a>; Smith, Yoshida, Colunga, Jones, &amp; Drake, 2003). At its core, this debate is about the foundational nature of cognition and whether knowledge/competence can be separated from performance (<a href=\"#R11\">Colunga &amp; Smith, 2008</a>; <a href=\"#R53\">Samuelson &amp; Horst, 2008</a>; <a href=\"#R69\">Smith &amp; Samuelson, 2006</a>). <a href=\"#R9\">Booth, Waxman &amp; Haung (2005)</a>, and Bloom and colleagues (<a href=\"#R6\">Bloom, 2000</a>; <a href=\"#R7\">Bloom &amp; Markson, 1998</a>; <a href=\"#R15\">Diesendruck &amp; Bloom, 2003</a>) argue that children's biased attention to shape reflects their conceptual understanding that shape is an important indicator of object kind. These arguments stem from a traditional view of cognition that parses mental activity into discrete and separable processes of sensing, thinking, and acting. In contrast, Smith and colleagues argue that the shape bias is an attentional bias that itself is the developmental product of the child's exposure to a language in which solidity and category organization by shape are highly correlated (<a href=\"#R65\">Smith, 2000</a>; <a href=\"#R69\">Smith &amp; Samuelson, 2006</a>). This idea stems from the view of cognition that sees knowledge as embedded in process and denies a separation between sensing, thinking, and acting.</p>\n<p>Critically, progress in this debate has been hampered by the fact that little attention has been paid to differences in the tasks and stimuli used to elicit noun generalizations in studies that purport to support one view over another. In this way, then, the word learning literature mirrors the larger developmental and cognitive science literatures both in terms of the existing disagreements concerning the nature of the cognitive system and in the need for a greater understanding of how the specifics of a task elicit knowledge in a moment. In the present paper, we examine these issues via a case study that probes similarities and differences in children's novel noun generalizations for solid and deformable things and, critically, how these differences depend on the details of the tasks that are used to elicit those generalizations. We show how an understanding of the processes that support behavior in a task yield insights into the nature of developmental changes in knowledge.</p>\n<p>Our work is inspired by the view that knowledge is not separate from the processes that create behavior in a task. Note that this view does not deny a long-term accumulation of information based on specific experiences with objects and words. As applied to the development of the shape bias, this view suggests that as children learn individual name-object pairings, they learn a system of regularities between linguistic devices, the structure of object categories, and perceptual properties (see <a href=\"#R69\">Smith &amp; Sam",
        "html": "<div><div>\n<main>\n<article><section><div>\n<p>. Author manuscript; available in PMC: 2011 Mar 24.</p></div></section><section><section><h2>Abstract</h2>\n<p>The present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decision processes in these tasks were instantiated in a dynamic field model. The model captures both qualitative and quantitative differences in performance across tasks and reveals constraints on the nature of children's accumulated knowledge. Additional simulations of developmental change in the yes/no task between 2 and 4 years of age illustrate how changes in children's representations translate into developmental changes in behavior. Together, the empirical data and model demonstrate the dynamic nature of knowledge and are consistent with the perspective that knowledge cannot be separated from the task-specific processes that create behavior in the moment.</p></section><hr/>\n<p>There are numerous examples in the cognitive development literature where children's abilities appear to shift across ages and tasks in seemingly paradoxical ways. For example, studies with young infants suggest that three- and four-month-old children can use knowledge of physical laws of continuity and solidity to determine where a ball rolled down a ramp should stop (<a href=\"#R73\">Spelke, Breinlinger, Macomber, &amp; Jacobson, 1992</a>). Yet, when tested in similar paradigms, 2- and 3-year-old children do not seem to have this same knowledge (<a href=\"#R5\">Berthier, DeBlois, Poirier, Novak, &amp; Clifton, 2000</a>). Similarly, research suggests that 6- to 8-month-old infants can detect the numerical equivalence between sets of auditory and visual stimuli (<a href=\"#R79\">Starkey, Spelke, &amp; Gelman, 1990</a>); yet, 3-year-old children fail at a similar task (<a href=\"#R42\">Mix, Huttenlocher, &amp; Levine, 1996</a>). Such examples leave the field in a difficult position: how are we to know when a child possesses some bit of knowledge?</p>\n<p>This question comes from a view of cognition that separates knowledge from process. By this view, knowledge resides in the head of the child, waiting to be accessed by the appropriate stimuli or task. Thus, developmentalists design tasks to tap into children's knowledge; if children perform competently they are said to have the requisite knowledge, if children fail they are said to lack the knowledge. One problem with this view is that it pits children's competence (i.e., knowledge) against their performance (i.e., behavior). Consequently, when children fail at a task it can always be claimed that they have the knowledge, but that the task did not effectively elicit that knowledge (see <a href=\"#R72\">Sophian, 1997</a>, and commentaries for discussion). A second problem with this view is that it leaves unexplained what is critical for acting in the world and for the unfolding of developmental process—how knowledge is created and how it is brought to bear in a task.</p>\n<p>An alternative and growing view is that knowledge is not separate from the processes that create behavior in a task. That is, knowledge is not a unitary thing that can be had, rather, it is distributed in and across many processes (e.g. <a href=\"#R2\">Barsalou, 1999</a>; <a href=\"#R47\">Plumert, in press</a>; <a href=\"#R48\">Port &amp; VanGelder, 1995</a>; <a href=\"#R57\">Samuelson &amp; Smith, 2000b</a>; <a href=\"#R64\">Skarda &amp; Freeman, 1987</a>; <a href=\"#R75\">Spencer &amp; Schöner, 2003</a>; <a href=\"#R78\">Spivey &amp; Dale, 2006</a>; <a href=\"#R81\">Thelen &amp; Smith, 1994</a>). By this view, one cannot ask about knowledge independent of the task that brings that knowledge to bear in a moment in time. Rather, the question to be asked is how the specifics of the task cohere with the child's prior history of perceiving, thinking, and acting to create behavior in the moment.</p>\n<p>Direct support for this view in developmental science comes from work by Esther Thelen, Linda Smith, and their colleagues showing how infants’ performance in the classic Piagetian A-not-B task is influenced by a host of intrinsic and extrinsic factors (<a href=\"#R10\">Clearfield, Diedrich, Smith, &amp; Thelen, 2006</a>; <a href=\"#R13\">Diedrich, Highlands, Thelen, &amp; Smith, 2001</a>; <a href=\"#R14\">Diedrich, Thelen, Smith, &amp; Corbetta, 2000</a>; <a href=\"#R70\">Smith, Thelen, Titzer, &amp; McLin, 1999</a>; <a href=\"#R80\">Thelen, Schöner, Scheier, &amp; Smith, 2001</a>; <a href=\"#R82\">Thelen &amp; Smith, 1997</a>). Although such studies have contributed foundational support for the idea that knowledge is bound to behavior in a particular task, the implications of this work for cognition more generally have been called into question given that the A-not-B phenomenon is largely grounded in sensori-motor activity (<a href=\"#R21\">Freeman, 2001</a>; <a href=\"#R29\">Glenberg, Cowart, &amp; Kaschak, 2001</a>; <a href=\"#R41\">Markman, 2001</a>; <a href=\"#R43\">Munakata &amp; McClelland, 2003</a>; but see <a href=\"#R75\">Spencer &amp; Schöner, 2003</a>). An important question, then, is whether this view has implications for higher-order cognition.</p>\n<p>This question is well illustrated by a current debate in the word learning literature (see <a href=\"#R51\">Samuelson &amp; Bloom, 2008</a>). In a typical experimental procedure, a young child shown a novel solid, rigid object and told a novel name (e.g., “this is a dax”) will most likely say that only other objects that share the same shape as the exemplar can be called by the same name (<a href=\"#R32\">Imai, Gentner, &amp; Uchida, 1994</a>; <a href=\"#R37\">Landau, Smith, &amp; Jones, 1988</a>; <a href=\"#R55\">Samuelson &amp; Smith, 1999</a>). Young children are thus said to show a “shape bias” when generalizing novel names for solid objects. Importantly, however, children do not always generalize novel names by shape similarity. Rather, attention to shape and other object dimensions has been shown to be context, stimulus, and language specific, and thus exquisitely tuned to the language being learned (see, <a href=\"#R69\">Smith &amp; Samuelson, 2006</a>; <a href=\"#R83\">Yoshida &amp; Smith, 2003</a>). Furthermore, recent studies suggest that children who learn to attend to shape when naming novel objects subsequently show accelerated vocabulary development (<a href=\"#R50\">Samuelson, 2002</a>; <a href=\"#R68\">Smith, Jones, Landau, Gershkoff-Stowe, &amp; Samuelson, 2002</a>) and that development of a shape bias is related to the development of the early noun vocabulary (<a href=\"#R27\">Gershkoff-Stowe &amp; Smith, 2004</a>; <a href=\"#R55\">Samuelson &amp; Smith, 1999</a>).</p>\n<p>Nevertheless, there has been sharp debate regarding the origin of the shape bias (<a href=\"#R8\">Booth &amp; Waxman, 2002</a>; <a href=\"#R15\">Diesendruck &amp; Bloom, 2003</a>; Smith, Yoshida, Colunga, Jones, &amp; Drake, 2003). At its core, this debate is about the foundational nature of cognition and whether knowledge/competence can be separated from performance (<a href=\"#R11\">Colunga &amp; Smith, 2008</a>; <a href=\"#R53\">Samuelson &amp; Horst, 2008</a>; <a href=\"#R69\">Smith &amp; Samuelson, 2006</a>). <a href=\"#R9\">Booth, Waxman &amp; Haung (2005)</a>, and Bloom and colleagues (<a href=\"#R6\">Bloom, 2000</a>; <a href=\"#R7\">Bloom &amp; Markson, 1998</a>; <a href=\"#R15\">Diesendruck &amp; Bloom, 2003</a>) argue that children's biased attention to shape reflects their conceptual understanding that shape is an important indicator of object kind. These arguments stem from a traditional view of cognition that parses mental activity into discrete and separable processes of sensing, thinking, and acting. In contrast, Smith and colleagues argue that the shape bias is an attentional bias that itself is the developmental product of the child's exposure to a language in which solidity and category organization by shape are highly correlated (<a href=\"#R65\">Smith, 2000</a>; <a href=\"#R69\">Smith &amp; Samuelson, 2006</a>). This idea stems from the view of cognition that sees knowledge as embedded in process and denies a separation between sensing, thinking, and acting.</p>\n<p>Critically, progress in this debate has been hampered by the fact that little attention has been paid to differences in the tasks and stimuli used to elicit noun generalizations in studies that purport to support one view over another. In this way, then, the word learning literature mirrors the larger developmental and cognitive science literatures both in terms of the existing disagreements concerning the nature of the cognitive system and in the need for a greater understanding of how the specifics of a task elicit knowledge in a moment. In the present paper, we examine these issues via a case study that probes similarities and differences in children's novel noun generalizations for solid and deformable things and, critically, how these differences depend on the details of the tasks that are used to elicit those generalizations. We show how an understanding of the processes that support behavior in a task yield insights into the nature of developmental changes in knowledge.</p>\n<p>Our work is inspired by the view that knowledge is not separate from the processes that create behavior in a task. Note that this view does not deny a long-term accumulation of information based on specific experiences with objects and words. As applied to the development of the shape bias, this view suggests that as children learn individual name-object pairings, they learn a system of regularities between linguistic devices, the structure of object categories, and perceptual properties (see <a href=\"#R69\">Smith &amp; Sam",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": ". Author manuscript; available in PMC: 2011 Mar 24.AbstractThe present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decisi",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": ". Author manuscript; available in PMC: 2011 Mar 24.AbstractThe present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decisi",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": ". Author manuscript; available in PMC: 2011 Mar 24.AbstractThe present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decisi",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": ". Author manuscript; available in PMC: 2011 Mar 24.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": ". Author manuscript; available in PMC: 2011 Mar 24.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractThe present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decision processes in these tasks were instantiated in a ",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractThe present paper examines the tie between knowledge and behavior in a noun generalization context. An experiment directly comparing noun generalizations of children at the same point in development in forced choice and yes/no tasks reveals task-specific differences in the way children's knowledge of nominal categories is brought to bear in a moment. To understand the cognitive system that produced these differences, the real-time decision processes in these tasks were instantiated in a ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.irma-international.org/viewtitle/49001/?isxn=9781599049311",
      "title": "",
      "author": "",
      "published_date": "2025-01-19T00:00:00.000Z",
      "content": {
        "text": "515\nCopyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nChapter 50\nKnowledge Communication\nMartin J. Eppler\nUniversity of Lugano, Switzerland\nCategory: Processes of Knowledge Management\nINTRODUCTION: THE IMPORTANCE\nOF KNOWLEDGE COMMUNICATION\nIN MANAGEMENT\nCommunicating professional knowledge is a key\nactivity for today’s specialized workforce. The\nefficient and effective transfer of experiences, in\u0002sights, and know-how among different experts and\ndecision makers is a prerequisite for high-quality\ndecision making and coordinated, organizational\naction (Straub & Karahanna, 1998). Situations\nof such deliberate (interfunctional) knowledge\ntransfer through interpersonal communication\nor group conversations (Gratton & Goshal, 2002)\ncan be found in many business constellations, as\nthe following typical examples illustrate:\nTechnology experts present their evaluation\nof a new technology to management in order to\njointly devise a new production strategy (McDer\u0002mott, 1999). Engineers who have discovered how\nto master a difficult manufacturing process need\nto convey their methods to engineers in other\nbusiness units (Szulanski, 1996, 1999). Legal\nexperts brief a management team on the implica\u0002tions of new regulations on their business model\n(Wilmotte & Morgan, 1984). Experts from various\ndomains need to share their views and insights\nregarding a common goal in order to agree on a\ncommon rating of risks, requirements (Browne\n& Ramesh, 2002), industries, or clients. Project\nleaders need to present their results to the upper\nmanagement and share their experiences of past\nprojects in order to assess the potential of new\nproject candidates (Schindler & Eppler, 2003).\nScientists who work as drug developers present\nnew avenues for future products that business unit\nmanagers must assess. Market researchers pres\u0002ent their statistical analyses of recent consumer\nsurveys to the head of marketing (Boland et al.,\n2001). Strategy consultants present the findings\nof their strategic company assessment to the\nboard of directors in order to devise adequate\nmeasures (Creplet, Duouet, Kern, Mehmanzapir,\n& Munier, 2001).\nWhat these diverse situations all have in com\u0002mon is the problem of knowledge asymmetry\n(Sharma, 1997) that has to be resolved through\ninterpersonal communication. While the manager\ntypically has the authority to make strategic or\ntactical decisions, he or she often lacks the spe\u0002cialized expertise required to make an informed\nDOI: 10.4018/978-1-59904-931-1.ch050\nKnowledge Communication\n516\ndecision on a complex issue (Watson, 2004).\nBecause of the wide scope of decisions that need\nto be made, a manager frequently has to delegate\nthe decision preparation to experts who—based\non their professional training and previous ex\u0002perience—can analyze complex situations or\ntechnological options in a more reliable manner.\nThe results of such analyses then need to be\ncommunicated back to the manager, often under\nconsiderable time constraints. The knowledge\ncommunication challenge, however, begins long\nbefore that, at the time when the manager has to\nconvey his or her knowledge needs and decision\nconstraints to the experts in order to delegate the\nanalysis task effectively.\nBACKGROUND: THE CONCEPT OF\nKNOWLEDGE COMMUNICATION\nBased on the reasoning described in the previous\nsection, we define knowledge communication as\nthe (deliberate) activity of interactively conveying\nand co-constructing insights, assessments, expe\u0002riences, or skills through verbal and non-verbal\nmeans. Knowledge communication has taken\nplace when an insight, experience, or skill has\nbeen successfully reconstructed by an individual\nbecause of the communicative actions of another.\nKnowledge communication thus designates the\nsuccessful transfer of know-how (e.g., how to ac\u0002complish a task), know-why (e.g., the cause-effect\nrelationships of a complex phenomenon), know\u0002what (e.g., the results of a test), and know-who (e.g.,\nthe experiences with others) through face-to-face\n(co-located) or media-based (virtual) interactions.\nThis type of knowledge communication can take\nplace synchronously or asynchronously.1 The\nfirst mode of communication refers to (often\nface-to-face) real-time interactions, while the\nlatter designates delayed (usually media-based)\ninteractions.\nWe use the term knowledge dialogues for\nthe first type of (synchronous) knowledge com\u0002munication, stressing the interactive and col\u0002laborative style of knowledge exchange in this\ncommunication mode (see Isaacs, 1997; Nonaka,\nToyama, & Konno, 2000). Depending on the\nknowledge-focused goal of such dialogues, we\ndistinguish among Crealogues (that focus on\nin the creation of new insights), Sharealogues\n(facilitating knowledge transfer), Assessalogues\n(focusing on the evaluation of new insights), and\nDoalogues (e.g., turning understanding into com\u0002mitted action, i.e., ‘talk the walk’). Each type of\nknowledge dialogue requires different behavior\nand interaction patterns and support measures\n(e.g., whereas Assessalogues require critical,\nconvergent evaluation tools, Crealogues require\nan open atmosphere for divergent thinking and\nrapid idea generation without judgment).\nWith regard to asynchronous knowledge\ncommunication, we refer to the concept of knowl\u0002edge media (see Eppler, Röpnack, & Seifried,\n1999) as enabling knowledge transfer through\ntechnology-based communication, collaboration,\ne-learning, aggregation, retrieval, and archiving\nservices. Knowledge media can be differentiated\nin terms of their target community, such as scien\u0002tific knowledge media, public knowledge media,\nprofessional knowledge media, and so forth. The\nconcept of knowledge media in general stresses\nthe importance of a community that collaborates\nregularly using a common platform that consists\nnot only of IT functionalities, but also of common\ncommunication norms and (usage) rules.\nIn this understanding, knowledge communica\u0002tion is more than communicating information (e.g.,\nfacts, figures, events, situations, developments,\netc.) or emotions (e.g., fears, hopes, reservations,\ncommitment) because it requires conveying\ncontext, background, and basic assumptions.\nIt requires the communication of personal in\u0002sights and experiences. Communicating insights\nrequires the elicitation of one’s rationale and\nreasoning (i.e., one’s argumentation structure);\nof one’s perspective, ratings, and priorities; and\nof one’s hunches and intuition. At times it may\n10 more pages are available in the full version of this document, which may\nbe purchased using the \"Add to Cart\" button on the publisher's webpage:\nwww.igi-global.com/chapter/knowledge-communication/49001\nRelated Content\nCase Studies on Applying Knowledge Economy Principles for Economic Growth in Developing\nNations: CanopyLAB Implementing LXPs in Digitally Challenged Areas\nDavid E. Pinesand Natalia Bernal Restrepo (2022). Cases on Applying Knowledge Economy Principles for\nEconomic Growth in Developing Nations (pp. 91-107).\nwww.irma-international.org/chapter/case-studies-on-applying-knowledge-economy-principles-for-economic-growth-in\u0002developing-nations/296221\n“They Care, We Share”: Perceived Fairness in Performance Appraisal Systems on Knowledge\nSharing\nJatinder Kumar Jhaand Prantika Ray (2022). International Journal of Knowledge Management (pp. 1-28).\nwww.irma-international.org/article/they-care-we-share/291095\nData in the Wild: A KM Approach to Collecting Census Data Without Surveying the Population\nand the Issue of Data Privacy\nJames Kelly, Murray Eugene Jennex, Kaveh Abhari, Alexandra Durcikovaand Eric Frost (2020). Knowledge\nManagement, Innovation, and Entrepreneurship in a Changing World (pp. 286-312).\nwww.irma-international.org/chapter/data-in-the-wild/250978\nThe Impact of Supporting Organizational Knowledge Management through a Corporate Portal on\nEmployees and Business Processes\nKamla Ali Al-Busaidi (2010). International Journal of Knowledge Management (pp. 44-64).\nwww.irma-international.org/article/impact-supporting-organizational-knowledge-management/45168\nIntegrating Knowledge Management into Information Security: From Audit to Practice\nCheuk Hang Auand Walter S. L. Fung (2019). International Journal of Knowledge Management (pp. 37-52).\nwww.irma-international.org/article/integrating-knowledge-management-into-information-security/218233",
        "html": "515\nCopyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nChapter 50\nKnowledge Communication\nMartin J. Eppler\nUniversity of Lugano, Switzerland\nCategory: Processes of Knowledge Management\nINTRODUCTION: THE IMPORTANCE\nOF KNOWLEDGE COMMUNICATION\nIN MANAGEMENT\nCommunicating professional knowledge is a key\nactivity for today’s specialized workforce. The\nefficient and effective transfer of experiences, in\u0002sights, and know-how among different experts and\ndecision makers is a prerequisite for high-quality\ndecision making and coordinated, organizational\naction (Straub & Karahanna, 1998). Situations\nof such deliberate (interfunctional) knowledge\ntransfer through interpersonal communication\nor group conversations (Gratton & Goshal, 2002)\ncan be found in many business constellations, as\nthe following typical examples illustrate:\nTechnology experts present their evaluation\nof a new technology to management in order to\njointly devise a new production strategy (McDer\u0002mott, 1999). Engineers who have discovered how\nto master a difficult manufacturing process need\nto convey their methods to engineers in other\nbusiness units (Szulanski, 1996, 1999). Legal\nexperts brief a management team on the implica\u0002tions of new regulations on their business model\n(Wilmotte & Morgan, 1984). Experts from various\ndomains need to share their views and insights\nregarding a common goal in order to agree on a\ncommon rating of risks, requirements (Browne\n& Ramesh, 2002), industries, or clients. Project\nleaders need to present their results to the upper\nmanagement and share their experiences of past\nprojects in order to assess the potential of new\nproject candidates (Schindler & Eppler, 2003).\nScientists who work as drug developers present\nnew avenues for future products that business unit\nmanagers must assess. Market researchers pres\u0002ent their statistical analyses of recent consumer\nsurveys to the head of marketing (Boland et al.,\n2001). Strategy consultants present the findings\nof their strategic company assessment to the\nboard of directors in order to devise adequate\nmeasures (Creplet, Duouet, Kern, Mehmanzapir,\n& Munier, 2001).\nWhat these diverse situations all have in com\u0002mon is the problem of knowledge asymmetry\n(Sharma, 1997) that has to be resolved through\ninterpersonal communication. While the manager\ntypically has the authority to make strategic or\ntactical decisions, he or she often lacks the spe\u0002cialized expertise required to make an informed\nDOI: 10.4018/978-1-59904-931-1.ch050\nKnowledge Communication\n516\ndecision on a complex issue (Watson, 2004).\nBecause of the wide scope of decisions that need\nto be made, a manager frequently has to delegate\nthe decision preparation to experts who—based\non their professional training and previous ex\u0002perience—can analyze complex situations or\ntechnological options in a more reliable manner.\nThe results of such analyses then need to be\ncommunicated back to the manager, often under\nconsiderable time constraints. The knowledge\ncommunication challenge, however, begins long\nbefore that, at the time when the manager has to\nconvey his or her knowledge needs and decision\nconstraints to the experts in order to delegate the\nanalysis task effectively.\nBACKGROUND: THE CONCEPT OF\nKNOWLEDGE COMMUNICATION\nBased on the reasoning described in the previous\nsection, we define knowledge communication as\nthe (deliberate) activity of interactively conveying\nand co-constructing insights, assessments, expe\u0002riences, or skills through verbal and non-verbal\nmeans. Knowledge communication has taken\nplace when an insight, experience, or skill has\nbeen successfully reconstructed by an individual\nbecause of the communicative actions of another.\nKnowledge communication thus designates the\nsuccessful transfer of know-how (e.g., how to ac\u0002complish a task), know-why (e.g., the cause-effect\nrelationships of a complex phenomenon), know\u0002what (e.g., the results of a test), and know-who (e.g.,\nthe experiences with others) through face-to-face\n(co-located) or media-based (virtual) interactions.\nThis type of knowledge communication can take\nplace synchronously or asynchronously.1 The\nfirst mode of communication refers to (often\nface-to-face) real-time interactions, while the\nlatter designates delayed (usually media-based)\ninteractions.\nWe use the term knowledge dialogues for\nthe first type of (synchronous) knowledge com\u0002munication, stressing the interactive and col\u0002laborative style of knowledge exchange in this\ncommunication mode (see Isaacs, 1997; Nonaka,\nToyama, & Konno, 2000). Depending on the\nknowledge-focused goal of such dialogues, we\ndistinguish among Crealogues (that focus on\nin the creation of new insights), Sharealogues\n(facilitating knowledge transfer), Assessalogues\n(focusing on the evaluation of new insights), and\nDoalogues (e.g., turning understanding into com\u0002mitted action, i.e., ‘talk the walk’). Each type of\nknowledge dialogue requires different behavior\nand interaction patterns and support measures\n(e.g., whereas Assessalogues require critical,\nconvergent evaluation tools, Crealogues require\nan open atmosphere for divergent thinking and\nrapid idea generation without judgment).\nWith regard to asynchronous knowledge\ncommunication, we refer to the concept of knowl\u0002edge media (see Eppler, Röpnack, & Seifried,\n1999) as enabling knowledge transfer through\ntechnology-based communication, collaboration,\ne-learning, aggregation, retrieval, and archiving\nservices. Knowledge media can be differentiated\nin terms of their target community, such as scien\u0002tific knowledge media, public knowledge media,\nprofessional knowledge media, and so forth. The\nconcept of knowledge media in general stresses\nthe importance of a community that collaborates\nregularly using a common platform that consists\nnot only of IT functionalities, but also of common\ncommunication norms and (usage) rules.\nIn this understanding, knowledge communica\u0002tion is more than communicating information (e.g.,\nfacts, figures, events, situations, developments,\netc.) or emotions (e.g., fears, hopes, reservations,\ncommitment) because it requires conveying\ncontext, background, and basic assumptions.\nIt requires the communication of personal in\u0002sights and experiences. Communicating insights\nrequires the elicitation of one’s rationale and\nreasoning (i.e., one’s argumentation structure);\nof one’s perspective, ratings, and priorities; and\nof one’s hunches and intuition. At times it may\n10 more pages are available in the full version of this document, which may\nbe purchased using the \"Add to Cart\" button on the publisher's webpage:\nwww.igi-global.com/chapter/knowledge-communication/49001\nRelated Content\nCase Studies on Applying Knowledge Economy Principles for Economic Growth in Developing\nNations: CanopyLAB Implementing LXPs in Digitally Challenged Areas\nDavid E. Pinesand Natalia Bernal Restrepo (2022). Cases on Applying Knowledge Economy Principles for\nEconomic Growth in Developing Nations (pp. 91-107).\nwww.irma-international.org/chapter/case-studies-on-applying-knowledge-economy-principles-for-economic-growth-in\u0002developing-nations/296221\n“They Care, We Share”: Perceived Fairness in Performance Appraisal Systems on Knowledge\nSharing\nJatinder Kumar Jhaand Prantika Ray (2022). International Journal of Knowledge Management (pp. 1-28).\nwww.irma-international.org/article/they-care-we-share/291095\nData in the Wild: A KM Approach to Collecting Census Data Without Surveying the Population\nand the Issue of Data Privacy\nJames Kelly, Murray Eugene Jennex, Kaveh Abhari, Alexandra Durcikovaand Eric Frost (2020). Knowledge\nManagement, Innovation, and Entrepreneurship in a Changing World (pp. 286-312).\nwww.irma-international.org/chapter/data-in-the-wild/250978\nThe Impact of Supporting Organizational Knowledge Management through a Corporate Portal on\nEmployees and Business Processes\nKamla Ali Al-Busaidi (2010). International Journal of Knowledge Management (pp. 44-64).\nwww.irma-international.org/article/impact-supporting-organizational-knowledge-management/45168\nIntegrating Knowledge Management into Information Security: From Audit to Practice\nCheuk Hang Auand Walter S. L. Fung (2019). International Journal of Knowledge Management (pp. 37-52).\nwww.irma-international.org/article/integrating-knowledge-management-into-information-security/218233",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://document360.com/knowledge-management/",
      "title": "Knowledge Management Guide: Types, Use Cases & More",
      "author": "",
      "published_date": "2024-06-03T05:41:25.000Z",
      "content": {
        "text": "<div><div>\n<div>\n<h2>Introduction</h2>\n<p>Knowledge is the lifeblood of every company. Without capturing knowledge, you’ll find it difficult to make decisions, learn from your mistakes, and develop new products. Knowledge Management is the approach you might take to capturing, organizing and sharing your company knowledge with both internal and external stakeholders.</p>\n<p>Knowledge Management is not a new concept and has been slowly developing in the business and academic worlds for a number of years. New technologies and the way we store information is changing how Knowledge Management initiatives operate.</p>\n<p>It’s not easy to set up a successful Knowledge Management system and it needs to be tailored to your own unique needs and circumstances. You need to gain a good grasp of how to structure your system, the potential obstacles that are in your way, and the most effective tools that will enable you to implement your system.</p>\n<p>In this guide, we are going to cover the definition of Knowledge Management, why Knowledge Management is important, challenges in Knowledge Management, Knowledge Management use cases, and more.</p>\n<h2>What is Knowledge Management?</h2>\n<blockquote>\n<p>“Knowledge Management is the process of capturing, distributing, and effectively using knowledge.” <a href=\"https://www.kmworld.com/About/What_is_Knowledge_Management\">Tom Davenport (1994). </a></p>\n</blockquote>\n<p>Knowledge Management is the process of making the knowledge available for everyone in your team, instead of having it reside in the heads of the few and causing information silos. Companies can more easily achieve their objectives by making better use of the knowledge that resides within their domain. They develop a culture of continuous learning and allow knowledge to flow freely throughout their organization.</p>\n<p>Knowledge Management includes those necessary systems and tools for creating effective KM processes. It is a combination of people, processes and tools.</p>\n</div>\n<hr/>\n<div>\n<p>When we are dealing with knowledge within an organization there are three different types that we need to be aware of.</p>\n<h3>Explicit</h3>\n<p>Explicit knowledge is information that can be codified and communicated. It’s easy to share this type of knowledge and it can be quickly understood by others. Some types of explicit knowledge are standard operating procedures, employee handbooks, and HR policies.</p>\n<h3>Tacit</h3>\n<p><a href=\"https://document360.com/blog/tacit-knowledge/\">Tacit knowledge</a> is much harder to capture than explicit knowledge. It typically comprises the skills and experience of your employee that is difficult to explain or share with others. Tacit knowledge includes customer support know-how, design skills, and so on.</p>\n<h3>Implicit</h3>\n<p>Implicit knowledge is very similar to tacit knowledge except that it can more easily be codified. It’s information that is embedded in the organization’s processes and is currently unarticulated. It’s tribal knowledge that can be learned and communicated but hasn’t yet been formally captured.</p>\n</div>\n<hr/>\n<div>\n<h2>Importance of Knowledge Management</h2>\n<p>Without Knowledge Management, it’s impossible to control or understand the way information flows through your organization.</p>\n<p>A lack of information management systems also puts knowledgeable employees under more pressure. In most cases, your team members will seek the help of their most knowledgeable peers. But, this also means that skilful employees will spend a lot of time helping others, which can put a dent in their productivity.</p>\n<p>Instead of relying on an unstructured system, information management lets you control the way knowledge flows in your company. In simple terms, a good system ensures that information is available to those who need it when they need it.</p>\n<p>What’s more, knowledge management is important because it can:</p>\n<h3>Capture Valuable Information</h3>\n<p>Regardless of the industry, your company should be the biggest source of information about your product. Data management allows you to capture valuable information from different sources. Then, you can create articles, videos, and similar resources that help users solve their problems.</p>\n<h3>Allow Easy Access to Knowledge Resources</h3>\n<p>Creating the resources your team and customers need is a great first step. But, this doesn’t mean it’s easy to access.</p>\n<p>It’s normal for an employee to spend more than 12 hours per week researching information. Knowledge management allows your team to track down resources through a centralized platform. In other words, employees can find the data they need without spending hours looking for a specific email or IM.</p>\n<h3>Cultivate an Environment Where Knowledge is Valued</h3>\n<p>The modern concept of knowledge management is relatively new. And, like many innovative business practices, there are many challenges that come with this new philosophy.</p>\n<p>One of the biggest setbacks is cultivating the right environment. Knowledge is as an advantage and your team should see it as such. By improving the way information flows, you can change the way your employees view knowledge resources. It can also help ingrain the idea that knowledge and collaboration are as valuable as any other business tool.</p>\n<h3>Help Treat Knowledgeable Employees as an Asset</h3>\n<p>In many cases, knowledgeable employees don’t feel like a valuable asset. Some companies expect them to take on more responsibility without showing gratitude or awarding recognition. Needless to say, this can result in high employee churn, which can translate into higher expenses.</p>\n<p>Knowledgeable employees play an important role in companies that focus on information sharing. It allows your skillful employees to share their knowledge without putting them under enormous pressure. This will make knowledgeable team members feel like the valuable assets they are and give them the credit they deserve.</p>\n</div>\n<hr/>\n<div>\n<h2>Knowledge Management Process – Creating, Organizing, Sharing, Analyzing &amp; Optimizing</h2>\n<p>The Knowledge Management process can be broken down into 5 steps.</p>\n<h3>Creating</h3>\n<p>Organizations should identify and record any knowledge that they want to disseminate across the company. Knowledge should be written down and adapted in a form that will be suitable for the target audience. You need to liaise with subject matter experts to capture knowledge that resides in their heads and turn it into content that can be available for anyone in the company.</p>\n<h3>Organizing</h3>\n<p>Once you have gathered the necessary information you need to store it in a way that makes sense for your chosen IT system. Knowledge may need to be formatted in a way that meets the requirements for your system. During this stage you will be uploading your content to your Knowledge Management system and organizing it into categories ready for consumption.</p>\n<h3>Sharing</h3>\n<p>A Knowledge Management system is no good if nobody can find it. You need to share your knowledge across email, collaboration systems, intranets and so on. If you see somebody asking a question that could be answered by your KM system then make a point to share the relevant article.</p>\n<h3>Analyzing</h3>\n<p>Over time, you need to analyze whether your content is working or not. You can look at search results to see terms that are returning no entries and create relevant content to fill the gap. You can identify articles that are not being used and delete them, and take note of any comments your audience has left to update articles.</p>\n<h3>Optimizing</h3>\n<p>This is the stage where you take action on your analysis. You need to keep current articles up-to-date and plug any knowledge gaps with new content. Actively solicit feedback from your users about how your Knowledge Management system is working and highlight any areas for improvement. It should always be evolving to keep pace with the changing knowledge in your organization.</p>\n</div>\n<hr/>\n<div>\n<h2>What can be included in a Knowledge Management System</h2>\n<p>There are many types of knowledge that can be included in a Knowledge Management system.</p>\n<ul>\n<li><a href=\"https://document360.com/blog/standard-operating-procedure/\">Standard operating procedures </a>– a set of instructions explaining how to complete a particular task, process or procedure</li>\n<li><a href=\"https://docs.document360.com/\">Documentation </a>– information relating to your product, service, or company</li>\n<li>HR policies – a set of guidelines explaining the policies of your company</li>\n<li>Academies and training programs – a set of tutorials and lessons that train employees in a particular area</li>\n<li>Webinars – recorded video sessions on a given topic</li>\n</ul>\n<div>\n<div>\n<h6>An intuitive knowledge management software to easily add your content and integrate it with any application. Give Document360 a try!</h6>\n<p><a href=\"https://document360.com/?utm_source=blog&amp;utm_medium=cta-button&amp;utm_campaign=Get%20Started\">Get Started</a></p></div>\n<p></p>\n</div>\n</div>\n<hr/>\n<div>\n<h2>Benefits of Knowledge Management</h2>\n<h3>1. Faster decision-making</h3>\n<p>When employees have easy access to the right knowledge this can accelerate their decision-making. Employees spend less time reinventing the wheel because they can learn from decisions that have already been made and benefit from collective wisdom.</p>\n<h3>2. Efficient access to knowledge and information</h3>\n<p>Employees spend a significant portion of their working week simply searching for information that should be readily available. With the right Knowledge Management program employees will have efficient access to knowledge and be able to spend more of their time on outcome-focused assignments that directly benefit the company.</p>\n<h3>3. Increased collaboration and idea generation</h3>\n<p>When knowledge is shared effectively this promotes collaboration betwe",
        "html": "<div><div>\n<div>\n<h2>Introduction</h2>\n<p>Knowledge is the lifeblood of every company. Without capturing knowledge, you’ll find it difficult to make decisions, learn from your mistakes, and develop new products. Knowledge Management is the approach you might take to capturing, organizing and sharing your company knowledge with both internal and external stakeholders.</p>\n<p>Knowledge Management is not a new concept and has been slowly developing in the business and academic worlds for a number of years. New technologies and the way we store information is changing how Knowledge Management initiatives operate.</p>\n<p>It’s not easy to set up a successful Knowledge Management system and it needs to be tailored to your own unique needs and circumstances. You need to gain a good grasp of how to structure your system, the potential obstacles that are in your way, and the most effective tools that will enable you to implement your system.</p>\n<p>In this guide, we are going to cover the definition of Knowledge Management, why Knowledge Management is important, challenges in Knowledge Management, Knowledge Management use cases, and more.</p>\n<h2>What is Knowledge Management?</h2>\n<blockquote>\n<p>“Knowledge Management is the process of capturing, distributing, and effectively using knowledge.” <a href=\"https://www.kmworld.com/About/What_is_Knowledge_Management\">Tom Davenport (1994). </a></p>\n</blockquote>\n<p>Knowledge Management is the process of making the knowledge available for everyone in your team, instead of having it reside in the heads of the few and causing information silos. Companies can more easily achieve their objectives by making better use of the knowledge that resides within their domain. They develop a culture of continuous learning and allow knowledge to flow freely throughout their organization.</p>\n<p>Knowledge Management includes those necessary systems and tools for creating effective KM processes. It is a combination of people, processes and tools.</p>\n</div>\n<hr/>\n<div>\n<p>When we are dealing with knowledge within an organization there are three different types that we need to be aware of.</p>\n<h3>Explicit</h3>\n<p>Explicit knowledge is information that can be codified and communicated. It’s easy to share this type of knowledge and it can be quickly understood by others. Some types of explicit knowledge are standard operating procedures, employee handbooks, and HR policies.</p>\n<h3>Tacit</h3>\n<p><a href=\"https://document360.com/blog/tacit-knowledge/\">Tacit knowledge</a> is much harder to capture than explicit knowledge. It typically comprises the skills and experience of your employee that is difficult to explain or share with others. Tacit knowledge includes customer support know-how, design skills, and so on.</p>\n<h3>Implicit</h3>\n<p>Implicit knowledge is very similar to tacit knowledge except that it can more easily be codified. It’s information that is embedded in the organization’s processes and is currently unarticulated. It’s tribal knowledge that can be learned and communicated but hasn’t yet been formally captured.</p>\n</div>\n<hr/>\n<div>\n<h2>Importance of Knowledge Management</h2>\n<p>Without Knowledge Management, it’s impossible to control or understand the way information flows through your organization.</p>\n<p>A lack of information management systems also puts knowledgeable employees under more pressure. In most cases, your team members will seek the help of their most knowledgeable peers. But, this also means that skilful employees will spend a lot of time helping others, which can put a dent in their productivity.</p>\n<p>Instead of relying on an unstructured system, information management lets you control the way knowledge flows in your company. In simple terms, a good system ensures that information is available to those who need it when they need it.</p>\n<p>What’s more, knowledge management is important because it can:</p>\n<h3>Capture Valuable Information</h3>\n<p>Regardless of the industry, your company should be the biggest source of information about your product. Data management allows you to capture valuable information from different sources. Then, you can create articles, videos, and similar resources that help users solve their problems.</p>\n<h3>Allow Easy Access to Knowledge Resources</h3>\n<p>Creating the resources your team and customers need is a great first step. But, this doesn’t mean it’s easy to access.</p>\n<p>It’s normal for an employee to spend more than 12 hours per week researching information. Knowledge management allows your team to track down resources through a centralized platform. In other words, employees can find the data they need without spending hours looking for a specific email or IM.</p>\n<h3>Cultivate an Environment Where Knowledge is Valued</h3>\n<p>The modern concept of knowledge management is relatively new. And, like many innovative business practices, there are many challenges that come with this new philosophy.</p>\n<p>One of the biggest setbacks is cultivating the right environment. Knowledge is as an advantage and your team should see it as such. By improving the way information flows, you can change the way your employees view knowledge resources. It can also help ingrain the idea that knowledge and collaboration are as valuable as any other business tool.</p>\n<h3>Help Treat Knowledgeable Employees as an Asset</h3>\n<p>In many cases, knowledgeable employees don’t feel like a valuable asset. Some companies expect them to take on more responsibility without showing gratitude or awarding recognition. Needless to say, this can result in high employee churn, which can translate into higher expenses.</p>\n<p>Knowledgeable employees play an important role in companies that focus on information sharing. It allows your skillful employees to share their knowledge without putting them under enormous pressure. This will make knowledgeable team members feel like the valuable assets they are and give them the credit they deserve.</p>\n</div>\n<hr/>\n<div>\n<h2>Knowledge Management Process – Creating, Organizing, Sharing, Analyzing &amp; Optimizing</h2>\n<p>The Knowledge Management process can be broken down into 5 steps.</p>\n<h3>Creating</h3>\n<p>Organizations should identify and record any knowledge that they want to disseminate across the company. Knowledge should be written down and adapted in a form that will be suitable for the target audience. You need to liaise with subject matter experts to capture knowledge that resides in their heads and turn it into content that can be available for anyone in the company.</p>\n<h3>Organizing</h3>\n<p>Once you have gathered the necessary information you need to store it in a way that makes sense for your chosen IT system. Knowledge may need to be formatted in a way that meets the requirements for your system. During this stage you will be uploading your content to your Knowledge Management system and organizing it into categories ready for consumption.</p>\n<h3>Sharing</h3>\n<p>A Knowledge Management system is no good if nobody can find it. You need to share your knowledge across email, collaboration systems, intranets and so on. If you see somebody asking a question that could be answered by your KM system then make a point to share the relevant article.</p>\n<h3>Analyzing</h3>\n<p>Over time, you need to analyze whether your content is working or not. You can look at search results to see terms that are returning no entries and create relevant content to fill the gap. You can identify articles that are not being used and delete them, and take note of any comments your audience has left to update articles.</p>\n<h3>Optimizing</h3>\n<p>This is the stage where you take action on your analysis. You need to keep current articles up-to-date and plug any knowledge gaps with new content. Actively solicit feedback from your users about how your Knowledge Management system is working and highlight any areas for improvement. It should always be evolving to keep pace with the changing knowledge in your organization.</p>\n</div>\n<hr/>\n<div>\n<h2>What can be included in a Knowledge Management System</h2>\n<p>There are many types of knowledge that can be included in a Knowledge Management system.</p>\n<ul>\n<li><a href=\"https://document360.com/blog/standard-operating-procedure/\">Standard operating procedures </a>– a set of instructions explaining how to complete a particular task, process or procedure</li>\n<li><a href=\"https://docs.document360.com/\">Documentation </a>– information relating to your product, service, or company</li>\n<li>HR policies – a set of guidelines explaining the policies of your company</li>\n<li>Academies and training programs – a set of tutorials and lessons that train employees in a particular area</li>\n<li>Webinars – recorded video sessions on a given topic</li>\n</ul>\n<div>\n<div>\n<h6>An intuitive knowledge management software to easily add your content and integrate it with any application. Give Document360 a try!</h6>\n<p><a href=\"https://document360.com/?utm_source=blog&amp;utm_medium=cta-button&amp;utm_campaign=Get%20Started\">Get Started</a></p></div>\n<p></p>\n</div>\n</div>\n<hr/>\n<div>\n<h2>Benefits of Knowledge Management</h2>\n<h3>1. Faster decision-making</h3>\n<p>When employees have easy access to the right knowledge this can accelerate their decision-making. Employees spend less time reinventing the wheel because they can learn from decisions that have already been made and benefit from collective wisdom.</p>\n<h3>2. Efficient access to knowledge and information</h3>\n<p>Employees spend a significant portion of their working week simply searching for information that should be readily available. With the right Knowledge Management program employees will have efficient access to knowledge and be able to spend more of their time on outcome-focused assignments that directly benefit the company.</p>\n<h3>3. Increased collaboration and idea generation</h3>\n<p>When knowledge is shared effectively this promotes collaboration betwe",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "IntroductionKnowledge is the lifeblood of every company. Without capturing knowledge, you’ll find it difficult to make decisions, learn from your mistakes, and develop new products. Knowledge Management is the approach you might take to capturing, organizing and sharing your company knowledge with both internal and external stakeholders.Knowledge Management is not a new concept and has been slowly developing in the business and academic worlds for a number of years. New technologies and the way ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionKnowledge is the lifeblood of every company. Without capturing knowledge, you’ll find it difficult to make decisions, learn from your mistakes, and develop new products. Knowledge Management is the approach you might take to capturing, organizing and sharing your company knowledge with both internal and external stakeholders.Knowledge Management is not a new concept and has been slowly developing in the business and academic worlds for a number of years. New technologies and the way ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionKnowledge is the lifeblood of every company. Without capturing knowledge, you’ll find it difficult to make decisions, learn from your mistakes, and develop new products. Knowledge Management is the approach you might take to capturing, organizing and sharing your company knowledge with both internal and external stakeholders.Knowledge Management is not a new concept and has been slowly developing in the business and academic worlds for a number of years. New technologies and the way ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "When we are dealing with knowledge within an organization there are three different types that we need to be aware of.ExplicitExplicit knowledge is information that can be codified and communicated. It’s easy to share this type of knowledge and it can be quickly understood by others. Some types of explicit knowledge are standard operating procedures, employee handbooks, and HR policies.TacitTacit knowledgeis much harder to capture than explicit knowledge. It typically comprises the skills and ex",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Importance of Knowledge ManagementWithout Knowledge Management, it’s impossible to control or understand the way information flows through your organization.A lack of information management systems also puts knowledgeable employees under more pressure. In most cases, your team members will seek the help of their most knowledgeable peers. But, this also means that skilful employees will spend a lot of time helping others, which can put a dent in their productivity.Instead of relying on an unstruc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Knowledge Management Process – Creating, Organizing, Sharing, Analyzing & OptimizingThe Knowledge Management process can be broken down into 5 steps.CreatingOrganizations should identify and record any knowledge that they want to disseminate across the company. Knowledge should be written down and adapted in a form that will be suitable for the target audience. You need to liaise with subject matter experts to capture knowledge that resides in their heads and turn it into content that can be ava",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "What can be included in a Knowledge Management SystemThere are many types of knowledge that can be included in a Knowledge Management system.Standard operating procedures– a set of instructions explaining how to complete a particular task, process or procedureDocumentation– information relating to your product, service, or companyHR policies – a set of guidelines explaining the policies of your companyAcademies and training programs – a set of tutorials and lessons that train employees in a part",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "An intuitive knowledge management software to easily add your content and integrate it with any application. Give Document360 a try!Get Started",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "An intuitive knowledge management software to easily add your content and integrate it with any application. Give Document360 a try!Get Started",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Benefits of Knowledge Management1. Faster decision-makingWhen employees have easy access to the right knowledge this can accelerate their decision-making. Employees spend less time reinventing the wheel because they can learn from decisions that have already been made and benefit from collective wisdom.2. Efficient access to knowledge and informationEmployees spend a significant portion of their working week simply searching for information that should be readily available. With the right Knowle",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "What is Knowledge Management?",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Explicit",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Tacit",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Implicit",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Importance of Knowledge Management",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Capture Valuable Information",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Allow Easy Access to Knowledge Resources",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Cultivate an Environment Where Knowledge is Valued",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Help Treat Knowledgeable Employees as an Asset",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Knowledge Management Process – Creating, Organizing, Sharing, Analyzing & Optimizing",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Creating",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Organizing",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Sharing",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Analyzing",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Optimizing",
              "id": ""
            },
            {
              "level": "h2",
              "text": "What can be included in a Knowledge Management System",
              "id": ""
            },
            {
              "level": "h6",
              "text": "An intuitive knowledge management software to easily add your content and integrate it with any application. Give Document360 a try!",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Benefits of Knowledge Management",
              "id": ""
            },
            {
              "level": "h3",
              "text": "1. Faster decision-making",
              "id": ""
            },
            {
              "level": "h3",
              "text": "2. Efficient access to knowledge and information",
              "id": ""
            },
            {
              "level": "h3",
              "text": "3. Increased collaboration and idea generation",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "http://www.tlainc.com/articl133.htm",
      "title": "Journal of Knowledge Management Practice,",
      "author": "",
      "published_date": "2007-05-31T03:23:00.000Z",
      "content": {
        "text": "<div><div>\n</div></div>",
        "html": "<div><div>\n</div></div>",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://ecampusontario.pressbooks.pub/knowledgemanagement/chapter/chapter-1/",
      "title": "Introduction to Knowledge Management and Communications",
      "author": "",
      "published_date": "2022-05-01T00:00:00.000Z",
      "content": {
        "text": "<div><section>\n<header>\n</header>\n<p></p>\n<p>Knowledge management and communication of research has become increasingly important to research funders, decision-makers in industry, government and the community, and members of the public. A strong knowledge management strategy (developing or using systems to manage access and use of your data) and a strong communication plan (moving your research knowledge in focused ways and more broadly) will help you to maximize the impact of your research – ultimately influencing social, health, environmental or economic changes within Canada and beyond.</p>\n<p>This course will walk you through the various components of knowledge management and communication. You’ll learn how to manage and share your data, tools to communicate your research, principles of social media engagement, guidelines to engage with communities, support for intellectual property management and commercialization, and strategies to engage with policy-makers.</p>\n<p>This introductory module will help you to think more deeply about knowledge management and mobilization. You’ll learn about various definitions and models of knowledge mobilization, the benefits of engaging with end users, and the basics of plain language communication – supporting you to start building a knowledge mobilization plan of your own.</p>\n</section></div>",
        "html": "<div><section>\n<header>\n</header>\n<p></p>\n<p>Knowledge management and communication of research has become increasingly important to research funders, decision-makers in industry, government and the community, and members of the public. A strong knowledge management strategy (developing or using systems to manage access and use of your data) and a strong communication plan (moving your research knowledge in focused ways and more broadly) will help you to maximize the impact of your research – ultimately influencing social, health, environmental or economic changes within Canada and beyond.</p>\n<p>This course will walk you through the various components of knowledge management and communication. You’ll learn how to manage and share your data, tools to communicate your research, principles of social media engagement, guidelines to engage with communities, support for intellectual property management and commercialization, and strategies to engage with policy-makers.</p>\n<p>This introductory module will help you to think more deeply about knowledge management and mobilization. You’ll learn about various definitions and models of knowledge mobilization, the benefits of engaging with end users, and the basics of plain language communication – supporting you to start building a knowledge mobilization plan of your own.</p>\n</section></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Knowledge management and communication of research has become increasingly important to research funders, decision-makers in industry, government and the community, and members of the public. A strong knowledge management strategy (developing or using systems to manage access and use of your data) and a strong communication plan (moving your research knowledge in focused ways and more broadly) will help you to maximize the impact of your research – ultimately influencing social, health, environm",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Knowledge management and communication of research has become increasingly important to research funders, decision-makers in industry, government and the community, and members of the public. A strong knowledge management strategy (developing or using systems to manage access and use of your data) and a strong communication plan (moving your research knowledge in focused ways and more broadly) will help you to maximize the impact of your research – ultimately influencing social, health, environm",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://dynamicemergence.net/what-is-dynamic-emergence-and-why-study-it/",
      "title": "Dynamic Emergence – why study it?",
      "author": "",
      "published_date": "2019-05-26T19:30:48.000Z",
      "content": {
        "text": "<div><div><main><article><div><h3><a href=\"https://dynamicemergence.net/events/de-course-1-de-explained-2/\">*Next online 6 week class June 19, 8pm GMT. Details/Register</a></h3>\n<blockquote>\n<p>There are lots of reasons to wonder who you are, and what you are here to do. You may already have a good idea of it, but then you look around and see how much good work there is still to be done, to help us evolve, to help yourself live a full life, to be all that you are designed to be. I’ve been studying this for a long time, very carefully, and I offer this to you to help you achieve all that, not just for yourself, but for all of us. Say yes to the invitation to deepen your experience of living this life with the knowledge and ability to do so on your own terms, your fullest life.</p>\n</blockquote>\n<h4><span><strong>Who… <em>what</em> are you??</strong></span></h4>\n<p>Are you aware that you are literally energy flowing, shaping itself into patterns <em>through</em> you, and <em>as</em> you, affecting your moods, your ideas, your thinking, even your creativity… affecting what happens next in your life? There are some really amazing things about being human that I’d like you to know about, to empower you, give you the gift of knowing your own energetic, psychic, social, physical territory, your own emotional truths. It’s simple, engaging and, quite honestly, an amazing thing to know about ourselves. After years of study, this is what I can now share with you. Use it for your freedom, your activism, your creative push, your social impact, your personal relationships, and your professional strength.<span></span></p>\n<h4><span><strong>What is it?</strong></span></h4>\n<p>Dynamic Emergence is a conceptual model of consciousness that has practical application. It is defined as <em>the phenomena of novelty arising when two or more elements meet</em> – in layperson’s terms it is <i>our process of becoming,</i> explained. DE shows how human energy systems works, i.e. how they move, interact, influence and create, it shares how we shape the creation of what happens next by what we know and what we do with that knowing – both conscious and unconscious. It is the exploration of the human experience of being a living system within networks of living systems, an exploration of how the universe talks to each of us uniquely, based on who we each uniquely are. It is how information comes to us, through us, and also travels from us, as information, feelings, and data. It demonstrates how we create belief systems based on the movement of energy and how we can track and re-shape those beliefs to grant us more freedom. It basically shows our potential and our infinite capacity and where we often limit that unknowingly.</p>\n<h4><span><strong>Why does it matter right now?</strong></span></h4>\n<p>There are millions of people being left out of the creation of societies around the world. This means we are losing intelligence, diverse ways of knowing, wisdom, compassionate, healthy, and robust societies. There has been a strong emphasis on only partial ways of knowing, the ways that support the creation of big business and fiscal profit creation. And yet, buried right within our fabric, is a social capital that surpasses all transitory attainments: US – body, heart, and soul. Those that get ‘left out’ become a burden on this type of society but are also an essential component to its idea of progress; to have winners you must have losers. This has lead to an intolerable – and tragic – burden not just on humans, but on our ecological home, planet Earth.</p>\n<h4><span><strong>Belonging</strong></span></h4>\n<p>There are many who feel they don’t belong, just because they haven’t been included. They haven’t been included because of a lack of understanding of <em>what</em> we are capable of being, <em>who</em> we are capable of being, and what we are capable of achieving, together. Artists, Highly Sensitive People, Sensitives, Empaths, Indigenous, Whole People (holistic), are aware of highly intelligent ways of being but not being invited to use that to help themselves, and their communities thrive. We can change that. If you look at where funding cuts occur in ‘developed’ countries, it’s the arts, and most particularly dance and theater and if you look at the health issues that drive many suicides and illnesses, it is the emotional, such as depression and disenfranchisement; not belonging. And yet DE shows us that we <em>do</em> belong, it shows us that we are designed to thrive in truly magical, pragmatic, and inspiring ways.</p>\n<h4><span><strong><em>Our</em> evolution is <em>the</em> evolution</strong></span></h4>\n<p>The importance of DE coming at this time, is that we are at a time of profound social and evolutionary change, with a deep need to understand who we are, so we can evolve safely into a sustainable future. It houses two tenets that relate to how we co-create: 1. Nothing is fixed and 2. Energy waits to be noticed (they are explained in the course). It contains experiential truths, personal truths, global truths. Learning about how we are made up, in the sense of our aliveness interacting, we can better understand our creativity, imagination, feelings, reactions, causality.</p>\n<h4><span><strong>Mastery</strong></span></h4>\n<p>Learning how to work with all of that gives us mastery, personal protection, definition, power, and sovereignty. It means we are at choice, capable of change, able to discern situations, study the movement of energy, and work with it. Learning about the nested hierarchies, or networks, that we co-exist in, we can learn to communicate with nature, and the extended field – i.e. make decisions about which social, geographical and professional environments to be in, and who to be around, with conviction, compassion, and confidence. This model embeds us within Planetary Consciousness and highlights the sentience of the Planet.</p>\n<h4><span><strong>What’s possible?</strong></span></h4>\n<p>We learn about what kinds of interior boundaries we made growing up (based on our psychic environment) and how that influenced all our future relationship choices, we can also see how we became – as a species – susceptible to today’s marketing and coercion by governments and corporations, to ‘buy buy buy’ and how some of us became susceptible to abuse or neglect. These influences and decisions can all be rectified. This can all be healed. We can emerge as we are meant to, into our own authentic sense of self, and power.</p>\n<p>Simply put, DE teaches us about energy, how to tap into it, how to relate to it, how to understand it and therefore how to sympathetically manage, develop, and navigate our experience of it. DE also helps us come to terms with the beautiful integration of the spiritual alignment of our lives in relationship to all life in the Cosmos, to our sense of belonging, to the intimate experience of our own immanent presence.</p>\n<h4><span><strong>The basis</strong></span></h4>\n<p>Taking Howard Gardner and Elaine De Beauport’s study of human intelligences, mixed with a deep understanding of energy systems, healing, creativity, and numinous space, I have coalesced various systems into this presentation, uniquely showing how we know, how we are embedded in all of life, how we <i>belong</i> to life, to this Planet, and to the Cosmos itself. We are each at the center of infinity and we influence the collective field of consciousness, therefore our potential, for humans, and all life on earth. All this is explained very accessibly, very conversationally, in videos with supporting mindmaps. I present it from the perspective of an artist/healer/researcher and educator. I have had the good fortune of sharing the model with Fritjof Capra and received his blessing for how it extends from his amazing systems work, adding in the human experience. He encouraged me to let my voice of artist lead – and I concur because that brings in so much that is subtle, and yet not new age, into the equation, and into more accessible mainstream dialogue. I feel the artist’s voice (in general) is a gift to our evolution and needs to be there with the other voices. It invites in our imagination, our flexibility, our ‘reach’ and our play. It helps us access numinous space.</p>\n<h4><span><strong>The crisis and the possibilities</strong></span></h4>\n<p>Our lack of understanding of the phenomenal nature of who and what we are made of inside means we have developed a disconnection from life’s sentience, and this has caused us to grab at manufactured reality in an attempt to return home – it created a binary world of black and white when we really exist in a full-color spectrum of infinite and multiple frequencies. It means we can damage our Earth without sensing it, and that we can damage each other without feeling it. And, for many, our voluminous, historical, territorial traveling (which became, in many instances, colonialism), i.e. leaving the lands of our origins, has also left us in a position where we do not recall where, how, or that, we belong. I have done a presentation on this phenomena to the Foundation for Mind-Being Research, San Jose. Coming home is a matter of re-learning the three ways of knowing (Rational, Emotional, Sensory), fleshing them out, feeling into them, understanding their – and our – potential, and letting them open up as gateways to our higher belonging, deeper experiencing and most profound reconnecting. Imagine the good work you can do from here!</p>\n<h4><span><strong>How we learn what’s possible</strong></span></h4>\n<p>Online there are<strong> 7 Courses</strong> that take people through different areas of knowledge. You can take all of them, or individual ones – after the first two foundational courses:</p>\n<div>\n<div>\n<div>\n<ol>\n<li>Dynamic Emergence Explained (Foundation Course 1).</li>\n<li>DE Foundations, *RES at its core (Foundation Course 2).</li>\n<li>Fields of Influence &amp; Theory of Resonance.</li>\n<li>Vulnerabili",
        "html": "<div><div><main><article><div><h3><a href=\"https://dynamicemergence.net/events/de-course-1-de-explained-2/\">*Next online 6 week class June 19, 8pm GMT. Details/Register</a></h3>\n<blockquote>\n<p>There are lots of reasons to wonder who you are, and what you are here to do. You may already have a good idea of it, but then you look around and see how much good work there is still to be done, to help us evolve, to help yourself live a full life, to be all that you are designed to be. I’ve been studying this for a long time, very carefully, and I offer this to you to help you achieve all that, not just for yourself, but for all of us. Say yes to the invitation to deepen your experience of living this life with the knowledge and ability to do so on your own terms, your fullest life.</p>\n</blockquote>\n<h4><span><strong>Who… <em>what</em> are you??</strong></span></h4>\n<p>Are you aware that you are literally energy flowing, shaping itself into patterns <em>through</em> you, and <em>as</em> you, affecting your moods, your ideas, your thinking, even your creativity… affecting what happens next in your life? There are some really amazing things about being human that I’d like you to know about, to empower you, give you the gift of knowing your own energetic, psychic, social, physical territory, your own emotional truths. It’s simple, engaging and, quite honestly, an amazing thing to know about ourselves. After years of study, this is what I can now share with you. Use it for your freedom, your activism, your creative push, your social impact, your personal relationships, and your professional strength.<span></span></p>\n<h4><span><strong>What is it?</strong></span></h4>\n<p>Dynamic Emergence is a conceptual model of consciousness that has practical application. It is defined as <em>the phenomena of novelty arising when two or more elements meet</em> – in layperson’s terms it is <i>our process of becoming,</i> explained. DE shows how human energy systems works, i.e. how they move, interact, influence and create, it shares how we shape the creation of what happens next by what we know and what we do with that knowing – both conscious and unconscious. It is the exploration of the human experience of being a living system within networks of living systems, an exploration of how the universe talks to each of us uniquely, based on who we each uniquely are. It is how information comes to us, through us, and also travels from us, as information, feelings, and data. It demonstrates how we create belief systems based on the movement of energy and how we can track and re-shape those beliefs to grant us more freedom. It basically shows our potential and our infinite capacity and where we often limit that unknowingly.</p>\n<h4><span><strong>Why does it matter right now?</strong></span></h4>\n<p>There are millions of people being left out of the creation of societies around the world. This means we are losing intelligence, diverse ways of knowing, wisdom, compassionate, healthy, and robust societies. There has been a strong emphasis on only partial ways of knowing, the ways that support the creation of big business and fiscal profit creation. And yet, buried right within our fabric, is a social capital that surpasses all transitory attainments: US – body, heart, and soul. Those that get ‘left out’ become a burden on this type of society but are also an essential component to its idea of progress; to have winners you must have losers. This has lead to an intolerable – and tragic – burden not just on humans, but on our ecological home, planet Earth.</p>\n<h4><span><strong>Belonging</strong></span></h4>\n<p>There are many who feel they don’t belong, just because they haven’t been included. They haven’t been included because of a lack of understanding of <em>what</em> we are capable of being, <em>who</em> we are capable of being, and what we are capable of achieving, together. Artists, Highly Sensitive People, Sensitives, Empaths, Indigenous, Whole People (holistic), are aware of highly intelligent ways of being but not being invited to use that to help themselves, and their communities thrive. We can change that. If you look at where funding cuts occur in ‘developed’ countries, it’s the arts, and most particularly dance and theater and if you look at the health issues that drive many suicides and illnesses, it is the emotional, such as depression and disenfranchisement; not belonging. And yet DE shows us that we <em>do</em> belong, it shows us that we are designed to thrive in truly magical, pragmatic, and inspiring ways.</p>\n<h4><span><strong><em>Our</em> evolution is <em>the</em> evolution</strong></span></h4>\n<p>The importance of DE coming at this time, is that we are at a time of profound social and evolutionary change, with a deep need to understand who we are, so we can evolve safely into a sustainable future. It houses two tenets that relate to how we co-create: 1. Nothing is fixed and 2. Energy waits to be noticed (they are explained in the course). It contains experiential truths, personal truths, global truths. Learning about how we are made up, in the sense of our aliveness interacting, we can better understand our creativity, imagination, feelings, reactions, causality.</p>\n<h4><span><strong>Mastery</strong></span></h4>\n<p>Learning how to work with all of that gives us mastery, personal protection, definition, power, and sovereignty. It means we are at choice, capable of change, able to discern situations, study the movement of energy, and work with it. Learning about the nested hierarchies, or networks, that we co-exist in, we can learn to communicate with nature, and the extended field – i.e. make decisions about which social, geographical and professional environments to be in, and who to be around, with conviction, compassion, and confidence. This model embeds us within Planetary Consciousness and highlights the sentience of the Planet.</p>\n<h4><span><strong>What’s possible?</strong></span></h4>\n<p>We learn about what kinds of interior boundaries we made growing up (based on our psychic environment) and how that influenced all our future relationship choices, we can also see how we became – as a species – susceptible to today’s marketing and coercion by governments and corporations, to ‘buy buy buy’ and how some of us became susceptible to abuse or neglect. These influences and decisions can all be rectified. This can all be healed. We can emerge as we are meant to, into our own authentic sense of self, and power.</p>\n<p>Simply put, DE teaches us about energy, how to tap into it, how to relate to it, how to understand it and therefore how to sympathetically manage, develop, and navigate our experience of it. DE also helps us come to terms with the beautiful integration of the spiritual alignment of our lives in relationship to all life in the Cosmos, to our sense of belonging, to the intimate experience of our own immanent presence.</p>\n<h4><span><strong>The basis</strong></span></h4>\n<p>Taking Howard Gardner and Elaine De Beauport’s study of human intelligences, mixed with a deep understanding of energy systems, healing, creativity, and numinous space, I have coalesced various systems into this presentation, uniquely showing how we know, how we are embedded in all of life, how we <i>belong</i> to life, to this Planet, and to the Cosmos itself. We are each at the center of infinity and we influence the collective field of consciousness, therefore our potential, for humans, and all life on earth. All this is explained very accessibly, very conversationally, in videos with supporting mindmaps. I present it from the perspective of an artist/healer/researcher and educator. I have had the good fortune of sharing the model with Fritjof Capra and received his blessing for how it extends from his amazing systems work, adding in the human experience. He encouraged me to let my voice of artist lead – and I concur because that brings in so much that is subtle, and yet not new age, into the equation, and into more accessible mainstream dialogue. I feel the artist’s voice (in general) is a gift to our evolution and needs to be there with the other voices. It invites in our imagination, our flexibility, our ‘reach’ and our play. It helps us access numinous space.</p>\n<h4><span><strong>The crisis and the possibilities</strong></span></h4>\n<p>Our lack of understanding of the phenomenal nature of who and what we are made of inside means we have developed a disconnection from life’s sentience, and this has caused us to grab at manufactured reality in an attempt to return home – it created a binary world of black and white when we really exist in a full-color spectrum of infinite and multiple frequencies. It means we can damage our Earth without sensing it, and that we can damage each other without feeling it. And, for many, our voluminous, historical, territorial traveling (which became, in many instances, colonialism), i.e. leaving the lands of our origins, has also left us in a position where we do not recall where, how, or that, we belong. I have done a presentation on this phenomena to the Foundation for Mind-Being Research, San Jose. Coming home is a matter of re-learning the three ways of knowing (Rational, Emotional, Sensory), fleshing them out, feeling into them, understanding their – and our – potential, and letting them open up as gateways to our higher belonging, deeper experiencing and most profound reconnecting. Imagine the good work you can do from here!</p>\n<h4><span><strong>How we learn what’s possible</strong></span></h4>\n<p>Online there are<strong> 7 Courses</strong> that take people through different areas of knowledge. You can take all of them, or individual ones – after the first two foundational courses:</p>\n<div>\n<div>\n<div>\n<ol>\n<li>Dynamic Emergence Explained (Foundation Course 1).</li>\n<li>DE Foundations, *RES at its core (Foundation Course 2).</li>\n<li>Fields of Influence &amp; Theory of Resonance.</li>\n<li>Vulnerabili",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "*Next online 6 week class June 19, 8pm GMT. Details/RegisterThere are lots of reasons to wonder who you are, and what you are here to do. You may already have a good idea of it, but then you look around and see how much good work there is still to be done, to help us evolve, to help yourself live a full life, to be all that you are designed to be. I’ve been studying this for a long time, very carefully, and I offer this to you to help you achieve all that, not just for yourself, but for all of u",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "*Next online 6 week class June 19, 8pm GMT. Details/RegisterThere are lots of reasons to wonder who you are, and what you are here to do. You may already have a good idea of it, but then you look around and see how much good work there is still to be done, to help us evolve, to help yourself live a full life, to be all that you are designed to be. I’ve been studying this for a long time, very carefully, and I offer this to you to help you achieve all that, not just for yourself, but for all of u",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "*Next online 6 week class June 19, 8pm GMT. Details/RegisterThere are lots of reasons to wonder who you are, and what you are here to do. You may already have a good idea of it, but then you look around and see how much good work there is still to be done, to help us evolve, to help yourself live a full life, to be all that you are designed to be. I’ve been studying this for a long time, very carefully, and I offer this to you to help you achieve all that, not just for yourself, but for all of u",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "*Next online 6 week class June 19, 8pm GMT. Details/RegisterThere are lots of reasons to wonder who you are, and what you are here to do. You may already have a good idea of it, but then you look around and see how much good work there is still to be done, to help us evolve, to help yourself live a full life, to be all that you are designed to be. I’ve been studying this for a long time, very carefully, and I offer this to you to help you achieve all that, not just for yourself, but for all of u",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dynamic Emergence Explained (Foundation Course 1).DE Foundations, *RES at its core (Foundation Course 2).Fields of Influence & Theory of Resonance.Vulnerabili",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dynamic Emergence Explained (Foundation Course 1).DE Foundations, *RES at its core (Foundation Course 2).Fields of Influence & Theory of Resonance.Vulnerabili",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dynamic Emergence Explained (Foundation Course 1).DE Foundations, *RES at its core (Foundation Course 2).Fields of Influence & Theory of Resonance.Vulnerabili",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "*Next online 6 week class June 19, 8pm GMT. Details/Register",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Who…whatare you??",
              "id": ""
            },
            {
              "level": "h4",
              "text": "What is it?",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Why does it matter right now?",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Belonging",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Ourevolution istheevolution",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Mastery",
              "id": ""
            },
            {
              "level": "h4",
              "text": "What’s possible?",
              "id": ""
            },
            {
              "level": "h4",
              "text": "The basis",
              "id": ""
            },
            {
              "level": "h4",
              "text": "The crisis and the possibilities",
              "id": ""
            },
            {
              "level": "h4",
              "text": "How we learn what’s possible",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    }
  ]
}