{
  "metadata": {
    "chunk_number": 6,
    "timestamp": "2025-01-19T18:33:40.256413",
    "total_successful": 37
  },
  "documents": [
    {
      "url": "https://www.britannica.com/science/evolution-scientific-theory/Genetic-drift",
      "title": "Evolution | Definition, History, Types, & Examples",
      "author": "Francisco Jose Ayala",
      "published_date": "2024-07-24T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<section> <span></span><span></span><p>Gene frequencies can change from one generation to another by a process of pure chance known as <a href=\"https://www.britannica.com/science/genetic-drift\">genetic drift</a>. This occurs because the number of individuals in any population is finite, and thus the frequency of a <a href=\"https://www.britannica.com/science/gene\">gene</a> may change in the following generation by accidents of sampling, just as it is possible to get more or fewer than 50 “heads” in 100 throws of a coin simply by chance.</p> <span></span><div>\n<h2>\nRecent News</h2>\n</div><span></span><p>The magnitude of the gene frequency changes due to genetic drift is inversely related to the size of the population—the larger the number of reproducing individuals, the smaller the effects of genetic drift. This <a href=\"https://www.britannica.com/dictionary/inverse\">inverse</a> relationship between sample size and magnitude of sampling errors can be illustrated by referring again to tossing a coin. When a penny is tossed twice, two heads are not surprising. But it will be surprising, and suspicious, if 20 tosses all yield heads. The proportion of heads obtained in a series of throws approaches closer to 0.5 as the number of throws grows larger.</p> <span></span><span></span><p>The relationship is the same in populations, although the important value here is not the actual number of individuals in the population but the “effective” population size. This is the number of individuals that produce offspring, because only reproducing individuals transmit their genes to the following generation. It is not unusual, in plants as well as animals, for some individuals to have large numbers of <a href=\"https://www.britannica.com/dictionary/progeny\">progeny</a> while others have none. In marine seals, antelopes, baboons, and many other mammals, for example, a dominant male may keep a large harem of females at the expense of many other males who can find no mates. It often happens that the <a href=\"https://www.britannica.com/science/effective-population-size\">effective population size</a> is substantially smaller than the number of individuals in any one generation.</p> <span></span><span></span><p>The effects of genetic drift in changing gene frequencies from one generation to the next are quite small in most natural populations, which generally consist of thousands of reproducing individuals. The effects over many generations are more important. Indeed, in the absence of other processes of change (such as natural selection and mutation), populations would eventually become fixed, having one <a href=\"https://www.britannica.com/science/allele\">allele</a> at each <a href=\"https://www.britannica.com/dictionary/locus\">locus</a> after the gradual elimination of all others. With genetic drift as the only force in operation, the probability of a given allele’s eventually reaching a frequency of 1 would be precisely the frequency of the allele—that is, an allele with a frequency of 0.8 would have an 80 percent chance of ultimately becoming the only allele present in the population. The process would, however, take a long time, because increases and decreases are likely to alternate with equal probability. More important, natural selection and other processes change gene frequencies in ways not governed by pure chance, so that no allele has an opportunity to become fixed as a consequence of genetic drift alone.</p> <span></span><span></span><p>Genetic drift can have important evolutionary <a href=\"https://www.britannica.com/dictionary/consequences\">consequences</a> when a new population becomes established by only a few individuals—a phenomenon known as the <span></span><a href=\"https://www.britannica.com/science/founder-principle\">founder principle</a>. Islands, lakes, and other isolated ecological sites are often colonized by one or very few seeds or animals of a <a href=\"https://www.britannica.com/science/species-taxon\">species</a>, which are transported there passively by wind, in the fur of larger animals, or in some other way. The allelic frequencies present in these few colonizers are likely to differ at many loci from those in the population they left, and those differences have a lasting impact on the evolution of the new population. The founder principle is one reason that species in neighbouring islands, such as those in the Hawaiian archipelago, are often more <a href=\"https://www.merriam-webster.com/dictionary/heterogeneous\">heterogeneous</a> than species in comparable continental areas <a href=\"https://www.merriam-webster.com/dictionary/adjacent\">adjacent</a> to one another.</p> <span></span><span></span><p>Climatic or other conditions, if unfavourable, may on occasion drastically reduce the number of individuals in a population and even threaten it with <a href=\"https://www.britannica.com/science/extinction-biology\">extinction</a>. Such occasional reductions are called <span></span><a href=\"https://www.britannica.com/science/population-bottleneck\">population bottlenecks</a>. The populations may later recover their typical size, but the allelic frequencies may have been considerably altered and thereby affect the future evolution of the species. Bottlenecks are more likely in relatively large animals and plants than in smaller ones, because populations of large organisms typically consist of fewer individuals. Primitive <a href=\"https://www.britannica.com/topic/human-being\">human</a> populations of the past were subdivided into many small tribes that were time and again <a href=\"https://www.britannica.com/dictionary/decimated\">decimated</a> by <a href=\"https://www.britannica.com/science/disease\">disease</a>, war, and other disasters. Differences among current human populations in the allele frequencies of many genes—such as those determining the ABO and other <a href=\"https://www.britannica.com/science/blood-group\">blood group</a>s—may have arisen at least in part as a consequence of bottlenecks in ancestral populations. Persistent population bottlenecks may reduce the overall genetic <a href=\"https://www.britannica.com/science/variation-biology\">variation</a> so greatly as to alter future evolution and endanger the survival of the species. A well-authenticated case is that of the <a href=\"https://www.britannica.com/animal/cheetah-mammal\">cheetah</a>, where no allelic variation whatsoever has been found among the many scores of gene loci studied.</p></section> <section><h2>The operation of natural selection in populations</h2> <section><h2>Natural selection as a process of genetic change</h2> <span></span><span></span><p><a href=\"https://www.britannica.com/science/natural-selection\">Natural selection</a> refers to any reproductive bias favouring some genes or genotypes over others. Natural selection promotes the <a href=\"https://www.britannica.com/science/adaptation-biology-and-physiology\">adaptation</a> of organisms to the <a href=\"https://www.merriam-webster.com/dictionary/environments\">environments</a> in which they live; any hereditary variant that improves the ability to survive and reproduce in an <a href=\"https://www.britannica.com/science/environment\">environment</a> will increase in frequency over the generations, precisely because the organisms carrying such a variant will leave more descendants than those lacking it. Hereditary variants, favourable or not to the organisms, arise by <a href=\"https://www.britannica.com/science/mutation-genetics\">mutation</a>. Unfavourable ones are eventually eliminated by natural selection; their carriers leave no descendants or leave fewer than those carrying <a href=\"https://www.merriam-webster.com/dictionary/alternative\">alternative</a> variants. Favourable mutations accumulate over the generations. The process continues indefinitely because the environments that organisms inhabit are forever changing. Environments change physically—in their climate, configuration, and so on—but also biologically, because the predators, parasites, competitors, and food sources with which an organism interacts are themselves evolving.</p> <span></span><span></span><p>Mutation, <a href=\"https://www.britannica.com/science/gene-flow\">gene flow</a>, and <a href=\"https://www.britannica.com/science/genetic-drift\">genetic drift</a> are random processes with respect to adaptation; they change gene frequencies without regard for the consequences that such changes may have in the ability of the organisms to survive and reproduce. If these were the only processes of evolutionary change, the organization of living things would gradually disintegrate. The effects of such processes alone would be <a href=\"https://www.merriam-webster.com/dictionary/analogous\">analogous</a> to those of a mechanic who changed parts in an automobile engine at random, with no regard for the role of the parts in the engine. Natural selection keeps the disorganizing effects of mutation and other processes in check because it multiplies <a href=\"https://www.merriam-webster.com/dictionary/beneficial\">beneficial</a> mutations and eliminates harmful ones.</p> <span></span><span></span><p>Natural selection accounts not only for the preservation and improvement of the organization of living beings but also for their <a href=\"https://www.merriam-webster.com/dictionary/diversity\">diversity</a>. In different localities or in different circumstances, natural selection favours different traits, precisely those that make the organisms well adapted to their particular circumstances and ways of life.</p> <span></span><span></span><p>The <a href=\"https://www.merriam-webster.com/dictionary/parameter\">parameter</a> used to measure the effects of natural selection is fitness (<em>see above</em> <a href=\"https://www.britannica.com/science/evolution-scientific-theory/The-science-of-evolution#ref49853\">The concept of natural selection</a>), which can be expressed as an absolute or as a relative value. Consider a population consisting at",
        "html": "<div><div>\n<section> <span></span><span></span><p>Gene frequencies can change from one generation to another by a process of pure chance known as <a href=\"https://www.britannica.com/science/genetic-drift\">genetic drift</a>. This occurs because the number of individuals in any population is finite, and thus the frequency of a <a href=\"https://www.britannica.com/science/gene\">gene</a> may change in the following generation by accidents of sampling, just as it is possible to get more or fewer than 50 “heads” in 100 throws of a coin simply by chance.</p> <span></span><div>\n<h2>\nRecent News</h2>\n</div><span></span><p>The magnitude of the gene frequency changes due to genetic drift is inversely related to the size of the population—the larger the number of reproducing individuals, the smaller the effects of genetic drift. This <a href=\"https://www.britannica.com/dictionary/inverse\">inverse</a> relationship between sample size and magnitude of sampling errors can be illustrated by referring again to tossing a coin. When a penny is tossed twice, two heads are not surprising. But it will be surprising, and suspicious, if 20 tosses all yield heads. The proportion of heads obtained in a series of throws approaches closer to 0.5 as the number of throws grows larger.</p> <span></span><span></span><p>The relationship is the same in populations, although the important value here is not the actual number of individuals in the population but the “effective” population size. This is the number of individuals that produce offspring, because only reproducing individuals transmit their genes to the following generation. It is not unusual, in plants as well as animals, for some individuals to have large numbers of <a href=\"https://www.britannica.com/dictionary/progeny\">progeny</a> while others have none. In marine seals, antelopes, baboons, and many other mammals, for example, a dominant male may keep a large harem of females at the expense of many other males who can find no mates. It often happens that the <a href=\"https://www.britannica.com/science/effective-population-size\">effective population size</a> is substantially smaller than the number of individuals in any one generation.</p> <span></span><span></span><p>The effects of genetic drift in changing gene frequencies from one generation to the next are quite small in most natural populations, which generally consist of thousands of reproducing individuals. The effects over many generations are more important. Indeed, in the absence of other processes of change (such as natural selection and mutation), populations would eventually become fixed, having one <a href=\"https://www.britannica.com/science/allele\">allele</a> at each <a href=\"https://www.britannica.com/dictionary/locus\">locus</a> after the gradual elimination of all others. With genetic drift as the only force in operation, the probability of a given allele’s eventually reaching a frequency of 1 would be precisely the frequency of the allele—that is, an allele with a frequency of 0.8 would have an 80 percent chance of ultimately becoming the only allele present in the population. The process would, however, take a long time, because increases and decreases are likely to alternate with equal probability. More important, natural selection and other processes change gene frequencies in ways not governed by pure chance, so that no allele has an opportunity to become fixed as a consequence of genetic drift alone.</p> <span></span><span></span><p>Genetic drift can have important evolutionary <a href=\"https://www.britannica.com/dictionary/consequences\">consequences</a> when a new population becomes established by only a few individuals—a phenomenon known as the <span></span><a href=\"https://www.britannica.com/science/founder-principle\">founder principle</a>. Islands, lakes, and other isolated ecological sites are often colonized by one or very few seeds or animals of a <a href=\"https://www.britannica.com/science/species-taxon\">species</a>, which are transported there passively by wind, in the fur of larger animals, or in some other way. The allelic frequencies present in these few colonizers are likely to differ at many loci from those in the population they left, and those differences have a lasting impact on the evolution of the new population. The founder principle is one reason that species in neighbouring islands, such as those in the Hawaiian archipelago, are often more <a href=\"https://www.merriam-webster.com/dictionary/heterogeneous\">heterogeneous</a> than species in comparable continental areas <a href=\"https://www.merriam-webster.com/dictionary/adjacent\">adjacent</a> to one another.</p> <span></span><span></span><p>Climatic or other conditions, if unfavourable, may on occasion drastically reduce the number of individuals in a population and even threaten it with <a href=\"https://www.britannica.com/science/extinction-biology\">extinction</a>. Such occasional reductions are called <span></span><a href=\"https://www.britannica.com/science/population-bottleneck\">population bottlenecks</a>. The populations may later recover their typical size, but the allelic frequencies may have been considerably altered and thereby affect the future evolution of the species. Bottlenecks are more likely in relatively large animals and plants than in smaller ones, because populations of large organisms typically consist of fewer individuals. Primitive <a href=\"https://www.britannica.com/topic/human-being\">human</a> populations of the past were subdivided into many small tribes that were time and again <a href=\"https://www.britannica.com/dictionary/decimated\">decimated</a> by <a href=\"https://www.britannica.com/science/disease\">disease</a>, war, and other disasters. Differences among current human populations in the allele frequencies of many genes—such as those determining the ABO and other <a href=\"https://www.britannica.com/science/blood-group\">blood group</a>s—may have arisen at least in part as a consequence of bottlenecks in ancestral populations. Persistent population bottlenecks may reduce the overall genetic <a href=\"https://www.britannica.com/science/variation-biology\">variation</a> so greatly as to alter future evolution and endanger the survival of the species. A well-authenticated case is that of the <a href=\"https://www.britannica.com/animal/cheetah-mammal\">cheetah</a>, where no allelic variation whatsoever has been found among the many scores of gene loci studied.</p></section> <section><h2>The operation of natural selection in populations</h2> <section><h2>Natural selection as a process of genetic change</h2> <span></span><span></span><p><a href=\"https://www.britannica.com/science/natural-selection\">Natural selection</a> refers to any reproductive bias favouring some genes or genotypes over others. Natural selection promotes the <a href=\"https://www.britannica.com/science/adaptation-biology-and-physiology\">adaptation</a> of organisms to the <a href=\"https://www.merriam-webster.com/dictionary/environments\">environments</a> in which they live; any hereditary variant that improves the ability to survive and reproduce in an <a href=\"https://www.britannica.com/science/environment\">environment</a> will increase in frequency over the generations, precisely because the organisms carrying such a variant will leave more descendants than those lacking it. Hereditary variants, favourable or not to the organisms, arise by <a href=\"https://www.britannica.com/science/mutation-genetics\">mutation</a>. Unfavourable ones are eventually eliminated by natural selection; their carriers leave no descendants or leave fewer than those carrying <a href=\"https://www.merriam-webster.com/dictionary/alternative\">alternative</a> variants. Favourable mutations accumulate over the generations. The process continues indefinitely because the environments that organisms inhabit are forever changing. Environments change physically—in their climate, configuration, and so on—but also biologically, because the predators, parasites, competitors, and food sources with which an organism interacts are themselves evolving.</p> <span></span><span></span><p>Mutation, <a href=\"https://www.britannica.com/science/gene-flow\">gene flow</a>, and <a href=\"https://www.britannica.com/science/genetic-drift\">genetic drift</a> are random processes with respect to adaptation; they change gene frequencies without regard for the consequences that such changes may have in the ability of the organisms to survive and reproduce. If these were the only processes of evolutionary change, the organization of living things would gradually disintegrate. The effects of such processes alone would be <a href=\"https://www.merriam-webster.com/dictionary/analogous\">analogous</a> to those of a mechanic who changed parts in an automobile engine at random, with no regard for the role of the parts in the engine. Natural selection keeps the disorganizing effects of mutation and other processes in check because it multiplies <a href=\"https://www.merriam-webster.com/dictionary/beneficial\">beneficial</a> mutations and eliminates harmful ones.</p> <span></span><span></span><p>Natural selection accounts not only for the preservation and improvement of the organization of living beings but also for their <a href=\"https://www.merriam-webster.com/dictionary/diversity\">diversity</a>. In different localities or in different circumstances, natural selection favours different traits, precisely those that make the organisms well adapted to their particular circumstances and ways of life.</p> <span></span><span></span><p>The <a href=\"https://www.merriam-webster.com/dictionary/parameter\">parameter</a> used to measure the effects of natural selection is fitness (<em>see above</em> <a href=\"https://www.britannica.com/science/evolution-scientific-theory/The-science-of-evolution#ref49853\">The concept of natural selection</a>), which can be expressed as an absolute or as a relative value. Consider a population consisting at",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Gene frequencies can change from one generation to another by a process of pure chance known asgenetic drift. This occurs because the number of individuals in any population is finite, and thus the frequency of agenemay change in the following generation by accidents of sampling, just as it is possible to get more or fewer than 50 “heads” in 100 throws of a coin simply by chance.Recent NewsThe magnitude of the gene frequency changes due to genetic drift is inversely related to the size of the po",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Gene frequencies can change from one generation to another by a process of pure chance known asgenetic drift. This occurs because the number of individuals in any population is finite, and thus the frequency of agenemay change in the following generation by accidents of sampling, just as it is possible to get more or fewer than 50 “heads” in 100 throws of a coin simply by chance.Recent NewsThe magnitude of the gene frequency changes due to genetic drift is inversely related to the size of the po",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Gene frequencies can change from one generation to another by a process of pure chance known asgenetic drift. This occurs because the number of individuals in any population is finite, and thus the frequency of agenemay change in the following generation by accidents of sampling, just as it is possible to get more or fewer than 50 “heads” in 100 throws of a coin simply by chance.Recent NewsThe magnitude of the gene frequency changes due to genetic drift is inversely related to the size of the po",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Recent News",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "The operation of natural selection in populationsNatural selection as a process of genetic changeNatural selectionrefers to any reproductive bias favouring some genes or genotypes over others. Natural selection promotes theadaptationof organisms to theenvironmentsin which they live; any hereditary variant that improves the ability to survive and reproduce in anenvironmentwill increase in frequency over the generations, precisely because the organisms carrying such a variant will leave more desce",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Natural selection as a process of genetic changeNatural selectionrefers to any reproductive bias favouring some genes or genotypes over others. Natural selection promotes theadaptationof organisms to theenvironmentsin which they live; any hereditary variant that improves the ability to survive and reproduce in anenvironmentwill increase in frequency over the generations, precisely because the organisms carrying such a variant will leave more descendants than those lacking it. Hereditary variants",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Recent News",
              "id": ""
            },
            {
              "level": "h2",
              "text": "The operation of natural selection in populations",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Natural selection as a process of genetic change",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.nature.com/articles/nature01407",
      "title": "DNA replication and recombination - Nature",
      "author": "Alberts; Bruce",
      "published_date": "2023-02-07T16:08:09.000Z",
      "content": {
        "text": "<div><div><p><i>“Though facts are inherently less satisfying than the intellectual conclusions drawn from them, their importance should never be questioned.”</i> James D. Watson, 2002.</p><p>DNA carries all of the genetic information for life. One enormously long DNA molecule forms each of the chromosomes of an organism, 23 of them in a human. The fundamental living unit is the single cell. A cell gives rise to many more cells through serial repetitions of a process known as cell division. Before each division, new copies must be made of each of the many molecules that form the cell, including the duplication of all DNA molecules. DNA replication is the name given to this duplication process, which enables an organism's genetic information — its genes — to be passed to the two daughter cells created when a cell divides. Only slightly less central to life is a process that requires dynamic DNA acrobatics, called homologous DNA recombination, which reshuffles the genes on chromosomes. In reactions closely linked to DNA replication, the recombination machinery also repairs damage that inevitably occurs to the long, fragile DNA molecules inside cells (see article in this issue by Friedberg, <a href=\"https://www.nature.com/articles/nature01408\">page 436</a>).</p><p>The model for the DNA double helix<sup><a href=\"/articles/nature01407#ref-CR1\">1</a></sup> proposed by James Watson and Francis Crick is based on two paired DNA strands that are complementary in their nucleotide sequence. The model had striking implications for the processes of DNA replication and DNA recombination. Before 1953, there had been no meaningful way of even speculating about the molecular mechanisms of these two central genetic processes. But the proposal that each nucleotide in one strand of DNA was tightly base-paired with its complementary nucleotide on the opposite strand — either adenine (A) with thymine (T), or guanine (G) with cytosine (C) — meant that any part of the nucleotide sequence could act as a direct template for the corresponding portion of the other strand. As a result, any part of the sequence can be used either to create or to recognize its partner nucleotide sequence — the two functions that are central for DNA replication and DNA recombination, respectively.</p><p>In this review, I discuss how the discovery of the structure of DNA half a century ago opened new avenues for understanding the processes of DNA replication and recombination. I shall also emphasize how, as our understanding of complex biological molecules and their interactions increased over the years, there have been profound changes in the way that biologists view the chemistry of life.</p><p>\n<b>Structural features of DNA</b>\n</p><p>The research that immediately followed the discovery of the double helix focused primarily on understanding the structural properties of the molecule. DNA specifies RNA through the process of gene transcription, and the RNA molecules in turn specify all of the proteins of a cell. This is the 'central dogma' of genetic information transfer<sup><a href=\"/articles/nature01407#ref-CR2\">2</a></sup>. Any read-out of genetic information — whether it be during DNA replication or gene transcription — requires access to the sequence of the bases buried in the interior of the double helix. DNA strand separation is therefore critical to DNA function. Thus, the Watson–Crick model drove scientists to a search for conditions that would disrupt the hydrogen bonds joining the complementary base pairs, so as to separate the two strands of the DNA double helix.</p><p>Physical chemists found that heating a solution of DNA to temperatures near boiling (100 °C), or subjecting it to extremes of pH, would cause the strands to separate — a change termed 'DNA denaturation'. The so-called 'melting temperature' (or <i>T</i><sub>m</sub>) of a stretch of DNA sequence depends on its nucleotide composition: those DNAs with a larger proportion of G–C base pairs exhibit a higher <i>T</i><sub>m</sub> because of the three hydrogen bonds that Watson and Crick had predicted to hold a G–C base pair together, compared with only two for the A–T base pair. At physiological salt concentrations, the <i>T</i><sub>m</sub> of mammalian DNA is nearly 90 °C, owing to the particular mix of its base pairs (47% G–C and 53% A–T)<sup><a href=\"/articles/nature01407#ref-CR3\">3</a></sup>.</p><p>Initially it seemed inconceivable that, once separated from its complementary partner, a DNA strand could reform a double helix again. In a complex mixture of DNA molecules, such a feat would require finding the one sequence match amongst millions during random collisions with other sequences, and then rapidly rewinding with a new partner strand. The dramatic discovery of this unexpected phenomenon<sup><a href=\"/articles/nature01407#ref-CR4\">4</a></sup>, called 'DNA renaturation', shed light on how sequences could be rearranged by DNA recombination. And it also provided a critical means by which DNA could be manipulated in the laboratory. The annealing of complementary nucleotide sequences, a process called hybridization, forms the basis of several DNA technologies that helped launch the biotechnology industry and modern genomics. These include gene cloning, genomic sequencing, and DNA copying by the polymerase chain reaction (see article by Hood and Galas on <a href=\"https://www.nature.com/articles/nature01410\">page 444</a>).</p><p>The arrangement of DNA molecules in chromosomes presented another mystery for scientists: a long, thin molecule would be highly sensitive to shear-induced breakage, and it was hard to imagine that a mammalian chromosome might contain only a single DNA molecule. This would require that a typical chromosome be formed from a continuous DNA helix more than 100 million nucleotide pairs long — a massive molecule weighing more than 100 billion daltons, with an end-to-end distance of more than 3 cm. How could such a giant molecule be protected from accidental fragmentation in a cell only microns in diameter, while keeping it organized for efficient gene readout and other genetic functions?</p><p>There was no precedent for such giant molecules outside the world of biology. But in the early 1960s, autoradiographic studies revealed that the chromosome of the bacterium <i>Escherichia coli</i> was in fact a single DNA molecule, more than 3 million nucleotide pairs in length<sup><a href=\"/articles/nature01407#ref-CR5\">5</a></sup>. And when — more than a decade later — innovative physical techniques demonstrated that a single huge DNA molecule formed the basis for each mammalian chromosome<sup><a href=\"/articles/nature01407#ref-CR6\">6</a></sup>, the result was welcomed by scientists with little surprise.</p><p>\n<b>DNA replication forks</b>\n</p><p>How is the enormously long double-stranded DNA molecule that forms a chromosome accurately copied to produce a second identical chromosome each time a cell divides? The template model for DNA replication, proposed by Watson and Crick in 1953 (ref. <a href=\"/articles/nature01407#ref-CR7\">7</a>), gained universal acceptance after two discoveries in the late 1950s. One was an elegant experiment using density-labelled bacterial DNAs that confirmed the predicted template–anti-template scheme<sup><a href=\"/articles/nature01407#ref-CR8\">8</a></sup>. The other was the discovery of an enzyme called DNA polymerase, which uses one strand of DNA as a template to synthesize a new complementary strand<sup><a href=\"/articles/nature01407#ref-CR9\">9</a></sup>. Four deoxyribonucleoside triphosphate nucleotides — dATP, dTTP, dGTP and dCTP — are the precursors to a new daughter DNA strand, each nucleotide selected by pairing with its complementary nucleotide (T, A, C or G, respectively) on the parental template strand. The DNA polymerase was shown to use these triphosphates to add nucleotides one at a time to the 3′ end of the newly synthesized DNA molecule, thereby catalysing DNA chain growth in the 5′ to 3′ chemical direction.</p><p>Although the synthesis of short stretches of DNA sequence on a single-stranded template could be demonstrated in a test tube, how an enormous, twisted double-stranded DNA molecule is replicated was a puzzle. Inside the cell, DNA replication was observed to occur at a Y-shaped structure, called a 'replication fork', which moves steadily along a parental DNA helix, spinning out two daughter DNA helices behind it (the two arms of the 'Y')<sup><a href=\"/articles/nature01407#ref-CR5\">5</a></sup>. As predicted by Watson and Crick, the two strands of the double helix run in opposite chemical directions. Therefore, as a replication fork moves, DNA polymerase can move continuously along only one arm of the Y — the arm on which the new daughter strand is being elongated in the 5′ to 3′ chemical direction. On the other arm, the new daughter strand would need to be produced in the opposite, 3′ to 5′ chemical direction (<a href=\"/articles/nature01407#Fig1\">Fig. 1a</a>). So, whereas Watson and Crick's central predictions were confirmed at the end of the first decade of research that followed their landmark discovery, the details of the DNA replication process remained a mystery.</p><div><figure><figcaption><b>Figure 1: The DNA replication fork.</b></figcaption><div><div><a href=\"/articles/nature01407/figures/1\"></a></div><p><b>a,</b> Nucleoside triphosphates serve as a substrate for DNA polymerase, according to the mechanism shown on the top strand. Each nucleoside triphosphate is made up of three phosphates (represented here by yellow spheres), a deoxyribose sugar (beige rectangle) and one of four bases (differently coloured cylinders). The three phosphates are joined to each other by high-energy bonds, and the cleavage of these bonds during the polymerization reaction releases the free energy needed to drive the incorporation of each nucleotide into the growing DNA chain. The reaction shown on the bottom strand, which would cause DNA cha",
        "html": "<div><div><p><i>“Though facts are inherently less satisfying than the intellectual conclusions drawn from them, their importance should never be questioned.”</i> James D. Watson, 2002.</p><p>DNA carries all of the genetic information for life. One enormously long DNA molecule forms each of the chromosomes of an organism, 23 of them in a human. The fundamental living unit is the single cell. A cell gives rise to many more cells through serial repetitions of a process known as cell division. Before each division, new copies must be made of each of the many molecules that form the cell, including the duplication of all DNA molecules. DNA replication is the name given to this duplication process, which enables an organism's genetic information — its genes — to be passed to the two daughter cells created when a cell divides. Only slightly less central to life is a process that requires dynamic DNA acrobatics, called homologous DNA recombination, which reshuffles the genes on chromosomes. In reactions closely linked to DNA replication, the recombination machinery also repairs damage that inevitably occurs to the long, fragile DNA molecules inside cells (see article in this issue by Friedberg, <a href=\"https://www.nature.com/articles/nature01408\">page 436</a>).</p><p>The model for the DNA double helix<sup><a href=\"/articles/nature01407#ref-CR1\">1</a></sup> proposed by James Watson and Francis Crick is based on two paired DNA strands that are complementary in their nucleotide sequence. The model had striking implications for the processes of DNA replication and DNA recombination. Before 1953, there had been no meaningful way of even speculating about the molecular mechanisms of these two central genetic processes. But the proposal that each nucleotide in one strand of DNA was tightly base-paired with its complementary nucleotide on the opposite strand — either adenine (A) with thymine (T), or guanine (G) with cytosine (C) — meant that any part of the nucleotide sequence could act as a direct template for the corresponding portion of the other strand. As a result, any part of the sequence can be used either to create or to recognize its partner nucleotide sequence — the two functions that are central for DNA replication and DNA recombination, respectively.</p><p>In this review, I discuss how the discovery of the structure of DNA half a century ago opened new avenues for understanding the processes of DNA replication and recombination. I shall also emphasize how, as our understanding of complex biological molecules and their interactions increased over the years, there have been profound changes in the way that biologists view the chemistry of life.</p><p>\n<b>Structural features of DNA</b>\n</p><p>The research that immediately followed the discovery of the double helix focused primarily on understanding the structural properties of the molecule. DNA specifies RNA through the process of gene transcription, and the RNA molecules in turn specify all of the proteins of a cell. This is the 'central dogma' of genetic information transfer<sup><a href=\"/articles/nature01407#ref-CR2\">2</a></sup>. Any read-out of genetic information — whether it be during DNA replication or gene transcription — requires access to the sequence of the bases buried in the interior of the double helix. DNA strand separation is therefore critical to DNA function. Thus, the Watson–Crick model drove scientists to a search for conditions that would disrupt the hydrogen bonds joining the complementary base pairs, so as to separate the two strands of the DNA double helix.</p><p>Physical chemists found that heating a solution of DNA to temperatures near boiling (100 °C), or subjecting it to extremes of pH, would cause the strands to separate — a change termed 'DNA denaturation'. The so-called 'melting temperature' (or <i>T</i><sub>m</sub>) of a stretch of DNA sequence depends on its nucleotide composition: those DNAs with a larger proportion of G–C base pairs exhibit a higher <i>T</i><sub>m</sub> because of the three hydrogen bonds that Watson and Crick had predicted to hold a G–C base pair together, compared with only two for the A–T base pair. At physiological salt concentrations, the <i>T</i><sub>m</sub> of mammalian DNA is nearly 90 °C, owing to the particular mix of its base pairs (47% G–C and 53% A–T)<sup><a href=\"/articles/nature01407#ref-CR3\">3</a></sup>.</p><p>Initially it seemed inconceivable that, once separated from its complementary partner, a DNA strand could reform a double helix again. In a complex mixture of DNA molecules, such a feat would require finding the one sequence match amongst millions during random collisions with other sequences, and then rapidly rewinding with a new partner strand. The dramatic discovery of this unexpected phenomenon<sup><a href=\"/articles/nature01407#ref-CR4\">4</a></sup>, called 'DNA renaturation', shed light on how sequences could be rearranged by DNA recombination. And it also provided a critical means by which DNA could be manipulated in the laboratory. The annealing of complementary nucleotide sequences, a process called hybridization, forms the basis of several DNA technologies that helped launch the biotechnology industry and modern genomics. These include gene cloning, genomic sequencing, and DNA copying by the polymerase chain reaction (see article by Hood and Galas on <a href=\"https://www.nature.com/articles/nature01410\">page 444</a>).</p><p>The arrangement of DNA molecules in chromosomes presented another mystery for scientists: a long, thin molecule would be highly sensitive to shear-induced breakage, and it was hard to imagine that a mammalian chromosome might contain only a single DNA molecule. This would require that a typical chromosome be formed from a continuous DNA helix more than 100 million nucleotide pairs long — a massive molecule weighing more than 100 billion daltons, with an end-to-end distance of more than 3 cm. How could such a giant molecule be protected from accidental fragmentation in a cell only microns in diameter, while keeping it organized for efficient gene readout and other genetic functions?</p><p>There was no precedent for such giant molecules outside the world of biology. But in the early 1960s, autoradiographic studies revealed that the chromosome of the bacterium <i>Escherichia coli</i> was in fact a single DNA molecule, more than 3 million nucleotide pairs in length<sup><a href=\"/articles/nature01407#ref-CR5\">5</a></sup>. And when — more than a decade later — innovative physical techniques demonstrated that a single huge DNA molecule formed the basis for each mammalian chromosome<sup><a href=\"/articles/nature01407#ref-CR6\">6</a></sup>, the result was welcomed by scientists with little surprise.</p><p>\n<b>DNA replication forks</b>\n</p><p>How is the enormously long double-stranded DNA molecule that forms a chromosome accurately copied to produce a second identical chromosome each time a cell divides? The template model for DNA replication, proposed by Watson and Crick in 1953 (ref. <a href=\"/articles/nature01407#ref-CR7\">7</a>), gained universal acceptance after two discoveries in the late 1950s. One was an elegant experiment using density-labelled bacterial DNAs that confirmed the predicted template–anti-template scheme<sup><a href=\"/articles/nature01407#ref-CR8\">8</a></sup>. The other was the discovery of an enzyme called DNA polymerase, which uses one strand of DNA as a template to synthesize a new complementary strand<sup><a href=\"/articles/nature01407#ref-CR9\">9</a></sup>. Four deoxyribonucleoside triphosphate nucleotides — dATP, dTTP, dGTP and dCTP — are the precursors to a new daughter DNA strand, each nucleotide selected by pairing with its complementary nucleotide (T, A, C or G, respectively) on the parental template strand. The DNA polymerase was shown to use these triphosphates to add nucleotides one at a time to the 3′ end of the newly synthesized DNA molecule, thereby catalysing DNA chain growth in the 5′ to 3′ chemical direction.</p><p>Although the synthesis of short stretches of DNA sequence on a single-stranded template could be demonstrated in a test tube, how an enormous, twisted double-stranded DNA molecule is replicated was a puzzle. Inside the cell, DNA replication was observed to occur at a Y-shaped structure, called a 'replication fork', which moves steadily along a parental DNA helix, spinning out two daughter DNA helices behind it (the two arms of the 'Y')<sup><a href=\"/articles/nature01407#ref-CR5\">5</a></sup>. As predicted by Watson and Crick, the two strands of the double helix run in opposite chemical directions. Therefore, as a replication fork moves, DNA polymerase can move continuously along only one arm of the Y — the arm on which the new daughter strand is being elongated in the 5′ to 3′ chemical direction. On the other arm, the new daughter strand would need to be produced in the opposite, 3′ to 5′ chemical direction (<a href=\"/articles/nature01407#Fig1\">Fig. 1a</a>). So, whereas Watson and Crick's central predictions were confirmed at the end of the first decade of research that followed their landmark discovery, the details of the DNA replication process remained a mystery.</p><div><figure><figcaption><b>Figure 1: The DNA replication fork.</b></figcaption><div><div><a href=\"/articles/nature01407/figures/1\"></a></div><p><b>a,</b> Nucleoside triphosphates serve as a substrate for DNA polymerase, according to the mechanism shown on the top strand. Each nucleoside triphosphate is made up of three phosphates (represented here by yellow spheres), a deoxyribose sugar (beige rectangle) and one of four bases (differently coloured cylinders). The three phosphates are joined to each other by high-energy bonds, and the cleavage of these bonds during the polymerization reaction releases the free energy needed to drive the incorporation of each nucleotide into the growing DNA chain. The reaction shown on the bottom strand, which would cause DNA cha",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "“Though facts are inherently less satisfying than the intellectual conclusions drawn from them, their importance should never be questioned.”James D. Watson, 2002.DNA carries all of the genetic information for life. One enormously long DNA molecule forms each of the chromosomes of an organism, 23 of them in a human. The fundamental living unit is the single cell. A cell gives rise to many more cells through serial repetitions of a process known as cell division. Before each division, new copies ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "“Though facts are inherently less satisfying than the intellectual conclusions drawn from them, their importance should never be questioned.”James D. Watson, 2002.DNA carries all of the genetic information for life. One enormously long DNA molecule forms each of the chromosomes of an organism, 23 of them in a human. The fundamental living unit is the single cell. A cell gives rise to many more cells through serial repetitions of a process known as cell division. Before each division, new copies ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 1: The DNA replication fork.a,Nucleoside triphosphates serve as a substrate for DNA polymerase, according to the mechanism shown on the top strand. Each nucleoside triphosphate is made up of three phosphates (represented here by yellow spheres), a deoxyribose sugar (beige rectangle) and one of four bases (differently coloured cylinders). The three phosphates are joined to each other by high-energy bonds, and the cleavage of these bonds during the polymerization reaction releases the free ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "a,Nucleoside triphosphates serve as a substrate for DNA polymerase, according to the mechanism shown on the top strand. Each nucleoside triphosphate is made up of three phosphates (represented here by yellow spheres), a deoxyribose sugar (beige rectangle) and one of four bases (differently coloured cylinders). The three phosphates are joined to each other by high-energy bonds, and the cleavage of these bonds during the polymerization reaction releases the free energy needed to drive the incorpor",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "transcription"
    },
    {
      "url": "https://www.nature.com/articles/d41586-025-00054-x",
      "title": "A new vision for how evolution works is long overdue",
      "author": "Jablonka, Eva",
      "published_date": "2025-01-13T00:00:00.000Z",
      "content": {
        "text": "<div><div> <p><b>Evolution Evolving: The Developmental Origins of Adaptation and Biodiversity</b> <i>Kevin Lala et al</i>. Viking Books (2024)</p><p>It’s rare that researchers question theories that make up the backbone of whole fields. But in <i>Evolution Evolving</i>, Kevin Lala and four other eminent evolutionary biologists do just that. Their philosophically informed discussion challenges the textbook version of evolutionary theory, known as the modern synthesis, which has been regarded by many scientists as sacrosanct <a href=\"https://www.nature.com/articles/d41586-022-03579-7\">since its conception in the mid-twentieth century</a>. This shift in thinking — which amounts to a new way of unifying the life sciences — is long overdue.</p><p>The modern synthesis contends that the only process that leads to evolutionary adaptations is the gradual natural selection of DNA mutations, which arise at random. Lala and colleagues argue that how an organism develops also plays a central part in evolution, not just natural selection. They have been championing this view, which they call the <a href=\"https://www.nature.com/articles/514161a\">extended evolutionary synthesis</a>, for more than a decade (<a href=\"https://doi.org/10.1098/rspb.2015.1019\">K. N. Lala <i>et al. Proc. R. Soc. B </i><b>282</b>, 20151019; 2015</a>). And it is hotly debated in the field.</p><article><a href=\"https://www.nature.com/articles/d41586-024-03991-1\"><p>Richard Dawkins book of the dead is haunted by ghosts of past works</p></a></article><p>The authors explain how development — influenced by the conditions in which organisms live — drives <a href=\"https://www.nature.com/articles/nature.2014.15778\">how an organism looks, behaves and evolves</a>. To demonstrate this, they give the example of the Mexican tetra fish <i>Astyanax mexicanus</i>.</p><p>Some populations of <i>A. mexicanus</i> are blind cave fish that live in darkness. Other, genetically distinct populations consist of sighted, surface dwellers. If the surface-dwelling fish are kept in total darkness for two years, they develop traits similar to those of the blind cave fish, including a better ability to store fat — beneficial in a dark environment, where the next meal is hard to come by. The stress of darkness seems to activate sets of genes that alter the fishes’ development.</p><p>Genetic mutations that help to maintain useful traits are then selected for over many generations, and the traits eventually become entrenched. As the authors put it, “evolution must proceed where development leads”.</p><h2><b>Developmental focus</b></h2><p>Under the extended evolutionary synthesis, the questions that are fundamental to the field change. Instead of just asking what genetic mutations might give one organism an advantage over its peers, the authors argue, evolutionary biologists should also focus on the developmental mechanisms and structures that underlie fitness differences.</p><article><a href=\"https://www.nature.com/articles/d41586-024-00327-x\"><p>It’s time to admit that genes are not the blueprint for life</p></a></article><p>A developmental focus, they say, could help in understanding phenomena that are mysterious under the modern synthesis. For example, selective breeding for ‘tameness’, whether in sheep, pigs, horses, dogs or foxes, leads to the evolution of a common series of traits that are not necessarily adaptive — including smaller brains and teeth, curly tails, white patches and flat muzzles. This link, across different animal groups, bred in different ways and at different times, baffled Darwin and others for more than a century.</p><p>The modern synthesis dictates that genetic mutations arise at random, which makes it hard to understand why these traits would consistently evolve in all these tamed animals. But seen through a developmental lens, things are clearer. All these features involve the same embryonic cell type (the neural crest) and their development is thus driven by similar sets of genes.</p><p>Thus, new traits do not arise at random. Some are more likely than others, and suites of traits often arise together. Understanding such ‘developmental biases’ can enable researchers to better understand how traits originate, what directions future evolution might take and how rapidly evolution might proceed.</p><h2><b>Inheritance beyond genes</b></h2><p>Another aspect of evolution often ignored or downplayed by orthodox evolutionists is the passing down of traits through generations in ways that do not involve variations in DNA sequence. These ‘extragenetic’ modes of inheritance should be incorporated into evolutionary models, the authors contend.</p><p>For example, certain whales learn from their mothers how to corral schools of fish into air bubbles. Desert woodrats (<i>Neotoma lepida</i>) eat their mothers’ faeces, which contain gut microorganisms that allow the woodrats to digest plants rich in highly toxic creosote. And molecules called epigenetic marks, which are associated with DNA and modify gene activity, are passed down through generations too. Epigenetic marks that form when mice in the laboratory are trained to link a particular smell with an electric shock, for example, have been passed down to their grandchildren — the young mice are scared of the same smell, even though they have never received the shock.</p><figure></figure><p>Furthermore, some organisms construct environments to benefit the development of subsequent generations. Dung beetles, for instance, make balls of cow dung, into which they add their own faeces as food, and lay a single egg. The nutrients and microbes in these balls influence how the larvae develop, and in turn the sizes and shapes of the beetles and how they evolve.</p></div></div>",
        "html": "<div><div> <p><b>Evolution Evolving: The Developmental Origins of Adaptation and Biodiversity</b> <i>Kevin Lala et al</i>. Viking Books (2024)</p><p>It’s rare that researchers question theories that make up the backbone of whole fields. But in <i>Evolution Evolving</i>, Kevin Lala and four other eminent evolutionary biologists do just that. Their philosophically informed discussion challenges the textbook version of evolutionary theory, known as the modern synthesis, which has been regarded by many scientists as sacrosanct <a href=\"https://www.nature.com/articles/d41586-022-03579-7\">since its conception in the mid-twentieth century</a>. This shift in thinking — which amounts to a new way of unifying the life sciences — is long overdue.</p><p>The modern synthesis contends that the only process that leads to evolutionary adaptations is the gradual natural selection of DNA mutations, which arise at random. Lala and colleagues argue that how an organism develops also plays a central part in evolution, not just natural selection. They have been championing this view, which they call the <a href=\"https://www.nature.com/articles/514161a\">extended evolutionary synthesis</a>, for more than a decade (<a href=\"https://doi.org/10.1098/rspb.2015.1019\">K. N. Lala <i>et al. Proc. R. Soc. B </i><b>282</b>, 20151019; 2015</a>). And it is hotly debated in the field.</p><article><a href=\"https://www.nature.com/articles/d41586-024-03991-1\"><p>Richard Dawkins book of the dead is haunted by ghosts of past works</p></a></article><p>The authors explain how development — influenced by the conditions in which organisms live — drives <a href=\"https://www.nature.com/articles/nature.2014.15778\">how an organism looks, behaves and evolves</a>. To demonstrate this, they give the example of the Mexican tetra fish <i>Astyanax mexicanus</i>.</p><p>Some populations of <i>A. mexicanus</i> are blind cave fish that live in darkness. Other, genetically distinct populations consist of sighted, surface dwellers. If the surface-dwelling fish are kept in total darkness for two years, they develop traits similar to those of the blind cave fish, including a better ability to store fat — beneficial in a dark environment, where the next meal is hard to come by. The stress of darkness seems to activate sets of genes that alter the fishes’ development.</p><p>Genetic mutations that help to maintain useful traits are then selected for over many generations, and the traits eventually become entrenched. As the authors put it, “evolution must proceed where development leads”.</p><h2><b>Developmental focus</b></h2><p>Under the extended evolutionary synthesis, the questions that are fundamental to the field change. Instead of just asking what genetic mutations might give one organism an advantage over its peers, the authors argue, evolutionary biologists should also focus on the developmental mechanisms and structures that underlie fitness differences.</p><article><a href=\"https://www.nature.com/articles/d41586-024-00327-x\"><p>It’s time to admit that genes are not the blueprint for life</p></a></article><p>A developmental focus, they say, could help in understanding phenomena that are mysterious under the modern synthesis. For example, selective breeding for ‘tameness’, whether in sheep, pigs, horses, dogs or foxes, leads to the evolution of a common series of traits that are not necessarily adaptive — including smaller brains and teeth, curly tails, white patches and flat muzzles. This link, across different animal groups, bred in different ways and at different times, baffled Darwin and others for more than a century.</p><p>The modern synthesis dictates that genetic mutations arise at random, which makes it hard to understand why these traits would consistently evolve in all these tamed animals. But seen through a developmental lens, things are clearer. All these features involve the same embryonic cell type (the neural crest) and their development is thus driven by similar sets of genes.</p><p>Thus, new traits do not arise at random. Some are more likely than others, and suites of traits often arise together. Understanding such ‘developmental biases’ can enable researchers to better understand how traits originate, what directions future evolution might take and how rapidly evolution might proceed.</p><h2><b>Inheritance beyond genes</b></h2><p>Another aspect of evolution often ignored or downplayed by orthodox evolutionists is the passing down of traits through generations in ways that do not involve variations in DNA sequence. These ‘extragenetic’ modes of inheritance should be incorporated into evolutionary models, the authors contend.</p><p>For example, certain whales learn from their mothers how to corral schools of fish into air bubbles. Desert woodrats (<i>Neotoma lepida</i>) eat their mothers’ faeces, which contain gut microorganisms that allow the woodrats to digest plants rich in highly toxic creosote. And molecules called epigenetic marks, which are associated with DNA and modify gene activity, are passed down through generations too. Epigenetic marks that form when mice in the laboratory are trained to link a particular smell with an electric shock, for example, have been passed down to their grandchildren — the young mice are scared of the same smell, even though they have never received the shock.</p><figure></figure><p>Furthermore, some organisms construct environments to benefit the development of subsequent generations. Dung beetles, for instance, make balls of cow dung, into which they add their own faeces as food, and lay a single egg. The nutrients and microbes in these balls influence how the larvae develop, and in turn the sizes and shapes of the beetles and how they evolve.</p></div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Evolution Evolving: The Developmental Origins of Adaptation and BiodiversityKevin Lala et al. Viking Books (2024)It’s rare that researchers question theories that make up the backbone of whole fields. But inEvolution Evolving, Kevin Lala and four other eminent evolutionary biologists do just that. Their philosophically informed discussion challenges the textbook version of evolutionary theory, known as the modern synthesis, which has been regarded by many scientists as sacrosanctsince its concep",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Evolution Evolving: The Developmental Origins of Adaptation and BiodiversityKevin Lala et al. Viking Books (2024)It’s rare that researchers question theories that make up the backbone of whole fields. But inEvolution Evolving, Kevin Lala and four other eminent evolutionary biologists do just that. Their philosophically informed discussion challenges the textbook version of evolutionary theory, known as the modern synthesis, which has been regarded by many scientists as sacrosanctsince its concep",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "Richard Dawkins book of the dead is haunted by ghosts of past works",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "It’s time to admit that genes are not the blueprint for life",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Developmental focus",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Inheritance beyond genes",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC5698631/",
      "title": "Recombination: the good, the bad and the variable",
      "author": "",
      "published_date": "2017-11-06T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Recombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can be <em>good</em>, as it can facilitate adaptation, but also <em>bad</em> when it breaks apart beneficial combinations of alleles, and recombination is highly <em>variable</em> between taxa, species, individuals and across the genome. Understanding how and why recombination rate varies is a major challenge in biology. Most theoretical and empirical work has been devoted to understanding the role of recombination in the evolution of sex—comparing between sexual and asexual species or populations. How recombination rate evolves and what impact this has on evolutionary processes within sexually reproducing organisms has received much less attention. This Theme Issue focusses on how and why recombination rate varies in sexual species, and aims to coalesce knowledge of the molecular mechanisms governing recombination with our understanding of the evolutionary processes driving variation in recombination within and between species. By integrating these fields, we can identify important knowledge gaps and areas for future research, and pave the way for a more comprehensive understanding of how and why recombination rate varies.</p>\n<section><p><strong>Keywords:</strong> crossing over, meiosis, genetic linkage, evolution, adaptation, genomics</p></section></section><section><h2>1. Introduction</h2>\n<p>Recombination, the exchange of DNA between maternal and paternal chromosomes during meiosis, is a near universal processes occurring in almost all forms of life and is fundamental for DNA repair and meiotic cell division. Recombination is <em>good</em> as it can facilitate adaptation through the creation of novel genetic combinations [<a href=\"#RSTB20170279C1\">1</a>,<a href=\"#RSTB20170279C2\">2</a>], but also <em>bad</em> as it can break apart favourable combinations of alleles [<a href=\"#RSTB20170279C3\">3</a>], and despite meiosis and recombination being highly regulated, recombination is frequently <em>variable</em> across the genome, across taxa, between the sexes, populations and individuals [<a href=\"#RSTB20170279C4\">4</a>]. Although ongoing advances in DNA sequencing technology and methods to estimate recombination from population-based samples are providing much needed empirical evidence of ‘How’ recombination varies, our understanding of ‘Why’ it varies is progressing more slowly.</p>\n<p>When considering this question: ‘Why does recombination rate vary?’, there is much focus on the evolutionary advantage of sex, but much less attention given to understanding why recombination varies between sexually reproducing organisms. For us, as a group of evolutionary biologists who have observed variation in recombination rate in sexually reproducing organisms—we considered this an important knowledge gap. Hence, we proposed this special issue ‘Evolutionary causes and consequences of recombination rate variation in sexual organisms' with the aim to bring this question to the fore and to encourage more researchers to investigate if and how recombination rate varies, whether it responds to natural or sexual selection, and how it influences fundamental evolutionary processes within sexually reproducing organisms, such as adaptation and speciation.</p>\n<p>To understand the evolution of recombination, like any trait, we need information on the heritability and plasticity of the trait, on how the trait influences fitness, and on the molecular mechanisms controlling the trait. In this respect, we know a lot about recombination—recombination is heritable, many populations harbour additive genetic variation for it, and it can respond to selection in the laboratory [<a href=\"#RSTB20170279C4\">4</a>]. Recombination is also modified by a range of environmental stimuli, including temperature [<a href=\"#RSTB20170279C5\">5</a>] and condition [<a href=\"#RSTB20170279C6\">6</a>]. Recombination has well-characterized fitness effects: for example, in humans, altered rates of recombination can cause chromosomal abnormalities, reduced fertility and disease [<a href=\"#RSTB20170279C7\">7</a>]. Enormous progress has been made recently in understanding the genetic elements that control recombination, and these include elements that are highly conserved across eukaryotes (e.g. SPO11), as well as evolutionarily dynamic elements such as PRDM9 [<a href=\"#RSTB20170279C8\">8</a>]. However, unlike other traits that evolutionary biologists commonly study, recombination has some very unusual properties: it can influence the efficacy of selection [<a href=\"#RSTB20170279C9\">9</a>,<a href=\"#RSTB20170279C10\">10</a>], facilitate adaptation to changing environments [<a href=\"#RSTB20170279C1\">1</a>,<a href=\"#RSTB20170279C11\">11</a>], it can alter patterns of nucleotide diversity [<a href=\"#RSTB20170279C8\">8</a>] and influence genetic diversity within populations [<a href=\"#RSTB20170279C12\">12</a>,<a href=\"#RSTB20170279C13\">13</a>]. Thus, variation in recombination can experience direct and indirect selection, and this selection can result from short-term (in the next generation) and long-term (over many generations) benefits.</p>\n<p>Addressing the question ‘Why does recombination rate vary?’ necessitates understanding both direct and indirect effects of selection. However, most researchers often do not consider selection operating at these different scales simultaneously. For example, population geneticists often view recombination as a population parameter that is under indirect and long-term selection, whereas developmental biologists consider the direct, short-term effects that an altered rate of recombination has on individual traits like fertility. One goal of this Special Issue is to try to better integrate these different perspectives. Thus, we sought contributions from the ‘population genetics–evolutionary’ perspective [<a href=\"#RSTB20170279C14\">14</a>–<a href=\"#RSTB20170279C16\">16</a>] as well as the ‘developmental–molecular’ perspective [<a href=\"#RSTB20170279C5\">5</a>,<a href=\"#RSTB20170279C7\">7</a>,<a href=\"#RSTB20170279C8\">8</a>], with the hope that this will foster greater communication across these disciplines.</p>\n<p>The Special Issue opens with a general review of how and why recombination rate varies across eukaryotes. It includes an analysis of data from the largest collection of linkage maps to date and an overview of the processes that explain variation in recombination rate—from genome architecture to evolutionary explanations. The review introduces many of the concepts and evolutionary theories that are explored in greater depth in the proceeding articles. Although empirical data for recombination are growing rapidly, progress in explaining this variation has been slow. Dapper &amp; Payseur [<a href=\"#RSTB20170279C17\">17</a>] argue that progress in the field is hampered by a disconnect between empirical data and the large body of theory that has been developed to explain variation in recombination. For example, much theory has been developed to explain the evolutionary advantage of recombination, but this theory does not address quantitative differences among individuals or variation at different genomic scales [<a href=\"#RSTB20170279C17\">17</a>]. Likewise, empirical data are often not collected to directly test current theories and to address this Dapper &amp; Payseur [<a href=\"#RSTB20170279C17\">17</a>] provide a useful table that lists the main hypotheses proposed to explain the evolution of recombination, along with their key requirements and testable predictions relating to each.</p>\n<p>Variation in recombination may be explained by variation in the sexual system and the evolutionary consequences of different reproductive modes. For example, selfing and inbreeding species may benefit from high rates of recombination because it can increase genetic diversity and allelic shuffling, and there is some evidence to support this [<a href=\"#RSTB20170279C4\">4</a>]. However, the transition to obligate asexuality may result in suppression of recombination, because asexuals often have modified meiosis and because recombination can erode heterozygosity in asexuals [<a href=\"#RSTB20170279C18\">18</a>]. To investigate how recombination rate varies between sexual and asexual species, Haag <em>et al</em>. [<a href=\"#RSTB20170279C18\">18</a>] build a new linkage map for an undescribed species of brine shrimp whose closest relative is an obligate asexual. In their focal sexual species, they report one of the shortest linkage maps known, and propose that the observed low recombination rates in some sexual species may favour sex–asex transitions or, alternatively, may be a consequence of it. The generality of this finding has yet to be tested and Haag <em>et al</em>. [<a href=\"#RSTB20170279C18\">18</a>] acknowledge that counter examples in other groups exist. One notable counter example is observed in <em>Daphnia</em>, a genus that contains both sexual and asexual parthenogenetic species. In cyclically parthenogenic species for which linkage maps have been made, we observe a very high recombination rate per megabase compared to other crustaceans [<a href=\"#RSTB20170279C4\">4</a>]. These apparent contradictory results demonstrate that we need more recombination data in a greater ranges of species in order to begin to address long-standing theories on the evolution of recombination.</p>\n<p>A notable pattern to emerge from empirical data is the observation that the distribution of recombination events is distinctly non-random across the genome. Variation is observed at many genomic scales: between chromosomes, between megabase regions within chromosomes and across regions spanning only a few kilobases. Between closely related species, the",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Recombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can be <em>good</em>, as it can facilitate adaptation, but also <em>bad</em> when it breaks apart beneficial combinations of alleles, and recombination is highly <em>variable</em> between taxa, species, individuals and across the genome. Understanding how and why recombination rate varies is a major challenge in biology. Most theoretical and empirical work has been devoted to understanding the role of recombination in the evolution of sex—comparing between sexual and asexual species or populations. How recombination rate evolves and what impact this has on evolutionary processes within sexually reproducing organisms has received much less attention. This Theme Issue focusses on how and why recombination rate varies in sexual species, and aims to coalesce knowledge of the molecular mechanisms governing recombination with our understanding of the evolutionary processes driving variation in recombination within and between species. By integrating these fields, we can identify important knowledge gaps and areas for future research, and pave the way for a more comprehensive understanding of how and why recombination rate varies.</p>\n<section><p><strong>Keywords:</strong> crossing over, meiosis, genetic linkage, evolution, adaptation, genomics</p></section></section><section><h2>1. Introduction</h2>\n<p>Recombination, the exchange of DNA between maternal and paternal chromosomes during meiosis, is a near universal processes occurring in almost all forms of life and is fundamental for DNA repair and meiotic cell division. Recombination is <em>good</em> as it can facilitate adaptation through the creation of novel genetic combinations [<a href=\"#RSTB20170279C1\">1</a>,<a href=\"#RSTB20170279C2\">2</a>], but also <em>bad</em> as it can break apart favourable combinations of alleles [<a href=\"#RSTB20170279C3\">3</a>], and despite meiosis and recombination being highly regulated, recombination is frequently <em>variable</em> across the genome, across taxa, between the sexes, populations and individuals [<a href=\"#RSTB20170279C4\">4</a>]. Although ongoing advances in DNA sequencing technology and methods to estimate recombination from population-based samples are providing much needed empirical evidence of ‘How’ recombination varies, our understanding of ‘Why’ it varies is progressing more slowly.</p>\n<p>When considering this question: ‘Why does recombination rate vary?’, there is much focus on the evolutionary advantage of sex, but much less attention given to understanding why recombination varies between sexually reproducing organisms. For us, as a group of evolutionary biologists who have observed variation in recombination rate in sexually reproducing organisms—we considered this an important knowledge gap. Hence, we proposed this special issue ‘Evolutionary causes and consequences of recombination rate variation in sexual organisms' with the aim to bring this question to the fore and to encourage more researchers to investigate if and how recombination rate varies, whether it responds to natural or sexual selection, and how it influences fundamental evolutionary processes within sexually reproducing organisms, such as adaptation and speciation.</p>\n<p>To understand the evolution of recombination, like any trait, we need information on the heritability and plasticity of the trait, on how the trait influences fitness, and on the molecular mechanisms controlling the trait. In this respect, we know a lot about recombination—recombination is heritable, many populations harbour additive genetic variation for it, and it can respond to selection in the laboratory [<a href=\"#RSTB20170279C4\">4</a>]. Recombination is also modified by a range of environmental stimuli, including temperature [<a href=\"#RSTB20170279C5\">5</a>] and condition [<a href=\"#RSTB20170279C6\">6</a>]. Recombination has well-characterized fitness effects: for example, in humans, altered rates of recombination can cause chromosomal abnormalities, reduced fertility and disease [<a href=\"#RSTB20170279C7\">7</a>]. Enormous progress has been made recently in understanding the genetic elements that control recombination, and these include elements that are highly conserved across eukaryotes (e.g. SPO11), as well as evolutionarily dynamic elements such as PRDM9 [<a href=\"#RSTB20170279C8\">8</a>]. However, unlike other traits that evolutionary biologists commonly study, recombination has some very unusual properties: it can influence the efficacy of selection [<a href=\"#RSTB20170279C9\">9</a>,<a href=\"#RSTB20170279C10\">10</a>], facilitate adaptation to changing environments [<a href=\"#RSTB20170279C1\">1</a>,<a href=\"#RSTB20170279C11\">11</a>], it can alter patterns of nucleotide diversity [<a href=\"#RSTB20170279C8\">8</a>] and influence genetic diversity within populations [<a href=\"#RSTB20170279C12\">12</a>,<a href=\"#RSTB20170279C13\">13</a>]. Thus, variation in recombination can experience direct and indirect selection, and this selection can result from short-term (in the next generation) and long-term (over many generations) benefits.</p>\n<p>Addressing the question ‘Why does recombination rate vary?’ necessitates understanding both direct and indirect effects of selection. However, most researchers often do not consider selection operating at these different scales simultaneously. For example, population geneticists often view recombination as a population parameter that is under indirect and long-term selection, whereas developmental biologists consider the direct, short-term effects that an altered rate of recombination has on individual traits like fertility. One goal of this Special Issue is to try to better integrate these different perspectives. Thus, we sought contributions from the ‘population genetics–evolutionary’ perspective [<a href=\"#RSTB20170279C14\">14</a>–<a href=\"#RSTB20170279C16\">16</a>] as well as the ‘developmental–molecular’ perspective [<a href=\"#RSTB20170279C5\">5</a>,<a href=\"#RSTB20170279C7\">7</a>,<a href=\"#RSTB20170279C8\">8</a>], with the hope that this will foster greater communication across these disciplines.</p>\n<p>The Special Issue opens with a general review of how and why recombination rate varies across eukaryotes. It includes an analysis of data from the largest collection of linkage maps to date and an overview of the processes that explain variation in recombination rate—from genome architecture to evolutionary explanations. The review introduces many of the concepts and evolutionary theories that are explored in greater depth in the proceeding articles. Although empirical data for recombination are growing rapidly, progress in explaining this variation has been slow. Dapper &amp; Payseur [<a href=\"#RSTB20170279C17\">17</a>] argue that progress in the field is hampered by a disconnect between empirical data and the large body of theory that has been developed to explain variation in recombination. For example, much theory has been developed to explain the evolutionary advantage of recombination, but this theory does not address quantitative differences among individuals or variation at different genomic scales [<a href=\"#RSTB20170279C17\">17</a>]. Likewise, empirical data are often not collected to directly test current theories and to address this Dapper &amp; Payseur [<a href=\"#RSTB20170279C17\">17</a>] provide a useful table that lists the main hypotheses proposed to explain the evolution of recombination, along with their key requirements and testable predictions relating to each.</p>\n<p>Variation in recombination may be explained by variation in the sexual system and the evolutionary consequences of different reproductive modes. For example, selfing and inbreeding species may benefit from high rates of recombination because it can increase genetic diversity and allelic shuffling, and there is some evidence to support this [<a href=\"#RSTB20170279C4\">4</a>]. However, the transition to obligate asexuality may result in suppression of recombination, because asexuals often have modified meiosis and because recombination can erode heterozygosity in asexuals [<a href=\"#RSTB20170279C18\">18</a>]. To investigate how recombination rate varies between sexual and asexual species, Haag <em>et al</em>. [<a href=\"#RSTB20170279C18\">18</a>] build a new linkage map for an undescribed species of brine shrimp whose closest relative is an obligate asexual. In their focal sexual species, they report one of the shortest linkage maps known, and propose that the observed low recombination rates in some sexual species may favour sex–asex transitions or, alternatively, may be a consequence of it. The generality of this finding has yet to be tested and Haag <em>et al</em>. [<a href=\"#RSTB20170279C18\">18</a>] acknowledge that counter examples in other groups exist. One notable counter example is observed in <em>Daphnia</em>, a genus that contains both sexual and asexual parthenogenetic species. In cyclically parthenogenic species for which linkage maps have been made, we observe a very high recombination rate per megabase compared to other crustaceans [<a href=\"#RSTB20170279C4\">4</a>]. These apparent contradictory results demonstrate that we need more recombination data in a greater ranges of species in order to begin to address long-standing theories on the evolution of recombination.</p>\n<p>A notable pattern to emerge from empirical data is the observation that the distribution of recombination events is distinctly non-random across the genome. Variation is observed at many genomic scales: between chromosomes, between megabase regions within chromosomes and across regions spanning only a few kilobases. Between closely related species, the",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractRecombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can begood, as it can facilitate adaptation, but alsobadwhen it breaks apart beneficial combinations of alleles, and recombination is highlyvariablebetween taxa, species, individuals and across the genome. Understanding how and why recombinat",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractRecombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can begood, as it can facilitate adaptation, but alsobadwhen it breaks apart beneficial combinations of alleles, and recombination is highlyvariablebetween taxa, species, individuals and across the genome. Understanding how and why recombinat",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractRecombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can begood, as it can facilitate adaptation, but alsobadwhen it breaks apart beneficial combinations of alleles, and recombination is highlyvariablebetween taxa, species, individuals and across the genome. Understanding how and why recombinat",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractRecombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can begood, as it can facilitate adaptation, but alsobadwhen it breaks apart beneficial combinations of alleles, and recombination is highlyvariablebetween taxa, species, individuals and across the genome. Understanding how and why recombinat",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractRecombination, the process by which DNA strands are broken and repaired, producing new combinations of alleles, occurs in nearly all multicellular organisms and has important implications for many evolutionary processes. The effects of recombination can begood, as it can facilitate adaptation, but alsobadwhen it breaks apart beneficial combinations of alleles, and recombination is highlyvariablebetween taxa, species, individuals and across the genome. Understanding how and why recombinat",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:crossing over, meiosis, genetic linkage, evolution, adaptation, genomics",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. IntroductionRecombination, the exchange of DNA between maternal and paternal chromosomes during meiosis, is a near universal processes occurring in almost all forms of life and is fundamental for DNA repair and meiotic cell division. Recombination isgoodas it can facilitate adaptation through the creation of novel genetic combinations [1,2], but alsobadas it can break apart favourable combinations of alleles [3], and despite meiosis and recombination being highly regulated, recombination is f",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "1. Introduction",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://zhaogroup.chbe.illinois.edu/publications/HZ61.pdf",
      "title": "s0b.dvi",
      "author": "",
      "published_date": null,
      "content": {
        "text": "Advanced Article\nArticle Contents\n• A Primer for Directed Evolution\n• Methods for Directed Evolution\n• Applications of Directed Evolution\n• Conclusions and Future Prospects\nDirected Evolution: Novel\nand Improved Enzymes\nFei Wen∗, Department of Chemical and Biomolecular Engineering, University of\nIllinois at Urbana-Champaign, Urbana, Illinois\nMichael McLachlan∗, Center for Biophysics and Computational Biology,\nUniversity of Illinois at Urbana-Champaign, Urbana, Illinois\nHuimin Zhao, Departments of Chemical and Biomolecular Engineering and\nChemistry, University of Illinois at Urbana-Champaign, Urbana, Illinois\ndoi: 10.1002/9780470048672.wecb125\nBy mimicking Darwinian evolution in the test tube, directed evolution has\nbecome a powerful tool for engineering novel enzymes for basic and\napplied biology research and medicine. Unlike structure-based rational\ndesign, directed evolution is capable of altering single or multiple\nfunctional properties such as activity, specificity, selectivity, stability, and\nsolubility of naturally occurring enzymes in the absence of detailed\nknowledge of enzyme structure, function, or mechanism. More recently,\ndirected evolution has also been used to engineer metabolic pathways,\nviruses, and whole microorganisms, and to address fundamental problems\nin biology. The success of directed evolution has been largely fueled by the\ndevelopment of numerous molecular biology techniques that enable the\ncreation of genetic diversity through random mutagenesis or homologous\nor nonhomologous recombination in the target genes and the\ndevelopment of powerful high throughput screening or selection methods\nas well as by novel applications. This review will highlight the key\ndevelopments in directed evolution and focus on the design and\nengineering of novel enzymes through directed evolution and their\nimplications in chemical biology.\nEnzymes are truly remarkable catalysts that are essential to ev\u0002ery biological process. They can catalyze a broad range of chem\u0002ical transformations with exquisite selectivity (stereo-, regio-,\nand chemo-) and specificity. In addition, most enzymes are\nvery efficient and operate at mild conditions. It is, therefore,\nnot surprising that enzymes have been increasingly used as bi\u0002ological catalysts or therapeutic agents in various industries,\nincluding the chemical, pharmaceutical, agricultural, and food\nindustries. However, the number and diversity of enzyme-based\napplications are still modest compared with the total number of\nenzymes identified so far (∼5000 enzymes) (1). One main rea\u0002son for this functional gap is that naturally occurring enzymes\nare the products of Darwinian evolution and are not designed\nfor optimal industrial applications. To address this limitation,\nseveral enzyme engineering approaches have been developed\n∗These two authors contributed equally.\nin the past few decades, among which directed evolution stands\nout as a particularly attractive approach. This entry discusses\nthe brief history of directed evolution, the main methods of di\u0002rected evolution, and their applications in engineering enzymes\nfor basic and applied biology research. For more in-depth in\u0002formation on directed evolution, interested readers are referred\nto the Further Reading list.\nA Primer for Directed Evolution\nBefore the advent of recombinant DNA technology in the 1970s,\nthe ability to engineer novel enzymes was limited to chemical\nmodification methods in which specific residues in an enzyme\nWILEY ENCYCLOPEDIA OF CHEMICAL BIOLOGY  2008, John Wiley & Sons, Inc. 1\nDirected Evolution: Novel and Improved Enzymes\nFigure 1 General scheme of directed evolution.\nare modified by chemical agents. With the development of\nrecombinant DNA technology, site-directed mutagenesis, and\npolymerase chain reaction (PCR) technology coupled with ad\u0002vances in X-ray crystallography, structure-based rational design\nbecame a dominant approach for engineering novel enzymes\nin the 1980s (2). Although rational design has achieved some\nnotable successes, the requirement for extensive structural and\nmechanistic information on a target enzyme beset this method.\nDespite decades of research in protein science, it is still very\ndifficult to identify the molecular determinants for the desired\nenzyme feature(s) even when the structure of the target enzyme\nis available, let alone the vast number of enzymes without crys\u0002tal structures.\nDirected evolution bypasses the bottleneck of rational design\nand mimics natural evolution in a test tube to evolve proteins\nwithout knowledge of their structures. What fundamentally dif\u0002ferentiates directed evolution from natural evolution is its power\nto significantly accelerate the process of evolution. As shown\nin Fig. 1, directed evolution uses various methods to gener\u0002ate a collection of random protein variants, called a library, at\nthe DNA level. Followed by screening/selection of the library,\nprotein variants with improvement in desired phenotypes are ob\u0002tained. Usually, the occurrence of these functionally improved\nprotein variants is a rare event; thus, this two-step procedure\nhas to be iterated several rounds until the goal is achieved or\nno further improvement is possible.\nOne of the very first directed evolution experiments can be\ntraced back to as early as 1967 (3), but directed evolution did\nnot become an established field until the mid-1990s. Advances\nin molecular biology have promoted rapid development of a\nwide variety of methods aimed at generating genetic diversities\nand at searching the molecular reservoir in a high throughput\nmanner. In the past few years, directed evolution has been used\nto successfully engineer many enzymes for commercial and\nindustrial applications (4), and the targets for directed enzyme\nevolution have been focused on activity, stability, specificity,\nand selectivity. It should be noted that the field of directed\nevolution is not limited only to enzyme engineering, but it can\nbe applied to any single protein. In addition, more research\n(a) (b) (c)\nFigure 2 Comparison of (a) random mutagenesis, (b) gene\nrecombination, and (c) semirational design.\nhas recently started addressing more complex systems, such as\npathways (metabolic engineering), viruses, and even genomes.\nMethods for Directed Evolution\nA successful directed evolution experiment involves two key\ncomponents: creating genetic diversity and developing a high\nthroughput screening or selection method. In the past decade,\nmany experimental methods and protocols for library construc\u0002tion and screening/selection have been developed. For more\ninformation on this topic, interested readers are referred to the\ntwo books edited by Arnold and Georgiou in the Further Read\u0002ing list.\nLibrary creation\nNumerous molecular biology methods have been developed to\nintroduce genetic diversity into the target gene, all of which can\nbe grouped into three categories: methods of random mutage\u0002nesis, methods of gene recombination, and methods of semira\u0002tional design. As shown in Fig. 2, random mutagenesis starts\nfrom a single parent gene and randomly introduces point muta\u0002tions or insertions/deletions into the progeny genes. In compar\u0002ison, gene recombination usually starts from a pool of mutants\nfrom a single gene or a pool of closely related or even non\u0002related parental genes of different origin and creates blockwise\nexchange of sequence information among the parental genes. Fi\u0002nally, semirational design combines rational design and directed\nevolution by focusing mutagenesis on a few selected important\nresidues or regions in a target gene.\nRandom mutagenesis\nAs a result of its simplicity and efficiency, error-prone poly\u0002merase chain reaction (EP-PCR) is the most widely used random\nmutagenesis method. It is essentially a variation of the standard\nPCR with slightly modified reaction conditions (5). There are\nmany different protocols to implement EP-PCR, and the most\npopular one includes the following adjustments to normal PCR\nconditions: 1) use of nonproofreading DNA polymerases, such\nas Taq DNA polymerase; 2) use of low or unbalanced amount\nof dNTPs; 3) use of high concentration of Mg2+ (up to 10 mM);\n2 WILEY ENCYCLOPEDIA OF CHEMICAL BIOLOGY  2008, John Wiley & Sons, Inc.\nDirected Evolution: Novel and Improved Enzymes\nand 4) incorporation of Mn2+. The fourth modification has made\nEP-PCR more popular, because the error rate can be controlled\nprecisely by the Mn2+ concentration (6). In general, 1–2 amino\nacid substitutions are introduced during each round of EP-PCR,\nwhich requires approximately 1–5 base mutations per kilobase\nof DNA. Higher mutagenic rates are not normally used because\nthey often damage enzyme function and lead to an increased\ntendency to negate positive mutations. In addition, higher mu\u0002tagenic rates result in a larger library size, which in turn requires\nan often unattainable robust screening/selection method to iden\u0002tify positive variants. On the other hand, a higher mutation rate\nincreases the frequency of multiple mutations with synergis\u0002tic effects, resulting in an overall enrichment of unique protein\nvariants, and up to 30 mutations per gene have been reported (7).\nThe great success of EP-PCR in engineering all aspects of\nenzyme properties has established this method as a cornerstone\nin directed evolution. It should be noted, however, that this tech\u0002nique is not truly random and suffers a number of limitations. In\naddition to the intrinsic bias of DNA polymerases (transitions\nare favored over transversions), EP-PCR can only access 5–6\namino acids substitutions on average at each residue because of\nthe degeneracy of genetic codons and the low probability of two\nmutations occurring right next to each other. Another limitation\nof EP-PCR is associated with the low mutation rates normally\nused, such that the progeny protein variants have similar pheno\u0002type to the parent. Thus, novel functions are difficult to evolve\nusing this method alone even after several rounds of iteration.\nTo search the sequenc",
        "html": "Advanced Article\nArticle Contents\n• A Primer for Directed Evolution\n• Methods for Directed Evolution\n• Applications of Directed Evolution\n• Conclusions and Future Prospects\nDirected Evolution: Novel\nand Improved Enzymes\nFei Wen∗, Department of Chemical and Biomolecular Engineering, University of\nIllinois at Urbana-Champaign, Urbana, Illinois\nMichael McLachlan∗, Center for Biophysics and Computational Biology,\nUniversity of Illinois at Urbana-Champaign, Urbana, Illinois\nHuimin Zhao, Departments of Chemical and Biomolecular Engineering and\nChemistry, University of Illinois at Urbana-Champaign, Urbana, Illinois\ndoi: 10.1002/9780470048672.wecb125\nBy mimicking Darwinian evolution in the test tube, directed evolution has\nbecome a powerful tool for engineering novel enzymes for basic and\napplied biology research and medicine. Unlike structure-based rational\ndesign, directed evolution is capable of altering single or multiple\nfunctional properties such as activity, specificity, selectivity, stability, and\nsolubility of naturally occurring enzymes in the absence of detailed\nknowledge of enzyme structure, function, or mechanism. More recently,\ndirected evolution has also been used to engineer metabolic pathways,\nviruses, and whole microorganisms, and to address fundamental problems\nin biology. The success of directed evolution has been largely fueled by the\ndevelopment of numerous molecular biology techniques that enable the\ncreation of genetic diversity through random mutagenesis or homologous\nor nonhomologous recombination in the target genes and the\ndevelopment of powerful high throughput screening or selection methods\nas well as by novel applications. This review will highlight the key\ndevelopments in directed evolution and focus on the design and\nengineering of novel enzymes through directed evolution and their\nimplications in chemical biology.\nEnzymes are truly remarkable catalysts that are essential to ev\u0002ery biological process. They can catalyze a broad range of chem\u0002ical transformations with exquisite selectivity (stereo-, regio-,\nand chemo-) and specificity. In addition, most enzymes are\nvery efficient and operate at mild conditions. It is, therefore,\nnot surprising that enzymes have been increasingly used as bi\u0002ological catalysts or therapeutic agents in various industries,\nincluding the chemical, pharmaceutical, agricultural, and food\nindustries. However, the number and diversity of enzyme-based\napplications are still modest compared with the total number of\nenzymes identified so far (∼5000 enzymes) (1). One main rea\u0002son for this functional gap is that naturally occurring enzymes\nare the products of Darwinian evolution and are not designed\nfor optimal industrial applications. To address this limitation,\nseveral enzyme engineering approaches have been developed\n∗These two authors contributed equally.\nin the past few decades, among which directed evolution stands\nout as a particularly attractive approach. This entry discusses\nthe brief history of directed evolution, the main methods of di\u0002rected evolution, and their applications in engineering enzymes\nfor basic and applied biology research. For more in-depth in\u0002formation on directed evolution, interested readers are referred\nto the Further Reading list.\nA Primer for Directed Evolution\nBefore the advent of recombinant DNA technology in the 1970s,\nthe ability to engineer novel enzymes was limited to chemical\nmodification methods in which specific residues in an enzyme\nWILEY ENCYCLOPEDIA OF CHEMICAL BIOLOGY  2008, John Wiley & Sons, Inc. 1\nDirected Evolution: Novel and Improved Enzymes\nFigure 1 General scheme of directed evolution.\nare modified by chemical agents. With the development of\nrecombinant DNA technology, site-directed mutagenesis, and\npolymerase chain reaction (PCR) technology coupled with ad\u0002vances in X-ray crystallography, structure-based rational design\nbecame a dominant approach for engineering novel enzymes\nin the 1980s (2). Although rational design has achieved some\nnotable successes, the requirement for extensive structural and\nmechanistic information on a target enzyme beset this method.\nDespite decades of research in protein science, it is still very\ndifficult to identify the molecular determinants for the desired\nenzyme feature(s) even when the structure of the target enzyme\nis available, let alone the vast number of enzymes without crys\u0002tal structures.\nDirected evolution bypasses the bottleneck of rational design\nand mimics natural evolution in a test tube to evolve proteins\nwithout knowledge of their structures. What fundamentally dif\u0002ferentiates directed evolution from natural evolution is its power\nto significantly accelerate the process of evolution. As shown\nin Fig. 1, directed evolution uses various methods to gener\u0002ate a collection of random protein variants, called a library, at\nthe DNA level. Followed by screening/selection of the library,\nprotein variants with improvement in desired phenotypes are ob\u0002tained. Usually, the occurrence of these functionally improved\nprotein variants is a rare event; thus, this two-step procedure\nhas to be iterated several rounds until the goal is achieved or\nno further improvement is possible.\nOne of the very first directed evolution experiments can be\ntraced back to as early as 1967 (3), but directed evolution did\nnot become an established field until the mid-1990s. Advances\nin molecular biology have promoted rapid development of a\nwide variety of methods aimed at generating genetic diversities\nand at searching the molecular reservoir in a high throughput\nmanner. In the past few years, directed evolution has been used\nto successfully engineer many enzymes for commercial and\nindustrial applications (4), and the targets for directed enzyme\nevolution have been focused on activity, stability, specificity,\nand selectivity. It should be noted that the field of directed\nevolution is not limited only to enzyme engineering, but it can\nbe applied to any single protein. In addition, more research\n(a) (b) (c)\nFigure 2 Comparison of (a) random mutagenesis, (b) gene\nrecombination, and (c) semirational design.\nhas recently started addressing more complex systems, such as\npathways (metabolic engineering), viruses, and even genomes.\nMethods for Directed Evolution\nA successful directed evolution experiment involves two key\ncomponents: creating genetic diversity and developing a high\nthroughput screening or selection method. In the past decade,\nmany experimental methods and protocols for library construc\u0002tion and screening/selection have been developed. For more\ninformation on this topic, interested readers are referred to the\ntwo books edited by Arnold and Georgiou in the Further Read\u0002ing list.\nLibrary creation\nNumerous molecular biology methods have been developed to\nintroduce genetic diversity into the target gene, all of which can\nbe grouped into three categories: methods of random mutage\u0002nesis, methods of gene recombination, and methods of semira\u0002tional design. As shown in Fig. 2, random mutagenesis starts\nfrom a single parent gene and randomly introduces point muta\u0002tions or insertions/deletions into the progeny genes. In compar\u0002ison, gene recombination usually starts from a pool of mutants\nfrom a single gene or a pool of closely related or even non\u0002related parental genes of different origin and creates blockwise\nexchange of sequence information among the parental genes. Fi\u0002nally, semirational design combines rational design and directed\nevolution by focusing mutagenesis on a few selected important\nresidues or regions in a target gene.\nRandom mutagenesis\nAs a result of its simplicity and efficiency, error-prone poly\u0002merase chain reaction (EP-PCR) is the most widely used random\nmutagenesis method. It is essentially a variation of the standard\nPCR with slightly modified reaction conditions (5). There are\nmany different protocols to implement EP-PCR, and the most\npopular one includes the following adjustments to normal PCR\nconditions: 1) use of nonproofreading DNA polymerases, such\nas Taq DNA polymerase; 2) use of low or unbalanced amount\nof dNTPs; 3) use of high concentration of Mg2+ (up to 10 mM);\n2 WILEY ENCYCLOPEDIA OF CHEMICAL BIOLOGY  2008, John Wiley & Sons, Inc.\nDirected Evolution: Novel and Improved Enzymes\nand 4) incorporation of Mn2+. The fourth modification has made\nEP-PCR more popular, because the error rate can be controlled\nprecisely by the Mn2+ concentration (6). In general, 1–2 amino\nacid substitutions are introduced during each round of EP-PCR,\nwhich requires approximately 1–5 base mutations per kilobase\nof DNA. Higher mutagenic rates are not normally used because\nthey often damage enzyme function and lead to an increased\ntendency to negate positive mutations. In addition, higher mu\u0002tagenic rates result in a larger library size, which in turn requires\nan often unattainable robust screening/selection method to iden\u0002tify positive variants. On the other hand, a higher mutation rate\nincreases the frequency of multiple mutations with synergis\u0002tic effects, resulting in an overall enrichment of unique protein\nvariants, and up to 30 mutations per gene have been reported (7).\nThe great success of EP-PCR in engineering all aspects of\nenzyme properties has established this method as a cornerstone\nin directed evolution. It should be noted, however, that this tech\u0002nique is not truly random and suffers a number of limitations. In\naddition to the intrinsic bias of DNA polymerases (transitions\nare favored over transversions), EP-PCR can only access 5–6\namino acids substitutions on average at each residue because of\nthe degeneracy of genetic codons and the low probability of two\nmutations occurring right next to each other. Another limitation\nof EP-PCR is associated with the low mutation rates normally\nused, such that the progeny protein variants have similar pheno\u0002type to the parent. Thus, novel functions are difficult to evolve\nusing this method alone even after several rounds of iteration.\nTo search the sequenc",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://royalsocietypublishing.org/doi/10.1098/rspb.2015.1019",
      "title": "The extended evolutionary synthesis: its structure, assumptions and predictions",
      "author": "Kevin N Laland, University of St Andrews, St Andrews, Fife, UK, Tobias  Uller, Edward Grey Institute, Marcus W Feldman, Stanford University, Herrin Hall, 94305, Stanford, CA, USA, Kim  Sterelny, Australian National University, Canberra, Australia, Gerd B Müller, Armin  Moczek, Indiana University, 47405-7107, Bloomington, IN, USA, Eva  Jablonka, Tel Aviv University, Tel Aviv, Israel, John  Odling-Smee, University of Oxford, Oxford, UK",
      "published_date": "2015-08-22T00:00:00.000Z",
      "content": {
        "text": "Scientific activities take place within the structured sets of ideas and assumptions that define a field and its practices. The conceptual framework of evolutionary biology emerged with the Modern Synthesis in the early twentieth century and has since expanded into a highly successful research program to explore the processes of diversification and adaptation. Nonetheless, the ability of that framework satisfactorily to accommodate the rapid advances in developmental biology, genomics and ecology has been questioned. We review some of these arguments, focusing on literatures (evo-devo, developmental plasticity, inclusive inheritance and niche construction) whose implications for evolution can be interpreted in two ways—one that preserves the internal structure of contemporary evolutionary theory and one that points towards an alternative conceptual framework. The latter, which we label the ‘extended evolutionary synthesis' (EES), retains the fundaments of evolutionary theory, but differs in its emphasis on the role of constructive processes in development and evolution, and reciprocal portrayals of causation. In the EES, developmental processes, operating through developmental bias, inclusive inheritance and niche construction, share responsibility for the direction and rate of evolution, the origin of character variation and organism–environment complementarity. We spell out the structure, core assumptions and novel predictions of the EES, and show how it can be deployed to stimulate and advance research in those fields that study or use evolutionary biology.",
        "html": "Scientific activities take place within the structured sets of ideas and assumptions that define a field and its practices. The conceptual framework of evolutionary biology emerged with the Modern Synthesis in the early twentieth century and has since expanded into a highly successful research program to explore the processes of diversification and adaptation. Nonetheless, the ability of that framework satisfactorily to accommodate the rapid advances in developmental biology, genomics and ecology has been questioned. We review some of these arguments, focusing on literatures (evo-devo, developmental plasticity, inclusive inheritance and niche construction) whose implications for evolution can be interpreted in two ways—one that preserves the internal structure of contemporary evolutionary theory and one that points towards an alternative conceptual framework. The latter, which we label the ‘extended evolutionary synthesis' (EES), retains the fundaments of evolutionary theory, but differs in its emphasis on the role of constructive processes in development and evolution, and reciprocal portrayals of causation. In the EES, developmental processes, operating through developmental bias, inclusive inheritance and niche construction, share responsibility for the direction and rate of evolution, the origin of character variation and organism–environment complementarity. We spell out the structure, core assumptions and novel predictions of the EES, and show how it can be deployed to stimulate and advance research in those fields that study or use evolutionary biology.",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10074555/",
      "title": "A primer to directed evolution: current methodologies and future directions",
      "author": "",
      "published_date": "2023-01-27T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Directed evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the first <em>in vitro</em> evolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (library generation), and isolation of the variants of interest. This review covers the main modern methodologies, discussing the advantages and drawbacks of each, and hence the considerations for designing directed evolution experiments. Furthermore, the most recent developments are discussed, showing how advances in the handling of ever larger library sizes are enabling new research questions to be tackled.</p></section><section><hr/>\n<p>This review summarises the methods available for directed evolution, including mutagenesis and variant selection techniques. The advantages and disadvantages of each technique are presented, and future challenges in the field are discussed.</p></section><section><h2>Introduction</h2>\n<p>Enzymes have attracted increasing interest from industry as more efficient and less costly alternatives to other synthetic chemistry tools, such as transition metal catalysts or organocatalysts.<sup><a href=\"#cit1\">1</a></sup> However, while the repertoire in nature provides a vast variety of biocatalysts, it is frequently the case that natural enzymes need to be tailored by protein engineering in order to maximise their performance for specific applications. The same applies to biomolecules performing other functions, such as binding partners (including antibodies), fluorescent or bioluminescent macromolecules and biocatalysts acting on other macromolecules.</p>\n<p>Two main approaches can be taken to carry out protein engineering: rational design and directed evolution. Rational design involves performing chosen point mutations, insertions or deletions in the coding sequence, and mutation choice is typically based on structural and functional information about the target biomolecule. Nonetheless, the sequence–structure–function relationship is often difficult to predict accurately, particularly at the single residue level. Additionally, reliable structural information is frequently not available for the protein of interest and, while progress is being made in methods for protein structure prediction thanks to artificial intelligence,<sup><a href=\"#cit2\">2</a></sup> these still remain rather limited, especially for larger proteins and macromolecular complexes.<sup><a href=\"#cit3\">3</a></sup> Often therefore, rationally designed mutations do not have the desired effect.</p>\n<p>Directed evolution, on the other hand, bypasses the need to determine specific mutations <em>a priori</em> by mimicking the process of natural evolution in the laboratory.<sup><a href=\"#cit4\">4,5</a></sup> In nature, mutations which are beneficial for individuals are iteratively selected through numerous generations. In directed evolution, this process takes place on a much shorter timescale, and generates biomolecules that suit human-defined applications.</p>\n<p>The first <em>in vitro</em> evolution experiments can be traced back to the 1960s. In a pioneering Darwinian experiment, Sol Spiegelman <em>et al.</em> iteratively selected RNA molecules based on their ability to be replicated by Q bacteriophage RNA polymerase.<sup><a href=\"#cit6\">6</a></sup> Over the next two decades, such <em>in vitro</em> evolution experiments shifted towards more application-driven approaches, which is exemplified by the development of phage display.<sup><a href=\"#cit7\">7</a></sup> In phage display, an exogenous sequence is fused to a gene encoding a minor coat protein of a filamentous phage, leading the assembled viral particles to display the extra amino acids. A set of phages with different fused peptides could then be subjected to affinity purification, against desired binding partners, to obtain variants with high affinity towards them.</p>\n<p>During the last 30 years, directed evolution approaches have diversified and shifted their focus towards more complex and varied properties and biomolecules (<a href=\"#fig1\">Fig. 1</a>). This can be easily visualized by analyzing the frequency of keywords associated with directed evolution papers (<a href=\"#fig2\">Fig. 2</a>). Our analysis suggests that from the early days of directed evolution and until the mid 2000s, directed evolution focused mostly on altering binding sites and improving enzyme kinetic parameters, with a special emphasis on the analysis of nucleotide and amino acid sequences when choosing the approach to take. At the beginning of the 21st century, protein structure and conformation became a major point of interest in directed evolution studies, probably due to the increasing availability of macromolecular structures as a consequence of the improvement and accessibility of structural biology techniques. Indeed, in the period 1995–2000, “structure–activity relationship” was one of the top keywords found in directed evolution papers. Such keywords ranked considerably lower from 2005, probably due to the realization that the mechanisms through which structure determines function in biological macromolecules cannot be easily unraveled. During the last decade, the variety of targeted properties has quickly increased (including a larger proportion of studies aiming to alter substrate specificity). The range of organisms employed in such studies has also been expanded, as demonstrated by the presence of keywords such as “HEK293 cells” or “cell line”. Interestingly, a persistent interest in recombinant proteins seems to have been sustained during the same period.</p>\n<figure><h3>Fig. 1. Timeline of directed evolution major developments. Representative examples of some of the most relevant developments and achievements in directed evolution are shown.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10074555_d2cb00231k-f1.jpg\"></a></p>\n</figure><figure><h3>Fig. 2. Evolution of keywords associated to directed evolution articles. Wordclouds of the keywords associated to directed evolution articles since 1985 are shown. Articles were grouped in blocks of five years. The wordclouds reveal a change over time of the focus and scope of directed evolution, with the most recent decade showing a larger variety of targeted properties and biomolecules. Data was retrieved, analysed and visualised with R.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10074555_d2cb00231k-f2.jpg\"></a></p>\n</figure><p>The large expansion of the scope of directed evolution is tightly linked to the ample variety of developed techniques that allow researchers to tackle more efficiently the two main steps of the process of artificial evolution of biomolecules (<a href=\"#tab1\">Table 1</a>). The first step consists in generating enough genetic diversity in a given parental sequence to cover the sequence-function space to be sampled. The resulting set of sequences, or library, often includes a majority of variants without the desired property or improvement. In a second step, the individual genotypes must be linked to the individual phenotypes<sup><a href=\"#cit8\">8</a></sup> to allow the variants of interest to be identified and isolated from the library. In this review, we aim to provide an overview of the different available methodologies, presenting the underlying principles, advantages and disadvantages of each one in order to facilitate readers to make an informed choice when determining the most appropriate techniques for a particular application of directed evolution.</p>\n<section><h3>Summary of techniques frequently applied in directed evolution.</h3>\n<div><table>\n<colgroup>\n<col/>\n<col/>\n<col/>\n<col/>\n<col/>\n<col/>\n</colgroup>\n<thead><tr>\n<th></th>\n<th>Technique</th>\n<th>Purpose</th>\n<th>Advantages</th>\n<th>Disadvantages</th>\n<th>Application examples</th>\n</tr></thead>\n<tbody>\n<tr>\n<td>Mutagenesis</td>\n<td>Error-prone PCR and error-prone RCA</td>\n<td>Insertion of point mutations across whole sequence</td>\n<td>• Easy to perform</td>\n<td>• Reduced sampling of mutagenesis space</td>\n<td>Subtilisin E<sup><a href=\"#cit12\">12</a></sup>\n</td>\n</tr>\n<tr>\n<td>• Does not require prior knowledge about key positions</td>\n<td>• Mutagenesis bias</td>\n<td>Glycolyl-CoA carboxylase<sup><a href=\"#cit124\">124</a></sup>\n</td>\n</tr>\n<tr>\n<td>RAISE</td>\n<td>Insertion of random short insertions and deletions</td>\n<td>• Enables random indels across sequence</td>\n<td>• Indels limited to few nucleotides</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>• Frameshifts introduced</td>\n<td>β-Lactamase<sup><a href=\"#cit17\">17</a></sup>\n</td>\n</tr>\n<tr>\n<td>TRINS</td>\n<td>Insertion of random tandem repeats</td>\n<td>• Mimics duplications that occur in natural evolution</td>\n<td>• Frameshifts introduced</td>\n<td>β-Lactamase<sup><a href=\"#cit18\">18</a></sup>\n</td>\n</tr>\n<tr>\n<td>Mini-mu based techniques</td>\n<td>Random insertion or deletion of one or multiple codons</td>\n<td>• Conservation of reading frame</td>\n<td></td>\n<td>Arylesterase<sup><a href=\"#cit18\">18</a></sup>\n</td>\n</tr>\n<tr>\n<td>• Modification of transposon enables customization of mutations</td>\n<td>• Additional steps of DNA manipulation required</td>\n<td>GFP<sup><a href=\"#cit125\">125</a></sup>\n</td>\n</tr>\n<tr>\n<td>Mutator strains</td>\n<td>\n<em>In vivo</em> random mutagenesis</td>\n<td>• Simple system</td>\n<td>• Biased and uncontrolled mutagenesis spectrum</td>\n<td>Vitamin K epoxide reductase<sup><a href=\"#cit126\"",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Directed evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the first <em>in vitro</em> evolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (library generation), and isolation of the variants of interest. This review covers the main modern methodologies, discussing the advantages and drawbacks of each, and hence the considerations for designing directed evolution experiments. Furthermore, the most recent developments are discussed, showing how advances in the handling of ever larger library sizes are enabling new research questions to be tackled.</p></section><section><hr/>\n<p>This review summarises the methods available for directed evolution, including mutagenesis and variant selection techniques. The advantages and disadvantages of each technique are presented, and future challenges in the field are discussed.</p></section><section><h2>Introduction</h2>\n<p>Enzymes have attracted increasing interest from industry as more efficient and less costly alternatives to other synthetic chemistry tools, such as transition metal catalysts or organocatalysts.<sup><a href=\"#cit1\">1</a></sup> However, while the repertoire in nature provides a vast variety of biocatalysts, it is frequently the case that natural enzymes need to be tailored by protein engineering in order to maximise their performance for specific applications. The same applies to biomolecules performing other functions, such as binding partners (including antibodies), fluorescent or bioluminescent macromolecules and biocatalysts acting on other macromolecules.</p>\n<p>Two main approaches can be taken to carry out protein engineering: rational design and directed evolution. Rational design involves performing chosen point mutations, insertions or deletions in the coding sequence, and mutation choice is typically based on structural and functional information about the target biomolecule. Nonetheless, the sequence–structure–function relationship is often difficult to predict accurately, particularly at the single residue level. Additionally, reliable structural information is frequently not available for the protein of interest and, while progress is being made in methods for protein structure prediction thanks to artificial intelligence,<sup><a href=\"#cit2\">2</a></sup> these still remain rather limited, especially for larger proteins and macromolecular complexes.<sup><a href=\"#cit3\">3</a></sup> Often therefore, rationally designed mutations do not have the desired effect.</p>\n<p>Directed evolution, on the other hand, bypasses the need to determine specific mutations <em>a priori</em> by mimicking the process of natural evolution in the laboratory.<sup><a href=\"#cit4\">4,5</a></sup> In nature, mutations which are beneficial for individuals are iteratively selected through numerous generations. In directed evolution, this process takes place on a much shorter timescale, and generates biomolecules that suit human-defined applications.</p>\n<p>The first <em>in vitro</em> evolution experiments can be traced back to the 1960s. In a pioneering Darwinian experiment, Sol Spiegelman <em>et al.</em> iteratively selected RNA molecules based on their ability to be replicated by Q bacteriophage RNA polymerase.<sup><a href=\"#cit6\">6</a></sup> Over the next two decades, such <em>in vitro</em> evolution experiments shifted towards more application-driven approaches, which is exemplified by the development of phage display.<sup><a href=\"#cit7\">7</a></sup> In phage display, an exogenous sequence is fused to a gene encoding a minor coat protein of a filamentous phage, leading the assembled viral particles to display the extra amino acids. A set of phages with different fused peptides could then be subjected to affinity purification, against desired binding partners, to obtain variants with high affinity towards them.</p>\n<p>During the last 30 years, directed evolution approaches have diversified and shifted their focus towards more complex and varied properties and biomolecules (<a href=\"#fig1\">Fig. 1</a>). This can be easily visualized by analyzing the frequency of keywords associated with directed evolution papers (<a href=\"#fig2\">Fig. 2</a>). Our analysis suggests that from the early days of directed evolution and until the mid 2000s, directed evolution focused mostly on altering binding sites and improving enzyme kinetic parameters, with a special emphasis on the analysis of nucleotide and amino acid sequences when choosing the approach to take. At the beginning of the 21st century, protein structure and conformation became a major point of interest in directed evolution studies, probably due to the increasing availability of macromolecular structures as a consequence of the improvement and accessibility of structural biology techniques. Indeed, in the period 1995–2000, “structure–activity relationship” was one of the top keywords found in directed evolution papers. Such keywords ranked considerably lower from 2005, probably due to the realization that the mechanisms through which structure determines function in biological macromolecules cannot be easily unraveled. During the last decade, the variety of targeted properties has quickly increased (including a larger proportion of studies aiming to alter substrate specificity). The range of organisms employed in such studies has also been expanded, as demonstrated by the presence of keywords such as “HEK293 cells” or “cell line”. Interestingly, a persistent interest in recombinant proteins seems to have been sustained during the same period.</p>\n<figure><h3>Fig. 1. Timeline of directed evolution major developments. Representative examples of some of the most relevant developments and achievements in directed evolution are shown.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10074555_d2cb00231k-f1.jpg\"></a></p>\n</figure><figure><h3>Fig. 2. Evolution of keywords associated to directed evolution articles. Wordclouds of the keywords associated to directed evolution articles since 1985 are shown. Articles were grouped in blocks of five years. The wordclouds reveal a change over time of the focus and scope of directed evolution, with the most recent decade showing a larger variety of targeted properties and biomolecules. Data was retrieved, analysed and visualised with R.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10074555_d2cb00231k-f2.jpg\"></a></p>\n</figure><p>The large expansion of the scope of directed evolution is tightly linked to the ample variety of developed techniques that allow researchers to tackle more efficiently the two main steps of the process of artificial evolution of biomolecules (<a href=\"#tab1\">Table 1</a>). The first step consists in generating enough genetic diversity in a given parental sequence to cover the sequence-function space to be sampled. The resulting set of sequences, or library, often includes a majority of variants without the desired property or improvement. In a second step, the individual genotypes must be linked to the individual phenotypes<sup><a href=\"#cit8\">8</a></sup> to allow the variants of interest to be identified and isolated from the library. In this review, we aim to provide an overview of the different available methodologies, presenting the underlying principles, advantages and disadvantages of each one in order to facilitate readers to make an informed choice when determining the most appropriate techniques for a particular application of directed evolution.</p>\n<section><h3>Summary of techniques frequently applied in directed evolution.</h3>\n<div><table>\n<colgroup>\n<col/>\n<col/>\n<col/>\n<col/>\n<col/>\n<col/>\n</colgroup>\n<thead><tr>\n<th></th>\n<th>Technique</th>\n<th>Purpose</th>\n<th>Advantages</th>\n<th>Disadvantages</th>\n<th>Application examples</th>\n</tr></thead>\n<tbody>\n<tr>\n<td>Mutagenesis</td>\n<td>Error-prone PCR and error-prone RCA</td>\n<td>Insertion of point mutations across whole sequence</td>\n<td>• Easy to perform</td>\n<td>• Reduced sampling of mutagenesis space</td>\n<td>Subtilisin E<sup><a href=\"#cit12\">12</a></sup>\n</td>\n</tr>\n<tr>\n<td>• Does not require prior knowledge about key positions</td>\n<td>• Mutagenesis bias</td>\n<td>Glycolyl-CoA carboxylase<sup><a href=\"#cit124\">124</a></sup>\n</td>\n</tr>\n<tr>\n<td>RAISE</td>\n<td>Insertion of random short insertions and deletions</td>\n<td>• Enables random indels across sequence</td>\n<td>• Indels limited to few nucleotides</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>• Frameshifts introduced</td>\n<td>β-Lactamase<sup><a href=\"#cit17\">17</a></sup>\n</td>\n</tr>\n<tr>\n<td>TRINS</td>\n<td>Insertion of random tandem repeats</td>\n<td>• Mimics duplications that occur in natural evolution</td>\n<td>• Frameshifts introduced</td>\n<td>β-Lactamase<sup><a href=\"#cit18\">18</a></sup>\n</td>\n</tr>\n<tr>\n<td>Mini-mu based techniques</td>\n<td>Random insertion or deletion of one or multiple codons</td>\n<td>• Conservation of reading frame</td>\n<td></td>\n<td>Arylesterase<sup><a href=\"#cit18\">18</a></sup>\n</td>\n</tr>\n<tr>\n<td>• Modification of transposon enables customization of mutations</td>\n<td>• Additional steps of DNA manipulation required</td>\n<td>GFP<sup><a href=\"#cit125\">125</a></sup>\n</td>\n</tr>\n<tr>\n<td>Mutator strains</td>\n<td>\n<em>In vivo</em> random mutagenesis</td>\n<td>• Simple system</td>\n<td>• Biased and uncontrolled mutagenesis spectrum</td>\n<td>Vitamin K epoxide reductase<sup><a href=\"#cit126\"",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractDirected evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the firstin vitroevolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (lib",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractDirected evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the firstin vitroevolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (lib",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractDirected evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the firstin vitroevolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (lib",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractDirected evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the firstin vitroevolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (lib",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractDirected evolution is one of the most powerful tools for protein engineering and functions by harnessing natural evolution, but on a shorter timescale. It enables the rapid selection of variants of biomolecules with properties that make them more suitable for specific applications. Since the firstin vitroevolution experiments performed by Sol Spiegelman in 1967, a wide range of techniques have been developed to tackle the main two steps of directed evolution: genetic diversification (lib",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "This review summarises the methods available for directed evolution, including mutagenesis and variant selection techniques. The advantages and disadvantages of each technique are presented, and future challenges in the field are discussed.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "IntroductionEnzymes have attracted increasing interest from industry as more efficient and less costly alternatives to other synthetic chemistry tools, such as transition metal catalysts or organocatalysts.1However, while the repertoire in nature provides a vast variety of biocatalysts, it is frequently the case that natural enzymes need to be tailored by protein engineering in order to maximise their performance for specific applications. The same applies to biomolecules performing other functi",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Summary of techniques frequently applied in directed evolution.TechniquePurposeAdvantagesDisadvantagesApplication examplesMutagenesisError-prone PCR and error-prone RCAInsertion of point mutations across whole sequence• Easy to perform• Reduced sampling of mutagenesis spaceSubtilisin E12• Does not require prior knowledge about key positions• Mutagenesis biasGlycolyl-CoA carboxylase124RAISEInsertion of random short insertions and deletions• Enables random indels across sequence• Indels limited to",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "TechniquePurposeAdvantagesDisadvantagesApplication examplesMutagenesisError-prone PCR and error-prone RCAInsertion of point mutations across whole sequence• Easy to perform• Reduced sampling of mutagenesis spaceSubtilisin E12• Does not require prior knowledge about key positions• Mutagenesis biasGlycolyl-CoA carboxylase124RAISEInsertion of random short insertions and deletions• Enables random indels across sequence• Indels limited to few nucleotides• Frameshifts introducedβ-Lactamase17TRINSInser",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Fig. 1. Timeline of directed evolution major developments. Representative examples of some of the most relevant developments and achievements in directed evolution are shown.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Fig. 2. Evolution of keywords associated to directed evolution articles. Wordclouds of the keywords associated to directed evolution articles since 1985 are shown. Articles were grouped in blocks of five years. The wordclouds reveal a change over time of the focus and scope of directed evolution, with the most recent decade showing a larger variety of targeted properties and biomolecules. Data was retrieved, analysed and visualised with R.",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Summary of techniques frequently applied in directed evolution.",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC4586258/",
      "title": "Genetic and Environmental Influence on DNA Strand Break Repair: A Twin Study",
      "author": "",
      "published_date": "2013-06-25T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section><section><div>\n<p>. Author manuscript; available in PMC: 2015 Sep 29.</p></div>\n<p><em>Published in final edited form as: </em>Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi: <a href=\"https://doi.org/10.1002/em.21791\">10.1002/em.21791</a>\n</p>\n</section></section><section><section><h2>Abstract</h2>\n<p>Accumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repair capacity. In order to gain more insight into the genetic and environmental contribution to the molecular basis of DNA repair, we have performed a human twin study, where we focused on the consequences of some of the most abundant types of DNA damage (single-strand breaks), and some of the most hazardous lesions (DNA double-strand breaks). DNA damage signaling response (Gamma-H2AX signaling), relative amount of endogenous damage, and DNA-strand break repair capacities were studied in peripheral blood mononuclear cells from 198 twins (94 monozygotic and 104 dizygotic). We did not detect genetic effects on the DNA-strand break variables in our study.</p>\n<section><p><strong>Keywords:</strong> DNA repair, single-strand break repair, double-strand break repair, gamma-H2AX, heritability, twins</p></section></section><section><h2>INTRODUCTION</h2>\n<p>Constant exposure to endogenous and exogenous agents induces damage to the cellular macromolecules including DNA. Many types of DNA lesions can cause genomic instability. Endogenous metabolic by-products frequently damage DNA but a broad range of DNA-damaging agents are also present in our environment including radiation from sunlight and radon, food mutagens, industrial chemicals, and cigarette smoke. The majority of DNA lesions are removed by the DNA repair mechanisms, and genomic stability is thereby maintained. Inefficient DNA repair may cause DNA damage accumulation, mutations, and cellular dysfunction, which is associated with cellular senescence, aging, cancer, and neurodegeneration [<a href=\"#R11\">Jeppesen et al., 2011</a>; <a href=\"#R26\">Wolters and Schumacher, 2013</a>].</p>\n<p>DNA single-strand breaks (SSBs) are some of the most abundant DNA lesions, and DNA double-strand breaks (DSBs) are among the most lethal. Thus, effective repair mechanisms for these specific lesions are essential for genomic stability. DNA lesions derived from endogenous cellular metabolism are removed through the base excision repair (BER) pathway, including SSB repair (SSBR). Nucleotide excision repair (NER) is the pathway by which helix distorting DNA lesions are repaired.</p>\n<p>DSBs are especially harmful, because they can lead to genome rearrangements. Immediately after DSB formation the histone protein H2AX is phosphorylated at serine 139 (γ-H2AX), which accumulates in the chromatin around the break as a DSB signaling response. Two major DSB repair (DSBR) mechanisms exist, they are nonhomologous end joining (NHEJ) and homologous recombination (HR). Briefly, NHEJ proteins recognize DSBs and form complexes on both sides of the DSB, and the DNA ends are processed and finally ligated. HR uses homologous sequences in sister chromatids to repair DSBs, especially those formed at collapsed replication forks. The error-free HR is active in the S and G<sub>2</sub> phases of the cell cycle, whereas the error-prone NHEJ operates throughout the cell cycle [<a href=\"#R14\">Kavanagh et al., 2013</a>].</p>\n<p>Monozygotic (MZ) twins derive from the same zygote and share all genetic material, whereas dizygotic (DZ) twins like ordinary siblings, share on average 50% of their segregating genes. In addition, twins also share early environmental factors. The classical twin study is based on the fact that MZ twins are genetically matched and relies on the assumption that intrapair MZ discordance in traits is attributed to environmental factors. In contrast, differences in both genetic and environmental factors influence DZ twins; hence, substantial influence from genetic factors on a trait is detectable as a greater MZ-compared to DZ similarity [<a href=\"#R12\">Jinks and Fulker, 1970</a>; <a href=\"#R25\">van Dongen et al., 2012</a>]. By twin studies, the variance of a trait can be divided into additive genetic- (A), dominance genetic- (D), shared environmental- (C), and nonshared environmental (E) effects. Additive genetic influence is the sum of effects of the individual alleles at all loci that influence the trait, whereas dominant genetic effects represent interaction between alleles at the same locus or different loci. Family members are exposed to shared environmental effects whereas nonshared environmental influences reflect differences among family members.</p>\n<p>Several reports have investigated DNA repair in human populations; however, only few in twin populations. Twin studies reporting heritability estimates on DNA repair-related parameters have mostly indicated high genetic contribution for measures like micronucleus frequency, mutagenic sensitivity, and apoptotic- and cell cycle response to ionizing radiation [<a href=\"#R3\">Camplejohn et al., 2006</a>; <a href=\"#R27\">Wu et al., 2006</a>; <a href=\"#R6\">Finnon et al., 2008</a>; <a href=\"#R21\">Surowy et al., 2011</a>].</p>\n<p>Twin studies estimating heritability of the capacity to repair specific DNA lesions are lacking. This may be due to limited availability of high-throughput methods for functional studies on DNA repair. Investigations of DNA repair factors in population studies have often included relatively few study participants resulting in low statistical power. Thus, we aimed to increase the statistical power by investigating a total of 198 twins (94 MZ and 104 DZ) from the Danish Twin Registry [<a href=\"#R19\">Skytthe et al., 2013</a>]. In this twin study, we investigated the influence of environmental and genetic factors on the DNA-strand break repair parameters, namely, endogenous SSB level, SSBR capacity, γ-H2AX response, and DSBR capacity in human peripheral blood mononuclear cells (PBMCs).</p></section><section><h2>MATERIALS AND METHODS</h2>\n<section><h3>Study Population</h3>\n<p>The study sample (<em>n</em> = 198) comprised participants from the Danish Twin Registry, which is a nationwide, population-based registry [<a href=\"#R19\">Skytthe et al., 2013</a>]. Only complete twin pairs were included in this analysis. Zygosity of the twin pairs was established through a questionnaire on the degree of similarity between twins in a pair [<a href=\"#R4\">Christiansen et al., 2003</a>]. Since the 1960s, selected cohorts from the registry have participated in questionnaire and survey studies. In the period 2008–2011, whole blood from randomly selected twins was collected. PBMCs were isolated according to the manufacturer’s protocol (BD Vacutainer® CPT<sup>™</sup>, REF 362761) and cryopreserved. The Science Ethics Committee of Southern Denmark has approved the study (Project number S-VF-19980072).</p></section><section><h3>Analysis of DNA Damage and Repair Parameters in PBMCs</h3>\n<p>The methodology for the analysis of DNA damage and repair parameters was described in detail and graphically explained previously [<a href=\"#R8\">Garm et al., 2013</a>].</p>\n<p>In short, Fluorimetric Detection of Alkaline DNA Unwinding (FADU) was performed in order to measure the level of endogenous strand breaks and DNA repair capacity in PBMCs 40 min after DNA damage induction by 3.8 Gy X-ray [<a href=\"#R16\">Moreno-Villanueva et al., 2009</a>; <a href=\"#R8\">Garm et al., 2013</a>]. By using a modified neutral comet assay γ-irradiated cells (6 Gy, Cs-137 source, 3 hr recovery) were analyzed for the capacity of repairing primarily induced DSBs [<a href=\"#R8\">Garm et al., 2013</a>]. The γ-H2AX response to induced DSBs (6 Gy, Cs-137 source, 1 hr incubation) was measured by flow cytometry [<a href=\"#R17\">Muslimovic et al., 2008</a>; <a href=\"#R8\">Garm et al., 2013</a>].</p>\n<p>In order to minimize experimental variability, the same investigator performed all analyses. The only selection criterion was zygosity status, in order to include similar numbers of MZ and DZ twin pairs. We aimed for similar batch effects among MZ and DZ twins by analyzing approximately equal numbers of MZ and DZ twin pairs in each batch. Both twins in the pairs were analyzed in the same batches. The FADU data was presented as mean of four replicates, comet data as mean of 60–100 cells, and flow cytometric data was based on a minimum of 50,000 cells. The sample material did not allow additional replicates. Reported coefficients of variance (CV) were based on minimum 10 replicates of an internal control sample, which was used for standardization of data from different batches.</p></section><section><h3>Analysis of Twin Similarity</h3>\n<p>A classical twin study approach was performed by analyzing MZ and DZ twins. Intraclass correlations (ICCs) were estimated using a Random ML regression approach (using Stata version 11.2). We included age and gender as covariates. To estimate the relative contribution of genetic and environmental factors to the DNA repair parameters, we performed a biometrical genetic analysis using model-fitting heritability [<a href=\"#R18\">Rijsdijk and Sham, 2002</a>]. The total variance was assumed to comprise A, D, C, and E effects. The effects of D and C cannot be simultaneously estimated because they are confounded. Therefore, ACE, ADE, AE, CE, and E models were fitted and compared by Akaike’s Information Criterion (AIC) and by likelihood ratio testing. Lowest AIC was used to determine which of the nonnested models had the best fit, whereas chi-squared likelihood ratio testing was used to select the best-fitting nested model, that is, the most parsimonious model was chosen if the <em>P</em>-value of the ",
        "html": "<div><div>\n<main>\n<article><section><section><div>\n<p>. Author manuscript; available in PMC: 2015 Sep 29.</p></div>\n<p><em>Published in final edited form as: </em>Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi: <a href=\"https://doi.org/10.1002/em.21791\">10.1002/em.21791</a>\n</p>\n</section></section><section><section><h2>Abstract</h2>\n<p>Accumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repair capacity. In order to gain more insight into the genetic and environmental contribution to the molecular basis of DNA repair, we have performed a human twin study, where we focused on the consequences of some of the most abundant types of DNA damage (single-strand breaks), and some of the most hazardous lesions (DNA double-strand breaks). DNA damage signaling response (Gamma-H2AX signaling), relative amount of endogenous damage, and DNA-strand break repair capacities were studied in peripheral blood mononuclear cells from 198 twins (94 monozygotic and 104 dizygotic). We did not detect genetic effects on the DNA-strand break variables in our study.</p>\n<section><p><strong>Keywords:</strong> DNA repair, single-strand break repair, double-strand break repair, gamma-H2AX, heritability, twins</p></section></section><section><h2>INTRODUCTION</h2>\n<p>Constant exposure to endogenous and exogenous agents induces damage to the cellular macromolecules including DNA. Many types of DNA lesions can cause genomic instability. Endogenous metabolic by-products frequently damage DNA but a broad range of DNA-damaging agents are also present in our environment including radiation from sunlight and radon, food mutagens, industrial chemicals, and cigarette smoke. The majority of DNA lesions are removed by the DNA repair mechanisms, and genomic stability is thereby maintained. Inefficient DNA repair may cause DNA damage accumulation, mutations, and cellular dysfunction, which is associated with cellular senescence, aging, cancer, and neurodegeneration [<a href=\"#R11\">Jeppesen et al., 2011</a>; <a href=\"#R26\">Wolters and Schumacher, 2013</a>].</p>\n<p>DNA single-strand breaks (SSBs) are some of the most abundant DNA lesions, and DNA double-strand breaks (DSBs) are among the most lethal. Thus, effective repair mechanisms for these specific lesions are essential for genomic stability. DNA lesions derived from endogenous cellular metabolism are removed through the base excision repair (BER) pathway, including SSB repair (SSBR). Nucleotide excision repair (NER) is the pathway by which helix distorting DNA lesions are repaired.</p>\n<p>DSBs are especially harmful, because they can lead to genome rearrangements. Immediately after DSB formation the histone protein H2AX is phosphorylated at serine 139 (γ-H2AX), which accumulates in the chromatin around the break as a DSB signaling response. Two major DSB repair (DSBR) mechanisms exist, they are nonhomologous end joining (NHEJ) and homologous recombination (HR). Briefly, NHEJ proteins recognize DSBs and form complexes on both sides of the DSB, and the DNA ends are processed and finally ligated. HR uses homologous sequences in sister chromatids to repair DSBs, especially those formed at collapsed replication forks. The error-free HR is active in the S and G<sub>2</sub> phases of the cell cycle, whereas the error-prone NHEJ operates throughout the cell cycle [<a href=\"#R14\">Kavanagh et al., 2013</a>].</p>\n<p>Monozygotic (MZ) twins derive from the same zygote and share all genetic material, whereas dizygotic (DZ) twins like ordinary siblings, share on average 50% of their segregating genes. In addition, twins also share early environmental factors. The classical twin study is based on the fact that MZ twins are genetically matched and relies on the assumption that intrapair MZ discordance in traits is attributed to environmental factors. In contrast, differences in both genetic and environmental factors influence DZ twins; hence, substantial influence from genetic factors on a trait is detectable as a greater MZ-compared to DZ similarity [<a href=\"#R12\">Jinks and Fulker, 1970</a>; <a href=\"#R25\">van Dongen et al., 2012</a>]. By twin studies, the variance of a trait can be divided into additive genetic- (A), dominance genetic- (D), shared environmental- (C), and nonshared environmental (E) effects. Additive genetic influence is the sum of effects of the individual alleles at all loci that influence the trait, whereas dominant genetic effects represent interaction between alleles at the same locus or different loci. Family members are exposed to shared environmental effects whereas nonshared environmental influences reflect differences among family members.</p>\n<p>Several reports have investigated DNA repair in human populations; however, only few in twin populations. Twin studies reporting heritability estimates on DNA repair-related parameters have mostly indicated high genetic contribution for measures like micronucleus frequency, mutagenic sensitivity, and apoptotic- and cell cycle response to ionizing radiation [<a href=\"#R3\">Camplejohn et al., 2006</a>; <a href=\"#R27\">Wu et al., 2006</a>; <a href=\"#R6\">Finnon et al., 2008</a>; <a href=\"#R21\">Surowy et al., 2011</a>].</p>\n<p>Twin studies estimating heritability of the capacity to repair specific DNA lesions are lacking. This may be due to limited availability of high-throughput methods for functional studies on DNA repair. Investigations of DNA repair factors in population studies have often included relatively few study participants resulting in low statistical power. Thus, we aimed to increase the statistical power by investigating a total of 198 twins (94 MZ and 104 DZ) from the Danish Twin Registry [<a href=\"#R19\">Skytthe et al., 2013</a>]. In this twin study, we investigated the influence of environmental and genetic factors on the DNA-strand break repair parameters, namely, endogenous SSB level, SSBR capacity, γ-H2AX response, and DSBR capacity in human peripheral blood mononuclear cells (PBMCs).</p></section><section><h2>MATERIALS AND METHODS</h2>\n<section><h3>Study Population</h3>\n<p>The study sample (<em>n</em> = 198) comprised participants from the Danish Twin Registry, which is a nationwide, population-based registry [<a href=\"#R19\">Skytthe et al., 2013</a>]. Only complete twin pairs were included in this analysis. Zygosity of the twin pairs was established through a questionnaire on the degree of similarity between twins in a pair [<a href=\"#R4\">Christiansen et al., 2003</a>]. Since the 1960s, selected cohorts from the registry have participated in questionnaire and survey studies. In the period 2008–2011, whole blood from randomly selected twins was collected. PBMCs were isolated according to the manufacturer’s protocol (BD Vacutainer® CPT<sup>™</sup>, REF 362761) and cryopreserved. The Science Ethics Committee of Southern Denmark has approved the study (Project number S-VF-19980072).</p></section><section><h3>Analysis of DNA Damage and Repair Parameters in PBMCs</h3>\n<p>The methodology for the analysis of DNA damage and repair parameters was described in detail and graphically explained previously [<a href=\"#R8\">Garm et al., 2013</a>].</p>\n<p>In short, Fluorimetric Detection of Alkaline DNA Unwinding (FADU) was performed in order to measure the level of endogenous strand breaks and DNA repair capacity in PBMCs 40 min after DNA damage induction by 3.8 Gy X-ray [<a href=\"#R16\">Moreno-Villanueva et al., 2009</a>; <a href=\"#R8\">Garm et al., 2013</a>]. By using a modified neutral comet assay γ-irradiated cells (6 Gy, Cs-137 source, 3 hr recovery) were analyzed for the capacity of repairing primarily induced DSBs [<a href=\"#R8\">Garm et al., 2013</a>]. The γ-H2AX response to induced DSBs (6 Gy, Cs-137 source, 1 hr incubation) was measured by flow cytometry [<a href=\"#R17\">Muslimovic et al., 2008</a>; <a href=\"#R8\">Garm et al., 2013</a>].</p>\n<p>In order to minimize experimental variability, the same investigator performed all analyses. The only selection criterion was zygosity status, in order to include similar numbers of MZ and DZ twin pairs. We aimed for similar batch effects among MZ and DZ twins by analyzing approximately equal numbers of MZ and DZ twin pairs in each batch. Both twins in the pairs were analyzed in the same batches. The FADU data was presented as mean of four replicates, comet data as mean of 60–100 cells, and flow cytometric data was based on a minimum of 50,000 cells. The sample material did not allow additional replicates. Reported coefficients of variance (CV) were based on minimum 10 replicates of an internal control sample, which was used for standardization of data from different batches.</p></section><section><h3>Analysis of Twin Similarity</h3>\n<p>A classical twin study approach was performed by analyzing MZ and DZ twins. Intraclass correlations (ICCs) were estimated using a Random ML regression approach (using Stata version 11.2). We included age and gender as covariates. To estimate the relative contribution of genetic and environmental factors to the DNA repair parameters, we performed a biometrical genetic analysis using model-fitting heritability [<a href=\"#R18\">Rijsdijk and Sham, 2002</a>]. The total variance was assumed to comprise A, D, C, and E effects. The effects of D and C cannot be simultaneously estimated because they are confounded. Therefore, ACE, ADE, AE, CE, and E models were fitted and compared by Akaike’s Information Criterion (AIC) and by likelihood ratio testing. Lowest AIC was used to determine which of the nonnested models had the best fit, whereas chi-squared likelihood ratio testing was used to select the best-fitting nested model, that is, the most parsimonious model was chosen if the <em>P</em>-value of the ",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": ". Author manuscript; available in PMC: 2015 Sep 29.Published in final edited form as:Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi:10.1002/em.21791AbstractAccumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repai",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": ". Author manuscript; available in PMC: 2015 Sep 29.Published in final edited form as:Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi:10.1002/em.21791AbstractAccumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repai",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": ". Author manuscript; available in PMC: 2015 Sep 29.Published in final edited form as:Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi:10.1002/em.21791AbstractAccumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repai",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": ". Author manuscript; available in PMC: 2015 Sep 29.Published in final edited form as:Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi:10.1002/em.21791",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": ". Author manuscript; available in PMC: 2015 Sep 29.Published in final edited form as:Environ Mol Mutagen. 2013 Jun 25;54(6):414–420. doi:10.1002/em.21791",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": ". Author manuscript; available in PMC: 2015 Sep 29.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractAccumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repair capacity. In order to gain more insight into the genetic and environmental contribution to the molecular basis of DNA repair, we have performed a human",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractAccumulation of DNA damage deriving from exogenous and endogenous sources has significant consequences for cellular survival, and is implicated in aging, cancer, and neurological diseases. Different DNA repair pathways have evolved in order to maintain genomic stability. Genetic and environmental factors are likely to influence DNA repair capacity. In order to gain more insight into the genetic and environmental contribution to the molecular basis of DNA repair, we have performed a human",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:DNA repair, single-strand break repair, double-strand break repair, gamma-H2AX, heritability, twins",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "INTRODUCTIONConstant exposure to endogenous and exogenous agents induces damage to the cellular macromolecules including DNA. Many types of DNA lesions can cause genomic instability. Endogenous metabolic by-products frequently damage DNA but a broad range of DNA-damaging agents are also present in our environment including radiation from sunlight and radon, food mutagens, industrial chemicals, and cigarette smoke. The majority of DNA lesions are removed by the DNA repair mechanisms, and genomic ",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "MATERIALS AND METHODSStudy PopulationThe study sample (n= 198) comprised participants from the Danish Twin Registry, which is a nationwide, population-based registry [Skytthe et al., 2013]. Only complete twin pairs were included in this analysis. Zygosity of the twin pairs was established through a questionnaire on the degree of similarity between twins in a pair [Christiansen et al., 2003]. Since the 1960s, selected cohorts from the registry have participated in questionnaire and survey studies",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Study PopulationThe study sample (n= 198) comprised participants from the Danish Twin Registry, which is a nationwide, population-based registry [Skytthe et al., 2013]. Only complete twin pairs were included in this analysis. Zygosity of the twin pairs was established through a questionnaire on the degree of similarity between twins in a pair [Christiansen et al., 2003]. Since the 1960s, selected cohorts from the registry have participated in questionnaire and survey studies. In the period 2008–",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Analysis of DNA Damage and Repair Parameters in PBMCsThe methodology for the analysis of DNA damage and repair parameters was described in detail and graphically explained previously [Garm et al., 2013].In short, Fluorimetric Detection of Alkaline DNA Unwinding (FADU) was performed in order to measure the level of endogenous strand breaks and DNA repair capacity in PBMCs 40 min after DNA damage induction by 3.8 Gy X-ray [Moreno-Villanueva et al., 2009;Garm et al., 2013]. By using a modified neut",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Analysis of Twin SimilarityA classical twin study approach was performed by analyzing MZ and DZ twins. Intraclass correlations (ICCs) were estimated using a Random ML regression approach (using Stata version 11.2). We included age and gender as covariates. To estimate the relative contribution of genetic and environmental factors to the DNA repair parameters, we performed a biometrical genetic analysis using model-fitting heritability [Rijsdijk and Sham, 2002]. The total variance was assumed to ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "INTRODUCTION",
              "id": ""
            },
            {
              "level": "h2",
              "text": "MATERIALS AND METHODS",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Study Population",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Analysis of DNA Damage and Repair Parameters in PBMCs",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Analysis of Twin Similarity",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pubmed.ncbi.nlm.nih.gov/26596548/",
      "title": "Super DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest old - PubMed",
      "author": "Bernhard Franzke 1 ,",
      "published_date": "2015-01-01T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<header>\n<div>\n<div>\n<p>Review</p>\n<div>\n<p><span>. </span><span>2015 Oct-Dec:766:48-57.</span>\n</p></div>\n<p><span>\ndoi: 10.1016/j.mrrev.2015.08.001.\n</span>\n<span>\nEpub 2015 Aug 28.\n</span>\n</p></div>\n<p>\nAffiliations\n</p>\n<ul>\n<li>\n<span>\n<span>\nPMID:\n</span>\n<strong>26596548</strong>\n</span>\n</li>\n<li>\n<span>\n<span>\nDOI:\n</span>\n<a href=\"https://doi.org/10.1016/j.mrrev.2015.08.001\">\n10.1016/j.mrrev.2015.08.001\n</a>\n</span>\n</li>\n</ul>\n</div>\n<div>\n<p>Review</p>\n<h2>\nSuper DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest old\n</h2>\n<p><span>\n<span><span>Bernhard Franzke</span><span> et al.</span></span>\n</span>\n<span>\nMutat Res Rev Mutat Res<span>.</span>\n</span>\n<span>\n<span>2015 Oct-Dec</span><span>.</span>\n</span>\n</p>\n</div>\n</header>\n<div>\n<h2>\nAbstract\n</h2>\n<p>\nReductions in DNA integrity, genome stability, and telomere length are strongly associated with the aging process, age-related diseases as well as the age-related loss of muscle mass. However, in people reaching an age far beyond their statistical life expectancy the prevalence of diseases, such as cancer, cardiovascular disease, diabetes or dementia, is much lower compared to \"averagely\" aged humans. These inverse observations in nonagenarians (90-99 years), centenarians (100-109 years) and super-centenarians (110 years and older) require a closer look into dynamics underlying DNA damage within the oldest old of our society. Available data indicate improved DNA repair and antioxidant defense mechanisms in \"super old\" humans, which are comparable with much younger cohorts. Partly as a result of these enhanced endogenous repair and protective mechanisms, the oldest old humans appear to cope better with risk factors for DNA damage over their lifetime compared to subjects whose lifespan coincides with the statistical life expectancy. This model is supported by study results demonstrating superior chromosomal stability, telomere dynamics and DNA integrity in \"successful agers\". There is also compelling evidence suggesting that life-style related factors including regular physical activity, a well-balanced diet and minimized psycho-social stress can reduce DNA damage and improve chromosomal stability. The most conclusive picture that emerges from reviewing the literature is that reaching \"super old\" age appears to be primarily determined by hereditary/genetic factors, while a healthy lifestyle additionally contributes to achieving the individual maximum lifespan in humans. More research is required in this rapidly growing population of super old people. In particular, there is need for more comprehensive investigations including short- and long-term lifestyle interventions as well as investigations focusing on the mechanisms causing DNA damage, mutations, and telomere shortening.\n</p>\n<p>\n<strong>\nKeywords:\n</strong>\nCentenarians; Genome stability; Healthy aging; Longevity; Maximum lifespan; Nonagenarians.\n</p>\n</div>\n<p>\nCopyright © 2015 Elsevier B.V. All rights reserved.\n</p>\n<p>\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/disclaimer/\">PubMed Disclaimer</a>\n</p>\n<div>\n<h2>\nSimilar articles\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/24975295/\">\nLeukocyte telomere length and prevalence of age-related diseases in semisupercentenarians, centenarians and centenarians' offspring.\n</a></p><p><span>Tedone E, Arosio B, Gussago C, Casati M, Ferri E, Ogliari G, Ronchetti F, Porta A, Massariello F, Nicolini P, Mari D.</span>\n<span>Tedone E, et al.</span>\n<span>Exp Gerontol. 2014 Oct;58:90-5. doi: 10.1016/j.exger.2014.06.018. Epub 2014 Jun 27.</span>\n<span>Exp Gerontol. 2014.</span>\n<span>PMID: <span>24975295</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/18765247/\">\nReduced telomere length variation in healthy oldest old.\n</a></p><p><span>Halaschek-Wiener J, Vulto I, Fornika D, Collins J, Connors JM, Le ND, Lansdorp PM, Brooks-Wilson A.</span>\n<span>Halaschek-Wiener J, et al.</span>\n<span>Mech Ageing Dev. 2008 Nov;129(11):638-41. doi: 10.1016/j.mad.2008.07.004. Epub 2008 Aug 14.</span>\n<span>Mech Ageing Dev. 2008.</span>\n<span>PMID: <span>18765247</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/28510637/\">\nTelomeres, Nutrition, and Longevity: Can We Really Navigate Our Aging?\n</a></p><p><span>Vidacek NŠ, Nanic L, Ravlic S, Sopta M, Geric M, Gajski G, Garaj-Vrhovac V, Rubelj I.</span>\n<span>Vidacek NŠ, et al.</span>\n<span>J Gerontol A Biol Sci Med Sci. 2017 Dec 12;73(1):39-47. doi: 10.1093/gerona/glx082.</span>\n<span>J Gerontol A Biol Sci Med Sci. 2017.</span>\n<span>PMID: <span>28510637</span></span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/18071200/\">\nTelomeres and longevity: testing an evolutionary hypothesis.\n</a></p><p><span>Haussmann MF, Mauck RA.</span>\n<span>Haussmann MF, et al.</span>\n<span>Mol Biol Evol. 2008 Jan;25(1):220-8. doi: 10.1093/molbev/msm244. Epub 2007 Dec 10.</span>\n<span>Mol Biol Evol. 2008.</span>\n<span>PMID: <span>18071200</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/10885805/\">\nCaloric restriction and genomic stability.\n</a></p><p><span>Raffoul JJ, Guo Z, Soofi A, Heydari AR.</span>\n<span>Raffoul JJ, et al.</span>\n<span>J Nutr Health Aging. 1999;3(2):102-10.</span>\n<span>J Nutr Health Aging. 1999.</span>\n<span>PMID: <span>10885805</span></span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nCited by\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35864870/\">\nAntiaging Effects of Dietary Polysaccharides: Advance and Mechanisms.\n</a></p><p><span>Xu W, Han S, Huang M, Yin J, Yang F, Luo F.</span>\n<span>Xu W, et al.</span>\n<span>Oxid Med Cell Longev. 2022 Jul 12;2022:4362479. doi: 10.1155/2022/4362479. eCollection 2022.</span>\n<span>Oxid Med Cell Longev. 2022.</span>\n<span>PMID: <span>35864870</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/30088610/\">\nAn association study of FOXO3 variant and longevity.\n</a></p><p><span>Silva-Sena GG, Camporez D, Santos LRD, Silva ASD, Sagrillo Pimassoni LH, Tieppo A, Pimentel Batitucci MDC, Morelato RL, Paula F.</span>\n<span>Silva-Sena GG, et al.</span>\n<span>Genet Mol Biol. 2018 Apr./Jun;41(2):386-396. doi: 10.1590/1678-4685-GMB-2017-0169. Epub 2018 Jun 11.</span>\n<span>Genet Mol Biol. 2018.</span>\n<span>PMID: <span>30088610</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/28661882/\">\nBienfaits du tai-chi sur la santé: Quelles sont les données probantes?\n</a></p><p><span>Huston P, McFarlane B.</span>\n<span>Huston P, et al.</span>\n<span>Can Fam Physician. 2016 Nov;62(11):e645-e654.</span>\n<span>Can Fam Physician. 2016.</span>\n<span>PMID: <span>28661882</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n<span>French.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/36388801/\">\nMesenchymal stem cells alleviate aging <em>in vitro</em> and <em>in vivo</em>.\n</a></p><p><span>Liu Q, Song S, Song L, Bi Y, Zhu K, Qiao X, Wang H, Gao C, Cai H, Ji G.</span>\n<span>Liu Q, et al.</span>\n<span>Ann Transl Med. 2022 Oct;10(20):1092. doi: 10.21037/atm-22-1206.</span>\n<span>Ann Transl Med. 2022.</span>\n<span>PMID: <span>36388801</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/31675674/\">\nChromosomal stability in buccal cells was linked to age but not affected by exercise and nutrients - Vienna Active Ageing Study (VAAS), a randomized controlled trial.\n</a></p><p><span>Franzke B, Schober-Halper B, Hofmann M, Oesen S, Tosevska A, Nersesyan A, Knasmüller S, Strasser EM, Wallner M, Wessner B, Wagner KH.</span>\n<span>Franzke B, et al.</span>\n<span>Redox Biol. 2020 Jan;28:101362. doi: 10.1016/j.redox.2019.101362. Epub 2019 Oct 24.</span>\n<span>Redox Biol. 2020.</span>\n<span>PMID: <span>31675674</span></span>\n<span>Free PMC article.</span>\n<span>Clinical Trial.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nPublication types\n</h2>\n<ul><li></li><li></li></ul>\n</div>\n<div>\n<h2>\nMeSH terms\n</h2>\n<ul><li></li><li></li><li></li><li></li><li></li><li></li></ul>\n</div>\n<div>\n<h2>\nLinkOut - more resources\n</h2>\n<ul><li><h3>Full Text Sources</h3><ul><li><a href=\"https://linkinghub.elsevier.com/retrieve/pii/S1383-5742(15)00062-9\">\nElsevier Science\n</a></li></ul></li><li><h3>Other Literature Sources</h3><ul><li><a href=\"https://www.lens.org/lens/search/patent/list?q=reference_cited.npl.ids.pmid:26596548\">\nThe Lens - Patent Citations Database\n</a></li></ul></li><li><h3>Medical</h3><ul><li><a href=\"https://medlineplus.gov/olderadulthealth.html\">\nMedlinePlus Health Information\n</a></li></ul></li></ul>\n</div>\n</main>\n</div></div>",
        "html": "<div><div>\n<main>\n<header>\n<div>\n<div>\n<p>Review</p>\n<div>\n<p><span>. </span><span>2015 Oct-Dec:766:48-57.</span>\n</p></div>\n<p><span>\ndoi: 10.1016/j.mrrev.2015.08.001.\n</span>\n<span>\nEpub 2015 Aug 28.\n</span>\n</p></div>\n<p>\nAffiliations\n</p>\n<ul>\n<li>\n<span>\n<span>\nPMID:\n</span>\n<strong>26596548</strong>\n</span>\n</li>\n<li>\n<span>\n<span>\nDOI:\n</span>\n<a href=\"https://doi.org/10.1016/j.mrrev.2015.08.001\">\n10.1016/j.mrrev.2015.08.001\n</a>\n</span>\n</li>\n</ul>\n</div>\n<div>\n<p>Review</p>\n<h2>\nSuper DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest old\n</h2>\n<p><span>\n<span><span>Bernhard Franzke</span><span> et al.</span></span>\n</span>\n<span>\nMutat Res Rev Mutat Res<span>.</span>\n</span>\n<span>\n<span>2015 Oct-Dec</span><span>.</span>\n</span>\n</p>\n</div>\n</header>\n<div>\n<h2>\nAbstract\n</h2>\n<p>\nReductions in DNA integrity, genome stability, and telomere length are strongly associated with the aging process, age-related diseases as well as the age-related loss of muscle mass. However, in people reaching an age far beyond their statistical life expectancy the prevalence of diseases, such as cancer, cardiovascular disease, diabetes or dementia, is much lower compared to \"averagely\" aged humans. These inverse observations in nonagenarians (90-99 years), centenarians (100-109 years) and super-centenarians (110 years and older) require a closer look into dynamics underlying DNA damage within the oldest old of our society. Available data indicate improved DNA repair and antioxidant defense mechanisms in \"super old\" humans, which are comparable with much younger cohorts. Partly as a result of these enhanced endogenous repair and protective mechanisms, the oldest old humans appear to cope better with risk factors for DNA damage over their lifetime compared to subjects whose lifespan coincides with the statistical life expectancy. This model is supported by study results demonstrating superior chromosomal stability, telomere dynamics and DNA integrity in \"successful agers\". There is also compelling evidence suggesting that life-style related factors including regular physical activity, a well-balanced diet and minimized psycho-social stress can reduce DNA damage and improve chromosomal stability. The most conclusive picture that emerges from reviewing the literature is that reaching \"super old\" age appears to be primarily determined by hereditary/genetic factors, while a healthy lifestyle additionally contributes to achieving the individual maximum lifespan in humans. More research is required in this rapidly growing population of super old people. In particular, there is need for more comprehensive investigations including short- and long-term lifestyle interventions as well as investigations focusing on the mechanisms causing DNA damage, mutations, and telomere shortening.\n</p>\n<p>\n<strong>\nKeywords:\n</strong>\nCentenarians; Genome stability; Healthy aging; Longevity; Maximum lifespan; Nonagenarians.\n</p>\n</div>\n<p>\nCopyright © 2015 Elsevier B.V. All rights reserved.\n</p>\n<p>\n<a href=\"https://pubmed.ncbi.nlm.nih.gov/disclaimer/\">PubMed Disclaimer</a>\n</p>\n<div>\n<h2>\nSimilar articles\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/24975295/\">\nLeukocyte telomere length and prevalence of age-related diseases in semisupercentenarians, centenarians and centenarians' offspring.\n</a></p><p><span>Tedone E, Arosio B, Gussago C, Casati M, Ferri E, Ogliari G, Ronchetti F, Porta A, Massariello F, Nicolini P, Mari D.</span>\n<span>Tedone E, et al.</span>\n<span>Exp Gerontol. 2014 Oct;58:90-5. doi: 10.1016/j.exger.2014.06.018. Epub 2014 Jun 27.</span>\n<span>Exp Gerontol. 2014.</span>\n<span>PMID: <span>24975295</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/18765247/\">\nReduced telomere length variation in healthy oldest old.\n</a></p><p><span>Halaschek-Wiener J, Vulto I, Fornika D, Collins J, Connors JM, Le ND, Lansdorp PM, Brooks-Wilson A.</span>\n<span>Halaschek-Wiener J, et al.</span>\n<span>Mech Ageing Dev. 2008 Nov;129(11):638-41. doi: 10.1016/j.mad.2008.07.004. Epub 2008 Aug 14.</span>\n<span>Mech Ageing Dev. 2008.</span>\n<span>PMID: <span>18765247</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/28510637/\">\nTelomeres, Nutrition, and Longevity: Can We Really Navigate Our Aging?\n</a></p><p><span>Vidacek NŠ, Nanic L, Ravlic S, Sopta M, Geric M, Gajski G, Garaj-Vrhovac V, Rubelj I.</span>\n<span>Vidacek NŠ, et al.</span>\n<span>J Gerontol A Biol Sci Med Sci. 2017 Dec 12;73(1):39-47. doi: 10.1093/gerona/glx082.</span>\n<span>J Gerontol A Biol Sci Med Sci. 2017.</span>\n<span>PMID: <span>28510637</span></span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/18071200/\">\nTelomeres and longevity: testing an evolutionary hypothesis.\n</a></p><p><span>Haussmann MF, Mauck RA.</span>\n<span>Haussmann MF, et al.</span>\n<span>Mol Biol Evol. 2008 Jan;25(1):220-8. doi: 10.1093/molbev/msm244. Epub 2007 Dec 10.</span>\n<span>Mol Biol Evol. 2008.</span>\n<span>PMID: <span>18071200</span></span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/10885805/\">\nCaloric restriction and genomic stability.\n</a></p><p><span>Raffoul JJ, Guo Z, Soofi A, Heydari AR.</span>\n<span>Raffoul JJ, et al.</span>\n<span>J Nutr Health Aging. 1999;3(2):102-10.</span>\n<span>J Nutr Health Aging. 1999.</span>\n<span>PMID: <span>10885805</span></span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nCited by\n</h2>\n<ul>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/35864870/\">\nAntiaging Effects of Dietary Polysaccharides: Advance and Mechanisms.\n</a></p><p><span>Xu W, Han S, Huang M, Yin J, Yang F, Luo F.</span>\n<span>Xu W, et al.</span>\n<span>Oxid Med Cell Longev. 2022 Jul 12;2022:4362479. doi: 10.1155/2022/4362479. eCollection 2022.</span>\n<span>Oxid Med Cell Longev. 2022.</span>\n<span>PMID: <span>35864870</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/30088610/\">\nAn association study of FOXO3 variant and longevity.\n</a></p><p><span>Silva-Sena GG, Camporez D, Santos LRD, Silva ASD, Sagrillo Pimassoni LH, Tieppo A, Pimentel Batitucci MDC, Morelato RL, Paula F.</span>\n<span>Silva-Sena GG, et al.</span>\n<span>Genet Mol Biol. 2018 Apr./Jun;41(2):386-396. doi: 10.1590/1678-4685-GMB-2017-0169. Epub 2018 Jun 11.</span>\n<span>Genet Mol Biol. 2018.</span>\n<span>PMID: <span>30088610</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/28661882/\">\nBienfaits du tai-chi sur la santé: Quelles sont les données probantes?\n</a></p><p><span>Huston P, McFarlane B.</span>\n<span>Huston P, et al.</span>\n<span>Can Fam Physician. 2016 Nov;62(11):e645-e654.</span>\n<span>Can Fam Physician. 2016.</span>\n<span>PMID: <span>28661882</span></span>\n<span>Free PMC article.</span>\n<span>Review.</span>\n<span>French.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/36388801/\">\nMesenchymal stem cells alleviate aging <em>in vitro</em> and <em>in vivo</em>.\n</a></p><p><span>Liu Q, Song S, Song L, Bi Y, Zhu K, Qiao X, Wang H, Gao C, Cai H, Ji G.</span>\n<span>Liu Q, et al.</span>\n<span>Ann Transl Med. 2022 Oct;10(20):1092. doi: 10.21037/atm-22-1206.</span>\n<span>Ann Transl Med. 2022.</span>\n<span>PMID: <span>36388801</span></span>\n<span>Free PMC article.</span>\n</p>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/31675674/\">\nChromosomal stability in buccal cells was linked to age but not affected by exercise and nutrients - Vienna Active Ageing Study (VAAS), a randomized controlled trial.\n</a></p><p><span>Franzke B, Schober-Halper B, Hofmann M, Oesen S, Tosevska A, Nersesyan A, Knasmüller S, Strasser EM, Wallner M, Wessner B, Wagner KH.</span>\n<span>Franzke B, et al.</span>\n<span>Redox Biol. 2020 Jan;28:101362. doi: 10.1016/j.redox.2019.101362. Epub 2019 Oct 24.</span>\n<span>Redox Biol. 2020.</span>\n<span>PMID: <span>31675674</span></span>\n<span>Free PMC article.</span>\n<span>Clinical Trial.</span>\n</p>\n</div>\n</li>\n</ul>\n</div>\n<div>\n<h2>\nPublication types\n</h2>\n<ul><li></li><li></li></ul>\n</div>\n<div>\n<h2>\nMeSH terms\n</h2>\n<ul><li></li><li></li><li></li><li></li><li></li><li></li></ul>\n</div>\n<div>\n<h2>\nLinkOut - more resources\n</h2>\n<ul><li><h3>Full Text Sources</h3><ul><li><a href=\"https://linkinghub.elsevier.com/retrieve/pii/S1383-5742(15)00062-9\">\nElsevier Science\n</a></li></ul></li><li><h3>Other Literature Sources</h3><ul><li><a href=\"https://www.lens.org/lens/search/patent/list?q=reference_cited.npl.ids.pmid:26596548\">\nThe Lens - Patent Citations Database\n</a></li></ul></li><li><h3>Medical</h3><ul><li><a href=\"https://medlineplus.gov/olderadulthealth.html\">\nMedlinePlus Health Information\n</a></li></ul></li></ul>\n</div>\n</main>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Review.2015 Oct-Dec:766:48-57.doi: 10.1016/j.mrrev.2015.08.001.Epub 2015 Aug 28.AffiliationsPMID:26596548DOI:10.1016/j.mrrev.2015.08.001ReviewSuper DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest oldBernhard Franzkeet al.Mutat Res Rev Mutat Res.2015 Oct-Dec.AbstractReductions in DNA integrity, genome stability, and telomere length are strongly associated with the aging process, age-related diseases as well as the age-related loss of muscle mass. However, in ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Review.2015 Oct-Dec:766:48-57.doi: 10.1016/j.mrrev.2015.08.001.Epub 2015 Aug 28.AffiliationsPMID:26596548DOI:10.1016/j.mrrev.2015.08.001ReviewSuper DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest oldBernhard Franzkeet al.Mutat Res Rev Mutat Res.2015 Oct-Dec.AbstractReductions in DNA integrity, genome stability, and telomere length are strongly associated with the aging process, age-related diseases as well as the age-related loss of muscle mass. However, in ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Review.2015 Oct-Dec:766:48-57.doi: 10.1016/j.mrrev.2015.08.001.Epub 2015 Aug 28.AffiliationsPMID:26596548DOI:10.1016/j.mrrev.2015.08.001",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Review.2015 Oct-Dec:766:48-57.doi: 10.1016/j.mrrev.2015.08.001.Epub 2015 Aug 28.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": ".2015 Oct-Dec:766:48-57.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "ReviewSuper DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest oldBernhard Franzkeet al.Mutat Res Rev Mutat Res.2015 Oct-Dec.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractReductions in DNA integrity, genome stability, and telomere length are strongly associated with the aging process, age-related diseases as well as the age-related loss of muscle mass. However, in people reaching an age far beyond their statistical life expectancy the prevalence of diseases, such as cancer, cardiovascular disease, diabetes or dementia, is much lower compared to \"averagely\" aged humans. These inverse observations in nonagenarians (90-99 years), centenarians (100-109 years)",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Similar articlesLeukocyte telomere length and prevalence of age-related diseases in semisupercentenarians, centenarians and centenarians' offspring.Tedone E, Arosio B, Gussago C, Casati M, Ferri E, Ogliari G, Ronchetti F, Porta A, Massariello F, Nicolini P, Mari D.Tedone E, et al.Exp Gerontol. 2014 Oct;58:90-5. doi: 10.1016/j.exger.2014.06.018. Epub 2014 Jun 27.Exp Gerontol. 2014.PMID:24975295Reduced telomere length variation in healthy oldest old.Halaschek-Wiener J, Vulto I, Fornika D, Collins ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Leukocyte telomere length and prevalence of age-related diseases in semisupercentenarians, centenarians and centenarians' offspring.Tedone E, Arosio B, Gussago C, Casati M, Ferri E, Ogliari G, Ronchetti F, Porta A, Massariello F, Nicolini P, Mari D.Tedone E, et al.Exp Gerontol. 2014 Oct;58:90-5. doi: 10.1016/j.exger.2014.06.018. Epub 2014 Jun 27.Exp Gerontol. 2014.PMID:24975295",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Reduced telomere length variation in healthy oldest old.Halaschek-Wiener J, Vulto I, Fornika D, Collins J, Connors JM, Le ND, Lansdorp PM, Brooks-Wilson A.Halaschek-Wiener J, et al.Mech Ageing Dev. 2008 Nov;129(11):638-41. doi: 10.1016/j.mad.2008.07.004. Epub 2008 Aug 14.Mech Ageing Dev. 2008.PMID:18765247",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Telomeres, Nutrition, and Longevity: Can We Really Navigate Our Aging?Vidacek NŠ, Nanic L, Ravlic S, Sopta M, Geric M, Gajski G, Garaj-Vrhovac V, Rubelj I.Vidacek NŠ, et al.J Gerontol A Biol Sci Med Sci. 2017 Dec 12;73(1):39-47. doi: 10.1093/gerona/glx082.J Gerontol A Biol Sci Med Sci. 2017.PMID:28510637Review.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Telomeres and longevity: testing an evolutionary hypothesis.Haussmann MF, Mauck RA.Haussmann MF, et al.Mol Biol Evol. 2008 Jan;25(1):220-8. doi: 10.1093/molbev/msm244. Epub 2007 Dec 10.Mol Biol Evol. 2008.PMID:18071200",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Caloric restriction and genomic stability.Raffoul JJ, Guo Z, Soofi A, Heydari AR.Raffoul JJ, et al.J Nutr Health Aging. 1999;3(2):102-10.J Nutr Health Aging. 1999.PMID:10885805Review.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Cited byAntiaging Effects of Dietary Polysaccharides: Advance and Mechanisms.Xu W, Han S, Huang M, Yin J, Yang F, Luo F.Xu W, et al.Oxid Med Cell Longev. 2022 Jul 12;2022:4362479. doi: 10.1155/2022/4362479. eCollection 2022.Oxid Med Cell Longev. 2022.PMID:35864870Free PMC article.Review.An association study of FOXO3 variant and longevity.Silva-Sena GG, Camporez D, Santos LRD, Silva ASD, Sagrillo Pimassoni LH, Tieppo A, Pimentel Batitucci MDC, Morelato RL, Paula F.Silva-Sena GG, et al.Genet Mol B",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Antiaging Effects of Dietary Polysaccharides: Advance and Mechanisms.Xu W, Han S, Huang M, Yin J, Yang F, Luo F.Xu W, et al.Oxid Med Cell Longev. 2022 Jul 12;2022:4362479. doi: 10.1155/2022/4362479. eCollection 2022.Oxid Med Cell Longev. 2022.PMID:35864870Free PMC article.Review.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "An association study of FOXO3 variant and longevity.Silva-Sena GG, Camporez D, Santos LRD, Silva ASD, Sagrillo Pimassoni LH, Tieppo A, Pimentel Batitucci MDC, Morelato RL, Paula F.Silva-Sena GG, et al.Genet Mol Biol. 2018 Apr./Jun;41(2):386-396. doi: 10.1590/1678-4685-GMB-2017-0169. Epub 2018 Jun 11.Genet Mol Biol. 2018.PMID:30088610Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Bienfaits du tai-chi sur la santé: Quelles sont les données probantes?Huston P, McFarlane B.Huston P, et al.Can Fam Physician. 2016 Nov;62(11):e645-e654.Can Fam Physician. 2016.PMID:28661882Free PMC article.Review.French.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mesenchymal stem cells alleviate agingin vitroandin vivo.Liu Q, Song S, Song L, Bi Y, Zhu K, Qiao X, Wang H, Gao C, Cai H, Ji G.Liu Q, et al.Ann Transl Med. 2022 Oct;10(20):1092. doi: 10.21037/atm-22-1206.Ann Transl Med. 2022.PMID:36388801Free PMC article.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Chromosomal stability in buccal cells was linked to age but not affected by exercise and nutrients - Vienna Active Ageing Study (VAAS), a randomized controlled trial.Franzke B, Schober-Halper B, Hofmann M, Oesen S, Tosevska A, Nersesyan A, Knasmüller S, Strasser EM, Wallner M, Wessner B, Wagner KH.Franzke B, et al.Redox Biol. 2020 Jan;28:101362. doi: 10.1016/j.redox.2019.101362. Epub 2019 Oct 24.Redox Biol. 2020.PMID:31675674Free PMC article.Clinical Trial.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Publication types",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "MeSH terms",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "LinkOut - more resourcesFull Text SourcesElsevier ScienceOther Literature SourcesThe Lens - Patent Citations DatabaseMedicalMedlinePlus Health Information",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Super DNAging-New insights into DNA integrity, genome stability and telomeres in the oldest old",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Similar articles",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Cited by",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Publication types",
              "id": ""
            },
            {
              "level": "h2",
              "text": "MeSH terms",
              "id": ""
            },
            {
              "level": "h2",
              "text": "LinkOut - more resources",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Full Text Sources",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Other Literature Sources",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Medical",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://gladstone.org/news/evolution-uniquely-human-dna-was-balancing-act-study-concludes",
      "title": "Evolution of Uniquely Human DNA Was a Balancing Act, Study Concludes",
      "author": "Share:",
      "published_date": "2023-01-13T00:00:00.000Z",
      "content": {
        "text": "<div><div><p>Humans and chimpanzees differ in only one percent of their DNA. Human accelerated regions (HARs) are parts of the genome with an unexpected amount of these differences. HARs were stable in mammals for millennia but quickly changed in early humans. Scientists have long wondered why these bits of DNA changed so much, and how the variations set humans apart from other primates.</p>\n<p>Now, researchers at Gladstone Institutes have analyzed thousands of human and chimpanzee HARs and discovered that many of the changes that accumulated during human evolution had opposing effects from each other.</p>\n<p>“This helps answer a longstanding question about why HARs evolved so quickly after being frozen for millions of years,” says <a href=\"https://gladstone.org/people/katie-pollard\">Katie Pollard, PhD,</a> director of the Gladstone Institute of Data Science and Biotechnology and lead author of the <a href=\"https://www.cell.com/neuron/fulltext/S0896-6273(22)01123-0\">new study published today in <em>Neuron</em>.</a> “An initial variation in a HAR might have turned up its activity too much, and then it needed to be turned down.”</p>\n<p>The findings, she says, have implications for understanding human evolution. In addition—because she and her team discovered that many HARs play roles in brain development—the study suggests that variations in human HARs could predispose people to psychiatric disease.</p>\n<p>“These results required cutting-edge machine learning tools to integrate dozens of novel datasets generated by our team, providing a new lens to examine the evolution of HAR variants,” says Sean Whalen, PhD, first author of the study and senior staff research scientist in Pollard’s lab.</p>\n<h2>Enabled by Machine Learning</h2>\n<p>Pollard discovered HARs in 2006 when comparing the human and chimpanzee genomes. While these stretches of DNA are nearly identical among all humans, they differ between humans and other mammals. Pollard’s lab went on to show that the vast majority of HARs are not genes, but enhancers— regulatory regions of the genome that control the activity of genes.</p>\n<p>More recently, Pollard’s group wanted to study how human HARs differ from chimpanzee HARs in their enhancer function. In the past, this would have required testing HARs one at a time in mice, using a system that stains tissues when a HAR is active.</p>\n<p>Instead, Whalen input hundreds of known human brain enhancers, and hundreds of other non-enhancer sequences, into a computer program so that it could identify patterns that predicted whether any given stretch of DNA was an enhancer. Then he used the model to predict that a third of HARs control brain development.</p>\n<p>“Basically, the computer was able to learn the signatures of brain enhancers,” says Whalen.</p>\n<p></p>\n<p>Whalen and his fellow scientists found that nearly half of HARs contain two or more variants with large opposing effects, mimicking what the machine learning algorithms had predicted.</p>\n<p>Knowing that each HAR has multiple differences between humans and chimpanzees, Pollard and her team questioned how individual variants in a HAR impacted its enhancer strength. For instance, if eight nucleotides of DNA differed between a chimpanzee and human HAR, did all eight have the same effect, either making the enhancer stronger or weaker?</p>\n<p>“We’ve wondered for a long time if all the variants in HARs were required for it to function differently in humans, or if some changes were just hitchhiking along for the ride with more important ones,” says Pollard, who is also chief of the division of bioinformatics in the Department of Epidemiology and Biostatistics at UC San Francisco (UCSF), as well as a Chan Zuckerberg Biohub investigator.</p>\n<p>To test this, Whalen applied a second machine learning model, which was originally designed to determine if DNA differences from person to person affect enhancer activity. The computer predicted that 43 percent of HARs contain two or more variants with large opposing effects: some variants in a given HAR made it a stronger enhancer, while other changes made the HAR a weaker enhancer.</p>\n<p>This result surprised the team, who had expected that all changes would push the enhancer in the same direction, or that some “hitchhiker” changes would have no impact on the enhancer at all.</p>\n<h2>Measuring HAR Strength</h2>\n<p>To validate this compelling prediction, Pollard collaborated with the laboratories of <a href=\"https://profiles.ucsf.edu/nadav.ahituv\">Nadav Ahituv, PhD,</a> and <a href=\"https://profiles.ucsf.edu/alex.pollen\">Alex Pollen, PhD,</a> at UCSF. The researchers fused each HAR to a small DNA barcode. Each time a HAR was active, enhancing the expression of a gene, the barcode was transcribed into a piece of RNA. Then, the researchers used RNA sequencing technology to analyze how much of that barcode was present in any cell—indicating how active the HAR had been in that cell.</p>\n<p>“This method is much more quantitative because we have exact barcode counts instead of microscopy images,” says Ahituv. “It’s also much higher throughput; we can look at hundreds of HARs in a single experiment.”</p>\n<p>“We can never wind the clock back and know exactly what happened in evolution. But we can simulate what might have happened and identify which DNA changes are most likely to explain unique aspects of the human brain, including its propensity for psychiatric disease.”</p>\n<p>Katie Pollard, PhD</p>\n<p>When the group carried out their lab experiments on over 700 HARs in precursors to human and chimpanzee brain cells, the data mimicked what the machine learning algorithms had predicted.</p>\n<p>“We might not have discovered human HAR variants with opposing effects at all if the machine learning model hadn’t produced these startling predictions,” said Pollard.</p>\n<h2>Implications for Understanding Psychiatric Disease</h2>\n<p>The idea that HAR variants played tug-of-war over enhancer levels fits in well with a theory that has already been proposed about human evolution: that the advanced cognition in our species is also what has given us psychiatric diseases.</p>\n<p>“What this kind of pattern indicates is something called compensatory evolution,” says Pollard. “A large change was made in an enhancer, but maybe it was too much and led to harmful side effects, so the change was tuned back down over time—that’s why we see opposing effects.”</p>\n<p></p>\n<p>By better understanding HARs, Pollard (left)—in conversation here with Whalen (right)—hopes her research might eventually help shed light on new treatments for psychiatric diseases.</p>\n<p>If initial changes to HARs led to increased cognition, perhaps subsequent compensatory changes helped tune back down the risk of psychiatric diseases, Pollard speculates. Her data, she adds, can’t directly prove or disprove that idea. But in the future, a better understanding of how HARs contribute to psychiatric disease could not only shed light on evolution, but on new treatments for these diseases.</p>\n<p>“We can never wind the clock back and know exactly what happened in evolution,” says Pollard. “But we can use all these scientific techniques to simulate what might have happened and identify which DNA changes are most likely to explain unique aspects of the human brain, including its propensity for psychiatric disease.”</p></div></div>",
        "html": "<div><div><p>Humans and chimpanzees differ in only one percent of their DNA. Human accelerated regions (HARs) are parts of the genome with an unexpected amount of these differences. HARs were stable in mammals for millennia but quickly changed in early humans. Scientists have long wondered why these bits of DNA changed so much, and how the variations set humans apart from other primates.</p>\n<p>Now, researchers at Gladstone Institutes have analyzed thousands of human and chimpanzee HARs and discovered that many of the changes that accumulated during human evolution had opposing effects from each other.</p>\n<p>“This helps answer a longstanding question about why HARs evolved so quickly after being frozen for millions of years,” says <a href=\"https://gladstone.org/people/katie-pollard\">Katie Pollard, PhD,</a> director of the Gladstone Institute of Data Science and Biotechnology and lead author of the <a href=\"https://www.cell.com/neuron/fulltext/S0896-6273(22)01123-0\">new study published today in <em>Neuron</em>.</a> “An initial variation in a HAR might have turned up its activity too much, and then it needed to be turned down.”</p>\n<p>The findings, she says, have implications for understanding human evolution. In addition—because she and her team discovered that many HARs play roles in brain development—the study suggests that variations in human HARs could predispose people to psychiatric disease.</p>\n<p>“These results required cutting-edge machine learning tools to integrate dozens of novel datasets generated by our team, providing a new lens to examine the evolution of HAR variants,” says Sean Whalen, PhD, first author of the study and senior staff research scientist in Pollard’s lab.</p>\n<h2>Enabled by Machine Learning</h2>\n<p>Pollard discovered HARs in 2006 when comparing the human and chimpanzee genomes. While these stretches of DNA are nearly identical among all humans, they differ between humans and other mammals. Pollard’s lab went on to show that the vast majority of HARs are not genes, but enhancers— regulatory regions of the genome that control the activity of genes.</p>\n<p>More recently, Pollard’s group wanted to study how human HARs differ from chimpanzee HARs in their enhancer function. In the past, this would have required testing HARs one at a time in mice, using a system that stains tissues when a HAR is active.</p>\n<p>Instead, Whalen input hundreds of known human brain enhancers, and hundreds of other non-enhancer sequences, into a computer program so that it could identify patterns that predicted whether any given stretch of DNA was an enhancer. Then he used the model to predict that a third of HARs control brain development.</p>\n<p>“Basically, the computer was able to learn the signatures of brain enhancers,” says Whalen.</p>\n<p></p>\n<p>Whalen and his fellow scientists found that nearly half of HARs contain two or more variants with large opposing effects, mimicking what the machine learning algorithms had predicted.</p>\n<p>Knowing that each HAR has multiple differences between humans and chimpanzees, Pollard and her team questioned how individual variants in a HAR impacted its enhancer strength. For instance, if eight nucleotides of DNA differed between a chimpanzee and human HAR, did all eight have the same effect, either making the enhancer stronger or weaker?</p>\n<p>“We’ve wondered for a long time if all the variants in HARs were required for it to function differently in humans, or if some changes were just hitchhiking along for the ride with more important ones,” says Pollard, who is also chief of the division of bioinformatics in the Department of Epidemiology and Biostatistics at UC San Francisco (UCSF), as well as a Chan Zuckerberg Biohub investigator.</p>\n<p>To test this, Whalen applied a second machine learning model, which was originally designed to determine if DNA differences from person to person affect enhancer activity. The computer predicted that 43 percent of HARs contain two or more variants with large opposing effects: some variants in a given HAR made it a stronger enhancer, while other changes made the HAR a weaker enhancer.</p>\n<p>This result surprised the team, who had expected that all changes would push the enhancer in the same direction, or that some “hitchhiker” changes would have no impact on the enhancer at all.</p>\n<h2>Measuring HAR Strength</h2>\n<p>To validate this compelling prediction, Pollard collaborated with the laboratories of <a href=\"https://profiles.ucsf.edu/nadav.ahituv\">Nadav Ahituv, PhD,</a> and <a href=\"https://profiles.ucsf.edu/alex.pollen\">Alex Pollen, PhD,</a> at UCSF. The researchers fused each HAR to a small DNA barcode. Each time a HAR was active, enhancing the expression of a gene, the barcode was transcribed into a piece of RNA. Then, the researchers used RNA sequencing technology to analyze how much of that barcode was present in any cell—indicating how active the HAR had been in that cell.</p>\n<p>“This method is much more quantitative because we have exact barcode counts instead of microscopy images,” says Ahituv. “It’s also much higher throughput; we can look at hundreds of HARs in a single experiment.”</p>\n<p>“We can never wind the clock back and know exactly what happened in evolution. But we can simulate what might have happened and identify which DNA changes are most likely to explain unique aspects of the human brain, including its propensity for psychiatric disease.”</p>\n<p>Katie Pollard, PhD</p>\n<p>When the group carried out their lab experiments on over 700 HARs in precursors to human and chimpanzee brain cells, the data mimicked what the machine learning algorithms had predicted.</p>\n<p>“We might not have discovered human HAR variants with opposing effects at all if the machine learning model hadn’t produced these startling predictions,” said Pollard.</p>\n<h2>Implications for Understanding Psychiatric Disease</h2>\n<p>The idea that HAR variants played tug-of-war over enhancer levels fits in well with a theory that has already been proposed about human evolution: that the advanced cognition in our species is also what has given us psychiatric diseases.</p>\n<p>“What this kind of pattern indicates is something called compensatory evolution,” says Pollard. “A large change was made in an enhancer, but maybe it was too much and led to harmful side effects, so the change was tuned back down over time—that’s why we see opposing effects.”</p>\n<p></p>\n<p>By better understanding HARs, Pollard (left)—in conversation here with Whalen (right)—hopes her research might eventually help shed light on new treatments for psychiatric diseases.</p>\n<p>If initial changes to HARs led to increased cognition, perhaps subsequent compensatory changes helped tune back down the risk of psychiatric diseases, Pollard speculates. Her data, she adds, can’t directly prove or disprove that idea. But in the future, a better understanding of how HARs contribute to psychiatric disease could not only shed light on evolution, but on new treatments for these diseases.</p>\n<p>“We can never wind the clock back and know exactly what happened in evolution,” says Pollard. “But we can use all these scientific techniques to simulate what might have happened and identify which DNA changes are most likely to explain unique aspects of the human brain, including its propensity for psychiatric disease.”</p></div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Humans and chimpanzees differ in only one percent of their DNA. Human accelerated regions (HARs) are parts of the genome with an unexpected amount of these differences. HARs were stable in mammals for millennia but quickly changed in early humans. Scientists have long wondered why these bits of DNA changed so much, and how the variations set humans apart from other primates.Now, researchers at Gladstone Institutes have analyzed thousands of human and chimpanzee HARs and discovered that many of t",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Humans and chimpanzees differ in only one percent of their DNA. Human accelerated regions (HARs) are parts of the genome with an unexpected amount of these differences. HARs were stable in mammals for millennia but quickly changed in early humans. Scientists have long wondered why these bits of DNA changed so much, and how the variations set humans apart from other primates.Now, researchers at Gladstone Institutes have analyzed thousands of human and chimpanzee HARs and discovered that many of t",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Enabled by Machine Learning",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Measuring HAR Strength",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Implications for Understanding Psychiatric Disease",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.biorxiv.org/content/10.1101/2025.01.09.631797v1",
      "title": "Inherent instability of simple DNA repeats shapes an evolutionarily stable distribution of repeat lengths",
      "author": "View ORCID ProfileRyan J. McGinty",
      "published_date": "2025-01-10T00:00:00.000Z",
      "content": {
        "text": "<div><div><div>\n<p><span>\nNew Results </span></p>\n<p><span><span>doi:</span> https://doi.org/10.1101/2025.01.09.631797 </span></p>\n</div>\n<div><div><div><h2>Abstract</h2><p>Using the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instability, quantitatively modeled the per-generation action of mutations, and observed the corresponding long-term behavior shaping the repeat length distribution. We found that short repetitive sequences appear to be a straightforward consequence of random substitution. Evolving largely independently, longer repeats (10+ nucleotides) emerge and persist in a rapidly mutating dynamic balance between expansion, contraction and interruption. These mutational processes, collectively, are sufficient to explain the abundance of long repeats, without invoking natural selection. Our analysis constrains properties of molecular mechanisms responsible for maintaining genome fidelity that underlie repeat instability.</p></div><h3>Competing Interest Statement</h3><p>The authors have declared no competing interest.</p></div>\n<div><p>Copyright </p><div><p>The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.<span> It is made available under a <a href=\"http://creativecommons.org/licenses/by/4.0/\">CC-BY 4.0 International license</a>.</span></p></div></div>\n</div>\n</div></div>",
        "html": "<div><div><div>\n<p><span>\nNew Results </span></p>\n<p><span><span>doi:</span> https://doi.org/10.1101/2025.01.09.631797 </span></p>\n</div>\n<div><div><div><h2>Abstract</h2><p>Using the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instability, quantitatively modeled the per-generation action of mutations, and observed the corresponding long-term behavior shaping the repeat length distribution. We found that short repetitive sequences appear to be a straightforward consequence of random substitution. Evolving largely independently, longer repeats (10+ nucleotides) emerge and persist in a rapidly mutating dynamic balance between expansion, contraction and interruption. These mutational processes, collectively, are sufficient to explain the abundance of long repeats, without invoking natural selection. Our analysis constrains properties of molecular mechanisms responsible for maintaining genome fidelity that underlie repeat instability.</p></div><h3>Competing Interest Statement</h3><p>The authors have declared no competing interest.</p></div>\n<div><p>Copyright </p><div><p>The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.<span> It is made available under a <a href=\"http://creativecommons.org/licenses/by/4.0/\">CC-BY 4.0 International license</a>.</span></p></div></div>\n</div>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "New Resultsdoi:https://doi.org/10.1101/2025.01.09.631797AbstractUsing the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instabil",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "New Resultsdoi:https://doi.org/10.1101/2025.01.09.631797AbstractUsing the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instabil",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "New Resultsdoi:https://doi.org/10.1101/2025.01.09.631797",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractUsing the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instability, quantitatively modeled the per-generation action of",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractUsing the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instability, quantitatively modeled the per-generation action of",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractUsing the Telomere-to-Telomere reference, we assembled the distribution of simple repeat lengths present in the human genome. Analyzing over two hundred mammalian genomes, we found remarkable consistency in the shape of the distribution across evolutionary epochs. All observed genomes harbor an excess of long repeats, which are prone to developing into repeat expansion disorders. We measured mutation rates for repeat length instability, quantitatively modeled the per-generation action of",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "CopyrightThe copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.It is made available under aCC-BY 4.0 International license.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.It is made available under aCC-BY 4.0 International license.",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Competing Interest Statement",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.proscieurope.com/innovation-now-part-our-dna-go-innovate",
      "title": "",
      "author": "",
      "published_date": null,
      "content": {
        "text": "<div>(µ/ý\u0004XÔ\u0001Ú„…CF gˆš\u0003 î\u0003Dâ\u0002�€ \u0004\u0010‚\"÷ \u001a¤É$2v&amp;Š�$B’Èùý‹‹‡ü_Ù\u0016±ŠUÿp½[}@ è‹~7J©\u000eÀ{\u0005Ø\u0014bðn\u0004Q\u0004»\u0003\u0015\u0016Ö¶1 \u0005\u0004d±°‡6Qa�h\u0011\u0013Ñ\u0003…óÔEi1&lt;•\u0006F§®öÖ\u0006Ó,ñs\bý±l¾=j0P³‰þ)\u0014\u0010Eƒˆ¢‰h¡\u0006‘\u0004\u0005„…Ä„DÛeQÄnƒŠ\bršó ê¹…�ÜÃŸC\u001a¡ò�[Swû*‡\u0003\u00159lWàR;}Å9\nq\u000f\u000f\n2\u0012´ÐÐÁ²!rLˆ¨\u0010A0 ®Ø€!JX –zè•Á\u0002\u0002±ÐØ.±\u0001:¨(M \u0002�\t‚\u0006˜ÂÄµ\u000f\u0015l‚F€\u000eD&amp;\u0011aUVÕìj\u0011PT@@ÏÀ_ AW°:h‡w€\u0001‹\u0004\u0016 P4\u0010!D@\u0013¸R\u0010\tVêˆ€\u0002††\n,¢#c‚°LL°œÓ\u0006£Ü–¢HP\u000f\u0011o! PÊÚà\\È \u00119H\u001b8ÄÉÒ\"\t¾\u0003E\u0006ëÈ‰\u0018x\u0019žÃÁ\u0001\u0004BV��5\u0010²J-ˆ¹ÔU�[\u0002\u000f\u000f\n&lt;</div>",
        "html": "<div>(µ/ý\u0004XÔ\u0001Ú„…CF gˆš\u0003 î\u0003Dâ\u0002�€ \u0004\u0010‚\"÷ \u001a¤É$2v&amp;Š�$B’Èùý‹‹‡ü_Ù\u0016±ŠUÿp½[}@ è‹~7J©\u000eÀ{\u0005Ø\u0014bðn\u0004Q\u0004»\u0003\u0015\u0016Ö¶1 \u0005\u0004d±°‡6Qa�h\u0011\u0013Ñ\u0003…óÔEi1&lt;•\u0006F§®öÖ\u0006Ó,ñs\bý±l¾=j0P³‰þ)\u0014\u0010Eƒˆ¢‰h¡\u0006‘\u0004\u0005„…Ä„DÛeQÄnƒŠ\bršó ê¹…�ÜÃŸC\u001a¡ò�[Swû*‡\u0003\u00159lWàR;}Å9\nq\u000f\u000f\n2\u0012´ÐÐÁ²!rLˆ¨\u0010A0 ®Ø€!JX –zè•Á\u0002\u0002±ÐØ.±\u0001:¨(M \u0002�\t‚\u0006˜ÂÄµ\u000f\u0015l‚F€\u000eD&amp;\u0011aUVÕìj\u0011PT@@ÏÀ_ AW°:h‡w€\u0001‹\u0004\u0016 P4\u0010!D@\u0013¸R\u0010\tVêˆ€\u0002††\n,¢#c‚°LL°œÓ\u0006£Ü–¢HP\u000f\u0011o! PÊÚà\\È \u00119H\u001b8ÄÉÒ\"\t¾\u0003E\u0006ëÈ‰\u0018x\u0019žÃÁ\u0001\u0004BV��5\u0010²J-ˆ¹ÔU�[\u0002\u000f\u000f\n&lt;</div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "(µ/ý\u0004XÔ\u0001Ú„…CF gˆš\u0003 î\u0003Dâ\u0002�€ \u0004\u0010‚\"÷ \u001a¤É$2v&Š�$B’Èùý‹‹‡ü_Ù\u0016±ŠUÿp½[}@ è‹~7J©\u000eÀ{\u0005Ø\u0014bðn\u0004Q\u0004»\u0003\u0015\u0016Ö¶1 \u0005\u0004d±°‡6Qa�h\u0011\u0013Ñ\u0003…óÔEi1<•\u0006F§®öÖ\u0006Ó,ñs\bý±l¾=j0P³‰þ)\u0014\u0010Eƒˆ¢‰h¡\u0006‘\u0004\u0005„…Ä„DÛeQÄnƒŠ\bršó ê¹…�ÜÃŸC\u001a¡ò�[Swû*‡\u0003\u00159lWàR;}Å9\nq\u000f\u000f\n2\u0012´ÐÐÁ²!rLˆ¨\u0010A0 ®Ø€!JX –zè•Á\u0002\u0002±ÐØ.±\u0001:¨(M \u0002�\t‚\u0006˜ÂÄµ\u000f\u0015l‚F€\u000eD&\u0011aUVÕìj\u0011PT@@ÏÀ_ AW°:h‡w€\u0001‹\u0004\u0016 P4\u0010!D@\u0013¸R\u0010\tVêˆ€\u0002††\n,¢#c‚°LL°œÓ\u0006£Ü–¢HP\u000f\u0011o! PÊÚà\\È \u00119H\u001b8ÄÉÒ\"\t¾\u0003E\u0006ëÈ‰\u0018x\u0019žÃÁ\u0001\u0004BV��5\u0010²J-ˆ¹ÔU�[\u0002\u000f\u000f\n<",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://blog.workday.com/en-ca/rewire-the-dna-of-your-business-for-speed-and-agility.html",
      "title": "Rewire the DNA of Your Business for Speed and Agility",
      "author": "Chris Ernst",
      "published_date": "2024-07-08T16:00:00.000Z",
      "content": {
        "text": "<div><div>\n<article>\n<p>We talked to two McKinsey experts about the helix organizational model, and how it can help cultivate a workforce that adapts to the dynamic demands of the business.</p>\n<figure>\n</figure>\n</article>\n</div><div>\n<div>\n<p><i>In this article, we discuss:</i></p>\n<ul>\n<li><a href=\"#trends-pushing-the-need-for-agile-ways-of-working-and-key-characteristics-associated-with-them\">Trends pushing the need for agile ways of working and key characteristics associated with them</a></li>\n<li><a href=\"#an-overview-of-the-mckinsey-developed-helix-model-and-how-it-differs-from-other-types-of-organizational-models\">An overview of the McKinsey-developed helix model and how it differs from other types of organizational models</a></li>\n<li><a href=\"#the-four-principles-to-achieve-success-with-a-helix-organizational-model\">The four principles to achieve success with a helix organizational model</a></li>\n</ul>\n</div>\n<div>\n<p>No longer just an aspirational state of being, agility has become a necessity for companies to survive and thrive. But despite the acceptance of agility as a pressing imperative of the modern organization, HR leaders need to confront the next challenge: making agility scalable and sustainable.</p>\n<p>That requires agility built into the company’s organizational structure, meaning the reporting structure or management hierarchy within your company. To thrive in the fast-changing and disruptive “now” of work (to say nothing of the future), all companies need a consistent approach that enables agility.</p>\n<p>We talked with Dr. Kirsten Weerda and Andy Fong, partners within McKinsey’s people and organizational performance practice, about a structure worth considering for maintaining sustainable and scalable agility: a helix organizational model.<a></a></p>\n<p>Developed by <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/become-flexible-and-speed-up-with-a-helix-model-part-one\">McKinsey</a>, this model is designed to promote cross-functional agility backed by stability, or, put another way, to strike a better balance between centralization (being efficient and stable) and decentralization (ensuring speed, flexibility, and entrepreneurship).</p>\n</div>\n<div>\n<h2>Uncertainty Pushes the Need for Agile Ways of Working</h2>\n<p>Operating with agility has always been needed in business but has come to the forefront as companies now regularly face changing, unprecedented demands. These include adapting to emerging technology, quickly shifting to a digital business model, and navigating an increasing number of remote and hybrid work structures.</p>\n</div>\n<div>\n<blockquote>\n<p>“Agility—it rhymes with stability.”</p>\n<cite>\n<span>\n<span>Dr. Kirsten Weerda</span>\n<span>McKinsey Partner</span>\n<span>People and Organizational Performance practice</span>\n</span>\n</cite>\n</blockquote>\n</div>\n<div>\n<p>For example, the automotive industry has seen tremendous technology shifts—autonomous driving, electromobility, and so on, Weerda explained. At the same time, there’s uncertainty about when the new technologies will fully pick up in the market. In fact, many manufacturers were surprised that <a href=\"https://www.iea.org/commentaries/how-global-electric-car-sales-defied-covid-19-in-2020\">demand</a> for electric vehicles picked up quite quickly during the coronavirus pandemic. Entering 2024, the demand for electric vehicles is expected to <a href=\"https://www.npr.org/2024/02/07/1227707306/ev-electric-vehicles-sales-2024\">slow down</a>.</p>\n<p>“Manufacturers still need to develop in parallel both electric vehicles and traditional combustion vehicles, which requires shifting the right workforce to other areas,” Weerda said. “The uncertainty and cost pressure on one side and the need for more flexibility and speed in the way people work is tremendous.”</p>\n<p>But while agility in an organization can refer to moving fast, it’s not necessarily about breaking things or creating chaos.</p>\n<p>“If you’re only stable, you might become overly bureaucratic. If you’re only dynamic, you’re more in a start-up mode where things are just done by, ‘Ah, you do that. I do this,’” Weerda said.</p>\n<p>You need both for agility, Weerda explained. Stability means having consistent development processes with clarity on roles and responsibilities across the company. Dynamic includes having the capability of moving people within a development organization and quickly creating a new team that knows how to work together.</p>\n<p>As Weerda put it, “Agility—it rhymes with stability.”</p>\n<p>“Agility and stability go hand in hand,” Weerda said. “To achieve this, a clear organizational frame and meaning; consistent structures, processes, and ways of working; and aligned priorities must be established. This overarching frame allows individuals to act and make decisions flexibly without creating chaos.”</p>\n<p>Consider this: When working in a remote environment, a traditional, chain-of-command structure can create a dependence on managers for day-to-day direction. However, this level of direction may not be possible due to the lack of face-to-face interaction.</p>\n<p>Instead, an agile organizational model with agile capabilities aims to cultivate a self-directed mindset in individuals, encouraging them to take initiative and collaborate with team members to solve problems on a day-to-day level—without waiting for instruction from managers.<a></a></p>\n</div>\n<p>\n</p><section>\n<figure>\n<figure></figure>\n<figcaption>\nLearn how we’re empowering organizations to transform how they manage their people and their money and how we’re boldly leading global brands toward an AI-enabled future with trust at the heart of everything we do.\n</figcaption>\n</figure>\n</section>\n<p></p>\n<div>\n<h2>Empowering the Future of Work: How the Helix Organizational Model Drives Agility</h2>\n<p>Leaders know that innovation and change are the keys to success in digital transformation. That requires empowering individuals to move quickly while also ensuring that business priorities are met. </p>\n<p>Seeing that need, McKinsey developed the helix model—an approach that generates high clarity into the balance between flexibility and stability.</p>\n<p>So what is a helix organizational model?</p>\n</div>\n<p>\n</p><section>\n<figure>\n<figure></figure>\n<figcaption>\nValue creation managers drive the day-to-day work of employees while the capability managers drive how the work gets done.\n</figcaption>\n</figure>\n</section>\n<p></p>\n<div>\n<p>A helix model is a double-helix structure where each spiral is a line that represents a differentiated reporting line with different management tasks associated with it. One of the reporting lines is primarily concerned with developing the individual’s capabilities and functional excellence. The supervisor in this role is considered the “<b>capability manager</b>” who sets the standards for how the work is done. This reporting line is referred to as the “capability” unit and considered the stable “home” for employees. </p>\n<p>The capability manager’s key tasks are to ensure two things. first, the capability manager ensures that your people have the right capabilities and provide the right people at the right time to the value-creation areas. Second, because the right people know the topic well, the capability manager ensures that they have the functional excellence and state-of-the-art processes and tools to best do their job.</p>\n<p>The other reporting line has the end-to-end business responsibility (for example, profit and loss, and budget responsibility). It focuses on the individual employee’s day-to-day work and aligns this work to the business’s priorities. This is considered the “value creation” unit, and the supervisor representing this reporting line is considered the “<b>value creation manager</b>.”</p>\n<p>Individuals can be shifted across value creation units easily; for example, to other projects, as the business priorities change. This is possible because the capability manager, who is responsible for the people, has no reason to hold on to the people, which typically happens in more rigid business unit structures.</p>\n<p>“Unlike a traditional hierarchical model where individuals are rigidly tied to a supervisor [traditionally called the “solid line manager”] or a project, the helix model promotes fluidity,” Weerda explained. “Personnel can be seamlessly integrated, being staffed out of the capability units into various projects as needed, emphasizing the organization’s adaptability to changing market demands and project scopes.” </p>\n<p>Other key differences exist between a helix model and other organizational models. For example, some modern organizational structures, such as a dual or <a href=\"https://www.indeed.com/career-advice/career-development/matrix-organizational-structure\">matrix</a> structure reporting model, have two supervisory reporting lines but one is a metaphorical solid reporting line and the other is a dotted reporting line. This can mean a supervisor formally manages project-based tasks and evaluates the employee’s performance while the secondary supervisor is involved in some project-based work. In a helix model, both reporting lines are considered accountable and equally important while still having clearly differentiated management tasks: one about the people and one about driving the business and managing the budget.</p>\n<p>And unlike the highly dynamic working models such as the “<a href=\"https://www.atlassian.com/agile/agile-at-scale/spotify#:~:text=What%20is%20the%20Spotify%20model,communication%2C%20accountability%2C%20and%20quality.\">Spotify model</a>,” the helix model does not hand over complete control of resources to the value creation leads, thereby avoiding the pitfall of having a workforce that feels transient, with members being shuffled too frequently. </p>\n</div>\n<div>\n<blockquote>\n<p>“To build their capabilities and encourage positiv",
        "html": "<div><div>\n<article>\n<p>We talked to two McKinsey experts about the helix organizational model, and how it can help cultivate a workforce that adapts to the dynamic demands of the business.</p>\n<figure>\n</figure>\n</article>\n</div><div>\n<div>\n<p><i>In this article, we discuss:</i></p>\n<ul>\n<li><a href=\"#trends-pushing-the-need-for-agile-ways-of-working-and-key-characteristics-associated-with-them\">Trends pushing the need for agile ways of working and key characteristics associated with them</a></li>\n<li><a href=\"#an-overview-of-the-mckinsey-developed-helix-model-and-how-it-differs-from-other-types-of-organizational-models\">An overview of the McKinsey-developed helix model and how it differs from other types of organizational models</a></li>\n<li><a href=\"#the-four-principles-to-achieve-success-with-a-helix-organizational-model\">The four principles to achieve success with a helix organizational model</a></li>\n</ul>\n</div>\n<div>\n<p>No longer just an aspirational state of being, agility has become a necessity for companies to survive and thrive. But despite the acceptance of agility as a pressing imperative of the modern organization, HR leaders need to confront the next challenge: making agility scalable and sustainable.</p>\n<p>That requires agility built into the company’s organizational structure, meaning the reporting structure or management hierarchy within your company. To thrive in the fast-changing and disruptive “now” of work (to say nothing of the future), all companies need a consistent approach that enables agility.</p>\n<p>We talked with Dr. Kirsten Weerda and Andy Fong, partners within McKinsey’s people and organizational performance practice, about a structure worth considering for maintaining sustainable and scalable agility: a helix organizational model.<a></a></p>\n<p>Developed by <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/become-flexible-and-speed-up-with-a-helix-model-part-one\">McKinsey</a>, this model is designed to promote cross-functional agility backed by stability, or, put another way, to strike a better balance between centralization (being efficient and stable) and decentralization (ensuring speed, flexibility, and entrepreneurship).</p>\n</div>\n<div>\n<h2>Uncertainty Pushes the Need for Agile Ways of Working</h2>\n<p>Operating with agility has always been needed in business but has come to the forefront as companies now regularly face changing, unprecedented demands. These include adapting to emerging technology, quickly shifting to a digital business model, and navigating an increasing number of remote and hybrid work structures.</p>\n</div>\n<div>\n<blockquote>\n<p>“Agility—it rhymes with stability.”</p>\n<cite>\n<span>\n<span>Dr. Kirsten Weerda</span>\n<span>McKinsey Partner</span>\n<span>People and Organizational Performance practice</span>\n</span>\n</cite>\n</blockquote>\n</div>\n<div>\n<p>For example, the automotive industry has seen tremendous technology shifts—autonomous driving, electromobility, and so on, Weerda explained. At the same time, there’s uncertainty about when the new technologies will fully pick up in the market. In fact, many manufacturers were surprised that <a href=\"https://www.iea.org/commentaries/how-global-electric-car-sales-defied-covid-19-in-2020\">demand</a> for electric vehicles picked up quite quickly during the coronavirus pandemic. Entering 2024, the demand for electric vehicles is expected to <a href=\"https://www.npr.org/2024/02/07/1227707306/ev-electric-vehicles-sales-2024\">slow down</a>.</p>\n<p>“Manufacturers still need to develop in parallel both electric vehicles and traditional combustion vehicles, which requires shifting the right workforce to other areas,” Weerda said. “The uncertainty and cost pressure on one side and the need for more flexibility and speed in the way people work is tremendous.”</p>\n<p>But while agility in an organization can refer to moving fast, it’s not necessarily about breaking things or creating chaos.</p>\n<p>“If you’re only stable, you might become overly bureaucratic. If you’re only dynamic, you’re more in a start-up mode where things are just done by, ‘Ah, you do that. I do this,’” Weerda said.</p>\n<p>You need both for agility, Weerda explained. Stability means having consistent development processes with clarity on roles and responsibilities across the company. Dynamic includes having the capability of moving people within a development organization and quickly creating a new team that knows how to work together.</p>\n<p>As Weerda put it, “Agility—it rhymes with stability.”</p>\n<p>“Agility and stability go hand in hand,” Weerda said. “To achieve this, a clear organizational frame and meaning; consistent structures, processes, and ways of working; and aligned priorities must be established. This overarching frame allows individuals to act and make decisions flexibly without creating chaos.”</p>\n<p>Consider this: When working in a remote environment, a traditional, chain-of-command structure can create a dependence on managers for day-to-day direction. However, this level of direction may not be possible due to the lack of face-to-face interaction.</p>\n<p>Instead, an agile organizational model with agile capabilities aims to cultivate a self-directed mindset in individuals, encouraging them to take initiative and collaborate with team members to solve problems on a day-to-day level—without waiting for instruction from managers.<a></a></p>\n</div>\n<p>\n</p><section>\n<figure>\n<figure></figure>\n<figcaption>\nLearn how we’re empowering organizations to transform how they manage their people and their money and how we’re boldly leading global brands toward an AI-enabled future with trust at the heart of everything we do.\n</figcaption>\n</figure>\n</section>\n<p></p>\n<div>\n<h2>Empowering the Future of Work: How the Helix Organizational Model Drives Agility</h2>\n<p>Leaders know that innovation and change are the keys to success in digital transformation. That requires empowering individuals to move quickly while also ensuring that business priorities are met. </p>\n<p>Seeing that need, McKinsey developed the helix model—an approach that generates high clarity into the balance between flexibility and stability.</p>\n<p>So what is a helix organizational model?</p>\n</div>\n<p>\n</p><section>\n<figure>\n<figure></figure>\n<figcaption>\nValue creation managers drive the day-to-day work of employees while the capability managers drive how the work gets done.\n</figcaption>\n</figure>\n</section>\n<p></p>\n<div>\n<p>A helix model is a double-helix structure where each spiral is a line that represents a differentiated reporting line with different management tasks associated with it. One of the reporting lines is primarily concerned with developing the individual’s capabilities and functional excellence. The supervisor in this role is considered the “<b>capability manager</b>” who sets the standards for how the work is done. This reporting line is referred to as the “capability” unit and considered the stable “home” for employees. </p>\n<p>The capability manager’s key tasks are to ensure two things. first, the capability manager ensures that your people have the right capabilities and provide the right people at the right time to the value-creation areas. Second, because the right people know the topic well, the capability manager ensures that they have the functional excellence and state-of-the-art processes and tools to best do their job.</p>\n<p>The other reporting line has the end-to-end business responsibility (for example, profit and loss, and budget responsibility). It focuses on the individual employee’s day-to-day work and aligns this work to the business’s priorities. This is considered the “value creation” unit, and the supervisor representing this reporting line is considered the “<b>value creation manager</b>.”</p>\n<p>Individuals can be shifted across value creation units easily; for example, to other projects, as the business priorities change. This is possible because the capability manager, who is responsible for the people, has no reason to hold on to the people, which typically happens in more rigid business unit structures.</p>\n<p>“Unlike a traditional hierarchical model where individuals are rigidly tied to a supervisor [traditionally called the “solid line manager”] or a project, the helix model promotes fluidity,” Weerda explained. “Personnel can be seamlessly integrated, being staffed out of the capability units into various projects as needed, emphasizing the organization’s adaptability to changing market demands and project scopes.” </p>\n<p>Other key differences exist between a helix model and other organizational models. For example, some modern organizational structures, such as a dual or <a href=\"https://www.indeed.com/career-advice/career-development/matrix-organizational-structure\">matrix</a> structure reporting model, have two supervisory reporting lines but one is a metaphorical solid reporting line and the other is a dotted reporting line. This can mean a supervisor formally manages project-based tasks and evaluates the employee’s performance while the secondary supervisor is involved in some project-based work. In a helix model, both reporting lines are considered accountable and equally important while still having clearly differentiated management tasks: one about the people and one about driving the business and managing the budget.</p>\n<p>And unlike the highly dynamic working models such as the “<a href=\"https://www.atlassian.com/agile/agile-at-scale/spotify#:~:text=What%20is%20the%20Spotify%20model,communication%2C%20accountability%2C%20and%20quality.\">Spotify model</a>,” the helix model does not hand over complete control of resources to the value creation leads, thereby avoiding the pitfall of having a workforce that feels transient, with members being shuffled too frequently. </p>\n</div>\n<div>\n<blockquote>\n<p>“To build their capabilities and encourage positiv",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "We talked to two McKinsey experts about the helix organizational model, and how it can help cultivate a workforce that adapts to the dynamic demands of the business.In this article, we discuss:Trends pushing the need for agile ways of working and key characteristics associated with themAn overview of the McKinsey-developed helix model and how it differs from other types of organizational modelsThe four principles to achieve success with a helix organizational modelNo longer just an aspirational ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "We talked to two McKinsey experts about the helix organizational model, and how it can help cultivate a workforce that adapts to the dynamic demands of the business.",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "We talked to two McKinsey experts about the helix organizational model, and how it can help cultivate a workforce that adapts to the dynamic demands of the business.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "In this article, we discuss:Trends pushing the need for agile ways of working and key characteristics associated with themAn overview of the McKinsey-developed helix model and how it differs from other types of organizational modelsThe four principles to achieve success with a helix organizational modelNo longer just an aspirational state of being, agility has become a necessity for companies to survive and thrive. But despite the acceptance of agility as a pressing imperative of the modern orga",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "In this article, we discuss:Trends pushing the need for agile ways of working and key characteristics associated with themAn overview of the McKinsey-developed helix model and how it differs from other types of organizational modelsThe four principles to achieve success with a helix organizational model",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "No longer just an aspirational state of being, agility has become a necessity for companies to survive and thrive. But despite the acceptance of agility as a pressing imperative of the modern organization, HR leaders need to confront the next challenge: making agility scalable and sustainable.That requires agility built into the company’s organizational structure, meaning the reporting structure or management hierarchy within your company. To thrive in the fast-changing and disruptive “now” of w",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Uncertainty Pushes the Need for Agile Ways of WorkingOperating with agility has always been needed in business but has come to the forefront as companies now regularly face changing, unprecedented demands. These include adapting to emerging technology, quickly shifting to a digital business model, and navigating an increasing number of remote and hybrid work structures.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "“Agility—it rhymes with stability.”Dr. Kirsten WeerdaMcKinsey PartnerPeople and Organizational Performance practice",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "For example, the automotive industry has seen tremendous technology shifts—autonomous driving, electromobility, and so on, Weerda explained. At the same time, there’s uncertainty about when the new technologies will fully pick up in the market. In fact, many manufacturers were surprised thatdemandfor electric vehicles picked up quite quickly during the coronavirus pandemic. Entering 2024, the demand for electric vehicles is expected toslow down.“Manufacturers still need to develop in parallel bo",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Learn how we’re empowering organizations to transform how they manage their people and their money and how we’re boldly leading global brands toward an AI-enabled future with trust at the heart of everything we do.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Empowering the Future of Work: How the Helix Organizational Model Drives AgilityLeaders know that innovation and change are the keys to success in digital transformation. That requires empowering individuals to move quickly while also ensuring that business priorities are met.Seeing that need, McKinsey developed the helix model—an approach that generates high clarity into the balance between flexibility and stability.So what is a helix organizational model?",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Value creation managers drive the day-to-day work of employees while the capability managers drive how the work gets done.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "A helix model is a double-helix structure where each spiral is a line that represents a differentiated reporting line with different management tasks associated with it. One of the reporting lines is primarily concerned with developing the individual’s capabilities and functional excellence. The supervisor in this role is considered the “capability manager” who sets the standards for how the work is done. This reporting line is referred to as the “capability” unit and considered the stable “home",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "“To build their capabilities and encourage positiv",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Uncertainty Pushes the Need for Agile Ways of Working",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Empowering the Future of Work: How the Helix Organizational Model Drives Agility",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://plato.stanford.edu/entries/genetic-drift/",
      "title": "Genetic Drift",
      "author": "Millstein, Roberta L.",
      "published_date": "2016-09-15T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<h2>1. Origins of the Concept of Genetic Drift</h2>\n<p>\nAlthough Charles Darwin invoked “chance” in various ways\nin the <em>Origin of Species</em> (Beatty 1984), he seems not to have\nincluded a concept of drift in his account. He does note in passing\nthat</p>\n<blockquote>\n<p>\n[v]ariations neither useful nor injurious would not be affected by\nnatural selection, and would be left either a fluctuating element, as\nperhaps we see in certain polymorphic species, or would ultimately\nbecome fixed, owing to the nature of the organism and the nature of\nthe conditions. (Darwin 1872: 63; see similar claims on p. 120 and p.\n176)</p>\n</blockquote>\n<p>\nAs the reader will see, this is tantalizingly similar to contemporary\nconceptions of drift. But Darwin does not develop the idea further; in\nparticular, he does not tell us why the distributions of such\nvariations would be fluctuating over time or how it is that they would\nultimately become fixed. The first serious (and mathematical)\ntreatments of drift are usually traced to two of the founders of\npopulation genetics, Sewall Wright and R.A. Fisher, although neither\nclaimed to have developed the ideas behind drift (Beatty 1992). Wright\n(1951) credits John Gulick (1873) with the genesis of the idea whereas\nFisher (1922b) first discussed the idea as derived from the work of\nA.C. and A.L. Hagedoorn (1921), although Wright (1931a) cites the\nHagedoorns too. It is unclear who first uses the term\n“drift” in this context; it appears as early as Wright\n(1929). So, let us briefly examine Gulick and the Hagedoorns in order\nto understand the origins of the term “drift”.</p>\n<p>\nGulick (1873) points out that with natural selection, one can assume\nthat where different forms are found, different external conditions\nwill also be found (with the different forms having adapted over the\ncourse of generations to the different external conditions). However,\nthere seem to be cases (e.g., among snails) where the external\nconditions are very similar, yet the organismic forms are very\ndifferent. He notes that these species tend to occupy very small\nareas, even though there is reason to believe it is not because they\nlack the ability to migrate further. He then postulates a scenario:\nSuppose some members of a species migrate to a new area where they are\nfree from competition and largely separated from the original\npopulation. New variations will arise in the new population, but\nunless they are “decidedly malformed”, they will persist.\nThe new population will thus come to differentiate itself from the\noriginal population (e.g., with new shades of color or with variations\nof shape), perhaps rapidly if there is a “preexisting tendency\nto rapid variation”.</p>\n<p>\nSome points to note here that become relevant in later discussions of\ndrift: 1) Drift is described in contrast to natural selection. 2) The\nvariations increasing in the population are those that are neutral, or\nat least not severely deleterious. (Note that 1 and 2 are also present\nin the quote from Darwin above). 3) Drift is associated with small\npopulations (although it is not fully clear why). 4) Drift is\nassociated with the founding of a new population in a new area. 5)\nChanges in the population are the result of movements of organisms and\ntheir tendency to produce new variations, both of which are physical\nprocesses and not purely mathematical constructs (something that\nbecomes an issue in later debates). 6) The changes described are of\norganisms in a population.</p>\n<p>\nHagedoorn and Hagedoorn (1921) similarly point out that some traits of\norganisms are “trivial”, i.e., “cannot possibly be\naccounted for as useful”, such as “the shape and\narrangement of small hairs on the seeds of some cereals” (p.\n107). They likewise maintain that such traits, which can be stable\n(“pure”, i.e., fixed) within a species, cannot be the\nproduct of natural selection; instead, the Hagedoorns assert, they\nmust be “due to some process which accompanies selection”\n(p. 108). The Hagedoorns then proceed to describe several ways in\nwhich variability in a population can be reduced: a new population is\nfounded which lacks some of the variability of the original\npopulation; a population is split in half (with the variability in the\ndaughter populations differing from each other and from the original);\nand “random sampling” where even though the size of the\npopulation remains relatively constant from year to year, only a small\nfraction successfully reproduce. On this last point, they state,</p>\n<blockquote>\n<p>\nThe group of organisms chosen by fate to become the parents of the\nnext generation is usually, but always occasionally, considerably\nsmaller than the number of individuals of their species. (1921:\n120)</p>\n</blockquote>\n<p>\nThus, the Hagedoorns endorse points 1–5 above, while describing\ntwo additional processes besides #4 (the founding of a new\npopulation), namely the splitting of a population and the random\nsampling of parents. They further explain the relevance of #3 (small\npopulations): “the smaller the group, the more limited its\npotential variability, the sooner it will be pure altogether”\n(p. 123). And finally, they maintain that drift can produce fixation\n(“purity”), or the complete loss of variation within a\npopulation, even in the absence of selection. Fisher (1922b) reads the\nHagedoorns as claiming that “random survival is a more important\nfactor in limiting the variability of species than preferential\nsurvival” (p. 321), a claim that he challenged by attempting to\nshow that such a process would be too slow to overcome the rate of\nmutation (and thus the introduction of new variability—but he\nseems to say otherwise in 1922a).</p>\n<p>\nAn essay published by Wright in 1931 provides what is perhaps one of\nthe earliest <em>explicit</em> characterizations of drift:</p>\n<blockquote>\n<p>\nIt has seemed to me that another factor should be much more important\nin keeping the system of gene frequencies from settling into\nequilibrium. This is the effect of <em>random sampling</em> in a\nbreeding population of limited size. The gene frequencies of one\ngeneration may be expected to differ a little from those of the\npreceding <em>merely by chance</em>. In the course of generations this\nmay bring about important changes, although the farther the\n<em>drift</em> from the theoretical equilibrium, the greater will be\nthe pressure toward return. (Wright 1931b: 205; emphasis added)</p>\n</blockquote>\n<p>\nThe paper from which this quote is taken was meant to be a summary of\na longer paper, also published in 1931 (Wright 1986: 88). In the\nlonger paper (1931a), Wright specifies that the random sampling is of\n<em>gametes</em>. (Gametes are cells that fuse together during\nfertilization, such as an egg and a sperm). So, even though Wright\n(1931a) notes that the Hagedoorns had “urged the importance of\nsuch random fixation as a factor in evolution”, and states that\nFisher (1922b) had analyzed the issue, has he changed the subject to\nbe random sampling of <em>gametes</em> rather than of\n“parents” (i.e., organisms)? In short, no: Wright (1932\nand elsewhere) makes it clear that he considers drift to encompass\nboth random sampling of gametes and random sampling of organisms. In\nother words, he has <em>expanded</em> the phenomena that the concept\nof drift is meant to cover from that discussed by Gulick, the\nHagedoorns, and Fisher. But Wright’s 1932 paper also emphasized\nwhat would become a persistent confusion between drift and inbreeding;\nboth inbreeding and drift are more significant in small populations,\nso it can become easy to conflate them. But you can have random\nsampling of parents (say, through a population split) without\ninbreeding, and inbreeding without random sampling of parents. That\nalone shows that drift and inbreeding are not the same. So, not all of\nthe expansions of drift were productive ones.</p>\n<p>\nIt should be noted that while Wright and Fisher had numerous\nback-and-forth discussions and disagreements about each other’s\nclaims concerning the role of drift in evolution (Provine 1986,\nSkipper 2002), they did not seem to disagree about what drift\n<em>was</em>. Wright (1948) considered the following to be an\n“acceptable statement” of his view from Fisher and E.B.\nFord:</p>\n<blockquote>\n<p>\nGreat evolutionary importance has been attached by Sewall Wright\n(1931, 1932, 1935, 1940) to the fact that small shifts in the\ngene-ratios of all segregating factors will occur from generation to\ngeneration owing to the errors of random sampling in the process by\nwhich the gametes available in any one generation are chosen to\nconstitute the next. Such chance deviations will, of course, be\ngreater the smaller the isolated populations concerned. (Fisher and\nFord 1947)</p>\n</blockquote>\n<p>\nOn the other hand, Wright’s later incorporation of fluctuations\nin mutation rate, fluctuations in migration, and fluctuations in\nselection (see, e.g., Wright 1949) as types of drift was challenged by\nCain and Currey, who asserted that “the worker on actual\nexamples must classify processes according to their biological\nsignificance” and that such lumping together would produce\nconfusion and prevent proper analysis of actual situations (Cain &amp;\nCurrey 1963: 59). They thus urged the use of the term “sampling\ndrift”, which Wright adopted in the fourth volume of his 1978\nmagnum opus, <em>Evolution and the Genetics of Populations</em>.</p>\n<p>\nIn short, drift’s founders exhibit a diversity of views about\ndrift, which John Beatty helpfully describes as follows:</p>\n<blockquote>\n<p>\ndrift is a heterogeneous category of evolutionary causes and effects,\nwhose overall significance relative to other modes of evolution\n(especially evolution by natural selection) has been greatly disputed.\n(Beatty 1992: 273)</p>\n</blockquote>\n<p>\nPotential causes invoked in the discussion above include sampling of\ngametes, sampling of parents, founding of new populations, splitting\nof populations, each of which is intensified",
        "html": "<div><div>\n<h2>1. Origins of the Concept of Genetic Drift</h2>\n<p>\nAlthough Charles Darwin invoked “chance” in various ways\nin the <em>Origin of Species</em> (Beatty 1984), he seems not to have\nincluded a concept of drift in his account. He does note in passing\nthat</p>\n<blockquote>\n<p>\n[v]ariations neither useful nor injurious would not be affected by\nnatural selection, and would be left either a fluctuating element, as\nperhaps we see in certain polymorphic species, or would ultimately\nbecome fixed, owing to the nature of the organism and the nature of\nthe conditions. (Darwin 1872: 63; see similar claims on p. 120 and p.\n176)</p>\n</blockquote>\n<p>\nAs the reader will see, this is tantalizingly similar to contemporary\nconceptions of drift. But Darwin does not develop the idea further; in\nparticular, he does not tell us why the distributions of such\nvariations would be fluctuating over time or how it is that they would\nultimately become fixed. The first serious (and mathematical)\ntreatments of drift are usually traced to two of the founders of\npopulation genetics, Sewall Wright and R.A. Fisher, although neither\nclaimed to have developed the ideas behind drift (Beatty 1992). Wright\n(1951) credits John Gulick (1873) with the genesis of the idea whereas\nFisher (1922b) first discussed the idea as derived from the work of\nA.C. and A.L. Hagedoorn (1921), although Wright (1931a) cites the\nHagedoorns too. It is unclear who first uses the term\n“drift” in this context; it appears as early as Wright\n(1929). So, let us briefly examine Gulick and the Hagedoorns in order\nto understand the origins of the term “drift”.</p>\n<p>\nGulick (1873) points out that with natural selection, one can assume\nthat where different forms are found, different external conditions\nwill also be found (with the different forms having adapted over the\ncourse of generations to the different external conditions). However,\nthere seem to be cases (e.g., among snails) where the external\nconditions are very similar, yet the organismic forms are very\ndifferent. He notes that these species tend to occupy very small\nareas, even though there is reason to believe it is not because they\nlack the ability to migrate further. He then postulates a scenario:\nSuppose some members of a species migrate to a new area where they are\nfree from competition and largely separated from the original\npopulation. New variations will arise in the new population, but\nunless they are “decidedly malformed”, they will persist.\nThe new population will thus come to differentiate itself from the\noriginal population (e.g., with new shades of color or with variations\nof shape), perhaps rapidly if there is a “preexisting tendency\nto rapid variation”.</p>\n<p>\nSome points to note here that become relevant in later discussions of\ndrift: 1) Drift is described in contrast to natural selection. 2) The\nvariations increasing in the population are those that are neutral, or\nat least not severely deleterious. (Note that 1 and 2 are also present\nin the quote from Darwin above). 3) Drift is associated with small\npopulations (although it is not fully clear why). 4) Drift is\nassociated with the founding of a new population in a new area. 5)\nChanges in the population are the result of movements of organisms and\ntheir tendency to produce new variations, both of which are physical\nprocesses and not purely mathematical constructs (something that\nbecomes an issue in later debates). 6) The changes described are of\norganisms in a population.</p>\n<p>\nHagedoorn and Hagedoorn (1921) similarly point out that some traits of\norganisms are “trivial”, i.e., “cannot possibly be\naccounted for as useful”, such as “the shape and\narrangement of small hairs on the seeds of some cereals” (p.\n107). They likewise maintain that such traits, which can be stable\n(“pure”, i.e., fixed) within a species, cannot be the\nproduct of natural selection; instead, the Hagedoorns assert, they\nmust be “due to some process which accompanies selection”\n(p. 108). The Hagedoorns then proceed to describe several ways in\nwhich variability in a population can be reduced: a new population is\nfounded which lacks some of the variability of the original\npopulation; a population is split in half (with the variability in the\ndaughter populations differing from each other and from the original);\nand “random sampling” where even though the size of the\npopulation remains relatively constant from year to year, only a small\nfraction successfully reproduce. On this last point, they state,</p>\n<blockquote>\n<p>\nThe group of organisms chosen by fate to become the parents of the\nnext generation is usually, but always occasionally, considerably\nsmaller than the number of individuals of their species. (1921:\n120)</p>\n</blockquote>\n<p>\nThus, the Hagedoorns endorse points 1–5 above, while describing\ntwo additional processes besides #4 (the founding of a new\npopulation), namely the splitting of a population and the random\nsampling of parents. They further explain the relevance of #3 (small\npopulations): “the smaller the group, the more limited its\npotential variability, the sooner it will be pure altogether”\n(p. 123). And finally, they maintain that drift can produce fixation\n(“purity”), or the complete loss of variation within a\npopulation, even in the absence of selection. Fisher (1922b) reads the\nHagedoorns as claiming that “random survival is a more important\nfactor in limiting the variability of species than preferential\nsurvival” (p. 321), a claim that he challenged by attempting to\nshow that such a process would be too slow to overcome the rate of\nmutation (and thus the introduction of new variability—but he\nseems to say otherwise in 1922a).</p>\n<p>\nAn essay published by Wright in 1931 provides what is perhaps one of\nthe earliest <em>explicit</em> characterizations of drift:</p>\n<blockquote>\n<p>\nIt has seemed to me that another factor should be much more important\nin keeping the system of gene frequencies from settling into\nequilibrium. This is the effect of <em>random sampling</em> in a\nbreeding population of limited size. The gene frequencies of one\ngeneration may be expected to differ a little from those of the\npreceding <em>merely by chance</em>. In the course of generations this\nmay bring about important changes, although the farther the\n<em>drift</em> from the theoretical equilibrium, the greater will be\nthe pressure toward return. (Wright 1931b: 205; emphasis added)</p>\n</blockquote>\n<p>\nThe paper from which this quote is taken was meant to be a summary of\na longer paper, also published in 1931 (Wright 1986: 88). In the\nlonger paper (1931a), Wright specifies that the random sampling is of\n<em>gametes</em>. (Gametes are cells that fuse together during\nfertilization, such as an egg and a sperm). So, even though Wright\n(1931a) notes that the Hagedoorns had “urged the importance of\nsuch random fixation as a factor in evolution”, and states that\nFisher (1922b) had analyzed the issue, has he changed the subject to\nbe random sampling of <em>gametes</em> rather than of\n“parents” (i.e., organisms)? In short, no: Wright (1932\nand elsewhere) makes it clear that he considers drift to encompass\nboth random sampling of gametes and random sampling of organisms. In\nother words, he has <em>expanded</em> the phenomena that the concept\nof drift is meant to cover from that discussed by Gulick, the\nHagedoorns, and Fisher. But Wright’s 1932 paper also emphasized\nwhat would become a persistent confusion between drift and inbreeding;\nboth inbreeding and drift are more significant in small populations,\nso it can become easy to conflate them. But you can have random\nsampling of parents (say, through a population split) without\ninbreeding, and inbreeding without random sampling of parents. That\nalone shows that drift and inbreeding are not the same. So, not all of\nthe expansions of drift were productive ones.</p>\n<p>\nIt should be noted that while Wright and Fisher had numerous\nback-and-forth discussions and disagreements about each other’s\nclaims concerning the role of drift in evolution (Provine 1986,\nSkipper 2002), they did not seem to disagree about what drift\n<em>was</em>. Wright (1948) considered the following to be an\n“acceptable statement” of his view from Fisher and E.B.\nFord:</p>\n<blockquote>\n<p>\nGreat evolutionary importance has been attached by Sewall Wright\n(1931, 1932, 1935, 1940) to the fact that small shifts in the\ngene-ratios of all segregating factors will occur from generation to\ngeneration owing to the errors of random sampling in the process by\nwhich the gametes available in any one generation are chosen to\nconstitute the next. Such chance deviations will, of course, be\ngreater the smaller the isolated populations concerned. (Fisher and\nFord 1947)</p>\n</blockquote>\n<p>\nOn the other hand, Wright’s later incorporation of fluctuations\nin mutation rate, fluctuations in migration, and fluctuations in\nselection (see, e.g., Wright 1949) as types of drift was challenged by\nCain and Currey, who asserted that “the worker on actual\nexamples must classify processes according to their biological\nsignificance” and that such lumping together would produce\nconfusion and prevent proper analysis of actual situations (Cain &amp;\nCurrey 1963: 59). They thus urged the use of the term “sampling\ndrift”, which Wright adopted in the fourth volume of his 1978\nmagnum opus, <em>Evolution and the Genetics of Populations</em>.</p>\n<p>\nIn short, drift’s founders exhibit a diversity of views about\ndrift, which John Beatty helpfully describes as follows:</p>\n<blockquote>\n<p>\ndrift is a heterogeneous category of evolutionary causes and effects,\nwhose overall significance relative to other modes of evolution\n(especially evolution by natural selection) has been greatly disputed.\n(Beatty 1992: 273)</p>\n</blockquote>\n<p>\nPotential causes invoked in the discussion above include sampling of\ngametes, sampling of parents, founding of new populations, splitting\nof populations, each of which is intensified",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "1. Origins of the Concept of Genetic DriftAlthough Charles Darwin invoked “chance” in various ways\nin theOrigin of Species(Beatty 1984), he seems not to have\nincluded a concept of drift in his account. He does note in passing\nthat[v]ariations neither useful nor injurious would not be affected by\nnatural selection, and would be left either a fluctuating element, as\nperhaps we see in certain polymorphic species, or would ultimately\nbecome fixed, owing to the nature of the organism and the nature o",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "1. Origins of the Concept of Genetic DriftAlthough Charles Darwin invoked “chance” in various ways\nin theOrigin of Species(Beatty 1984), he seems not to have\nincluded a concept of drift in his account. He does note in passing\nthat[v]ariations neither useful nor injurious would not be affected by\nnatural selection, and would be left either a fluctuating element, as\nperhaps we see in certain polymorphic species, or would ultimately\nbecome fixed, owing to the nature of the organism and the nature o",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "1. Origins of the Concept of Genetic Drift",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.nature.com/articles/s41467-021-21587-5",
      "title": "DNA stability: a central design consideration for DNA data storage systems",
      "author": "Karishma  Matange, North Carolina State University, Raleigh, NC, USA, James M Tuck, North Carolina State University, Raleigh, NC, USA, jtuck@ncsu.edu, Albert J Keung, North Carolina State University, Raleigh, NC, USA, ajkeung@ncsu.edu",
      "published_date": "2021-03-01T00:00:00.000Z",
      "content": {
        "text": "Abstract Data storage in DNA is a rapidly evolving technology that could be a transformative solution for the rising energy, materials, and space needs of modern information storage. Given that the information medium is DNA itself, its stability under different storage and processing conditions will fundamentally impact and constrain design considerations and data system capabilities. Here we analyze the storage conditions, molecular mechanisms, and stabilization strategies influencing DNA stability and pose specific design configurations and scenarios for future systems that best leverage the considerable advantages of DNA storage.",
        "html": "Abstract Data storage in DNA is a rapidly evolving technology that could be a transformative solution for the rising energy, materials, and space needs of modern information storage. Given that the information medium is DNA itself, its stability under different storage and processing conditions will fundamentally impact and constrain design considerations and data system capabilities. Here we analyze the storage conditions, molecular mechanisms, and stabilization strategies influencing DNA stability and pose specific design configurations and scenarios for future systems that best leverage the considerable advantages of DNA storage.",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.indianhillschools.org/Downloads/Biology-I.pdf",
      "title": "Microsoft Word - Biology I.docx",
      "author": "StepheMC",
      "published_date": "2013-06-07T00:00:00.000Z",
      "content": {
        "text": "Page 1 of 11\nBiology I\nCore Ideas/Crosscutting Concepts:\nIntroduction to Biology, Characteristics of Life, the Scientific Method\nBiological knowledge applies directly to an individual's life, and is important in making personal\ndecisions.\nBiology is studied by using the scientific method.\nBiology is the study of life. In order to distinguish living from nonliving, a series of life determine\ncharacteristics must be confirmed.\nLaboratory investigations require attention to safety precautions\n1. How can living organisms be distinguished from nonliving matter?\n2. What are the major themes in Biology and how do they apply to everyday life?\n3. How can the scientific method be used to solve a problem?\n4. What procedures should be taken to assure safety in the lab? Where is safety equipment located?\nLearning Targets:\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nUse technology and mathematics to improve investigations and communications;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nRecognize and analyze explanations and models; and\nCommunicate and support a scientific argument.\nPage 2 of 11\nCore Ideas/Crosscutting Concepts:\nTAXONOMY\nClassification systems are frameworks created by scientists for describing the vast diversity of\norganisms, indicating the degree of relatedness between organisms.\nThis classification system is continually undergoing modification as it accommodates the enormous\ndiversity of living things.\nRecent molecular evidence sequence data generally support earlier hypotheses regarding lineages of\norganisms based upon morphological comparisons.\n1. What basic criteria should a classification system meet?\n2. Why is a classification system important?\nEcology\nThe great diversity of organisms and ecological niches they occupy result from more than 3.5 billion\nyears of evolution.\nLike many complex systems, ecosystems tend to have cyclic fluctuations around a state of rough\nequilibrium.\nEcosystems change as geological or biological conditions vary.\nEnergy flows from \"eaten\" to \"eater\" and this restricts the number, mass and energy at higher trophic\nlevels.\nFood webs are affected if any trophic level is severely altered, and producers, keystone species,\npredators and decomposers all have special effects on the web.\nPopulations are controlled by density dependent and density independent limiting factors.\nPopulation growth can take many forms, and overpopulation develops when carrying capacity is\nexceeded.\nNutrients cycle in predictable ways throughout the atmosphere, hydrosphere, earth and biota.\nLiving organisms fall into rhythms based on their biologic needs and the habitat in which they live.\nBiotic relationships such as predator/prey, symbiosis, and competition determine population size and\ngrowth.\nEcosystems change over time in successional patterns based on the severity of disruption and the\nhabitat's abiotic characteristics\nPage 3 of 11\nLearning Targets:\nBiology\nDiversity and Interdependence of Life\nClassification systems are frameworks created by scientists for describing the vast diversity of organisms\nindicating the degree of relatedness between organisms.\nEcosystems\nHomeostasis\nCarrying capacity\nEquilibrium and disequilibrium\nDiversity and Interdependence of Life\nClassification systems are frameworks created by scientists for describing the vast diversity of organisms\nindicating the degree of relatedness between organisms.\nCore Ideas/Crosscutting Concepts:\nBIOCHEMISTRY/ CELL STRUCTURE\nA living cell is composed of a number of smaller elements ‐ mainly carbon, hydrogen, nitrogen, oxygen,\nphosphorus, and sulfur.\nCarbon, because of its small size and four available bonding electrons, can join to other carbon atoms in\nchains and rings to form large and complex molecules.\nThe essential functions of cells involve chemical reactions that involve water and carbohydrates,\nproteins, lipids, and nucleic acids.\nAtomic structure and types of chemical bonds are described and related to physical properties.\nThe progress of chemical reactions can be diagrammed properly, and the role of enzymes and energy\ncan be assessed within chemical reactions.\nThe processes of condensation and hydrolysis, monomers and polymers are applied to the types of\norganic molecules.\nThe 4 major categories of biological molecules (lipid, carbohydrate, nucleic acid and protein) are\nidentified in terms of structure, function, nutritional value and dietary sources.\nMost cells function within a narrow range of temperature and pH. At low temperatures, reaction rates\nPage 4 of 11\nare slow. High temperatures and/or extremes of pH can irreversibly change the structure of most\nprotein molecules.\n1. What distinguishes the chemical molecules associated with life?\n2. How are the 4 organic molecule categories similar/different in structure and function?\n3. How do lipids, proteins, nucleic acids, and carbohydrates contribute to the total nutrition and\nstructure of organisms?\n4. How is the American diet balanced/unbalanced in major food categories?\n5. What constitutes the recommended nutrition pyramid?\nCELL STRUCTURE\nThe cell is the basic unit of structure and function of all living organisms.\nThis topic focuses on the cell as a system itself (single‐celled), and as part of a larger system\n(multicellular).\n1. How can the microscopic world be studied?\n2. How can microscopic evidence be used to solve a crime?\n3. How are plant and animal cells organized, and how do they carry out life activities?\n4. How is a cell membrane constructed, and how does it enable a cell to communicate with its\nenvironment?\n5. What distinguishes prokaryotic and eukaryotic cells? How did eukaryotic cells evolve?\n6. What is the cell theory and how was it developed?\nLearning Targets:\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nUse technology and mathematics to improve investigations and communications;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nPage 5 of 11\nRecognize and analyze explanations and models; and\nCommunicate and support a scientific argument.\nBiology\nCells\nCell structure and function\nStructure, function and interrelatedness of cell organelles\nEukaryotic cells and prokaryotic cells\nCellular processes\nCharacteristics of life regulated by cellular processes\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nRecognize and analyze explanations and models; and\nCore Ideas/Crosscutting Concepts:\nCELL TRANSPORT\nFluid transport model of cell membrane is related to activities such as diffusion, osmosis, active\ntransport and immunity.\nTransport needs can be analyzed based on daily cell activities.\nPredictions can be made for diffusion and osmosis events given concentration gradients.\nActive and passive transport methods can be differentiated.\nGiven solutions that are hypotonic, hypertonic or isotonic, predictions can be made for diffusion and\nosmosis.\nPage 6 of 11\nSodium potassium pump activities can be related to nerve and muscle functioning.\nBulk transport is related to Golgi, water vacuole and lysosomal functioning.\nOsmosis is related to turgor pressure in plants and food preservation.\n1. Why is cell size limited?\n2. How do cells control, through the structure of their cell membranes, what enters and exits through\ntheir membranes?\n3. Why do cells need to use energy to move some things in/out, and don't need to use energy to move\nother things in/out?\n4. How do concentration gradients affect osmosis and diffusion?\n5. How do plant and animal cells handle problems with osmolality differently?\n6. How do active transport methods relate to the development of membrane potentials, and why are\nmembrane potentials useful in nerve and muscle activity?\nLearning Targets:\nBiology\nCells\nCharacteristics of life regulated by cellular processes\nENERGY: PHOTOSYNTHESIS AND CELLULAR RESPIRATION\nEnergy flows through the living world.\nPlants capture energy from the sun and convert it to usable energy.\nAnimals obtain energy from plants when they eat the plants.\n1. How is the anatomy of a chloroplast related to photosynthesis?\n2. What is the role of various plant pigments in photosynthesis?\n3. How are oxygen and ATP involved in the breakdown of glucose?\n4. What are the products of fermentation and respiration?\nPage 7 of 11\nLearning Targets:\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nUse technology and mathematics to improve investigations and communications;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nRecognize and analyze explanations and models; and\nCommunicate and support a scientific argument.\nBiology\nCells\nCellular processes\nPhotosynthesis, chemosynthesis, cellular respiration\nDNA, Protein Synthesis & Cell Division\nDNA's structure comprised of a double helix with stron",
        "html": "Page 1 of 11\nBiology I\nCore Ideas/Crosscutting Concepts:\nIntroduction to Biology, Characteristics of Life, the Scientific Method\nBiological knowledge applies directly to an individual's life, and is important in making personal\ndecisions.\nBiology is studied by using the scientific method.\nBiology is the study of life. In order to distinguish living from nonliving, a series of life determine\ncharacteristics must be confirmed.\nLaboratory investigations require attention to safety precautions\n1. How can living organisms be distinguished from nonliving matter?\n2. What are the major themes in Biology and how do they apply to everyday life?\n3. How can the scientific method be used to solve a problem?\n4. What procedures should be taken to assure safety in the lab? Where is safety equipment located?\nLearning Targets:\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nUse technology and mathematics to improve investigations and communications;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nRecognize and analyze explanations and models; and\nCommunicate and support a scientific argument.\nPage 2 of 11\nCore Ideas/Crosscutting Concepts:\nTAXONOMY\nClassification systems are frameworks created by scientists for describing the vast diversity of\norganisms, indicating the degree of relatedness between organisms.\nThis classification system is continually undergoing modification as it accommodates the enormous\ndiversity of living things.\nRecent molecular evidence sequence data generally support earlier hypotheses regarding lineages of\norganisms based upon morphological comparisons.\n1. What basic criteria should a classification system meet?\n2. Why is a classification system important?\nEcology\nThe great diversity of organisms and ecological niches they occupy result from more than 3.5 billion\nyears of evolution.\nLike many complex systems, ecosystems tend to have cyclic fluctuations around a state of rough\nequilibrium.\nEcosystems change as geological or biological conditions vary.\nEnergy flows from \"eaten\" to \"eater\" and this restricts the number, mass and energy at higher trophic\nlevels.\nFood webs are affected if any trophic level is severely altered, and producers, keystone species,\npredators and decomposers all have special effects on the web.\nPopulations are controlled by density dependent and density independent limiting factors.\nPopulation growth can take many forms, and overpopulation develops when carrying capacity is\nexceeded.\nNutrients cycle in predictable ways throughout the atmosphere, hydrosphere, earth and biota.\nLiving organisms fall into rhythms based on their biologic needs and the habitat in which they live.\nBiotic relationships such as predator/prey, symbiosis, and competition determine population size and\ngrowth.\nEcosystems change over time in successional patterns based on the severity of disruption and the\nhabitat's abiotic characteristics\nPage 3 of 11\nLearning Targets:\nBiology\nDiversity and Interdependence of Life\nClassification systems are frameworks created by scientists for describing the vast diversity of organisms\nindicating the degree of relatedness between organisms.\nEcosystems\nHomeostasis\nCarrying capacity\nEquilibrium and disequilibrium\nDiversity and Interdependence of Life\nClassification systems are frameworks created by scientists for describing the vast diversity of organisms\nindicating the degree of relatedness between organisms.\nCore Ideas/Crosscutting Concepts:\nBIOCHEMISTRY/ CELL STRUCTURE\nA living cell is composed of a number of smaller elements ‐ mainly carbon, hydrogen, nitrogen, oxygen,\nphosphorus, and sulfur.\nCarbon, because of its small size and four available bonding electrons, can join to other carbon atoms in\nchains and rings to form large and complex molecules.\nThe essential functions of cells involve chemical reactions that involve water and carbohydrates,\nproteins, lipids, and nucleic acids.\nAtomic structure and types of chemical bonds are described and related to physical properties.\nThe progress of chemical reactions can be diagrammed properly, and the role of enzymes and energy\ncan be assessed within chemical reactions.\nThe processes of condensation and hydrolysis, monomers and polymers are applied to the types of\norganic molecules.\nThe 4 major categories of biological molecules (lipid, carbohydrate, nucleic acid and protein) are\nidentified in terms of structure, function, nutritional value and dietary sources.\nMost cells function within a narrow range of temperature and pH. At low temperatures, reaction rates\nPage 4 of 11\nare slow. High temperatures and/or extremes of pH can irreversibly change the structure of most\nprotein molecules.\n1. What distinguishes the chemical molecules associated with life?\n2. How are the 4 organic molecule categories similar/different in structure and function?\n3. How do lipids, proteins, nucleic acids, and carbohydrates contribute to the total nutrition and\nstructure of organisms?\n4. How is the American diet balanced/unbalanced in major food categories?\n5. What constitutes the recommended nutrition pyramid?\nCELL STRUCTURE\nThe cell is the basic unit of structure and function of all living organisms.\nThis topic focuses on the cell as a system itself (single‐celled), and as part of a larger system\n(multicellular).\n1. How can the microscopic world be studied?\n2. How can microscopic evidence be used to solve a crime?\n3. How are plant and animal cells organized, and how do they carry out life activities?\n4. How is a cell membrane constructed, and how does it enable a cell to communicate with its\nenvironment?\n5. What distinguishes prokaryotic and eukaryotic cells? How did eukaryotic cells evolve?\n6. What is the cell theory and how was it developed?\nLearning Targets:\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nUse technology and mathematics to improve investigations and communications;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nPage 5 of 11\nRecognize and analyze explanations and models; and\nCommunicate and support a scientific argument.\nBiology\nCells\nCell structure and function\nStructure, function and interrelatedness of cell organelles\nEukaryotic cells and prokaryotic cells\nCellular processes\nCharacteristics of life regulated by cellular processes\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nRecognize and analyze explanations and models; and\nCore Ideas/Crosscutting Concepts:\nCELL TRANSPORT\nFluid transport model of cell membrane is related to activities such as diffusion, osmosis, active\ntransport and immunity.\nTransport needs can be analyzed based on daily cell activities.\nPredictions can be made for diffusion and osmosis events given concentration gradients.\nActive and passive transport methods can be differentiated.\nGiven solutions that are hypotonic, hypertonic or isotonic, predictions can be made for diffusion and\nosmosis.\nPage 6 of 11\nSodium potassium pump activities can be related to nerve and muscle functioning.\nBulk transport is related to Golgi, water vacuole and lysosomal functioning.\nOsmosis is related to turgor pressure in plants and food preservation.\n1. Why is cell size limited?\n2. How do cells control, through the structure of their cell membranes, what enters and exits through\ntheir membranes?\n3. Why do cells need to use energy to move some things in/out, and don't need to use energy to move\nother things in/out?\n4. How do concentration gradients affect osmosis and diffusion?\n5. How do plant and animal cells handle problems with osmolality differently?\n6. How do active transport methods relate to the development of membrane potentials, and why are\nmembrane potentials useful in nerve and muscle activity?\nLearning Targets:\nBiology\nCells\nCharacteristics of life regulated by cellular processes\nENERGY: PHOTOSYNTHESIS AND CELLULAR RESPIRATION\nEnergy flows through the living world.\nPlants capture energy from the sun and convert it to usable energy.\nAnimals obtain energy from plants when they eat the plants.\n1. How is the anatomy of a chloroplast related to photosynthesis?\n2. What is the role of various plant pigments in photosynthesis?\n3. How are oxygen and ATP involved in the breakdown of glucose?\n4. What are the products of fermentation and respiration?\nPage 7 of 11\nLearning Targets:\nScience Inquiry and Application\nAll students must use the following scientific processes with appropriate laboratory safety techniques to\nconstruct their knowledge and understanding in all science content areas:\nIdentify questions and concepts that guide scientific investigations;\nDesign and conduct scientific investigations;\nUse technology and mathematics to improve investigations and communications;\nFormulate and revise explanations and models using logic and evidence (critical thinking);\nRecognize and analyze explanations and models; and\nCommunicate and support a scientific argument.\nBiology\nCells\nCellular processes\nPhotosynthesis, chemosynthesis, cellular respiration\nDNA, Protein Synthesis & Cell Division\nDNA's structure comprised of a double helix with stron",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC5575656/",
      "title": "Proteins Recognizing DNA: Structural Uniqueness and Versatility of DNA-Binding Domains in Stem Cell Transcription Factors",
      "author": "",
      "published_date": "2017-08-01T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Proteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on protein-DNA complexes and recognition mechanisms provides deeper insights into the nature of protein-DNA interactions and therefore, allows their manipulation. TFs utilize different mechanisms to recognize their cognate DNA (direct and indirect readouts). In this review, we focus on these recognition mechanisms as well as on the analysis of the DNA-binding domains of stem cell TFs, discussing the relative role of various amino acids toward facilitating such interactions. Unveiling such mechanisms will improve our understanding of the molecular pathways through which TFs are involved in repressing and activating gene expression.</p>\n<section><p><strong>Keywords:</strong> base and shape readouts, protein-DNA interaction, protein-DNA recognition, TF domain family</p></section></section><section><h2>1. Introduction</h2>\n<p>Most biological activities are governed by multiple protein-DNA interactions. The fundamental phenomenon underlying these interactions is the process by which proteins search and recognize their specific sites on the DNA, thereby enabling the transmission of genetic information to initiate various biological processes. Over the years, theoretical and experimental advances have allowed to improve our understanding of the mechanisms by which transcription factors (TFs) search for, and recognize these binding sites. In addition, researchers have explored how TFs interact with each other and with their binding partners. Although significant progress has been achieved toward understanding the TF search process, the details of this mechanism remain controversial [<a href=\"#B1-genes-08-00192\">1</a>,<a href=\"#B2-genes-08-00192\">2</a>].</p>\n<p>One of the most puzzling phenomena involved in protein search over DNA is the effect of multiple targets, which is particularly important in eukaryotic genomes. Eukaryotic genomes harbor multiple target sites between tightly bound nucleosome core particles on accessible DNA fragments [<a href=\"#B1-genes-08-00192\">1</a>]. Recent studies showed that single nucleotide changes can alter TF selectivity, and also influence the sequence of events culminating in the TF binding with its true recognition site. Additionally, other major hurdles faced by TFs regarding their selectivity include the existence of cellular networks, dynamic protein-DNA conformational changes, and tight packing of multiple TFs at the regulator sites of a single DNA section [<a href=\"#B3-genes-08-00192\">3</a>]. These factors affect the complexity of protein-DNA recognition processes at both sequence and structural levels, meaning nucleotide sequences and their resulting 3D structures. Furthermore, other factors such as TFs’ flexibility for their binding sites, the influence of cofactors, cooperative binding of other TFs, DNA methylation, and other epigenetic modifications add to the complexity of this process. The effect of nucleosomes and their binding with TFs, chromatin accessibility, and nucleosome occupancy will also have an impact on TF-DNA readouts [<a href=\"#B4-genes-08-00192\">4</a>]. Along with the nucleosomes, the distribution of sequence-specific TFs (cell-specific and tissue-specific, but also ubiquitous) also greatly affects TF binding. Recent studies show that realistic observations about the readout mechanism vary across the various protein families [<a href=\"#B4-genes-08-00192\">4</a>,<a href=\"#B5-genes-08-00192\">5</a>,<a href=\"#B6-genes-08-00192\">6</a>]. Most of these readout mechanisms are discussed in this review.</p>\n<p>Proteins use a wide range of DNA-binding structural motifs, such as homeodomain (HD), helix-turn-helix (HTH), and high-mobility group box (HMG) to recognize DNA. HTH is the most common binding motif and can be found in several repressor and activator proteins. Despite their structural diversity, these domains participate in a variety of functions that include acting as substrate interaction mediators, enzymes to operate DNA, and transcriptional regulators [<a href=\"#B7-genes-08-00192\">7</a>]. Several proteins also contain flexible segments outside the DNA-binding domain to facilitate specific and non-specific interactions. The phage Φ29 transcriptional regulator p4 uses its N-terminal beta-turn substructure for specific contact with DNA [<a href=\"#B8-genes-08-00192\">8</a>]. Likewise, HD proteins use N-terminal arms and a linker region to interact with DNA; for example, λ repressor uses its N-terminal arm to make contact with the major groove [<a href=\"#B9-genes-08-00192\">9</a>]. The Encyclopedia of DNA Elements (ENCODE) data suggest that about 99.8% of putative binding motifs of TFs are not bound by their respective TFs in the genome [<a href=\"#B10-genes-08-00192\">10</a>,<a href=\"#B11-genes-08-00192\">11</a>]. It is, therefore, clear that the presence of a single binding motif per TF is not adequate for TF binding.</p>\n<p>Over the past decades, developments in computational and structural biology have offered an immense potential toward studying the protein-DNA recognition code. Crystal structures of protein-DNA complexes were first solved in the 1980s [<a href=\"#B12-genes-08-00192\">12</a>], and more than 1600 protein–DNA structures have since been deposited in the Protein Data Bank (PDB) [<a href=\"#B4-genes-08-00192\">4</a>]. This plethora of information has helped us to conclude that preferential binding of a TF to its cognate site is purely based on its physical interactions, for instance, the physical interaction between the amino acid side chain of the TF and the atoms of DNA base pairs [<a href=\"#B13-genes-08-00192\">13</a>]. Most of these physical interactions rely on hydrogen bonds, as well as on hydrophobic and water-mediated contacts. Other mechanisms driving protein-DNA interaction involve the recognition of DNA structural features by proteins; these structural features include the DNA major and minor grooves, backbone features, intrinsic curvature, hydration shells, as well as flexibility of DNA bending [<a href=\"#B14-genes-08-00192\">14</a>] and unwinding [<a href=\"#B15-genes-08-00192\">15</a>]. The dynamic behavior of DNA structure mostly governs the binding properties, and that can be understood through computational techniques [<a href=\"#B4-genes-08-00192\">4</a>,<a href=\"#B16-genes-08-00192\">16</a>]. Theoretical studies, such as molecular dynamics (MD) simulations, can provide additional information toward understanding protein-DNA complexes. The monitored dynamic movements of atoms reflect the functional and structural phenomena undergone by proteins or DNA during the initial phase of complex formation.</p>\n<p>We have divided this review into two sections. The first section briefly discusses the DNA-recognition mechanisms, including historical mechanisms. The second section summarizes the major DNA-binding protein domains with reference to stem cell factors and their families. This section includes the structural properties of stem cell factor DNA-binding mechanisms and the cooperative binding phenomena driving target gene expression. Since stem cell factors are promising targets in the growing regenerative medicine field, researchers will benefit from the structural aspects of these factors provided in this review.</p></section><section><h2>2. Binding Site Recognition and TFs</h2>\n<p>Several mechanisms have been proposed to describe how TFs find their target sites on DNA. One of the main scenarios involves a ‘sliding’ mechanism, in which the protein moves from its initial non-specific site to its actual target site by sliding along the DNA (also known as 1-dimensional (1D) sliding) (<a href=\"#genes-08-00192-f001\">Figure 1</a>). The binding of the lactose (<em>lac</em>) repressor to non-operator sequences is an ideal example of sliding, since its DNA-binding entirely relies on electrostatic interactions, and consequently, diffusion occurs on an isopotential surface [<a href=\"#B17-genes-08-00192\">17</a>,<a href=\"#B18-genes-08-00192\">18</a>,<a href=\"#B19-genes-08-00192\">19</a>]. When the TF starts to move and shift counterions from the phosphate backbone, the same number of counterions binds to the site left free by the protein. The detailed sliding mechanism is explained later in this section. The sliding rate is also dependent on the hydrodynamic radius of the protein; the required rotational movement over the DNA backbone is greater for larger proteins, that tend to slide slowly [<a href=\"#B20-genes-08-00192\">20</a>,<a href=\"#B21-genes-08-00192\">21</a>]. Only a few DNA-binding proteins using the sliding mechanism from non-specific to specific binding have been structurally solved, among these, are BamHI [<a href=\"#B22-genes-08-00192\">22</a>], λ-repressor [<a href=\"#B23-genes-08-00192\">23</a>], and the lactose repressor [<a href=\"#B19-genes-08-00192\">19</a>,<a href=\"#B24-genes-08-00192\">24</a>].</p>\n<figure><h3>Figure 1.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5575656_genes-08-00192-g001.jpg\"></a></p>\n<figcaption><p>Protein-DNA recognition mechanisms. The main three protein-DNA recognition mechanisms are shown. When the transcription factor (pink ring) moves from one site to another by means of sliding along the DNA and is transferred from one base pair to another without dissociating from the DNA, this mechanism is called sliding (top). Hopping occurs when the transcriptio",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>Proteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on protein-DNA complexes and recognition mechanisms provides deeper insights into the nature of protein-DNA interactions and therefore, allows their manipulation. TFs utilize different mechanisms to recognize their cognate DNA (direct and indirect readouts). In this review, we focus on these recognition mechanisms as well as on the analysis of the DNA-binding domains of stem cell TFs, discussing the relative role of various amino acids toward facilitating such interactions. Unveiling such mechanisms will improve our understanding of the molecular pathways through which TFs are involved in repressing and activating gene expression.</p>\n<section><p><strong>Keywords:</strong> base and shape readouts, protein-DNA interaction, protein-DNA recognition, TF domain family</p></section></section><section><h2>1. Introduction</h2>\n<p>Most biological activities are governed by multiple protein-DNA interactions. The fundamental phenomenon underlying these interactions is the process by which proteins search and recognize their specific sites on the DNA, thereby enabling the transmission of genetic information to initiate various biological processes. Over the years, theoretical and experimental advances have allowed to improve our understanding of the mechanisms by which transcription factors (TFs) search for, and recognize these binding sites. In addition, researchers have explored how TFs interact with each other and with their binding partners. Although significant progress has been achieved toward understanding the TF search process, the details of this mechanism remain controversial [<a href=\"#B1-genes-08-00192\">1</a>,<a href=\"#B2-genes-08-00192\">2</a>].</p>\n<p>One of the most puzzling phenomena involved in protein search over DNA is the effect of multiple targets, which is particularly important in eukaryotic genomes. Eukaryotic genomes harbor multiple target sites between tightly bound nucleosome core particles on accessible DNA fragments [<a href=\"#B1-genes-08-00192\">1</a>]. Recent studies showed that single nucleotide changes can alter TF selectivity, and also influence the sequence of events culminating in the TF binding with its true recognition site. Additionally, other major hurdles faced by TFs regarding their selectivity include the existence of cellular networks, dynamic protein-DNA conformational changes, and tight packing of multiple TFs at the regulator sites of a single DNA section [<a href=\"#B3-genes-08-00192\">3</a>]. These factors affect the complexity of protein-DNA recognition processes at both sequence and structural levels, meaning nucleotide sequences and their resulting 3D structures. Furthermore, other factors such as TFs’ flexibility for their binding sites, the influence of cofactors, cooperative binding of other TFs, DNA methylation, and other epigenetic modifications add to the complexity of this process. The effect of nucleosomes and their binding with TFs, chromatin accessibility, and nucleosome occupancy will also have an impact on TF-DNA readouts [<a href=\"#B4-genes-08-00192\">4</a>]. Along with the nucleosomes, the distribution of sequence-specific TFs (cell-specific and tissue-specific, but also ubiquitous) also greatly affects TF binding. Recent studies show that realistic observations about the readout mechanism vary across the various protein families [<a href=\"#B4-genes-08-00192\">4</a>,<a href=\"#B5-genes-08-00192\">5</a>,<a href=\"#B6-genes-08-00192\">6</a>]. Most of these readout mechanisms are discussed in this review.</p>\n<p>Proteins use a wide range of DNA-binding structural motifs, such as homeodomain (HD), helix-turn-helix (HTH), and high-mobility group box (HMG) to recognize DNA. HTH is the most common binding motif and can be found in several repressor and activator proteins. Despite their structural diversity, these domains participate in a variety of functions that include acting as substrate interaction mediators, enzymes to operate DNA, and transcriptional regulators [<a href=\"#B7-genes-08-00192\">7</a>]. Several proteins also contain flexible segments outside the DNA-binding domain to facilitate specific and non-specific interactions. The phage Φ29 transcriptional regulator p4 uses its N-terminal beta-turn substructure for specific contact with DNA [<a href=\"#B8-genes-08-00192\">8</a>]. Likewise, HD proteins use N-terminal arms and a linker region to interact with DNA; for example, λ repressor uses its N-terminal arm to make contact with the major groove [<a href=\"#B9-genes-08-00192\">9</a>]. The Encyclopedia of DNA Elements (ENCODE) data suggest that about 99.8% of putative binding motifs of TFs are not bound by their respective TFs in the genome [<a href=\"#B10-genes-08-00192\">10</a>,<a href=\"#B11-genes-08-00192\">11</a>]. It is, therefore, clear that the presence of a single binding motif per TF is not adequate for TF binding.</p>\n<p>Over the past decades, developments in computational and structural biology have offered an immense potential toward studying the protein-DNA recognition code. Crystal structures of protein-DNA complexes were first solved in the 1980s [<a href=\"#B12-genes-08-00192\">12</a>], and more than 1600 protein–DNA structures have since been deposited in the Protein Data Bank (PDB) [<a href=\"#B4-genes-08-00192\">4</a>]. This plethora of information has helped us to conclude that preferential binding of a TF to its cognate site is purely based on its physical interactions, for instance, the physical interaction between the amino acid side chain of the TF and the atoms of DNA base pairs [<a href=\"#B13-genes-08-00192\">13</a>]. Most of these physical interactions rely on hydrogen bonds, as well as on hydrophobic and water-mediated contacts. Other mechanisms driving protein-DNA interaction involve the recognition of DNA structural features by proteins; these structural features include the DNA major and minor grooves, backbone features, intrinsic curvature, hydration shells, as well as flexibility of DNA bending [<a href=\"#B14-genes-08-00192\">14</a>] and unwinding [<a href=\"#B15-genes-08-00192\">15</a>]. The dynamic behavior of DNA structure mostly governs the binding properties, and that can be understood through computational techniques [<a href=\"#B4-genes-08-00192\">4</a>,<a href=\"#B16-genes-08-00192\">16</a>]. Theoretical studies, such as molecular dynamics (MD) simulations, can provide additional information toward understanding protein-DNA complexes. The monitored dynamic movements of atoms reflect the functional and structural phenomena undergone by proteins or DNA during the initial phase of complex formation.</p>\n<p>We have divided this review into two sections. The first section briefly discusses the DNA-recognition mechanisms, including historical mechanisms. The second section summarizes the major DNA-binding protein domains with reference to stem cell factors and their families. This section includes the structural properties of stem cell factor DNA-binding mechanisms and the cooperative binding phenomena driving target gene expression. Since stem cell factors are promising targets in the growing regenerative medicine field, researchers will benefit from the structural aspects of these factors provided in this review.</p></section><section><h2>2. Binding Site Recognition and TFs</h2>\n<p>Several mechanisms have been proposed to describe how TFs find their target sites on DNA. One of the main scenarios involves a ‘sliding’ mechanism, in which the protein moves from its initial non-specific site to its actual target site by sliding along the DNA (also known as 1-dimensional (1D) sliding) (<a href=\"#genes-08-00192-f001\">Figure 1</a>). The binding of the lactose (<em>lac</em>) repressor to non-operator sequences is an ideal example of sliding, since its DNA-binding entirely relies on electrostatic interactions, and consequently, diffusion occurs on an isopotential surface [<a href=\"#B17-genes-08-00192\">17</a>,<a href=\"#B18-genes-08-00192\">18</a>,<a href=\"#B19-genes-08-00192\">19</a>]. When the TF starts to move and shift counterions from the phosphate backbone, the same number of counterions binds to the site left free by the protein. The detailed sliding mechanism is explained later in this section. The sliding rate is also dependent on the hydrodynamic radius of the protein; the required rotational movement over the DNA backbone is greater for larger proteins, that tend to slide slowly [<a href=\"#B20-genes-08-00192\">20</a>,<a href=\"#B21-genes-08-00192\">21</a>]. Only a few DNA-binding proteins using the sliding mechanism from non-specific to specific binding have been structurally solved, among these, are BamHI [<a href=\"#B22-genes-08-00192\">22</a>], λ-repressor [<a href=\"#B23-genes-08-00192\">23</a>], and the lactose repressor [<a href=\"#B19-genes-08-00192\">19</a>,<a href=\"#B24-genes-08-00192\">24</a>].</p>\n<figure><h3>Figure 1.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5575656_genes-08-00192-g001.jpg\"></a></p>\n<figcaption><p>Protein-DNA recognition mechanisms. The main three protein-DNA recognition mechanisms are shown. When the transcription factor (pink ring) moves from one site to another by means of sliding along the DNA and is transferred from one base pair to another without dissociating from the DNA, this mechanism is called sliding (top). Hopping occurs when the transcriptio",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractProteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on p",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractProteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on p",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractProteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on p",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractProteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on p",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractProteins in the form of transcription factors (TFs) bind to specific DNA sites that regulate cell growth, differentiation, and cell development. The interactions between proteins and DNA are important toward maintaining and expressing genetic information. Without knowing TFs structures and DNA-binding properties, it is difficult to completely understand the mechanisms by which genetic information is transferred between DNA and proteins. The increasing availability of structural data on p",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:base and shape readouts, protein-DNA interaction, protein-DNA recognition, TF domain family",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. IntroductionMost biological activities are governed by multiple protein-DNA interactions. The fundamental phenomenon underlying these interactions is the process by which proteins search and recognize their specific sites on the DNA, thereby enabling the transmission of genetic information to initiate various biological processes. Over the years, theoretical and experimental advances have allowed to improve our understanding of the mechanisms by which transcription factors (TFs) search for, a",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "2. Binding Site Recognition and TFsSeveral mechanisms have been proposed to describe how TFs find their target sites on DNA. One of the main scenarios involves a ‘sliding’ mechanism, in which the protein moves from its initial non-specific site to its actual target site by sliding along the DNA (also known as 1-dimensional (1D) sliding) (Figure 1). The binding of the lactose (lac) repressor to non-operator sequences is an ideal example of sliding, since its DNA-binding entirely relies on electro",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "1. Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "2. Binding Site Recognition and TFs",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Figure 1.",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://metatheorie-der-veraenderung.info/wpmtags-en/structural-coupling/?lang=en",
      "title": "Structural Coupling | Metatheorie der Veränderung",
      "author": "",
      "published_date": "2020-01-01T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<p>Structural coupling is, system-theoretically, the substitute theory for causality. As no person can think in the head of another, it must be explained how people (=psychological systems) influence each other, or how they can even be in connection. The explanation of system theory is that the systems alternatively make their ‘complexity’ available to each other. This sounds rather mysterious. Simply put, what is meant is that no system can maintain itself without internally processing environmental events. In addition, to pick up the example one more time, no person could think if there were no language and he does not develop language by himself, rather, it is delivered in childhood (P. Fuchs). Therefore, people react to language, i.e. they are spoken to. However, no matter what the other party says, he cannot dictate what the receiver thinks as a response, nor does it ultimately determine what happens.</p>\n<p>At the same time, the psychological system is relieved of complexity because it cannot pick up upon that which is being said in the frequency area of ultrasound (unlike dolphins or whales). Through the limitation and the selection of coupling possibilities and coupling readiness, systems also become that which they make out of themselves: one always notices when he is criticised, the other never notices at all.</p>\n<p>When studying systems, one should always keep in mind the nature of the coupling to the environment. This is elementary for an understanding of change, because particularly through this the possibilities of coupling modifications can be examined.</p>\n</div></div>",
        "html": "<div><div>\n<p>Structural coupling is, system-theoretically, the substitute theory for causality. As no person can think in the head of another, it must be explained how people (=psychological systems) influence each other, or how they can even be in connection. The explanation of system theory is that the systems alternatively make their ‘complexity’ available to each other. This sounds rather mysterious. Simply put, what is meant is that no system can maintain itself without internally processing environmental events. In addition, to pick up the example one more time, no person could think if there were no language and he does not develop language by himself, rather, it is delivered in childhood (P. Fuchs). Therefore, people react to language, i.e. they are spoken to. However, no matter what the other party says, he cannot dictate what the receiver thinks as a response, nor does it ultimately determine what happens.</p>\n<p>At the same time, the psychological system is relieved of complexity because it cannot pick up upon that which is being said in the frequency area of ultrasound (unlike dolphins or whales). Through the limitation and the selection of coupling possibilities and coupling readiness, systems also become that which they make out of themselves: one always notices when he is criticised, the other never notices at all.</p>\n<p>When studying systems, one should always keep in mind the nature of the coupling to the environment. This is elementary for an understanding of change, because particularly through this the possibilities of coupling modifications can be examined.</p>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Structural coupling is, system-theoretically, the substitute theory for causality. As no person can think in the head of another, it must be explained how people (=psychological systems) influence each other, or how they can even be in connection. The explanation of system theory is that the systems alternatively make their ‘complexity’ available to each other. This sounds rather mysterious. Simply put, what is meant is that no system can maintain itself without internally processing environment",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Structural coupling is, system-theoretically, the substitute theory for causality. As no person can think in the head of another, it must be explained how people (=psychological systems) influence each other, or how they can even be in connection. The explanation of system theory is that the systems alternatively make their ‘complexity’ available to each other. This sounds rather mysterious. Simply put, what is meant is that no system can maintain itself without internally processing environment",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.nature.com/articles/s41598-021-04590-0",
      "title": "A review of some techniques for inclusion of domain-knowledge into deep neural networks",
      "author": "Dash; Tirtharaj; Chitlangia; Sharad; Ahuja; Aditya; Srinivasan; Ashwin",
      "published_date": "2022-01-20T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<div><h2>Abstract</h2><p>We present a survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently precise form. This paper examines the inclusion of domain-knowledge by means of changes to: the input, the loss-function, and the architecture of deep networks. The categorisation is for ease of exposition: in practice we expect a combination of such changes will be employed. In each category, we describe techniques that have been shown to yield significant changes in the performance of deep neural networks.</p></div>\n<section>\n<h3>Similar content being viewed by others</h3>\n</section>\n<div>\n<div><h2>Introduction</h2><div><p>Science is a cumulative enterprise, with generations of scientists discovering, refining, correcting and ultimately increasing our knowledge of how things are. The accelerating pace of development in software and hardware for machine learning–in particular, the area of deep neural networks (DNNs)–inevitably raises the prospect of Artificial Intelligence for Science<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR1\">1</a></sup>. That is, how can we best use AI methods to accelerate our understanding of the natural world? While ambitious plans exist for completely automated AI-based robot scientists<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR2\">2</a></sup>, the immediately useful prospect of using AI for Science remains semi-automated. An example of such a collaborative system is in Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig1\">1</a>. For such systems to work effectively, we need at least the following: (1) We have to be able to tell the machine what we know, in a suitably precise form; and (2) The machine has to be able to tell us what it has found, in a suitably understandable form. While the remarkable recent successes of deep neural networks on a wide variety of tasks makes a substantial case for their use in model construction, it is not immediately obvious how either (1) or (2) should be done with deep neural networks. In this paper, we examine ways of achieving (1), that is, the techniques for constructing deep neural networks from data and domain-knowledge concerning the problem. Understanding models constructed by deep neural networks is an area of intense research activity, and good summaries exist elsewhere<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR3\">3</a>,<a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR4\">4</a></sup>. To motivate the utility of providing domain-knowledge to a deep network, we reproduce two results from<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR5\">5</a></sup> in Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig2\">2</a>, which shows that predictive performance can increase significantly, even with a simplified encoding of domain-knowledge (see Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig2\">2</a>a).</p><div><figure><figcaption><b>Figure 1</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/1\"></a></div><p>An example of AI for Science. The human-in-the-loop is a biologist. The biologist conducts experiments in a biological system, obtains experimental observations. The biologist then extracts data that can be used to construct machine learning model(s). Additionally, the machine learning system has access to domain knowledge that can be obtained from the biologist. The machine learning system then conveys its explanations to the biologist.</p></div><p><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/1\"></a></p></figure></div><div><figure><figcaption><b>Figure 2</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/2\"></a></div><p>The plots from<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR6\">6</a></sup> showing gains in predictive accuracy of (<b>a</b>) multilayer perceptron (MLP), and (<b>b</b>) graph neural network (GNN) with the inclusion of domain-knowledge. The domain knowledge inclusion method in (<b>a</b>) is a simple technique known as ‘propositionalisation’ <sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR7\">7</a></sup>; and, the method in (<b>b</b>) is a general technique of incorporating domain-knowledge using bottom-graph construction. The results shown are over 70 datasets. No importance to be given to the line joining two points; this is done for visualisation purpose only.</p></div><p><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/2\"></a></p></figure></div><p>It is unsurprising that a recent report on AI for Science<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR1\">1</a></sup> identifies the incorporation of domain-knowledge as one of the 3 Grand Challenges in developing AI systems:</p><blockquote><p>“ML and AI are generally domain-agnostic...Off-the-shelf [ML and AI] practice treats [each of these] datasets in the same way and ignores domain knowledge that extends far beyond the raw data...Improving our ability to systematically incorporate diverse forms of domain knowledge can impact every aspect of AI.”</p></blockquote><p>But it is not just the construction of scientific-assistants that can benefit from this form of man-machine collaboration, and “human-in-the-loop” AI systems are likely to play an increasingly important role in engineering, medicine, healthcare, agriculture, environment and so on<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR8\">8</a></sup>. In this survey, we restrict the studies on incorporation of domain-knowledge into neural networks, with 1 or more hidden layers. If the domain-knowledge expressed in a symbolic form (for example, logical relations that are known to hold in the domain), then the broad area of hybrid neural-symbolic systems (see for example,<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR10\">10</a></sup>) is clearly relevant to the material in this paper. However, the motivation driving the development of hybrid systems is much broader than this paper, being concerned with general-purpose neural-based architectures for logical representation and inference. Here our goals are more modest: we are looking at the inclusion of problem-specific information into machine-learning models of a kind that will be described shortly. We refer the reader to<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR11\">11</a></sup> for reviews of work in the broader area of neural-symbolic modelling. More directly related to this paper is the work on “informed machine learning”, reviewed in<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR12\">12</a></sup>. We share with this work the interest in prior knowledge as an important source of information that can augment existing data. However, the goals of that paper are more ambitious than here. It aims to identify categories of prior knowledge, using as dimensions: the source of the knowledge, its representation, and its point of use in a machine-learning algorithm. In this survey, we are only concerned with some of these categories. Specifically, in terms of the categories in<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR12\">12</a></sup>, we are interested in implicit or explicit sources of domain-knowledge, represented either as logical or numeric constraints, and used at the model-construction stage by DNNs. Informal examples of what we mean by logical and numerical constraints are shown in Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig3\">3</a>. In general, we will assume logical constraints can, in principle, be represented as statements in propositional logic or predicate logic. Numerical constraints will be representable, in principle, as terms in an objective function being minimised (or maximised), or prior distributions on models. We believe this covers a wide range of potential applications, including those concerned with scientific discovery.</p><div><figure><figcaption><b>Figure 3</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/3\"></a></div><p>Informal descriptions of (<b>a</b>) logical; and (<b>b</b>) numerical constraints.</p></div><p><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/3\"></a></p></figure></div><h3>Focus of the paper</h3><p>We adhere to the following informal specification for constructing a deep neural network: given some data <i>D</i>, a structure and parameters of a deep network (denoted by and , respectively), a learner attempts to construct a neural network model <i>M</i> that minimises some loss function <i>L</i>. Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig4\">4</a> shows a diagrammatic representation. Note that: (a) we do not describe how the learner constructs a model <i>M</i> given the inputs. But, it would be normal for the learner to optimise the loss <i>L</i> by performing an iterative estimation of the parameters , given the model structure ; and (b) we are not concerned with how the constructed deep model <i>M</i> will be used. However, it suffices to say that when used, the model <i>M</i> would be given one or more data-instances encoded in the same way as was provided for model-construction.</p><div><figure><figcaption><b>Figure 4</b></figcaption><div><div><a hr",
        "html": "<div><div>\n<div><h2>Abstract</h2><p>We present a survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently precise form. This paper examines the inclusion of domain-knowledge by means of changes to: the input, the loss-function, and the architecture of deep networks. The categorisation is for ease of exposition: in practice we expect a combination of such changes will be employed. In each category, we describe techniques that have been shown to yield significant changes in the performance of deep neural networks.</p></div>\n<section>\n<h3>Similar content being viewed by others</h3>\n</section>\n<div>\n<div><h2>Introduction</h2><div><p>Science is a cumulative enterprise, with generations of scientists discovering, refining, correcting and ultimately increasing our knowledge of how things are. The accelerating pace of development in software and hardware for machine learning–in particular, the area of deep neural networks (DNNs)–inevitably raises the prospect of Artificial Intelligence for Science<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR1\">1</a></sup>. That is, how can we best use AI methods to accelerate our understanding of the natural world? While ambitious plans exist for completely automated AI-based robot scientists<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR2\">2</a></sup>, the immediately useful prospect of using AI for Science remains semi-automated. An example of such a collaborative system is in Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig1\">1</a>. For such systems to work effectively, we need at least the following: (1) We have to be able to tell the machine what we know, in a suitably precise form; and (2) The machine has to be able to tell us what it has found, in a suitably understandable form. While the remarkable recent successes of deep neural networks on a wide variety of tasks makes a substantial case for their use in model construction, it is not immediately obvious how either (1) or (2) should be done with deep neural networks. In this paper, we examine ways of achieving (1), that is, the techniques for constructing deep neural networks from data and domain-knowledge concerning the problem. Understanding models constructed by deep neural networks is an area of intense research activity, and good summaries exist elsewhere<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR3\">3</a>,<a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR4\">4</a></sup>. To motivate the utility of providing domain-knowledge to a deep network, we reproduce two results from<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR5\">5</a></sup> in Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig2\">2</a>, which shows that predictive performance can increase significantly, even with a simplified encoding of domain-knowledge (see Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig2\">2</a>a).</p><div><figure><figcaption><b>Figure 1</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/1\"></a></div><p>An example of AI for Science. The human-in-the-loop is a biologist. The biologist conducts experiments in a biological system, obtains experimental observations. The biologist then extracts data that can be used to construct machine learning model(s). Additionally, the machine learning system has access to domain knowledge that can be obtained from the biologist. The machine learning system then conveys its explanations to the biologist.</p></div><p><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/1\"></a></p></figure></div><div><figure><figcaption><b>Figure 2</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/2\"></a></div><p>The plots from<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR6\">6</a></sup> showing gains in predictive accuracy of (<b>a</b>) multilayer perceptron (MLP), and (<b>b</b>) graph neural network (GNN) with the inclusion of domain-knowledge. The domain knowledge inclusion method in (<b>a</b>) is a simple technique known as ‘propositionalisation’ <sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR7\">7</a></sup>; and, the method in (<b>b</b>) is a general technique of incorporating domain-knowledge using bottom-graph construction. The results shown are over 70 datasets. No importance to be given to the line joining two points; this is done for visualisation purpose only.</p></div><p><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/2\"></a></p></figure></div><p>It is unsurprising that a recent report on AI for Science<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR1\">1</a></sup> identifies the incorporation of domain-knowledge as one of the 3 Grand Challenges in developing AI systems:</p><blockquote><p>“ML and AI are generally domain-agnostic...Off-the-shelf [ML and AI] practice treats [each of these] datasets in the same way and ignores domain knowledge that extends far beyond the raw data...Improving our ability to systematically incorporate diverse forms of domain knowledge can impact every aspect of AI.”</p></blockquote><p>But it is not just the construction of scientific-assistants that can benefit from this form of man-machine collaboration, and “human-in-the-loop” AI systems are likely to play an increasingly important role in engineering, medicine, healthcare, agriculture, environment and so on<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR8\">8</a></sup>. In this survey, we restrict the studies on incorporation of domain-knowledge into neural networks, with 1 or more hidden layers. If the domain-knowledge expressed in a symbolic form (for example, logical relations that are known to hold in the domain), then the broad area of hybrid neural-symbolic systems (see for example,<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR10\">10</a></sup>) is clearly relevant to the material in this paper. However, the motivation driving the development of hybrid systems is much broader than this paper, being concerned with general-purpose neural-based architectures for logical representation and inference. Here our goals are more modest: we are looking at the inclusion of problem-specific information into machine-learning models of a kind that will be described shortly. We refer the reader to<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR11\">11</a></sup> for reviews of work in the broader area of neural-symbolic modelling. More directly related to this paper is the work on “informed machine learning”, reviewed in<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR12\">12</a></sup>. We share with this work the interest in prior knowledge as an important source of information that can augment existing data. However, the goals of that paper are more ambitious than here. It aims to identify categories of prior knowledge, using as dimensions: the source of the knowledge, its representation, and its point of use in a machine-learning algorithm. In this survey, we are only concerned with some of these categories. Specifically, in terms of the categories in<sup><a href=\"https://www.nature.com/articles/s41598-021-04590-0#ref-CR12\">12</a></sup>, we are interested in implicit or explicit sources of domain-knowledge, represented either as logical or numeric constraints, and used at the model-construction stage by DNNs. Informal examples of what we mean by logical and numerical constraints are shown in Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig3\">3</a>. In general, we will assume logical constraints can, in principle, be represented as statements in propositional logic or predicate logic. Numerical constraints will be representable, in principle, as terms in an objective function being minimised (or maximised), or prior distributions on models. We believe this covers a wide range of potential applications, including those concerned with scientific discovery.</p><div><figure><figcaption><b>Figure 3</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/3\"></a></div><p>Informal descriptions of (<b>a</b>) logical; and (<b>b</b>) numerical constraints.</p></div><p><a href=\"https://www.nature.com/articles/s41598-021-04590-0/figures/3\"></a></p></figure></div><h3>Focus of the paper</h3><p>We adhere to the following informal specification for constructing a deep neural network: given some data <i>D</i>, a structure and parameters of a deep network (denoted by and , respectively), a learner attempts to construct a neural network model <i>M</i> that minimises some loss function <i>L</i>. Fig. <a href=\"https://www.nature.com/articles/s41598-021-04590-0#Fig4\">4</a> shows a diagrammatic representation. Note that: (a) we do not describe how the learner constructs a model <i>M</i> given the inputs. But, it would be normal for the learner to optimise the loss <i>L</i> by performing an iterative estimation of the parameters , given the model structure ; and (b) we are not concerned with how the constructed deep model <i>M</i> will be used. However, it suffices to say that when used, the model <i>M</i> would be given one or more data-instances encoded in the same way as was provided for model-construction.</p><div><figure><figcaption><b>Figure 4</b></figcaption><div><div><a hr",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractWe present a survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently pr",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractWe present a survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently pr",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractWe present a survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently pr",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Similar content being viewed by others",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionScience is a cumulative enterprise, with generations of scientists discovering, refining, correcting and ultimately increasing our knowledge of how things are. The accelerating pace of development in software and hardware for machine learning–in particular, the area of deep neural networks (DNNs)–inevitably raises the prospect of Artificial Intelligence for Science1. That is, how can we best use AI methods to accelerate our understanding of the natural world? While ambitious plans ex",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionScience is a cumulative enterprise, with generations of scientists discovering, refining, correcting and ultimately increasing our knowledge of how things are. The accelerating pace of development in software and hardware for machine learning–in particular, the area of deep neural networks (DNNs)–inevitably raises the prospect of Artificial Intelligence for Science1. That is, how can we best use AI methods to accelerate our understanding of the natural world? While ambitious plans ex",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Science is a cumulative enterprise, with generations of scientists discovering, refining, correcting and ultimately increasing our knowledge of how things are. The accelerating pace of development in software and hardware for machine learning–in particular, the area of deep neural networks (DNNs)–inevitably raises the prospect of Artificial Intelligence for Science1. That is, how can we best use AI methods to accelerate our understanding of the natural world? While ambitious plans exist for comp",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 1An example of AI for Science. The human-in-the-loop is a biologist. The biologist conducts experiments in a biological system, obtains experimental observations. The biologist then extracts data that can be used to construct machine learning model(s). Additionally, the machine learning system has access to domain knowledge that can be obtained from the biologist. The machine learning system then conveys its explanations to the biologist.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "An example of AI for Science. The human-in-the-loop is a biologist. The biologist conducts experiments in a biological system, obtains experimental observations. The biologist then extracts data that can be used to construct machine learning model(s). Additionally, the machine learning system has access to domain knowledge that can be obtained from the biologist. The machine learning system then conveys its explanations to the biologist.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 2The plots from6showing gains in predictive accuracy of (a) multilayer perceptron (MLP), and (b) graph neural network (GNN) with the inclusion of domain-knowledge. The domain knowledge inclusion method in (a) is a simple technique known as ‘propositionalisation’7; and, the method in (b) is a general technique of incorporating domain-knowledge using bottom-graph construction. The results shown are over 70 datasets. No importance to be given to the line joining two points; this is done for ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The plots from6showing gains in predictive accuracy of (a) multilayer perceptron (MLP), and (b) graph neural network (GNN) with the inclusion of domain-knowledge. The domain knowledge inclusion method in (a) is a simple technique known as ‘propositionalisation’7; and, the method in (b) is a general technique of incorporating domain-knowledge using bottom-graph construction. The results shown are over 70 datasets. No importance to be given to the line joining two points; this is done for visualis",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 3Informal descriptions of (a) logical; and (b) numerical constraints.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Informal descriptions of (a) logical; and (b) numerical constraints.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 4<a hr",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "<a hr",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "<a hr",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Similar content being viewed by others",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Focus of the paper",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.businessperspectives.org/images/pdf/applications/publishing/templates/article/assets/5260/PPM_2013_02_Shahzad.pdf",
      "title": "Microsoft Word - PPM_issue_2_2013_online_",
      "author": "editor3",
      "published_date": null,
      "content": {
        "text": "“Role of organizational vision and adaptability in knowledge management”\nAUTHORS\nKhuram Shahzad\nShahid A. Zia\nM.M. Haris Aslam\nAly Raza Syed\nSami Ullah Bajwa\nARTICLE INFO\nKhuram Shahzad, Shahid A. Zia, M.M. Haris Aslam, Aly Raza Syed and Sami\nUllah Bajwa (2013). Role of organizational vision and adaptability in knowledge\nmanagement. Problems and Perspectives in Management, 11(2)\nRELEASED ON Monday, 01 July 2013\nJOURNAL \"Problems and Perspectives in Management\"\nFOUNDER LLC “Consulting Publishing Company “Business Perspectives”\nNUMBER OF REFERENCES\n0\nNUMBER OF FIGURES\n0\nNUMBER OF TABLES\n0\n© The author(s) 2024. This publication is an open access article.\nbusinessperspectives.org\nProblems and Perspectives in Management, Volume 11, Issue 2, 2013\n24\nKhuram Shahzad (Pakistan), Shahid A. Zia (Pakistan), M.M. Haris Aslam (Pakistan),\nAly Raza Syed (Pakistan), Sami Ullah Bajwa (Pakistan)\nRole of organizational vision and adaptability in knowledge\nmanagement\nAbstract\nThis paper focuses on the issues of effective prevalence of different knowledge management (KM) processes/practices\nin organizations. An effective knowledge management program largely depends on organizational members’\nwillingness and ability to participate in knowledge creation, knowledge sharing, knowledge acquisition, and knowledge\ncodification activities. This paper theoretically conceptualizes the role of organizational vision and adaptability in\ndeveloping employees’ willingness and ability to effectively participate in different knowledge management activities.\nA dearth of studies has, so far, exclusively investigated the joint impact of organizational vision and adaptability on\nfour key knowledge management processes/practices.\nPaper begins with a theoretical analysis of different aspects of knowledge management and issues related to the\neffective prevalence of different KM processes in organization. It then includes organization’s vision and adaptability\nto conceptualize their link with different knowledge management processes. Finally, based on the extensive review of\nthe literature related to knowledge management, organization’s vision, and adaptability, a conceptual understanding is\ndeveloped and proposed impact of organizational vision and adaptability on employees’ willingness and ability to\neffectively participate in different KM processes is presented. This paper may contribute to the existing body of\nknowledge by creating new insights for researchers as well as practitioners to help their organizations strengthening\ntheir knowledge management initiatives by building strong organizational vision and employees’ adaptive behaviors. It\nwill also be an opportunity for empiricist to empirically validate the proposed relationships between variables of\ninterest.\nKeywords: knowledge management, KM processes, KM effectiveness, organizational vision, adaptability.\nJEL Classification: M10.\nIntroduction45\nKnowledge management has gained a lot of attention\nof scholars as well as practitioners during the recent\npast years (Alavi & Leidner, 2001). The prevailing\nbusiness environment encompasses increased compe\u0002tition, complexity, uncertainty, and risk that have\nheightened the significance of knowledge and its\nmanagement in organizations (Paiva, Roth & Fens\u0002terseifer, 2002). Knowledge-based view of the firm\ndeclares knowledge as a most strategic resource and\nthe significant source of sustainable competitive\nadvantage for the firms (Kogut & Zander, 1992).\nEffective exploration and exploitation of knowledge\nhas been recognized as a key to competitive\norganizational performance (Nonaka & Takeuchi,\n1995). Organizations are initiating and implementing\ndifferent knowledge management (KM) practices to\nincrease their ability to take advantage of their\nknowledge to increase firm’s performance and\nsustainability (Nonaka, 1994). Knowledge manage\u0002ment literature usually identifies four to six interrelated\nand interdependent KM processes/practices such as\nknowledge creation, knowledge sharing, knowledge\nacquisition, and knowledge codification (Davenport &\nPrusak, 1998; Xu, Houssin, Caillaud & Gardoni, 2010)\nwhich enable organizations to develop knowledge\u0002based competitive advantage. Although these pro-\n Khuram Shahzad, Shahid A. Zia, M.M. Haris Aslam, Aly Raza Syed,\nSami Ullah Bajwa, 2013.\ncesses/practices seem varying in terms of their nature\nand content but they still share many commonalities in\nterms of their essence and outcomes (Andreeva &\nKianto, 2011).\nDespite the acknowledged contribution of know\u0002ledge management in bringing various positive\noutcomes for organizations, especially competitive\u0002ness and superior performance, the process of\nsuccessful initiation and implementation of know\u0002ledge management in organization is complex and\nbrings several challenges for organizations to deal\nwith. It is pertinent to understand that having\nknowledge management only symbolically present in\norganizations does not mean that organization will be\nautomatically taking advantage of its knowledge. In\nspite of having sophisticated technologies and\nsystems in place many organizations have not still\nbeen able to successfully exploit their knowledge\nresources (Kim & Yukl, 1995). Organizations are\nconfronting various challenges in effective planning\nand execution of knowledge management strategies\nand practices. There is an increased concern of\nresearchers as well as practitioners in identifying the\nfactors that can expedite or diminish the effectiveness\nof knowledge management processes.\nAccording to literature, knowledge management\nchallenges generally stem either from systems side,\nwhere appropriate information technology (IT)\nsystem, reward system, leadership, and sharing\nProblems and Perspectives in Management, Volume 11, Issue 2, 2013\n25\nopportunities are not present to facilitate creation,\nsharing, and exploitation of knowledge; or from the\npeople side where active participation of people in\ndifferent knowledge management activities is not\navailable. However, there is an increasing consensus\namong the researchers that major challenges being\nfaced by organizations in undertaking effective\nknowledge management are related to people where\nlack of understanding of knowledge management\npurposes and absence of motivation and ability to\nactively participate in different knowledge mana\u0002gement processes are major hurdles in effective\nmanagement of knowledge for organizations.\nThis scenario certainly yields some questions that\nhow to cope with these challenges. Regarding the\nmotivation/willingness of people question arises that\n“what can motivate/encou-rage people to willingly\nparticipate in different knowledge management\nactivities so that organization can attain superior\nperformance and competitive edge?” On the other\nhand, regarding the capability of people question\ncomes that “what can make people more capable to\neffectively participate in different knowledge\nmanagement activities to yield superior performance\nand competitive edge for organization?” This paper\nresponds to these questions by proposing that strong\n“organizational vision” (also called “vision salient”)\nand “employees adaptability” (or adaptive beha\u0002viors) can make people more motivated, willing,\nand able to actively and effectively participate in\ndifferent knowledge management activities.\nAlthough various studies have produced reasonable\nresearch in this area and have tried to explore the\nways organizations can make their knowledge\nmanagement initiatives more effective. However,\nthese research efforts are not sufficient in quantity\nand carry various limitations which create a\nrationale to undertake further studies on this topic to\nenhance our understanding. For example most of the\nstudies undertaken in this area have either\nemphasized on the role of extrinsic factors to\nincrease individuals’ participation in KM process, or\nhave seen different factors as enablers of KM\nprocesses. Despite the acknowledged role of\nvoluntary behaviors and intrinsic motivation in\nincreasing individuals’ participation in KM\nprocesses there is a dearth of studies that has\nidentified the factors which can increase internally\nmotivated behaviors to participation in organi\u0002zational KM processes. Similarly, most of the\nresearch undertaken in this regard has investigated\nthe knowledge creation and knowledge sharing\nprocesses to enhance the effectiveness of knowledge\nmanagement initiatives (e.g. see Cabrera & Cabrera,\n2005; Connelly & Kelloway, 2003; Gagne, 2009;\nRiege, 2005; Rosen, Furst & Blackburn, 2007).\nCreation and sharing of knowledge indeed are two\nvital pillars of knowledge management process;\nhowever it is pertinent to understand that emphasis\nonly on these two processes will not generate\ndesired results. The knowledge that an organization\nacquires, creates, and shares has to be translated into\ndocumentary and codified form; otherwise an\norganization may be in constant threat of losing the\nknowledge especially if knowledge holders leave. In\norder to attain competitive advantage through\ncreativity and innovation, an organization has to\nensure an easy access of members on a right kind of\nknowledge (Bhatt, 2001). Therefore, in order to\ncreate knowledge-based competitive advantage\norganizations have to simultaneously take care of all\nthe knowledge management activities. Very limited\nresearch is available on increasing the effectiveness\nof knowledge management through combination of\nits various initiatives. To cover this gap this study\nwill include all the salient activities/initiatives of\nknowledge management i.e. knowledge creation,\nknowledge sharing, knowledge acquisition, and\nknowledge documentation. On the other hand, very\nfew studies have so far investigated the role that\nstrong vision and adaptability can play in enhancing\nemployees’ willingness/motivation and ability to\neffectively participate in different knowledge\nmanagement initiatives. Although several resear\u0002chers have established the link between people’s\nbehaviors and actions tow",
        "html": "“Role of organizational vision and adaptability in knowledge management”\nAUTHORS\nKhuram Shahzad\nShahid A. Zia\nM.M. Haris Aslam\nAly Raza Syed\nSami Ullah Bajwa\nARTICLE INFO\nKhuram Shahzad, Shahid A. Zia, M.M. Haris Aslam, Aly Raza Syed and Sami\nUllah Bajwa (2013). Role of organizational vision and adaptability in knowledge\nmanagement. Problems and Perspectives in Management, 11(2)\nRELEASED ON Monday, 01 July 2013\nJOURNAL \"Problems and Perspectives in Management\"\nFOUNDER LLC “Consulting Publishing Company “Business Perspectives”\nNUMBER OF REFERENCES\n0\nNUMBER OF FIGURES\n0\nNUMBER OF TABLES\n0\n© The author(s) 2024. This publication is an open access article.\nbusinessperspectives.org\nProblems and Perspectives in Management, Volume 11, Issue 2, 2013\n24\nKhuram Shahzad (Pakistan), Shahid A. Zia (Pakistan), M.M. Haris Aslam (Pakistan),\nAly Raza Syed (Pakistan), Sami Ullah Bajwa (Pakistan)\nRole of organizational vision and adaptability in knowledge\nmanagement\nAbstract\nThis paper focuses on the issues of effective prevalence of different knowledge management (KM) processes/practices\nin organizations. An effective knowledge management program largely depends on organizational members’\nwillingness and ability to participate in knowledge creation, knowledge sharing, knowledge acquisition, and knowledge\ncodification activities. This paper theoretically conceptualizes the role of organizational vision and adaptability in\ndeveloping employees’ willingness and ability to effectively participate in different knowledge management activities.\nA dearth of studies has, so far, exclusively investigated the joint impact of organizational vision and adaptability on\nfour key knowledge management processes/practices.\nPaper begins with a theoretical analysis of different aspects of knowledge management and issues related to the\neffective prevalence of different KM processes in organization. It then includes organization’s vision and adaptability\nto conceptualize their link with different knowledge management processes. Finally, based on the extensive review of\nthe literature related to knowledge management, organization’s vision, and adaptability, a conceptual understanding is\ndeveloped and proposed impact of organizational vision and adaptability on employees’ willingness and ability to\neffectively participate in different KM processes is presented. This paper may contribute to the existing body of\nknowledge by creating new insights for researchers as well as practitioners to help their organizations strengthening\ntheir knowledge management initiatives by building strong organizational vision and employees’ adaptive behaviors. It\nwill also be an opportunity for empiricist to empirically validate the proposed relationships between variables of\ninterest.\nKeywords: knowledge management, KM processes, KM effectiveness, organizational vision, adaptability.\nJEL Classification: M10.\nIntroduction45\nKnowledge management has gained a lot of attention\nof scholars as well as practitioners during the recent\npast years (Alavi & Leidner, 2001). The prevailing\nbusiness environment encompasses increased compe\u0002tition, complexity, uncertainty, and risk that have\nheightened the significance of knowledge and its\nmanagement in organizations (Paiva, Roth & Fens\u0002terseifer, 2002). Knowledge-based view of the firm\ndeclares knowledge as a most strategic resource and\nthe significant source of sustainable competitive\nadvantage for the firms (Kogut & Zander, 1992).\nEffective exploration and exploitation of knowledge\nhas been recognized as a key to competitive\norganizational performance (Nonaka & Takeuchi,\n1995). Organizations are initiating and implementing\ndifferent knowledge management (KM) practices to\nincrease their ability to take advantage of their\nknowledge to increase firm’s performance and\nsustainability (Nonaka, 1994). Knowledge manage\u0002ment literature usually identifies four to six interrelated\nand interdependent KM processes/practices such as\nknowledge creation, knowledge sharing, knowledge\nacquisition, and knowledge codification (Davenport &\nPrusak, 1998; Xu, Houssin, Caillaud & Gardoni, 2010)\nwhich enable organizations to develop knowledge\u0002based competitive advantage. Although these pro-\n Khuram Shahzad, Shahid A. Zia, M.M. Haris Aslam, Aly Raza Syed,\nSami Ullah Bajwa, 2013.\ncesses/practices seem varying in terms of their nature\nand content but they still share many commonalities in\nterms of their essence and outcomes (Andreeva &\nKianto, 2011).\nDespite the acknowledged contribution of know\u0002ledge management in bringing various positive\noutcomes for organizations, especially competitive\u0002ness and superior performance, the process of\nsuccessful initiation and implementation of know\u0002ledge management in organization is complex and\nbrings several challenges for organizations to deal\nwith. It is pertinent to understand that having\nknowledge management only symbolically present in\norganizations does not mean that organization will be\nautomatically taking advantage of its knowledge. In\nspite of having sophisticated technologies and\nsystems in place many organizations have not still\nbeen able to successfully exploit their knowledge\nresources (Kim & Yukl, 1995). Organizations are\nconfronting various challenges in effective planning\nand execution of knowledge management strategies\nand practices. There is an increased concern of\nresearchers as well as practitioners in identifying the\nfactors that can expedite or diminish the effectiveness\nof knowledge management processes.\nAccording to literature, knowledge management\nchallenges generally stem either from systems side,\nwhere appropriate information technology (IT)\nsystem, reward system, leadership, and sharing\nProblems and Perspectives in Management, Volume 11, Issue 2, 2013\n25\nopportunities are not present to facilitate creation,\nsharing, and exploitation of knowledge; or from the\npeople side where active participation of people in\ndifferent knowledge management activities is not\navailable. However, there is an increasing consensus\namong the researchers that major challenges being\nfaced by organizations in undertaking effective\nknowledge management are related to people where\nlack of understanding of knowledge management\npurposes and absence of motivation and ability to\nactively participate in different knowledge mana\u0002gement processes are major hurdles in effective\nmanagement of knowledge for organizations.\nThis scenario certainly yields some questions that\nhow to cope with these challenges. Regarding the\nmotivation/willingness of people question arises that\n“what can motivate/encou-rage people to willingly\nparticipate in different knowledge management\nactivities so that organization can attain superior\nperformance and competitive edge?” On the other\nhand, regarding the capability of people question\ncomes that “what can make people more capable to\neffectively participate in different knowledge\nmanagement activities to yield superior performance\nand competitive edge for organization?” This paper\nresponds to these questions by proposing that strong\n“organizational vision” (also called “vision salient”)\nand “employees adaptability” (or adaptive beha\u0002viors) can make people more motivated, willing,\nand able to actively and effectively participate in\ndifferent knowledge management activities.\nAlthough various studies have produced reasonable\nresearch in this area and have tried to explore the\nways organizations can make their knowledge\nmanagement initiatives more effective. However,\nthese research efforts are not sufficient in quantity\nand carry various limitations which create a\nrationale to undertake further studies on this topic to\nenhance our understanding. For example most of the\nstudies undertaken in this area have either\nemphasized on the role of extrinsic factors to\nincrease individuals’ participation in KM process, or\nhave seen different factors as enablers of KM\nprocesses. Despite the acknowledged role of\nvoluntary behaviors and intrinsic motivation in\nincreasing individuals’ participation in KM\nprocesses there is a dearth of studies that has\nidentified the factors which can increase internally\nmotivated behaviors to participation in organi\u0002zational KM processes. Similarly, most of the\nresearch undertaken in this regard has investigated\nthe knowledge creation and knowledge sharing\nprocesses to enhance the effectiveness of knowledge\nmanagement initiatives (e.g. see Cabrera & Cabrera,\n2005; Connelly & Kelloway, 2003; Gagne, 2009;\nRiege, 2005; Rosen, Furst & Blackburn, 2007).\nCreation and sharing of knowledge indeed are two\nvital pillars of knowledge management process;\nhowever it is pertinent to understand that emphasis\nonly on these two processes will not generate\ndesired results. The knowledge that an organization\nacquires, creates, and shares has to be translated into\ndocumentary and codified form; otherwise an\norganization may be in constant threat of losing the\nknowledge especially if knowledge holders leave. In\norder to attain competitive advantage through\ncreativity and innovation, an organization has to\nensure an easy access of members on a right kind of\nknowledge (Bhatt, 2001). Therefore, in order to\ncreate knowledge-based competitive advantage\norganizations have to simultaneously take care of all\nthe knowledge management activities. Very limited\nresearch is available on increasing the effectiveness\nof knowledge management through combination of\nits various initiatives. To cover this gap this study\nwill include all the salient activities/initiatives of\nknowledge management i.e. knowledge creation,\nknowledge sharing, knowledge acquisition, and\nknowledge documentation. On the other hand, very\nfew studies have so far investigated the role that\nstrong vision and adaptability can play in enhancing\nemployees’ willingness/motivation and ability to\neffectively participate in different knowledge\nmanagement initiatives. Although several resear\u0002chers have established the link between people’s\nbehaviors and actions tow",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC6015514/",
      "title": "The Paradox of Intervening in Complex Adaptive Systems: Comment on \"Using Complexity and Network Concepts to Inform Healthcare Knowledge Translation\"",
      "author": "",
      "published_date": "2018-01-24T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>\nThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions may impact and indeed meet some of our objectives, system behaviour will always emerge with unpredictable consequences. Likewise, outcomes at the aggregated level of the system never reaches an optimal point as defined by the ‘external controller.’ Kitson and colleagues’ theoretical model may struggle to resolve the paradox of gaining control over the multiple knowledge translation (KT) systems covered by the model, because theoretically these systems retain control under the principle of self-organisation. That is not to suggest that individual agents cannot influence system dynamics just that the desired outcome cannot be guaranteed. Indeed, for systems to change they will need strong incentives.\n</p>\n<section><p><strong>Keywords:</strong> Complex Adaptive Systems, Complexity Theory, Knowledge Translation</p></section></section><section><h2>Introduction</h2>\n<p>\nApplying Complexity Theory concepts is largely selective and individually interpreted. Many examples within healthcare<sup><a href=\"#R1\">1</a>-<a href=\"#R4\">4</a></sup> are emerging as authors seek to make sense of how we manipulate Complex Adaptive System behaviour. Typically, core components<sup><a href=\"#R5\">5</a></sup> that characterise the use of Complexity Theory are: Interaction, emergence, self-organisation, dynamic and nonlinear, feedback loops, sensitivity to initial conditions, etc. Kitson and colleagues have utilised some of these concepts in their model which prospectively designs knowledge translation (KT) initiatives and their subsequent evaluation. They shift the typical KT metaphors from pipeline and cycles to one of interactive and dynamic systems. KT is conceptualised as a “multidimensional, dynamic, complex integrated process.”<sup><a href=\"#R6\">6</a></sup> Complexity thinking continues to strive to gain a foothold in healthcare.<sup><a href=\"#R7\">7</a></sup> So, I welcome this theoretical development that continues the shift in thinking because much energy is often exerted into ineffective KT.<sup><a href=\"#R8\">8</a></sup> In this commentary I make two key points, first, we need to be more systematic when applying this theoretical lens, and second, we need to consider the paradox created between the theory and our intentions.\n</p></section><section><h2>Defining Complex Adaptive Systems</h2>\n<p>\nKitson and colleagues undertook an inductive approach to identify Complexity Theory concepts using selected key documents. Applying this conceptual shift in thinking they re-interpreted mechanistic metaphors, ‘bridging gaps’ and ‘pull- push’ to “synapses of interaction and connectivity.” Kitson and colleagues identify the core key KT Process steps and apply the “identified literature” of Complexity Theory to knit together their model. Following consultation workshops, they affirm and iterate their model. They tested the model retrospectively on two case study examples. This led to “further interrogation of the complexity and networking literature.” Although references are available this interrogation is not reported. As the Complex Adaptive Systems and Complexity Theory literature increases more systematic approaches are needed to justify theory building,<sup><a href=\"#R9\">9</a></sup> the use and common understanding of key terms<sup><a href=\"#R10\">10</a></sup> and the intersection with philosophy and other theories to understand system behaviour.<sup><a href=\"#R11\">11</a></sup>\n</p>\n<p>\nThe literature on Complexity Theory is extensive<sup><a href=\"#R5\">5</a></sup> and increasingly applied to health and social systems. Different philosophical standpoints are taken such as complex realism<sup><a href=\"#R12\">12</a></sup> and logical positivism,<sup><a href=\"#R13\">13</a></sup> and connectionism.<sup><a href=\"#R14\">14</a></sup> Careful application of self-organisation, emergence and complex adaptive systems notions need to take account of whether they address complex physical processes (weather or climate), biological systems (evolution) or social systems (human created structures). The theory is itself multi layered based on the type of, or system level observed with blurring between concepts used.<sup><a href=\"#R4\">4</a></sup> Kitson and colleagues briefly define their terms, however, their application in the paper is at times inconsistent. We need to take care with the terminology and how we apply it to our setting or context of interest. The following definition, for example, blends physical and social systems.\n</p>\n<p>\n“A Complex Adaptive System is a collection of diverse parts interconnected such that the organisation (or organism) grows over time without centralised control….CAS is generated by the adaptive interactions of its components (nodes, hubs, clusters).”<sup><a href=\"#R6\">6</a></sup>\n</p></section><section><h2>The Paradox of Controlling Self-organising Systems</h2>\n<p>\nOur models are abstractions of the real world and will only ever provide a partial representation. The purpose of the KT model is to distribute knowledge advocating a connectionist approach, however, Complex Adaptive System’s develop in such a way that system information is distributed throughout the system.<sup><a href=\"#R14\">14</a></sup> That is each agent will only ever have a partial view of the whole system functioning. This creates a paradox between agents distributing knowledge between the connections of hubs and nodes by not having an overall view of that knowledge system and its multiple evolutions. Mechanisms such as audit can provide feedback on system behaviour at specific times. Likewise, greater connection between agents and their involvement potentially promotes distribution and take up of knowledge, however, in Complex Adaptive Systems, feedback between agents can either amplify or dampen the flow or connection of knowledge throughout the system. For human agents, this is typically their attitudes and beliefs. Increasing connections, as suggested, may be limited by the systems imperatives. For health systems, this is usually the busyness and pressure to meet priorities that will restrain adoption of new activity. System imperatives did not particularly feature in the paper. I would suggest this is an important driver in healthcare.<sup><a href=\"#R5\">5</a></sup> The success of the London Atlas of Dental Development and Eruption could also be due to the strong imperative to resolve, in this instance, an urgent and tragic problem involving a major incident. Thus, this was possibly a strong imperative to gain involvement. Much knowledge dissemination does not necessarily have such a strong imperative, and other system imperatives may override.<sup><a href=\"#R5\">5</a></sup>\n</p></section><section><h2>Simple Rules and Incentives</h2>\n<p>\nKitson and colleagues propose the KT Complexity Network will “generate the guiding principles or ‘simple rules’ required for the CAS to operate.”<sup><a href=\"#R6\">6</a></sup>\n</p>\n<p>\nThey suggest we can change the system rules once we have the model in place. First, the notion of ‘simple rules’ evolving into Complex Adaptive Systems needs greater explanation. John Holland captures the nature of Complex Adaptive Systems and the ‘simple rules’ that evolve into complex higher level aggregated system behaviour using examples as diverse as the immune system and the economy.<sup><a href=\"#R15\">15</a></sup> He defines the three key characteristics of such systems in an early paper as evolution, aggregate behaviour and anticipation. To adapt and learn you need to anticipate, thus creating the rules to maintain the system. He suggests models of Complex Adaptive Systems are hard to create. However, he suggests we need to look at the distributed, rule based structure of these systems, as Kitson and colleagues seek to do with their model.\n</p>\n<p>\nHolland describes these systems as undergoing continual change revising their rules and the system parts are each needing to adapt as they feed up to the aggregated structure that in turn feeds down. “As a result, the aggregate behavior of the system is usually far from optimal, if indeed optimality can even be defined for the system as a whole. For this reason, standard theories in physics, economics, and elsewhere, are of little help because they concentrate on optimal end-points, whereas complex adaptive systems ‘never get there.’ They continue to evolve, and they steadily exhibit new forms of emergent behavior”<sup><a href=\"#R15\">15</a></sup> (p 20).\n</p>\n<p>\nThe perpetual motion of these systems overtime presents challenges to identification of the rules that create aggregated structures, which overlays the nodes and hubs in the network. Similarly, to create change or influence the aggregated structure requires finding ways to incentivize components (human agents) within the system allowing for the new emergent behaviour.<sup><a href=\"#R5\">5</a></sup> Strategies are suggested to incentivize KT Networks with academic rewards. Complexity of human behaviour is an added dimension when applying the Complexity Theory lens. Others have sought to explain the emergence of social behaviour and structures.<sup><a href=\"#R12\">12</a>-<a href=\"#R14\">14</a>,<a href=\"#R16\">16</a></sup> Conversation as an organising system with in human structures is one model advocated.<sup><a href=\"#R16\">16</a></sup>\n</p>\n<p>\nKitson and colleagues suggest that application of the KT Complexity Network requires ‘painstaking work,’ which will comp",
        "html": "<div><div>\n<main>\n<article><section></section><section><section><h2>Abstract</h2>\n<p>\nThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions may impact and indeed meet some of our objectives, system behaviour will always emerge with unpredictable consequences. Likewise, outcomes at the aggregated level of the system never reaches an optimal point as defined by the ‘external controller.’ Kitson and colleagues’ theoretical model may struggle to resolve the paradox of gaining control over the multiple knowledge translation (KT) systems covered by the model, because theoretically these systems retain control under the principle of self-organisation. That is not to suggest that individual agents cannot influence system dynamics just that the desired outcome cannot be guaranteed. Indeed, for systems to change they will need strong incentives.\n</p>\n<section><p><strong>Keywords:</strong> Complex Adaptive Systems, Complexity Theory, Knowledge Translation</p></section></section><section><h2>Introduction</h2>\n<p>\nApplying Complexity Theory concepts is largely selective and individually interpreted. Many examples within healthcare<sup><a href=\"#R1\">1</a>-<a href=\"#R4\">4</a></sup> are emerging as authors seek to make sense of how we manipulate Complex Adaptive System behaviour. Typically, core components<sup><a href=\"#R5\">5</a></sup> that characterise the use of Complexity Theory are: Interaction, emergence, self-organisation, dynamic and nonlinear, feedback loops, sensitivity to initial conditions, etc. Kitson and colleagues have utilised some of these concepts in their model which prospectively designs knowledge translation (KT) initiatives and their subsequent evaluation. They shift the typical KT metaphors from pipeline and cycles to one of interactive and dynamic systems. KT is conceptualised as a “multidimensional, dynamic, complex integrated process.”<sup><a href=\"#R6\">6</a></sup> Complexity thinking continues to strive to gain a foothold in healthcare.<sup><a href=\"#R7\">7</a></sup> So, I welcome this theoretical development that continues the shift in thinking because much energy is often exerted into ineffective KT.<sup><a href=\"#R8\">8</a></sup> In this commentary I make two key points, first, we need to be more systematic when applying this theoretical lens, and second, we need to consider the paradox created between the theory and our intentions.\n</p></section><section><h2>Defining Complex Adaptive Systems</h2>\n<p>\nKitson and colleagues undertook an inductive approach to identify Complexity Theory concepts using selected key documents. Applying this conceptual shift in thinking they re-interpreted mechanistic metaphors, ‘bridging gaps’ and ‘pull- push’ to “synapses of interaction and connectivity.” Kitson and colleagues identify the core key KT Process steps and apply the “identified literature” of Complexity Theory to knit together their model. Following consultation workshops, they affirm and iterate their model. They tested the model retrospectively on two case study examples. This led to “further interrogation of the complexity and networking literature.” Although references are available this interrogation is not reported. As the Complex Adaptive Systems and Complexity Theory literature increases more systematic approaches are needed to justify theory building,<sup><a href=\"#R9\">9</a></sup> the use and common understanding of key terms<sup><a href=\"#R10\">10</a></sup> and the intersection with philosophy and other theories to understand system behaviour.<sup><a href=\"#R11\">11</a></sup>\n</p>\n<p>\nThe literature on Complexity Theory is extensive<sup><a href=\"#R5\">5</a></sup> and increasingly applied to health and social systems. Different philosophical standpoints are taken such as complex realism<sup><a href=\"#R12\">12</a></sup> and logical positivism,<sup><a href=\"#R13\">13</a></sup> and connectionism.<sup><a href=\"#R14\">14</a></sup> Careful application of self-organisation, emergence and complex adaptive systems notions need to take account of whether they address complex physical processes (weather or climate), biological systems (evolution) or social systems (human created structures). The theory is itself multi layered based on the type of, or system level observed with blurring between concepts used.<sup><a href=\"#R4\">4</a></sup> Kitson and colleagues briefly define their terms, however, their application in the paper is at times inconsistent. We need to take care with the terminology and how we apply it to our setting or context of interest. The following definition, for example, blends physical and social systems.\n</p>\n<p>\n“A Complex Adaptive System is a collection of diverse parts interconnected such that the organisation (or organism) grows over time without centralised control….CAS is generated by the adaptive interactions of its components (nodes, hubs, clusters).”<sup><a href=\"#R6\">6</a></sup>\n</p></section><section><h2>The Paradox of Controlling Self-organising Systems</h2>\n<p>\nOur models are abstractions of the real world and will only ever provide a partial representation. The purpose of the KT model is to distribute knowledge advocating a connectionist approach, however, Complex Adaptive System’s develop in such a way that system information is distributed throughout the system.<sup><a href=\"#R14\">14</a></sup> That is each agent will only ever have a partial view of the whole system functioning. This creates a paradox between agents distributing knowledge between the connections of hubs and nodes by not having an overall view of that knowledge system and its multiple evolutions. Mechanisms such as audit can provide feedback on system behaviour at specific times. Likewise, greater connection between agents and their involvement potentially promotes distribution and take up of knowledge, however, in Complex Adaptive Systems, feedback between agents can either amplify or dampen the flow or connection of knowledge throughout the system. For human agents, this is typically their attitudes and beliefs. Increasing connections, as suggested, may be limited by the systems imperatives. For health systems, this is usually the busyness and pressure to meet priorities that will restrain adoption of new activity. System imperatives did not particularly feature in the paper. I would suggest this is an important driver in healthcare.<sup><a href=\"#R5\">5</a></sup> The success of the London Atlas of Dental Development and Eruption could also be due to the strong imperative to resolve, in this instance, an urgent and tragic problem involving a major incident. Thus, this was possibly a strong imperative to gain involvement. Much knowledge dissemination does not necessarily have such a strong imperative, and other system imperatives may override.<sup><a href=\"#R5\">5</a></sup>\n</p></section><section><h2>Simple Rules and Incentives</h2>\n<p>\nKitson and colleagues propose the KT Complexity Network will “generate the guiding principles or ‘simple rules’ required for the CAS to operate.”<sup><a href=\"#R6\">6</a></sup>\n</p>\n<p>\nThey suggest we can change the system rules once we have the model in place. First, the notion of ‘simple rules’ evolving into Complex Adaptive Systems needs greater explanation. John Holland captures the nature of Complex Adaptive Systems and the ‘simple rules’ that evolve into complex higher level aggregated system behaviour using examples as diverse as the immune system and the economy.<sup><a href=\"#R15\">15</a></sup> He defines the three key characteristics of such systems in an early paper as evolution, aggregate behaviour and anticipation. To adapt and learn you need to anticipate, thus creating the rules to maintain the system. He suggests models of Complex Adaptive Systems are hard to create. However, he suggests we need to look at the distributed, rule based structure of these systems, as Kitson and colleagues seek to do with their model.\n</p>\n<p>\nHolland describes these systems as undergoing continual change revising their rules and the system parts are each needing to adapt as they feed up to the aggregated structure that in turn feeds down. “As a result, the aggregate behavior of the system is usually far from optimal, if indeed optimality can even be defined for the system as a whole. For this reason, standard theories in physics, economics, and elsewhere, are of little help because they concentrate on optimal end-points, whereas complex adaptive systems ‘never get there.’ They continue to evolve, and they steadily exhibit new forms of emergent behavior”<sup><a href=\"#R15\">15</a></sup> (p 20).\n</p>\n<p>\nThe perpetual motion of these systems overtime presents challenges to identification of the rules that create aggregated structures, which overlays the nodes and hubs in the network. Similarly, to create change or influence the aggregated structure requires finding ways to incentivize components (human agents) within the system allowing for the new emergent behaviour.<sup><a href=\"#R5\">5</a></sup> Strategies are suggested to incentivize KT Networks with academic rewards. Complexity of human behaviour is an added dimension when applying the Complexity Theory lens. Others have sought to explain the emergence of social behaviour and structures.<sup><a href=\"#R12\">12</a>-<a href=\"#R14\">14</a>,<a href=\"#R16\">16</a></sup> Conversation as an organising system with in human structures is one model advocated.<sup><a href=\"#R16\">16</a></sup>\n</p>\n<p>\nKitson and colleagues suggest that application of the KT Complexity Network requires ‘painstaking work,’ which will comp",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "AbstractThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "AbstractThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "AbstractThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "AbstractThis commentary addresses two points raised by Kitson and colleagues’ article. First, increasing interest in applying the Complexity Theory lens in healthcare needs further systematic work to create some commonality between concepts used. Second, our need to adopt a better understanding of how these systems organise so we can change the systems overall behaviour, creates a paradox. We seek to manipulate systems that self-organise and follow their own internal rules. Although, our actions",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Keywords:Complex Adaptive Systems, Complexity Theory, Knowledge Translation",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "IntroductionApplying Complexity Theory concepts is largely selective and individually interpreted. Many examples within healthcare1-4are emerging as authors seek to make sense of how we manipulate Complex Adaptive System behaviour. Typically, core components5that characterise the use of Complexity Theory are: Interaction, emergence, self-organisation, dynamic and nonlinear, feedback loops, sensitivity to initial conditions, etc. Kitson and colleagues have utilised some of these concepts in their",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Defining Complex Adaptive SystemsKitson and colleagues undertook an inductive approach to identify Complexity Theory concepts using selected key documents. Applying this conceptual shift in thinking they re-interpreted mechanistic metaphors, ‘bridging gaps’ and ‘pull- push’ to “synapses of interaction and connectivity.” Kitson and colleagues identify the core key KT Process steps and apply the “identified literature” of Complexity Theory to knit together their model. Following consultation works",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "The Paradox of Controlling Self-organising SystemsOur models are abstractions of the real world and will only ever provide a partial representation. The purpose of the KT model is to distribute knowledge advocating a connectionist approach, however, Complex Adaptive System’s develop in such a way that system information is distributed throughout the system.14That is each agent will only ever have a partial view of the whole system functioning. This creates a paradox between agents distributing k",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Simple Rules and IncentivesKitson and colleagues propose the KT Complexity Network will “generate the guiding principles or ‘simple rules’ required for the CAS to operate.”6They suggest we can change the system rules once we have the model in place. First, the notion of ‘simple rules’ evolving into Complex Adaptive Systems needs greater explanation. John Holland captures the nature of Complex Adaptive Systems and the ‘simple rules’ that evolve into complex higher level aggregated system behaviou",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Defining Complex Adaptive Systems",
              "id": ""
            },
            {
              "level": "h2",
              "text": "The Paradox of Controlling Self-organising Systems",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Simple Rules and Incentives",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.scitepress.org/Papers/2021/104819/104819.pdf",
      "title": "",
      "author": "",
      "published_date": "2021-05-06T00:00:00.000Z",
      "content": {
        "text": "Structural Coupling for Microservices\nSebastiano Panichella1 a\n, Mohammad Imranur Rahman2 band Davide Taibi2 c\n1Zurich University of Applied Science (ZHAW), Zurich, Switzerland\n2CLoWEE, Cloud and Web Engineering Group, Tampere University, Tampere, 33720, Finland\nKeywords: Cloud-native, Microservice, Coupling.\nAbstract: Cloud-native Applications are “distributed, elastic and horizontal-scalable systems composed of (mi\u0002cro)services which isolates states in a minimum of stateful components”. Hence, an important property is\nto ensure a low coupling and a high cohesion among the (micro)services composing the cloud-native applica\u0002tion.. Loosely coupled and highly cohesive services allow development teams to work in parallel, reducing the\ncommunication overhead between teams. However, despite both practitioners and researchers agreement on\nthe importance of this general property, there are no validated metrics to effectively measure or test the actual\ncoupling level between services. In this work, we propose ways to compute and to visualize the coupling\nbetween microservices, this by extending and adapting the concepts behind the computation of the traditional\nstructural coupling. We validate these measures with a case study involving 17 open source projects and we\nprovide an automatic approach to measure them. The results of this study highlight how these metrics pro\u0002vide to practitioners a quantitative and visual views of services compositions, which can be useful to conceive\nadvanced systems to monitor the services evolution.\n1 INTRODUCTION\nDecomposing a monolithic system into independent\nservices, and especially into microservices (Lewis\nand Fowler, 2014), is a very critical and complex task\nin modern applications, especially because of the lack\nof tools to support the decomposition of monolithic\nsystems and the lack of clear and usable measures to\nevaluate the quality of the decomposed systems. In\u0002deed, the architecture decomposition in microservices\nis usually performed manually and evaluated based\non the human perception of software architects (Taibi\net al., 2017),(Taibi et al., 2021),(Soldani et al., 2018).\nA desirable property of microservices is that\nthey should be as decoupled and as cohesive as\npossible (Lewis and Fowler, 2014). Specifically,\nwhile a low coupling is important in monolithic sys\u0002tems (Yourdon and Constantine, 1979), it is even\nmore important in microservices, since loosely cou\u0002pled services (statically and dynamically) allow the\ndeveloper to make changes to their service without the\nneed of modifying other services (Lewis and Fowler,\n2014). Therefore, investigating ways to measure the\na https://orcid.org/0000-0003-4120-626X\nb https://orcid.org/0000-0003-1430-5705\nc https://orcid.org/0000-0002-3210-3990\nevolving coupling between services is of fundamen\u0002tal importance, not only to increase the independence\nbetween teams, but to reduce also the level of depend\u0002ability among software changes occurring in different\nsystem components. Indeed, as discussed in previous\nwork, a high coupling can have a negative impact on\nreliability of changes, increasing the overall mainte\u0002nance effort (since the change of one service requires\nto change also all the services coupled to the same\nservice). However, besides the relevance of having\na low coupling and high cohesion in microservices,\nthere are no validated metrics to effectively measure\nor test the actual coupling level between the system\nservices.\nIn this paper, we propose the structural coupling\nmetric. An objective metrics that can be measured\nautomatically, and that can help practitioners to un\u0002derstand how decoupled are their services, and even\u0002tually to reason on decoupling strategies.\nWe validate the structural coupling with a case\nstudy involving 17 open source projects, available\nfrom the ”Microservice Dataset” (Rahman et al.,\n2019). The results of this study highlight how these\nmetrics provide to practitioners quantitative and vi\u0002sual views of service compositions, which can be use\u0002ful to conceive advanced systems to monitor the evo\u0002lution of services.\n280\nPanichella, S., Rahman, M. and Taibi, D.\nStructural Coupling for Microservices.\nDOI: 10.5220/0010481902800287\nIn Proceedings of the 11th International Conference on Cloud Computing and Services Science (CLOSER 2021), pages 280-287\nISBN: 978-989-758-510-4\nCopyright\nc 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved\nPaper Structure. The remainder of this paper is\nstructured as follows. Section 2 describes the back\u0002ground and related works. Section 3 presents the pro\u0002posed coupling metrics. Section 4 reports on a case\nstudy where we validate the proposed metrics while\nSection 5 draws conclusions of this work.\n2 BACKGROUND AND RELATED\nWORKS\nIn this Section we first introduce the background and\nthe terms adopted in this work, and then we describe\nthe metrics we proposed to evaluate cloud-native (and\nmicroservices) based applications services composi\u0002tion.\n2.1 What Is a Microservice\nA microservice-based system is a decentralized sys\u0002tem that is composed of several independent small\nservices, that communicate through different light\u0002weight mechanisms. Commonly, microservices ap\u0002ply decentralized mechanisms such as choreogra\u0002phy instead of choosing central service orchestra\u0002tions. Microservice adopt domain-driven designs,\nthat allow each microservice the responsibility for\nonly one bounded context, providing only a lim\u0002ited amount of functionality serving specific business\ncapabilities (Lewis and Fowler, 2014), (Hasselbring\nand Steinacker, 2017) and enabling continuous deliv\u0002ery (Amaral et al., 2015).\nIn microservices, scalability, losing coupling\nand high cohesion, independence, maintainabil\u0002ity, deployment, health management and modular\u0002ity are other fundamental properties of microser\u0002vices (Lewis and Fowler, 2014). The development\nof microservices-based system require to consider\nseveral aspects of the system (Taibi et al., 2021).\nFrom the architectural point of view, developers must\ncarefully consider the patterns adopted (Neri et al.,\n2020)(Taibi et al., 2018)(Taibi et al., 2019)(Taibi\net al., 2020)(Taibi and Lenarduzzi, 2018). For\nthis purpose, different tools might be adopted both\nbefore (Azadi et al., 2019) and after the migra\u0002tion (Pigazzini et al., 2020). Performance and com\u0002plexity should be considered as well, since they are\nfundamental for efficient communication among mi\u0002croservices (Pahl and Jamshidi, 2016), (Amaral et al.,\n2015) and also fault handling and fault tolerance play\nimportant roles to take under control security issues\n(Pahl and Jamshidi, 2016), (Dragoni et al., 2017),\n(Martin and Panichella, 2019). Last, but not least,\nwe need to consider that systems must be also main\u0002tained once they are deployed and therefore, devel\u0002opers should avoid to accumulate waste and techni\u0002cal debt during the development (Lenarduzzi et al.,\n2020)(Lenarduzzi and Taibi, 2018)(Soares de Toledo\net al., 2019).\n2.2 Cloud-native and Microservices\nMetrics\nDifferent metrics have been proposed for monolithic\nsystems. However, several properties have been high\u0002lighted for service-based systems, and especially for\nmicroservices.\nBogner et al. (Bogner et al., 2017b) pro\u0002posed a maintainability model for service-oriented\nsystems and microservices. Engel et al. (Engel et al.,\n2018) proposed a set of six measures to evaluate a\nmicroservice-based system. Taibi and Systa (Taibi ¨\nand Systa, 2019) proposed a decomposition frame- ¨\nwork based on process mining together with a set\nof metrics to evaluate the quality of the decomposi\u0002tion, identifying two size-related measures and a cou\u0002pling measure. However, all the proposed metrics are\nmainly based on the manual measurement of a set of\nproperties and they are not empirically validated. In\ntheir secondary study, Bogner et al. (Bogner et al.,\n2017a) highlighted that the majority of metrics ex\u0002plicitly designed for monolithic systems and for Ser\u0002vice Oriented Architecture (SOA) can be also suitable\nto (micro)services. However, they also highlight that\nthe different aspects of microservices can have a sig\u0002nificant impact on the complexity of automatic met\u0002ric collection, suggesting the need for specialized tool\nsupport.\nWe identified four groups of metrics in the litera\u0002ture (Table 1):\n• Service Size. We considered six measures pro\u0002posed by Engel et al. (Engel et al., 2018)and two\nproposed by Taibi and Systa (Taibi and Syst ¨ a,¨\n2019) with the goal of comparing two decompo\u0002sition options. Moreover, we also report two met\u0002rics originally defined for SOA, that can be ap\u0002plied in microservices (Bogner et al., 2017a).\n• Service Complexity. No microservice-specific\nmeasures have been proposed, but three metrics\noriginally proposed for SOA can be applied in mi\u0002croservices (Bogner et al., 2017a).\n• Service Cohesion. The degree to which the el\u0002ements of a certain class belong together. It is\na measure of how strongly related each piece of\nfunctionality of a software module is (Fenton,\n1991). High cohesion makes the reasoning easy\nand limits the dependencies (Kramer and Kaindl,\nStructural Coupling for Microservices\n281\nTable 1: The Metrics Proposed in the Literature.\nGroup Metric\n- Number of synchronous cycles (Engel et al., 2018)\n- Distribution of synchronous call per microservice (Engel et al., 2018)\n- Number of synchronous dependencies of each microservice (Engel et al., 2018)\nService Size - Average size of asynchronous messages (Engel et al., 2018)\n- Longest synchronous call trace (Engel et al., 2018)\n- Number of classes per microservice (Taibi and Systa, 2019) ¨\n- Number of classes that need to be duplicated (Taibi and Systa, 2019)(Taibi and Syst ¨ a, 2020) ¨\n- Weighted Service Interface Count (WSIC (Hirzalla et al., 2009))*: number of exposed inter\u0002face of a service be weighted on the number of parameters.\n- Component Balance (Bouwers et al., 2011)(Bogner et al., 2017b)*: number and size unifor\u0002mity of components (or services). Very bi",
        "html": "Structural Coupling for Microservices\nSebastiano Panichella1 a\n, Mohammad Imranur Rahman2 band Davide Taibi2 c\n1Zurich University of Applied Science (ZHAW), Zurich, Switzerland\n2CLoWEE, Cloud and Web Engineering Group, Tampere University, Tampere, 33720, Finland\nKeywords: Cloud-native, Microservice, Coupling.\nAbstract: Cloud-native Applications are “distributed, elastic and horizontal-scalable systems composed of (mi\u0002cro)services which isolates states in a minimum of stateful components”. Hence, an important property is\nto ensure a low coupling and a high cohesion among the (micro)services composing the cloud-native applica\u0002tion.. Loosely coupled and highly cohesive services allow development teams to work in parallel, reducing the\ncommunication overhead between teams. However, despite both practitioners and researchers agreement on\nthe importance of this general property, there are no validated metrics to effectively measure or test the actual\ncoupling level between services. In this work, we propose ways to compute and to visualize the coupling\nbetween microservices, this by extending and adapting the concepts behind the computation of the traditional\nstructural coupling. We validate these measures with a case study involving 17 open source projects and we\nprovide an automatic approach to measure them. The results of this study highlight how these metrics pro\u0002vide to practitioners a quantitative and visual views of services compositions, which can be useful to conceive\nadvanced systems to monitor the services evolution.\n1 INTRODUCTION\nDecomposing a monolithic system into independent\nservices, and especially into microservices (Lewis\nand Fowler, 2014), is a very critical and complex task\nin modern applications, especially because of the lack\nof tools to support the decomposition of monolithic\nsystems and the lack of clear and usable measures to\nevaluate the quality of the decomposed systems. In\u0002deed, the architecture decomposition in microservices\nis usually performed manually and evaluated based\non the human perception of software architects (Taibi\net al., 2017),(Taibi et al., 2021),(Soldani et al., 2018).\nA desirable property of microservices is that\nthey should be as decoupled and as cohesive as\npossible (Lewis and Fowler, 2014). Specifically,\nwhile a low coupling is important in monolithic sys\u0002tems (Yourdon and Constantine, 1979), it is even\nmore important in microservices, since loosely cou\u0002pled services (statically and dynamically) allow the\ndeveloper to make changes to their service without the\nneed of modifying other services (Lewis and Fowler,\n2014). Therefore, investigating ways to measure the\na https://orcid.org/0000-0003-4120-626X\nb https://orcid.org/0000-0003-1430-5705\nc https://orcid.org/0000-0002-3210-3990\nevolving coupling between services is of fundamen\u0002tal importance, not only to increase the independence\nbetween teams, but to reduce also the level of depend\u0002ability among software changes occurring in different\nsystem components. Indeed, as discussed in previous\nwork, a high coupling can have a negative impact on\nreliability of changes, increasing the overall mainte\u0002nance effort (since the change of one service requires\nto change also all the services coupled to the same\nservice). However, besides the relevance of having\na low coupling and high cohesion in microservices,\nthere are no validated metrics to effectively measure\nor test the actual coupling level between the system\nservices.\nIn this paper, we propose the structural coupling\nmetric. An objective metrics that can be measured\nautomatically, and that can help practitioners to un\u0002derstand how decoupled are their services, and even\u0002tually to reason on decoupling strategies.\nWe validate the structural coupling with a case\nstudy involving 17 open source projects, available\nfrom the ”Microservice Dataset” (Rahman et al.,\n2019). The results of this study highlight how these\nmetrics provide to practitioners quantitative and vi\u0002sual views of service compositions, which can be use\u0002ful to conceive advanced systems to monitor the evo\u0002lution of services.\n280\nPanichella, S., Rahman, M. and Taibi, D.\nStructural Coupling for Microservices.\nDOI: 10.5220/0010481902800287\nIn Proceedings of the 11th International Conference on Cloud Computing and Services Science (CLOSER 2021), pages 280-287\nISBN: 978-989-758-510-4\nCopyright\nc 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved\nPaper Structure. The remainder of this paper is\nstructured as follows. Section 2 describes the back\u0002ground and related works. Section 3 presents the pro\u0002posed coupling metrics. Section 4 reports on a case\nstudy where we validate the proposed metrics while\nSection 5 draws conclusions of this work.\n2 BACKGROUND AND RELATED\nWORKS\nIn this Section we first introduce the background and\nthe terms adopted in this work, and then we describe\nthe metrics we proposed to evaluate cloud-native (and\nmicroservices) based applications services composi\u0002tion.\n2.1 What Is a Microservice\nA microservice-based system is a decentralized sys\u0002tem that is composed of several independent small\nservices, that communicate through different light\u0002weight mechanisms. Commonly, microservices ap\u0002ply decentralized mechanisms such as choreogra\u0002phy instead of choosing central service orchestra\u0002tions. Microservice adopt domain-driven designs,\nthat allow each microservice the responsibility for\nonly one bounded context, providing only a lim\u0002ited amount of functionality serving specific business\ncapabilities (Lewis and Fowler, 2014), (Hasselbring\nand Steinacker, 2017) and enabling continuous deliv\u0002ery (Amaral et al., 2015).\nIn microservices, scalability, losing coupling\nand high cohesion, independence, maintainabil\u0002ity, deployment, health management and modular\u0002ity are other fundamental properties of microser\u0002vices (Lewis and Fowler, 2014). The development\nof microservices-based system require to consider\nseveral aspects of the system (Taibi et al., 2021).\nFrom the architectural point of view, developers must\ncarefully consider the patterns adopted (Neri et al.,\n2020)(Taibi et al., 2018)(Taibi et al., 2019)(Taibi\net al., 2020)(Taibi and Lenarduzzi, 2018). For\nthis purpose, different tools might be adopted both\nbefore (Azadi et al., 2019) and after the migra\u0002tion (Pigazzini et al., 2020). Performance and com\u0002plexity should be considered as well, since they are\nfundamental for efficient communication among mi\u0002croservices (Pahl and Jamshidi, 2016), (Amaral et al.,\n2015) and also fault handling and fault tolerance play\nimportant roles to take under control security issues\n(Pahl and Jamshidi, 2016), (Dragoni et al., 2017),\n(Martin and Panichella, 2019). Last, but not least,\nwe need to consider that systems must be also main\u0002tained once they are deployed and therefore, devel\u0002opers should avoid to accumulate waste and techni\u0002cal debt during the development (Lenarduzzi et al.,\n2020)(Lenarduzzi and Taibi, 2018)(Soares de Toledo\net al., 2019).\n2.2 Cloud-native and Microservices\nMetrics\nDifferent metrics have been proposed for monolithic\nsystems. However, several properties have been high\u0002lighted for service-based systems, and especially for\nmicroservices.\nBogner et al. (Bogner et al., 2017b) pro\u0002posed a maintainability model for service-oriented\nsystems and microservices. Engel et al. (Engel et al.,\n2018) proposed a set of six measures to evaluate a\nmicroservice-based system. Taibi and Systa (Taibi ¨\nand Systa, 2019) proposed a decomposition frame- ¨\nwork based on process mining together with a set\nof metrics to evaluate the quality of the decomposi\u0002tion, identifying two size-related measures and a cou\u0002pling measure. However, all the proposed metrics are\nmainly based on the manual measurement of a set of\nproperties and they are not empirically validated. In\ntheir secondary study, Bogner et al. (Bogner et al.,\n2017a) highlighted that the majority of metrics ex\u0002plicitly designed for monolithic systems and for Ser\u0002vice Oriented Architecture (SOA) can be also suitable\nto (micro)services. However, they also highlight that\nthe different aspects of microservices can have a sig\u0002nificant impact on the complexity of automatic met\u0002ric collection, suggesting the need for specialized tool\nsupport.\nWe identified four groups of metrics in the litera\u0002ture (Table 1):\n• Service Size. We considered six measures pro\u0002posed by Engel et al. (Engel et al., 2018)and two\nproposed by Taibi and Systa (Taibi and Syst ¨ a,¨\n2019) with the goal of comparing two decompo\u0002sition options. Moreover, we also report two met\u0002rics originally defined for SOA, that can be ap\u0002plied in microservices (Bogner et al., 2017a).\n• Service Complexity. No microservice-specific\nmeasures have been proposed, but three metrics\noriginally proposed for SOA can be applied in mi\u0002croservices (Bogner et al., 2017a).\n• Service Cohesion. The degree to which the el\u0002ements of a certain class belong together. It is\na measure of how strongly related each piece of\nfunctionality of a software module is (Fenton,\n1991). High cohesion makes the reasoning easy\nand limits the dependencies (Kramer and Kaindl,\nStructural Coupling for Microservices\n281\nTable 1: The Metrics Proposed in the Literature.\nGroup Metric\n- Number of synchronous cycles (Engel et al., 2018)\n- Distribution of synchronous call per microservice (Engel et al., 2018)\n- Number of synchronous dependencies of each microservice (Engel et al., 2018)\nService Size - Average size of asynchronous messages (Engel et al., 2018)\n- Longest synchronous call trace (Engel et al., 2018)\n- Number of classes per microservice (Taibi and Systa, 2019) ¨\n- Number of classes that need to be duplicated (Taibi and Systa, 2019)(Taibi and Syst ¨ a, 2020) ¨\n- Weighted Service Interface Count (WSIC (Hirzalla et al., 2009))*: number of exposed inter\u0002face of a service be weighted on the number of parameters.\n- Component Balance (Bouwers et al., 2011)(Bogner et al., 2017b)*: number and size unifor\u0002mity of components (or services). Very bi",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.mdpi.com/2079-8954/10/3/82",
      "title": "Knowledge Management as a Domain, System Dynamics as a Methodology",
      "author": "Vladimír Bureš",
      "published_date": "2022-06-14T00:00:00.000Z",
      "content": {
        "text": "<div><section>\n<header>\n<div>\n</div>\n</header>\n<div>\n<div>\n<p><a href=\"https://www.mdpi.com/journal/systems\">\n</a></p>\n<div>\n<p>\n</p><h2>Article Menu</h2>\n<p></p>\n</div>\n</div>\n<div>\n<div>\n<p>\nFont Type:\n</p>\n<p><span><i>Arial</i></span>\n<span><i>Georgia</i></span>\n<span><i>Verdana</i></span>\n</p>\n</div>\n<article><div>\n<p><span>Open Access</span><span>Systematic Review</span></p>\n<div><p>\nby\n<span></span></p><p>\nMarek Zanker</p><sup> *</sup><span></span><a href=\"https://www.mdpi.com/cdn-cgi/l/email-protection#406f232e246d2327296f2c6f252d21292c6d30322f34252334292f2e6370707023762471267078707674737177702370737076707871267224717870757076747370257177\"><sup><i></i></sup></a> and <span><p>\nVladimír Bureš</p><sup></sup><span></span><a href=\"https://www.mdpi.com/cdn-cgi/l/email-protection#a689c5c8c28bc5c1cf89ca89c3cbc7cfca8bd6d4c9d2c3c5d2cfc9c885969697c791909791979497c097c497c09692939e979296959692979596939590969597c397c2939e979396c5\"><sup><i></i></sup></a><a href=\"https://orcid.org/0000-0001-7788-7445\"></a></span> <p></p></div>\n<div>\n<div>\n<p>Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic</p>\n</div>\n<div>\n<p><sup>*</sup></p>\n<p>Author to whom correspondence should be addressed. </p>\n</div>\n</div>\n<p><span>Submission received: 20 April 2022</span>\n/\n<span>Revised: 6 June 2022</span>\n/\n<span>Accepted: 11 June 2022</span>\n/\n<span>Published: 14 June 2022</span>\n</p>\n<section>\n<h2>Abstract</h2><b>:</b>\n<p>For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of systems with varying degrees of complexity and knowledge demands. Knowledge management is strongly related to system dynamics on a thematic level. We did a thorough review to identify potential applications and analysed system dynamics and knowledge management domains. The systematic review followed the PRISMA method. We identified two major groups and one subgroup of the combination of system dynamics and knowledge management after examining and categorising 45 papers. Articles were searched for on Web of Science, Scopus, and LENS. We then concentrated on the categorisation of articles by theme. We discovered that system dynamics models were used as a component of a decision support tool or a knowledge management system in some instances, or the integration of knowledge management processes into specific systems. This study contributes to the growth of system dynamics as a methodology capable of generating novel ideas, highlighting limitations, and providing analogies for future research in a variety of academic areas.</p>\n</section>\n<div>\n<div>\n<section><h2> 1. Introduction</h2><p>System dynamics (SD) is a distinct methodological technique for modelling and simulating a variety of different types of systems. Interconnectedness, feedback, adaptive capacity/resilience, self-organisation, and emergence are all fundamental concepts in systems thinking that are applied in system dynamics to assist individuals in making better decisions in complicated settings [<a href=\"#B1-systems-10-00082\">1</a>,<a href=\"#B2-systems-10-00082\">2</a>,<a href=\"#B3-systems-10-00082\">3</a>,<a href=\"#B4-systems-10-00082\">4</a>]. The field provides a philosophy for modelling and evaluating dynamic systems as well as methodologies for modelling and analysing dynamic systems. Additionally, the discipline provides approaches and tools for probing current decision-making and aiding decision-makers in their learning. There are two types of diagrams in SD. While Causal-Loop Diagrams (CLD) are used in qualitative modelling, Stock-and-Flow Diagrams (SFD) are used in quantitative modelling to develop models that can be simulated and quantitatively interpreted. The number of applications of SD methods and models has increased dramatically across a wide variety of sectors. Zanker et al. [<a href=\"#B5-systems-10-00082\">5</a>] provide an overview of SD applications, whereas Darabi and Hosseinichimeh [<a href=\"#B6-systems-10-00082\">6</a>] or Shepherd [<a href=\"#B7-systems-10-00082\">7</a>] provide details on individual applications.</p><p>Knowledge management (KM) has become a significant problem over the last few decades, and the Knowledge Management community has developed a diverse set of tools and systems for academic research as well as commercial applications [<a href=\"#B8-systems-10-00082\">8</a>]. For instance, Al-Emran et al. [<a href=\"#B9-systems-10-00082\">9</a>] focus on knowledge acquisition and knowledge sharing in developing countries. In the educational realm, Arpaci [<a href=\"#B10-systems-10-00082\">10</a>] applies cloud computing as a platform for the development of KM, while Al-Sharafi et al. [<a href=\"#B11-systems-10-00082\">11</a>] used chatbots for the establishment of KM.</p><p>KM can be perceived from the perspective of two levels. While the first one apprehends knowledge as an object and is associated with the technological level where knowledge-oriented technologies such as expert systems are applied. Different types of knowledge are used here, for example, procedural and declarative knowledge. The second one focuses rather on knowledge processes and takes place at the organisational level [<a href=\"#B12-systems-10-00082\">12</a>]. KM uses a variety of processes, collectively referred to as Knowledge Management Processes (KMP). This study focuses on the latter. At this level, several definitions of KM exist. The example of the traditional definition is the one provided by Demarest [<a href=\"#B13-systems-10-00082\">13</a>] who understands KM as a process of systematic underpinning, observation, instrumentation, and optimization. Nonaka postulates KM as a transformation between explicit and tacit knowledge in a form of Socialization, Externalization, Combination, and Internalization. Current research defines KM as a multidisciplinary concept that deals with capturing knowledge and its distribution [<a href=\"#B14-systems-10-00082\">14</a>]. Moreover, the focus on KMP is intensified. There is no need to enumerate various types of KMP here. Systematic reviews in which KMPs are presented and classified can be found. For instance, Costa and Monteiro [<a href=\"#B15-systems-10-00082\">15</a>] use the innovation perspective and distinguish Knowledge acquisition, Knowledge sharing, Knowledge codification, Knowledge creation and Knowledge Application. Rollett [<a href=\"#B16-systems-10-00082\">16</a>] adds the following processes: Knowledge planning, Creating knowledge, Integrating knowledge, Organizing knowledge, Transferring knowledge, Maintaining knowledge and Assessing knowledge.</p><p>There is a plethora of methods, tools, or techniques associated with the application of KM. They belong to areas such as decision support, knowledge and expert systems, or evaluation of intellectual capital in an organisation [<a href=\"#B17-systems-10-00082\">17</a>,<a href=\"#B18-systems-10-00082\">18</a>,<a href=\"#B19-systems-10-00082\">19</a>]. KM is associated with models in various manners. For instance, conceptual maps, object-modelling diagrams, business process diagrams, or project-related schemas have been applied for quite a long time [<a href=\"#B20-systems-10-00082\">20</a>,<a href=\"#B21-systems-10-00082\">21</a>]. Even simulatable models have already been used. The development of multi-agent models is quite spread in the economic domain and can serve as an example [<a href=\"#B22-systems-10-00082\">22</a>]. KM and SD modelling and simulations share several principles and perspectives as well. From this point of view, SD constitutes the model-based knowledge-oriented approach as qualitative models are used as a knowledge base for decision support. Quantitative models represent knowledge which captures the dynamics of the analysed system. It can be simulated and single scenarios can be developed and tested. Indeed, SD models can be considered as a type of explicit knowledge as it comprises knowledge unreachable anywhere else [<a href=\"#B2-systems-10-00082\">2</a>]. SD requires scenario generation and hypothesis testing. A modeller is essentially attempting to generate information and knowledge about the system under inquiry through this activity. When examined through the same lens, concerning a specific situation, modelling can be called knowledge development, and group modelling can be considered knowledge sharing or knowledge integration.</p><p>SD models are used across disciplines. There are several systematic reviews addressing system dynamics applications with a focus on different sectors. Brent et al. [<a href=\"#B23-systems-10-00082\">23</a>] present how SD was applied to understand and evaluate societal and policy-related problems in Southern Africa. Zanker and Štekerová [<a href=\"#B24-systems-10-00082\">24</a>] describe the application of SD in the realm of tourism. A systematic review focusing on the uncertainty and hydrocarbon resources modelling is presented by Koul et al. [<a href=\"#B25-systems-10-00082\">25</a>]. Uriona and Grobbelaar [<a href=\"#B26-systems-10-00082\">26</a>] addressed the application of SD in the area of policy analysis. Zanker et al. [<a href=\"#B5-systems-10-00082\">5</a>] provide an extensive analysis of domains in which SD has been applied as a methodological approach, specifically the domains of Business, Environment, and Health, and conclude that the largest group of systematic reviews is focused on the health domain. A paper published by Cassidy et al. [<a href=\"#B27-systems-10-00082\">27</a>] can serve as an appropriate example as the authors focus on the use of system dynamics and agent-based models for modelling and simulating health system behaviour. Chang et al. address the use of system dynamics for health systems as well [<a href=\"#B28-systems-10-00082\">28</a>]. Davahli et al. [<a href=\"#B29-systems-10-00082\">29</a>] focus on the application of SD to all areas of the health care domain from the ageing population, through the understanding of diseases",
        "html": "<div><section>\n<header>\n<div>\n</div>\n</header>\n<div>\n<div>\n<p><a href=\"https://www.mdpi.com/journal/systems\">\n</a></p>\n<div>\n<p>\n</p><h2>Article Menu</h2>\n<p></p>\n</div>\n</div>\n<div>\n<div>\n<p>\nFont Type:\n</p>\n<p><span><i>Arial</i></span>\n<span><i>Georgia</i></span>\n<span><i>Verdana</i></span>\n</p>\n</div>\n<article><div>\n<p><span>Open Access</span><span>Systematic Review</span></p>\n<div><p>\nby\n<span></span></p><p>\nMarek Zanker</p><sup> *</sup><span></span><a href=\"https://www.mdpi.com/cdn-cgi/l/email-protection#406f232e246d2327296f2c6f252d21292c6d30322f34252334292f2e6370707023762471267078707674737177702370737076707871267224717870757076747370257177\"><sup><i></i></sup></a> and <span><p>\nVladimír Bureš</p><sup></sup><span></span><a href=\"https://www.mdpi.com/cdn-cgi/l/email-protection#a689c5c8c28bc5c1cf89ca89c3cbc7cfca8bd6d4c9d2c3c5d2cfc9c885969697c791909791979497c097c497c09692939e979296959692979596939590969597c397c2939e979396c5\"><sup><i></i></sup></a><a href=\"https://orcid.org/0000-0001-7788-7445\"></a></span> <p></p></div>\n<div>\n<div>\n<p>Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic</p>\n</div>\n<div>\n<p><sup>*</sup></p>\n<p>Author to whom correspondence should be addressed. </p>\n</div>\n</div>\n<p><span>Submission received: 20 April 2022</span>\n/\n<span>Revised: 6 June 2022</span>\n/\n<span>Accepted: 11 June 2022</span>\n/\n<span>Published: 14 June 2022</span>\n</p>\n<section>\n<h2>Abstract</h2><b>:</b>\n<p>For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of systems with varying degrees of complexity and knowledge demands. Knowledge management is strongly related to system dynamics on a thematic level. We did a thorough review to identify potential applications and analysed system dynamics and knowledge management domains. The systematic review followed the PRISMA method. We identified two major groups and one subgroup of the combination of system dynamics and knowledge management after examining and categorising 45 papers. Articles were searched for on Web of Science, Scopus, and LENS. We then concentrated on the categorisation of articles by theme. We discovered that system dynamics models were used as a component of a decision support tool or a knowledge management system in some instances, or the integration of knowledge management processes into specific systems. This study contributes to the growth of system dynamics as a methodology capable of generating novel ideas, highlighting limitations, and providing analogies for future research in a variety of academic areas.</p>\n</section>\n<div>\n<div>\n<section><h2> 1. Introduction</h2><p>System dynamics (SD) is a distinct methodological technique for modelling and simulating a variety of different types of systems. Interconnectedness, feedback, adaptive capacity/resilience, self-organisation, and emergence are all fundamental concepts in systems thinking that are applied in system dynamics to assist individuals in making better decisions in complicated settings [<a href=\"#B1-systems-10-00082\">1</a>,<a href=\"#B2-systems-10-00082\">2</a>,<a href=\"#B3-systems-10-00082\">3</a>,<a href=\"#B4-systems-10-00082\">4</a>]. The field provides a philosophy for modelling and evaluating dynamic systems as well as methodologies for modelling and analysing dynamic systems. Additionally, the discipline provides approaches and tools for probing current decision-making and aiding decision-makers in their learning. There are two types of diagrams in SD. While Causal-Loop Diagrams (CLD) are used in qualitative modelling, Stock-and-Flow Diagrams (SFD) are used in quantitative modelling to develop models that can be simulated and quantitatively interpreted. The number of applications of SD methods and models has increased dramatically across a wide variety of sectors. Zanker et al. [<a href=\"#B5-systems-10-00082\">5</a>] provide an overview of SD applications, whereas Darabi and Hosseinichimeh [<a href=\"#B6-systems-10-00082\">6</a>] or Shepherd [<a href=\"#B7-systems-10-00082\">7</a>] provide details on individual applications.</p><p>Knowledge management (KM) has become a significant problem over the last few decades, and the Knowledge Management community has developed a diverse set of tools and systems for academic research as well as commercial applications [<a href=\"#B8-systems-10-00082\">8</a>]. For instance, Al-Emran et al. [<a href=\"#B9-systems-10-00082\">9</a>] focus on knowledge acquisition and knowledge sharing in developing countries. In the educational realm, Arpaci [<a href=\"#B10-systems-10-00082\">10</a>] applies cloud computing as a platform for the development of KM, while Al-Sharafi et al. [<a href=\"#B11-systems-10-00082\">11</a>] used chatbots for the establishment of KM.</p><p>KM can be perceived from the perspective of two levels. While the first one apprehends knowledge as an object and is associated with the technological level where knowledge-oriented technologies such as expert systems are applied. Different types of knowledge are used here, for example, procedural and declarative knowledge. The second one focuses rather on knowledge processes and takes place at the organisational level [<a href=\"#B12-systems-10-00082\">12</a>]. KM uses a variety of processes, collectively referred to as Knowledge Management Processes (KMP). This study focuses on the latter. At this level, several definitions of KM exist. The example of the traditional definition is the one provided by Demarest [<a href=\"#B13-systems-10-00082\">13</a>] who understands KM as a process of systematic underpinning, observation, instrumentation, and optimization. Nonaka postulates KM as a transformation between explicit and tacit knowledge in a form of Socialization, Externalization, Combination, and Internalization. Current research defines KM as a multidisciplinary concept that deals with capturing knowledge and its distribution [<a href=\"#B14-systems-10-00082\">14</a>]. Moreover, the focus on KMP is intensified. There is no need to enumerate various types of KMP here. Systematic reviews in which KMPs are presented and classified can be found. For instance, Costa and Monteiro [<a href=\"#B15-systems-10-00082\">15</a>] use the innovation perspective and distinguish Knowledge acquisition, Knowledge sharing, Knowledge codification, Knowledge creation and Knowledge Application. Rollett [<a href=\"#B16-systems-10-00082\">16</a>] adds the following processes: Knowledge planning, Creating knowledge, Integrating knowledge, Organizing knowledge, Transferring knowledge, Maintaining knowledge and Assessing knowledge.</p><p>There is a plethora of methods, tools, or techniques associated with the application of KM. They belong to areas such as decision support, knowledge and expert systems, or evaluation of intellectual capital in an organisation [<a href=\"#B17-systems-10-00082\">17</a>,<a href=\"#B18-systems-10-00082\">18</a>,<a href=\"#B19-systems-10-00082\">19</a>]. KM is associated with models in various manners. For instance, conceptual maps, object-modelling diagrams, business process diagrams, or project-related schemas have been applied for quite a long time [<a href=\"#B20-systems-10-00082\">20</a>,<a href=\"#B21-systems-10-00082\">21</a>]. Even simulatable models have already been used. The development of multi-agent models is quite spread in the economic domain and can serve as an example [<a href=\"#B22-systems-10-00082\">22</a>]. KM and SD modelling and simulations share several principles and perspectives as well. From this point of view, SD constitutes the model-based knowledge-oriented approach as qualitative models are used as a knowledge base for decision support. Quantitative models represent knowledge which captures the dynamics of the analysed system. It can be simulated and single scenarios can be developed and tested. Indeed, SD models can be considered as a type of explicit knowledge as it comprises knowledge unreachable anywhere else [<a href=\"#B2-systems-10-00082\">2</a>]. SD requires scenario generation and hypothesis testing. A modeller is essentially attempting to generate information and knowledge about the system under inquiry through this activity. When examined through the same lens, concerning a specific situation, modelling can be called knowledge development, and group modelling can be considered knowledge sharing or knowledge integration.</p><p>SD models are used across disciplines. There are several systematic reviews addressing system dynamics applications with a focus on different sectors. Brent et al. [<a href=\"#B23-systems-10-00082\">23</a>] present how SD was applied to understand and evaluate societal and policy-related problems in Southern Africa. Zanker and Štekerová [<a href=\"#B24-systems-10-00082\">24</a>] describe the application of SD in the realm of tourism. A systematic review focusing on the uncertainty and hydrocarbon resources modelling is presented by Koul et al. [<a href=\"#B25-systems-10-00082\">25</a>]. Uriona and Grobbelaar [<a href=\"#B26-systems-10-00082\">26</a>] addressed the application of SD in the area of policy analysis. Zanker et al. [<a href=\"#B5-systems-10-00082\">5</a>] provide an extensive analysis of domains in which SD has been applied as a methodological approach, specifically the domains of Business, Environment, and Health, and conclude that the largest group of systematic reviews is focused on the health domain. A paper published by Cassidy et al. [<a href=\"#B27-systems-10-00082\">27</a>] can serve as an appropriate example as the authors focus on the use of system dynamics and agent-based models for modelling and simulating health system behaviour. Chang et al. address the use of system dynamics for health systems as well [<a href=\"#B28-systems-10-00082\">28</a>]. Davahli et al. [<a href=\"#B29-systems-10-00082\">29</a>] focus on the application of SD to all areas of the health care domain from the ageing population, through the understanding of diseases",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Article MenuFont Type:ArialGeorgiaVerdanaOpen AccessSystematic ReviewbyMarek Zanker*andVladimír BurešFaculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.Submission received: 20 April 2022/Revised: 6 June 2022/Accepted: 11 June 2022/Published: 14 June 2022Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of syst",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Article MenuFont Type:ArialGeorgiaVerdanaOpen AccessSystematic ReviewbyMarek Zanker*andVladimír BurešFaculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.Submission received: 20 April 2022/Revised: 6 June 2022/Accepted: 11 June 2022/Published: 14 June 2022Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of syst",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Article MenuFont Type:ArialGeorgiaVerdanaOpen AccessSystematic ReviewbyMarek Zanker*andVladimír BurešFaculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.Submission received: 20 April 2022/Revised: 6 June 2022/Accepted: 11 June 2022/Published: 14 June 2022Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of syst",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Article Menu",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Article Menu",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Font Type:ArialGeorgiaVerdanaOpen AccessSystematic ReviewbyMarek Zanker*andVladimír BurešFaculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.Submission received: 20 April 2022/Revised: 6 June 2022/Accepted: 11 June 2022/Published: 14 June 2022Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of systems with var",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Font Type:ArialGeorgiaVerdana",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "Open AccessSystematic ReviewbyMarek Zanker*andVladimír BurešFaculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.Submission received: 20 April 2022/Revised: 6 June 2022/Accepted: 11 June 2022/Published: 14 June 2022Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of systems with varying degrees of complexity an",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Open AccessSystematic ReviewbyMarek Zanker*andVladimír BurešFaculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.Submission received: 20 April 2022/Revised: 6 June 2022/Accepted: 11 June 2022/Published: 14 June 2022Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of systems with varying degrees of complexity an",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "byMarek Zanker*andVladimír Bureš",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic*Author to whom correspondence should be addressed.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 50003 Hradec Kralove, Czech Republic",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "*Author to whom correspondence should be addressed.",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Abstract:For decades, system dynamics has been utilised as a framework for evaluating and interpreting various types of systems with varying degrees of complexity and knowledge demands. Knowledge management is strongly related to system dynamics on a thematic level. We did a thorough review to identify potential applications and analysed system dynamics and knowledge management domains. The systematic review followed the PRISMA method. We identified two major groups and one subgroup of the combi",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "1. IntroductionSystem dynamics (SD) is a distinct methodological technique for modelling and simulating a variety of different types of systems. Interconnectedness, feedback, adaptive capacity/resilience, self-organisation, and emergence are all fundamental concepts in systems thinking that are applied in system dynamics to assist individuals in making better decisions in complicated settings [1,2,3,4]. The field provides a philosophy for modelling and evaluating dynamic systems as well as metho",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "1. IntroductionSystem dynamics (SD) is a distinct methodological technique for modelling and simulating a variety of different types of systems. Interconnectedness, feedback, adaptive capacity/resilience, self-organisation, and emergence are all fundamental concepts in systems thinking that are applied in system dynamics to assist individuals in making better decisions in complicated settings [1,2,3,4]. The field provides a philosophy for modelling and evaluating dynamic systems as well as metho",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "1. IntroductionSystem dynamics (SD) is a distinct methodological technique for modelling and simulating a variety of different types of systems. Interconnectedness, feedback, adaptive capacity/resilience, self-organisation, and emergence are all fundamental concepts in systems thinking that are applied in system dynamics to assist individuals in making better decisions in complicated settings [1,2,3,4]. The field provides a philosophy for modelling and evaluating dynamic systems as well as metho",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Article Menu",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Abstract",
              "id": ""
            },
            {
              "level": "h2",
              "text": "1. Introduction",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2018.01006/full",
      "title": "Frontiers | Observing the World Through Your Own Lenses – The Role of Perceived Adaptability for Epistemological Beliefs About the Development of Scientific Knowledge",
      "author": "Ronny Scherer1*Øystein Guttersrud2",
      "published_date": "2018-06-20T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<h2>Introduction</h2>\n<p>There is no doubt, the world is developing. In fact, knowledge, information, and technology are rapidly advancing, making it harder for us to keep up with the latest developments and insights. This development constantly exposes us to situations, in which we have to adjust our thinking and behavior to novel, uncertain, and changing situations across almost all areas of our lives (<a href=\"#B87\">Winthrop and McGivney, 2016</a>)—for instance, when dealing with disruptions in our daily commuter routes (<a href=\"#B30\">Harford, 2012</a>) or when making up our minds about climate change (<a href=\"#B57\">McClanahan and Cinner, 2011</a>). But how prepared do we feel to cope with such change? Indeed, our beliefs about how adaptable we are play a major role for performance and learning in complex problem situations (<a href=\"#B5\">Barak and Levenberg, 2016</a>).</p>\n<p>Our information society demands to constantly adjust one’s thinking, behavior, affect, and emotions to novel and changing situations—hence, this capacity, which is often called “adaptability,” has gained interest in educational and psychological research (<a href=\"#B64\">Pellegrino and Hilton, 2012</a>; <a href=\"#B51\">Martin et al., 2013</a>). More precisely, an increasing body of literature reports on the relevance of students’ beliefs about how adaptable they are for academic success, well-being, buoyancy, self-control – the list of important outcome variables is growing (e.g., <a href=\"#B66\">Pulakos et al., 2002</a>; <a href=\"#B28\">Gloster et al., 2011</a>; <a href=\"#B50\">Martin et al., 2015</a>; <a href=\"#B15\">Collie et al., 2016</a>). At the same time, the demands to adapt to novelty, uncertainty, or changes interfere with the way we perceive these demands. Put differently, our beliefs about the changing and developing nature of knowledge, information, or technology – so-called “epistemological beliefs” – play another critical role for success in many areas (<a href=\"#B81\">Trautwein and Lüdtke, 2007</a>; <a href=\"#B29\">Green and Hood, 2013</a>). In the pursuit of disentangling what might determine adaptive expertise, two questions remain largely unanswered: To what extent does adaptability correspond to the way we view this rapidly changing world? and to what extent are perceived adaptability and epistemological beliefs about the developing and changing nature of knowledge related? Knowledge about this relation clarifies whether two seemingly distinct belief systems—self-beliefs and epistemological beliefs—are linked. Moreover, it provides educators with possibilities to influence the one by fostering the other. We notice that adaptability surfaces in several life situations; hence, the questions we are posing here are not restricted to certain domains or contexts.</p>\n<p>Using assessments of cognitive flexibility—a concept that taps the cognitive aspects of adaptability, yet does not include affective-emotional aspects—some researchers uncovered a positive relation between flexibility and epistemological beliefs (<a href=\"#B40\">Kienhues and Bromme, 2011</a>; <a href=\"#B71\">Roex et al., 2011</a>). <a href=\"#B22\">Elen et al. (2011)</a> argued that the two concepts are closely connected and can even considered to be indicators of each other. Moreover, it has not yet become clear to what extent the measurement of epistemological beliefs is sufficiently invariant across different levels of flexibility. This question concerns the validity of the measure (<a href=\"#B63\">Pellegrino et al., 2016</a>). Knowledge about the invariance of epistemological beliefs measures along the continuum of adaptability provides test developers and assessment specialist with information about the functioning of the measures and the cautions associated with the interpretation of the resultant test scores (<a href=\"#B75\">Scherer, 2017</a>).</p>\n<p>This paper seeks to clarify the link between adaptability and epistemological beliefs about the development of scientific knowledge (EBDE) by examining (a) the correlations between perceived adaptability – including its cognitive-behavioral and affective-emotional aspects – and EBDE; (b) the extent to which the most commonly used measurement of EBDE—<a href=\"#B17\">Conley et al.’s (2004)</a> Science Epistemological Beliefs Scale (see also <a href=\"#B44\">Liu, 2010</a>; <a href=\"#B83\">Tsai et al., 2011</a>; <a href=\"#B37\">Kampa et al., 2016</a>)—is affected by individual differences in adaptability. We adopt a moderated factor analysis approach and include further variables representing students’ background.</p>\n<h2>Theoretical Framework</h2>\n<p>This section is organized as follows: First, we provide a brief review of the existing bodies of literature on students’ perceived adaptability and next EBDE. This brief review includes the conceptualization and aspects of the two constructs and describes the theoretical basis for the relation between perceived adaptability and EBDE.</p>\n<h3>Perceived Adaptability</h3>\n<h4>Construct Definition</h4>\n<p>Adaptability has many facets: First and foremost, it refers to the capacity to adjust one’s thinking, behavior, emotions, and affect to changing, novel, and uncertain<sup><a></a><a href=\"#note1\">1</a></sup> situations (<a href=\"#B85\">VandenBos, 2007</a>). In light of this conceptualization, adaptability comprises cognitive, metacognitive, volitional, motivational, and even emotional elements. <a href=\"#B56\">Mayer (2014)</a>, for instance, emphasized the cognitive and metacognitive processes of adaptability and summarized them under the umbrella of what he called ‘adaptive problem solving,’ that is, “a form of problem solving that requires a series of problem reformulations or continual reevaluation of problem formulations in light of changing conditions. In short, adaptive problem solving occurs when a problem solver continually revises his or her problem representations (and the corresponding solution plan) in light of the changes in the problem situation” (p. 153). Several problem situations in our daily lives require us to adapt, perhaps because our strategies to solve them did not work out or because the problem itself or the information attached to it changed. In fact, we are constantly required to perform adaptive problem solving and therefore engage in the cognitive and metacognitive processes <a href=\"#B56\">Mayer (2014)</a> mentioned. Acknowledging the importance of these processes and their relevance not only in everyday-life situations but also in work settings has led to the inclusion of adaptability in existing twenty-first century skills frameworks (<a href=\"#B12\">Chan, 2014</a>; <a href=\"#B78\">Soulé and Warrick, 2015</a>). In these frameworks, however, the status of adaptability may differ substantially: On the one hand, it might be considered a form of problem solving or critical thinking and therefore a construct that taps cognitive and metacognitive thinking processes (<a href=\"#B56\">Mayer, 2014</a>; <a href=\"#B74\">Scherer, 2015</a>; <a href=\"#B5\">Barak and Levenberg, 2016</a>). On the other hand, adaptability might be considered a personality trait that taps the willingness and openness to adjust our thinking and behavior to changing, novel, and uncertain situations (<a href=\"#B49\">Martin et al., 2012b</a>; <a href=\"#B39\">Kaufman et al., 2016</a>). Even further, in their almost exhaustive taxonomy describing the constituents of the composite construct adaptability, <a href=\"#B65\">Pulakos et al. (2000)</a> identified its core elements: the abilities to solve complex problems, to deal with uncertain problem situations, and to adapt to emotionally challenging situations or to cultural experiences. These different but related aspects capture the complexity of the construct, indicate the presence of possible sub-factors, and express the diversity of demands that come along with novel, uncertain, and changing situations.</p>\n<h4>Dimensions of Adaptability</h4>\n<p>The current perspective on adaptability suggests that cognitive-behavioral and affective-emotional aspects can be differentiated (<a href=\"#B53\">Martin and Rubin, 1995</a>; <a href=\"#B65\">Pulakos et al., 2000</a>). Putting this perspective to test, <a href=\"#B49\">Martin et al. (2012b</a>, <a href=\"#B51\">2013</a>) conducted multiple studies in which they specifically searched for evidence on the distinction between cognitive-behavioral and affective-emotional aspects of adaptability. Martin and colleagues developed a self-report scale measuring students’ perceived adaptability. The results were clear-cut across several student samples: Empirical evidence strengthened the hypothesized factor structure that distinguished between a cognitive-behavioral and affective-emotional adaptability; yet the correlation between the two aspects was high, <i>r</i> = 0.88. This structure was also invariant across educationally relevant groups, such as gender, age, and linguistic backgrounds (<a href=\"#B49\">Martin et al., 2012b</a>). These findings provide empirical evidence for the hypothesis that the two aspects of adaptability are distinct.</p>\n<p>From a conceptual perspective, the delineation of cognitive-behavioral and affective-emotional dimensions of adaptability relates to different research traditions: The <i>cognitive</i> aspect of adaptation or adaptive behavior is closely linked to basic executive functions, such as cognitive flexibility, working memory updating, and inhibitory control (<a href=\"#B20\">Diamond, 2013</a>). In fact, these functions form the basis for processing new information (updating), shifting between tasks and problem situations (flexibility), and focusing on relevant challenges and information (inhibition). Even further, students’ skills to adapt their thinking about scientific problems or concepts manifests in what is often referred to as “conceptual change,” that is, the adaptation of initial, everyday life conceptualizations of scientific phenomena to more scientific information ",
        "html": "<div><div>\n<h2>Introduction</h2>\n<p>There is no doubt, the world is developing. In fact, knowledge, information, and technology are rapidly advancing, making it harder for us to keep up with the latest developments and insights. This development constantly exposes us to situations, in which we have to adjust our thinking and behavior to novel, uncertain, and changing situations across almost all areas of our lives (<a href=\"#B87\">Winthrop and McGivney, 2016</a>)—for instance, when dealing with disruptions in our daily commuter routes (<a href=\"#B30\">Harford, 2012</a>) or when making up our minds about climate change (<a href=\"#B57\">McClanahan and Cinner, 2011</a>). But how prepared do we feel to cope with such change? Indeed, our beliefs about how adaptable we are play a major role for performance and learning in complex problem situations (<a href=\"#B5\">Barak and Levenberg, 2016</a>).</p>\n<p>Our information society demands to constantly adjust one’s thinking, behavior, affect, and emotions to novel and changing situations—hence, this capacity, which is often called “adaptability,” has gained interest in educational and psychological research (<a href=\"#B64\">Pellegrino and Hilton, 2012</a>; <a href=\"#B51\">Martin et al., 2013</a>). More precisely, an increasing body of literature reports on the relevance of students’ beliefs about how adaptable they are for academic success, well-being, buoyancy, self-control – the list of important outcome variables is growing (e.g., <a href=\"#B66\">Pulakos et al., 2002</a>; <a href=\"#B28\">Gloster et al., 2011</a>; <a href=\"#B50\">Martin et al., 2015</a>; <a href=\"#B15\">Collie et al., 2016</a>). At the same time, the demands to adapt to novelty, uncertainty, or changes interfere with the way we perceive these demands. Put differently, our beliefs about the changing and developing nature of knowledge, information, or technology – so-called “epistemological beliefs” – play another critical role for success in many areas (<a href=\"#B81\">Trautwein and Lüdtke, 2007</a>; <a href=\"#B29\">Green and Hood, 2013</a>). In the pursuit of disentangling what might determine adaptive expertise, two questions remain largely unanswered: To what extent does adaptability correspond to the way we view this rapidly changing world? and to what extent are perceived adaptability and epistemological beliefs about the developing and changing nature of knowledge related? Knowledge about this relation clarifies whether two seemingly distinct belief systems—self-beliefs and epistemological beliefs—are linked. Moreover, it provides educators with possibilities to influence the one by fostering the other. We notice that adaptability surfaces in several life situations; hence, the questions we are posing here are not restricted to certain domains or contexts.</p>\n<p>Using assessments of cognitive flexibility—a concept that taps the cognitive aspects of adaptability, yet does not include affective-emotional aspects—some researchers uncovered a positive relation between flexibility and epistemological beliefs (<a href=\"#B40\">Kienhues and Bromme, 2011</a>; <a href=\"#B71\">Roex et al., 2011</a>). <a href=\"#B22\">Elen et al. (2011)</a> argued that the two concepts are closely connected and can even considered to be indicators of each other. Moreover, it has not yet become clear to what extent the measurement of epistemological beliefs is sufficiently invariant across different levels of flexibility. This question concerns the validity of the measure (<a href=\"#B63\">Pellegrino et al., 2016</a>). Knowledge about the invariance of epistemological beliefs measures along the continuum of adaptability provides test developers and assessment specialist with information about the functioning of the measures and the cautions associated with the interpretation of the resultant test scores (<a href=\"#B75\">Scherer, 2017</a>).</p>\n<p>This paper seeks to clarify the link between adaptability and epistemological beliefs about the development of scientific knowledge (EBDE) by examining (a) the correlations between perceived adaptability – including its cognitive-behavioral and affective-emotional aspects – and EBDE; (b) the extent to which the most commonly used measurement of EBDE—<a href=\"#B17\">Conley et al.’s (2004)</a> Science Epistemological Beliefs Scale (see also <a href=\"#B44\">Liu, 2010</a>; <a href=\"#B83\">Tsai et al., 2011</a>; <a href=\"#B37\">Kampa et al., 2016</a>)—is affected by individual differences in adaptability. We adopt a moderated factor analysis approach and include further variables representing students’ background.</p>\n<h2>Theoretical Framework</h2>\n<p>This section is organized as follows: First, we provide a brief review of the existing bodies of literature on students’ perceived adaptability and next EBDE. This brief review includes the conceptualization and aspects of the two constructs and describes the theoretical basis for the relation between perceived adaptability and EBDE.</p>\n<h3>Perceived Adaptability</h3>\n<h4>Construct Definition</h4>\n<p>Adaptability has many facets: First and foremost, it refers to the capacity to adjust one’s thinking, behavior, emotions, and affect to changing, novel, and uncertain<sup><a></a><a href=\"#note1\">1</a></sup> situations (<a href=\"#B85\">VandenBos, 2007</a>). In light of this conceptualization, adaptability comprises cognitive, metacognitive, volitional, motivational, and even emotional elements. <a href=\"#B56\">Mayer (2014)</a>, for instance, emphasized the cognitive and metacognitive processes of adaptability and summarized them under the umbrella of what he called ‘adaptive problem solving,’ that is, “a form of problem solving that requires a series of problem reformulations or continual reevaluation of problem formulations in light of changing conditions. In short, adaptive problem solving occurs when a problem solver continually revises his or her problem representations (and the corresponding solution plan) in light of the changes in the problem situation” (p. 153). Several problem situations in our daily lives require us to adapt, perhaps because our strategies to solve them did not work out or because the problem itself or the information attached to it changed. In fact, we are constantly required to perform adaptive problem solving and therefore engage in the cognitive and metacognitive processes <a href=\"#B56\">Mayer (2014)</a> mentioned. Acknowledging the importance of these processes and their relevance not only in everyday-life situations but also in work settings has led to the inclusion of adaptability in existing twenty-first century skills frameworks (<a href=\"#B12\">Chan, 2014</a>; <a href=\"#B78\">Soulé and Warrick, 2015</a>). In these frameworks, however, the status of adaptability may differ substantially: On the one hand, it might be considered a form of problem solving or critical thinking and therefore a construct that taps cognitive and metacognitive thinking processes (<a href=\"#B56\">Mayer, 2014</a>; <a href=\"#B74\">Scherer, 2015</a>; <a href=\"#B5\">Barak and Levenberg, 2016</a>). On the other hand, adaptability might be considered a personality trait that taps the willingness and openness to adjust our thinking and behavior to changing, novel, and uncertain situations (<a href=\"#B49\">Martin et al., 2012b</a>; <a href=\"#B39\">Kaufman et al., 2016</a>). Even further, in their almost exhaustive taxonomy describing the constituents of the composite construct adaptability, <a href=\"#B65\">Pulakos et al. (2000)</a> identified its core elements: the abilities to solve complex problems, to deal with uncertain problem situations, and to adapt to emotionally challenging situations or to cultural experiences. These different but related aspects capture the complexity of the construct, indicate the presence of possible sub-factors, and express the diversity of demands that come along with novel, uncertain, and changing situations.</p>\n<h4>Dimensions of Adaptability</h4>\n<p>The current perspective on adaptability suggests that cognitive-behavioral and affective-emotional aspects can be differentiated (<a href=\"#B53\">Martin and Rubin, 1995</a>; <a href=\"#B65\">Pulakos et al., 2000</a>). Putting this perspective to test, <a href=\"#B49\">Martin et al. (2012b</a>, <a href=\"#B51\">2013</a>) conducted multiple studies in which they specifically searched for evidence on the distinction between cognitive-behavioral and affective-emotional aspects of adaptability. Martin and colleagues developed a self-report scale measuring students’ perceived adaptability. The results were clear-cut across several student samples: Empirical evidence strengthened the hypothesized factor structure that distinguished between a cognitive-behavioral and affective-emotional adaptability; yet the correlation between the two aspects was high, <i>r</i> = 0.88. This structure was also invariant across educationally relevant groups, such as gender, age, and linguistic backgrounds (<a href=\"#B49\">Martin et al., 2012b</a>). These findings provide empirical evidence for the hypothesis that the two aspects of adaptability are distinct.</p>\n<p>From a conceptual perspective, the delineation of cognitive-behavioral and affective-emotional dimensions of adaptability relates to different research traditions: The <i>cognitive</i> aspect of adaptation or adaptive behavior is closely linked to basic executive functions, such as cognitive flexibility, working memory updating, and inhibitory control (<a href=\"#B20\">Diamond, 2013</a>). In fact, these functions form the basis for processing new information (updating), shifting between tasks and problem situations (flexibility), and focusing on relevant challenges and information (inhibition). Even further, students’ skills to adapt their thinking about scientific problems or concepts manifests in what is often referred to as “conceptual change,” that is, the adaptation of initial, everyday life conceptualizations of scientific phenomena to more scientific information ",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "IntroductionThere is no doubt, the world is developing. In fact, knowledge, information, and technology are rapidly advancing, making it harder for us to keep up with the latest developments and insights. This development constantly exposes us to situations, in which we have to adjust our thinking and behavior to novel, uncertain, and changing situations across almost all areas of our lives (Winthrop and McGivney, 2016)—for instance, when dealing with disruptions in our daily commuter routes (Ha",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionThere is no doubt, the world is developing. In fact, knowledge, information, and technology are rapidly advancing, making it harder for us to keep up with the latest developments and insights. This development constantly exposes us to situations, in which we have to adjust our thinking and behavior to novel, uncertain, and changing situations across almost all areas of our lives (Winthrop and McGivney, 2016)—for instance, when dealing with disruptions in our daily commuter routes (Ha",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Theoretical Framework",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Perceived Adaptability",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Construct Definition",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Dimensions of Adaptability",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://en.wikipedia.org/wiki/Adaptive_management",
      "title": "Adaptive management",
      "author": "Contributors to Wikimedia projects",
      "published_date": "2024-01-04T09:35:44.000Z",
      "content": {
        "text": "<div><div>\n<p>From Wikipedia, the free encyclopedia</p>\n</div><div>\n<p><b>Adaptive management</b>, also known as <b>adaptive resource management</b> or <b>adaptive environmental assessment and management</b>, is a structured, <a href=\"https://en.wikipedia.org/wiki/Iteration\">iterative</a> process of robust <a href=\"https://en.wikipedia.org/wiki/Decision_making\">decision making</a> in the face of <a href=\"https://en.wikipedia.org/wiki/Uncertainty\">uncertainty</a>, with an aim to reducing uncertainty over time via <a href=\"https://en.wikipedia.org/wiki/System_monitoring\">system monitoring</a>. In this way, decision making simultaneously meets one or more <a href=\"https://en.wikipedia.org/wiki/Resource_management\">resource management</a> objectives and, either passively or actively, accrues information needed to improve future management. Adaptive management is a tool which should be used not only to change a system, but also to learn about the system.<sup><a href=\"#cite_note-:0-1\">[1]</a></sup> Because adaptive management is based on a learning process, it improves long-run management outcomes. The challenge in using the adaptive management approach lies in finding the correct balance between gaining knowledge to improve management in the future and achieving the best short-term outcome based on current knowledge.<sup><a href=\"#cite_note-2\">[2]</a></sup> This approach has more recently been employed in implementing <a href=\"https://en.wikipedia.org/wiki/International_development\">international development</a> programs.\n</p>\n<h2><span>Objectives</span><span><span>[</span><a href=\"https://en.wikipedia.org/w/index.php?title=Adaptive_management&amp;action=edit&amp;section=1\"><span>edit</span></a><span>]</span></span></h2>\n<p>There are a number of scientific and social processes which are vital components of adaptive management, including:\n</p>\n<ul><li>Management is linked to appropriate temporal and spatial scales</li>\n<li>Management retains a focus on <a href=\"https://en.wikipedia.org/wiki/Statistical_power\">statistical power</a> and controls</li>\n<li>Use of computer models to build synthesis and an embodied ecological consensus</li>\n<li>Use of embodied ecological consensus to evaluate strategic alternatives</li>\n<li>Communication of alternatives to political arena for negotiation of a selection</li></ul>\n<p>The achievement of these objectives requires an open management process which seeks to include past, present and future <a href=\"https://en.wikipedia.org/wiki/Stakeholder_(corporate)\">stakeholders</a>. Adaptive management needs to at least maintain <a href=\"https://en.wikipedia.org/wiki/Glasnost\">political openness</a>, but usually aims to create it. Adaptive management must therefore be a <a href=\"https://en.wikipedia.org/wiki/Scientific\">scientific</a> and social process. It must focus on the development of new <a href=\"https://en.wikipedia.org/wiki/Institutions\">institutions</a> and institutional strategies in balance with <a href=\"https://en.wikipedia.org/wiki/Scientific_hypothesis\">scientific hypothesis</a> and experimental frameworks (resilience.org).\n</p><p>Adaptive management can proceed as either passive or active adaptive management, depending on how learning takes place. Passive adaptive management values learning only insofar as it improves decision outcomes (i.e. passively), as measured by the specified utility function. In contrast, active adaptive management explicitly incorporates learning as part of the objective function, and hence, decisions which improve learning are valued over those which do not.<sup><a href=\"#cite_note-:0-1\">[1]</a></sup><sup><a href=\"#cite_note-:1-3\">[3]</a></sup> In both cases, as new knowledge is gained, the models are updated and optimal management strategies are derived accordingly. Thus, while learning occurs in both cases, it is treated differently. Often, deriving actively adaptive policies is technically very difficult, which prevents it being more commonly applied.<sup><a href=\"#cite_note-4\">[4]</a></sup>\n</p>\n<h2><span>Features</span><span><span>[</span><a href=\"https://en.wikipedia.org/w/index.php?title=Adaptive_management&amp;action=edit&amp;section=2\"><span>edit</span></a><span>]</span></span></h2>\n<p>Key features of both passive and active adaptive management are:\n</p>\n<ul><li>Iterative decision-making (evaluating results and adjusting actions on the basis of what has been learned)</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Feedback\">Feedback</a> between monitoring and decisions (learning)</li>\n<li>Explicit characterization of system uncertainty through multi-model inference</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Bayesian_inference\">Bayesian inference</a></li>\n<li>Embracing <a href=\"https://en.wikipedia.org/wiki/Risk\">risk</a> and uncertainty as a way of building understanding</li></ul>\n<p>However, a number of process failures related to information feedback can prevent effective adaptive management decision making:<sup><a href=\"#cite_note-5\">[5]</a></sup>\n</p>\n<ul><li><a href=\"https://en.wikipedia.org/wiki/Data_collection\">data collection</a> is never completely implemented</li>\n<li>data are collected but not analyzed</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Data_analysis\">data are analyzed</a> but results are inconclusive</li>\n<li>data are analyzed and are interesting, but are not presented to decision makers</li>\n<li>data are analyzed and presented, but are not used for decision-making because of internal or external factors</li></ul>\n<h2><span>History</span><span><span>[</span><a href=\"https://en.wikipedia.org/w/index.php?title=Adaptive_management&amp;action=edit&amp;section=3\"><span>edit</span></a><span>]</span></span></h2>\n<p>The use of adaptive management techniques can be traced back to peoples from ancient civilisations. For example, the <a href=\"https://en.wikipedia.org/wiki/Yap\">Yap</a> people of Micronesia have been using adaptive management techniques to sustain high <a href=\"https://en.wikipedia.org/wiki/Population_density\">population densities</a> in the face of resource scarcity for thousands of years (Falanruw 1984). In using these techniques, the Yap people have altered their environment creating, for example, coastal <a href=\"https://en.wikipedia.org/wiki/Mangrove\">mangrove</a> depressions and <a href=\"https://en.wikipedia.org/wiki/Seagrass_meadow\">seagrass meadows</a> to support fishing and termite resistant wood (Stankey and Shinder 1997).\n</p><p>The origin of the adaptive management concept can be traced back to ideas of <a href=\"https://en.wikipedia.org/wiki/Scientific_management\">scientific management</a> pioneered by <a href=\"https://en.wikipedia.org/wiki/Frederick_Winslow_Taylor\">Frederick Taylor</a> in the early 1900s (Haber 1964). While the term \"adaptive management\" evolved in natural resource management workshops through decision makers, managers and scientists focussing on building simulation models to uncover key assumptions and uncertainties (Bormann <i>et al.</i> 1999)\n</p><p>Two ecologists at The <a href=\"https://en.wikipedia.org/wiki/University_of_British_Columbia\">University of British Columbia</a>, <a href=\"https://en.wikipedia.org/wiki/C._S._Holling\">C.S. Holling</a><sup><a href=\"#cite_note-:0-1\">[1]</a></sup> and C.J Walters<sup><a href=\"#cite_note-:1-3\">[3]</a></sup> further developed the adaptive management approach as they distinguished between passive and active adaptive management practice. <a href=\"https://en.wikipedia.org/wiki/Kai_Lee\">Kai Lee</a>, notable Princeton physicist, expanded upon the approach in the late 1970s and early 1980s while pursuing a post-doctorate degree at UC <a href=\"https://en.wikipedia.org/wiki/Berkeley,_California\">Berkeley</a>. The approach was further developed at the International Institute for Applied Systems Analysis (IIASA) in <a href=\"https://en.wikipedia.org/wiki/Vienna\">Vienna</a>, <a href=\"https://en.wikipedia.org/wiki/Austria\">Austria</a>, while C.S. Holling was director of the institute. In 1992, Hilbourne described three learning models for federal land managers, around which adaptive management approaches could be developed, these are reactive, passive and active.\n</p><p>Adaptive management has probably been most frequently applied in Yap, <a href=\"https://en.wikipedia.org/wiki/Australia\">Australia</a> and <a href=\"https://en.wikipedia.org/wiki/North_America\">North America</a>, initially applied in <a href=\"https://en.wikipedia.org/wiki/Fishery\">fishery</a> management, but received more broad application in the 1990s and 2000s. One of the most successful applications of adaptive management has been in the area of waterfowl harvest management in North America, most notably for the <a href=\"https://en.wikipedia.org/wiki/Mallard\">mallard</a>.<sup><a href=\"#cite_note-6\">[6]</a></sup>\n</p><p>Adaptive management in a conservation project and program context can trace its roots back to at least the early 1990s, with the establishment of the Biodiversity Support Program (BSP)<sup><a href=\"#cite_note-7\">[7]</a></sup> in 1989. BSP was a <a href=\"http://www.usaid.gov/\">USAID</a>-funded consortium of WWF<sup><a href=\"#cite_note-8\">[8]</a></sup> The Nature Conservancy (TNC),<sup><a href=\"#cite_note-9\">[9]</a></sup> and World Resources Institute (WRI).<sup><a href=\"#cite_note-10\">[10]</a></sup> Its Analysis and Adaptive Management Program sought to understand the conditions under which certain conservation strategies were most effective and to identify lessons learned across conservation projects. When BSP ended in 2001, TNC and Foundations of Success<sup><a href=\"#cite_note-11\">[11]</a></sup> (FOS, a non-profit which grew out of BSP) continued to actively work in promoting adaptive management for conservation projects and programs. The approaches used included Conservation by Design<sup><a href=\"#cite_note-12\">[12]</a></sup> (TNC) and Measures of Success<sup><a href=\"#cite_note-13\">[13]</a></sup> (FOS).\n</p><p>In 2004, the Conservation Measures Partnership (CMP)<",
        "html": "<div><div>\n<p>From Wikipedia, the free encyclopedia</p>\n</div><div>\n<p><b>Adaptive management</b>, also known as <b>adaptive resource management</b> or <b>adaptive environmental assessment and management</b>, is a structured, <a href=\"https://en.wikipedia.org/wiki/Iteration\">iterative</a> process of robust <a href=\"https://en.wikipedia.org/wiki/Decision_making\">decision making</a> in the face of <a href=\"https://en.wikipedia.org/wiki/Uncertainty\">uncertainty</a>, with an aim to reducing uncertainty over time via <a href=\"https://en.wikipedia.org/wiki/System_monitoring\">system monitoring</a>. In this way, decision making simultaneously meets one or more <a href=\"https://en.wikipedia.org/wiki/Resource_management\">resource management</a> objectives and, either passively or actively, accrues information needed to improve future management. Adaptive management is a tool which should be used not only to change a system, but also to learn about the system.<sup><a href=\"#cite_note-:0-1\">[1]</a></sup> Because adaptive management is based on a learning process, it improves long-run management outcomes. The challenge in using the adaptive management approach lies in finding the correct balance between gaining knowledge to improve management in the future and achieving the best short-term outcome based on current knowledge.<sup><a href=\"#cite_note-2\">[2]</a></sup> This approach has more recently been employed in implementing <a href=\"https://en.wikipedia.org/wiki/International_development\">international development</a> programs.\n</p>\n<h2><span>Objectives</span><span><span>[</span><a href=\"https://en.wikipedia.org/w/index.php?title=Adaptive_management&amp;action=edit&amp;section=1\"><span>edit</span></a><span>]</span></span></h2>\n<p>There are a number of scientific and social processes which are vital components of adaptive management, including:\n</p>\n<ul><li>Management is linked to appropriate temporal and spatial scales</li>\n<li>Management retains a focus on <a href=\"https://en.wikipedia.org/wiki/Statistical_power\">statistical power</a> and controls</li>\n<li>Use of computer models to build synthesis and an embodied ecological consensus</li>\n<li>Use of embodied ecological consensus to evaluate strategic alternatives</li>\n<li>Communication of alternatives to political arena for negotiation of a selection</li></ul>\n<p>The achievement of these objectives requires an open management process which seeks to include past, present and future <a href=\"https://en.wikipedia.org/wiki/Stakeholder_(corporate)\">stakeholders</a>. Adaptive management needs to at least maintain <a href=\"https://en.wikipedia.org/wiki/Glasnost\">political openness</a>, but usually aims to create it. Adaptive management must therefore be a <a href=\"https://en.wikipedia.org/wiki/Scientific\">scientific</a> and social process. It must focus on the development of new <a href=\"https://en.wikipedia.org/wiki/Institutions\">institutions</a> and institutional strategies in balance with <a href=\"https://en.wikipedia.org/wiki/Scientific_hypothesis\">scientific hypothesis</a> and experimental frameworks (resilience.org).\n</p><p>Adaptive management can proceed as either passive or active adaptive management, depending on how learning takes place. Passive adaptive management values learning only insofar as it improves decision outcomes (i.e. passively), as measured by the specified utility function. In contrast, active adaptive management explicitly incorporates learning as part of the objective function, and hence, decisions which improve learning are valued over those which do not.<sup><a href=\"#cite_note-:0-1\">[1]</a></sup><sup><a href=\"#cite_note-:1-3\">[3]</a></sup> In both cases, as new knowledge is gained, the models are updated and optimal management strategies are derived accordingly. Thus, while learning occurs in both cases, it is treated differently. Often, deriving actively adaptive policies is technically very difficult, which prevents it being more commonly applied.<sup><a href=\"#cite_note-4\">[4]</a></sup>\n</p>\n<h2><span>Features</span><span><span>[</span><a href=\"https://en.wikipedia.org/w/index.php?title=Adaptive_management&amp;action=edit&amp;section=2\"><span>edit</span></a><span>]</span></span></h2>\n<p>Key features of both passive and active adaptive management are:\n</p>\n<ul><li>Iterative decision-making (evaluating results and adjusting actions on the basis of what has been learned)</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Feedback\">Feedback</a> between monitoring and decisions (learning)</li>\n<li>Explicit characterization of system uncertainty through multi-model inference</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Bayesian_inference\">Bayesian inference</a></li>\n<li>Embracing <a href=\"https://en.wikipedia.org/wiki/Risk\">risk</a> and uncertainty as a way of building understanding</li></ul>\n<p>However, a number of process failures related to information feedback can prevent effective adaptive management decision making:<sup><a href=\"#cite_note-5\">[5]</a></sup>\n</p>\n<ul><li><a href=\"https://en.wikipedia.org/wiki/Data_collection\">data collection</a> is never completely implemented</li>\n<li>data are collected but not analyzed</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Data_analysis\">data are analyzed</a> but results are inconclusive</li>\n<li>data are analyzed and are interesting, but are not presented to decision makers</li>\n<li>data are analyzed and presented, but are not used for decision-making because of internal or external factors</li></ul>\n<h2><span>History</span><span><span>[</span><a href=\"https://en.wikipedia.org/w/index.php?title=Adaptive_management&amp;action=edit&amp;section=3\"><span>edit</span></a><span>]</span></span></h2>\n<p>The use of adaptive management techniques can be traced back to peoples from ancient civilisations. For example, the <a href=\"https://en.wikipedia.org/wiki/Yap\">Yap</a> people of Micronesia have been using adaptive management techniques to sustain high <a href=\"https://en.wikipedia.org/wiki/Population_density\">population densities</a> in the face of resource scarcity for thousands of years (Falanruw 1984). In using these techniques, the Yap people have altered their environment creating, for example, coastal <a href=\"https://en.wikipedia.org/wiki/Mangrove\">mangrove</a> depressions and <a href=\"https://en.wikipedia.org/wiki/Seagrass_meadow\">seagrass meadows</a> to support fishing and termite resistant wood (Stankey and Shinder 1997).\n</p><p>The origin of the adaptive management concept can be traced back to ideas of <a href=\"https://en.wikipedia.org/wiki/Scientific_management\">scientific management</a> pioneered by <a href=\"https://en.wikipedia.org/wiki/Frederick_Winslow_Taylor\">Frederick Taylor</a> in the early 1900s (Haber 1964). While the term \"adaptive management\" evolved in natural resource management workshops through decision makers, managers and scientists focussing on building simulation models to uncover key assumptions and uncertainties (Bormann <i>et al.</i> 1999)\n</p><p>Two ecologists at The <a href=\"https://en.wikipedia.org/wiki/University_of_British_Columbia\">University of British Columbia</a>, <a href=\"https://en.wikipedia.org/wiki/C._S._Holling\">C.S. Holling</a><sup><a href=\"#cite_note-:0-1\">[1]</a></sup> and C.J Walters<sup><a href=\"#cite_note-:1-3\">[3]</a></sup> further developed the adaptive management approach as they distinguished between passive and active adaptive management practice. <a href=\"https://en.wikipedia.org/wiki/Kai_Lee\">Kai Lee</a>, notable Princeton physicist, expanded upon the approach in the late 1970s and early 1980s while pursuing a post-doctorate degree at UC <a href=\"https://en.wikipedia.org/wiki/Berkeley,_California\">Berkeley</a>. The approach was further developed at the International Institute for Applied Systems Analysis (IIASA) in <a href=\"https://en.wikipedia.org/wiki/Vienna\">Vienna</a>, <a href=\"https://en.wikipedia.org/wiki/Austria\">Austria</a>, while C.S. Holling was director of the institute. In 1992, Hilbourne described three learning models for federal land managers, around which adaptive management approaches could be developed, these are reactive, passive and active.\n</p><p>Adaptive management has probably been most frequently applied in Yap, <a href=\"https://en.wikipedia.org/wiki/Australia\">Australia</a> and <a href=\"https://en.wikipedia.org/wiki/North_America\">North America</a>, initially applied in <a href=\"https://en.wikipedia.org/wiki/Fishery\">fishery</a> management, but received more broad application in the 1990s and 2000s. One of the most successful applications of adaptive management has been in the area of waterfowl harvest management in North America, most notably for the <a href=\"https://en.wikipedia.org/wiki/Mallard\">mallard</a>.<sup><a href=\"#cite_note-6\">[6]</a></sup>\n</p><p>Adaptive management in a conservation project and program context can trace its roots back to at least the early 1990s, with the establishment of the Biodiversity Support Program (BSP)<sup><a href=\"#cite_note-7\">[7]</a></sup> in 1989. BSP was a <a href=\"http://www.usaid.gov/\">USAID</a>-funded consortium of WWF<sup><a href=\"#cite_note-8\">[8]</a></sup> The Nature Conservancy (TNC),<sup><a href=\"#cite_note-9\">[9]</a></sup> and World Resources Institute (WRI).<sup><a href=\"#cite_note-10\">[10]</a></sup> Its Analysis and Adaptive Management Program sought to understand the conditions under which certain conservation strategies were most effective and to identify lessons learned across conservation projects. When BSP ended in 2001, TNC and Foundations of Success<sup><a href=\"#cite_note-11\">[11]</a></sup> (FOS, a non-profit which grew out of BSP) continued to actively work in promoting adaptive management for conservation projects and programs. The approaches used included Conservation by Design<sup><a href=\"#cite_note-12\">[12]</a></sup> (TNC) and Measures of Success<sup><a href=\"#cite_note-13\">[13]</a></sup> (FOS).\n</p><p>In 2004, the Conservation Measures Partnership (CMP)<",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "From Wikipedia, the free encyclopediaAdaptive management, also known asadaptive resource managementoradaptive environmental assessment and management, is a structured,iterativeprocess of robustdecision makingin the face ofuncertainty, with an aim to reducing uncertainty over time viasystem monitoring. In this way, decision making simultaneously meets one or moreresource managementobjectives and, either passively or actively, accrues information needed to improve future management. Adaptive manag",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "From Wikipedia, the free encyclopedia",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Adaptive management, also known asadaptive resource managementoradaptive environmental assessment and management, is a structured,iterativeprocess of robustdecision makingin the face ofuncertainty, with an aim to reducing uncertainty over time viasystem monitoring. In this way, decision making simultaneously meets one or moreresource managementobjectives and, either passively or actively, accrues information needed to improve future management. Adaptive management is a tool which should be used ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Objectives[edit]",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Features[edit]",
              "id": ""
            },
            {
              "level": "h2",
              "text": "History[edit]",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://sebokwiki.org/wiki/Foundations_of_Systems_Engineering",
      "title": "Foundations of Systems Engineering - SEBoK",
      "author": "",
      "published_date": "2024-05-02T22:04:00.000Z",
      "content": {
        "text": "<div><div><hr/>\n<p><i><b>Lead Author:</b></i> <i>Rick Adcock</i>, <i><b>Contributing Authors:</b></i> <i>Scott Jackson, Janet Singer, Duane Hybertson, Gary Smith</i>\n</p>\n<hr/>\n<p>Part 2 of the Guide to the SE Body of Knowledge (SEBoK) is a guide to foundational knowledge which is relevant or useful to <span><a href=\"https://sebokwiki.org/wiki/Systems_Engineering_(glossary)\"><span>systems engineering</span></a></span><span>systems engineering</span> (SE).\n</p>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SEBoK_Context_Diagram_Inner_P2_Ifezue_Obiako.png\"></a></p></div>\n<p>This knowledge is included in the SEBoK firstly to help <span><a href=\"https://sebokwiki.org/wiki/Systems_Engineer_(glossary)\"><span>systems engineers</span></a></span><span>systems engineers</span> benefit from an understanding of the foundations of their discipline, and to provide them with access to some of the theories and practices of <span><a href=\"https://sebokwiki.org/wiki/Systems_Science_(glossary)\"><span>systems science</span></a></span><span>systems science</span> and other fields of systems practice. Including this wider integrative systems science context in the SEBoK should also help to make SE knowledge more accessible to a wider audience outside of its traditional <span><a href=\"https://sebokwiki.org/wiki/Domain_(glossary)\"><span>domains</span></a></span><span>domains</span>.\n</p>\n<h2><span>Knowledge Areas in Part 2</span></h2>\n<p>Each part of the SEBoK is divided into knowledge areas (KAs), which are groupings of information with a related theme. Part 2 contains the following KAs:\n</p>\n<ul><li><a href=\"https://sebokwiki.org/wiki/Systems_Fundamentals\">Systems Fundamentals</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/The_Nature_of_Systems\">The Nature of Systems</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Systems_Science\">Systems Science</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Systems_Thinking\">Systems Thinking</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Representing_Systems_with_Models\">Representing Systems with Models</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Systems_Approach_Applied_to_Engineered_Systems\">Systems Approach Applied to Engineered Systems</a></li></ul>\n<h2><span>Introduction</span></h2>\n<p>Most systems engineers are practitioners, applying <span><a href=\"https://sebokwiki.org/wiki/Process_(glossary)\"><span>processes</span></a></span><span>processes</span> and methods that have been developed and evolved over decades. SE is a pragmatic approach, inherently interdisciplinary, yet specialized. Systems engineers usually work within a specific domain using processes and methods that are tailored to their domain’s unique <span><a href=\"https://sebokwiki.org/wiki/Problem_(glossary)\"><span>problems</span></a></span><span>problems</span>, <span><a href=\"https://sebokwiki.org/wiki/Constraint_(glossary)\"><span>constraints</span></a></span><span>constraints</span>, <span><a href=\"https://sebokwiki.org/wiki/Risk_(glossary)\"><span>risks</span></a></span><span>risks</span> and <span><a href=\"https://sebokwiki.org/wiki/Opportunity_(glossary)\"><span>opportunities</span></a></span><span>opportunities</span>. These processes and methods have evolved to capture domain experts’ knowledge regarding the best approach to applying SE to the particular domain.\n</p><p>Specific domains in which <span><a href=\"https://sebokwiki.org/wiki/Systems_Approach_(glossary)\"><span>systems approaches</span></a></span><span>systems approaches</span> are used and adapted include:\n</p>\n<ul><li>Technology products, integrating multiple <span><a href=\"https://sebokwiki.org/wiki/Engineering_(glossary)\"><span>engineering</span></a></span><span>engineering</span> disciplines</li>\n<li>Information-rich systems, e.g. command &amp; control, air traffic management, etc.</li>\n<li>Platforms, e.g. aircraft, civil airliners, cars, trains, etc.</li>\n<li>Organizational and enterprise systems, which may be focused on delivering service or capability</li>\n<li>Civil engineering/infrastructure systems, e.g. roads networks, bridges, builds, communications networks, etc.</li></ul>\n<p>The specific skill-sets for each domain, and the kinds and scales of system it considers, may be quite different. However, there are certain underlying unifying systems principles that can improve the effectiveness of the systems approach in any domain. In particular, shared knowledge of systems principles and terminology will enable communication and improve system engineers’ ability to integrate <span><a href=\"https://sebokwiki.org/wiki/Complex_(glossary)\"><span>complex</span></a></span><span>complex</span> systems that span traditional domain <span><a href=\"https://sebokwiki.org/wiki/Boundary_(glossary)\"><span>boundaries</span></a></span><span>boundaries</span> (Sillitto 2012). This integrated approach is increasingly needed to solve today’s complex system challenges, but as these different communities come together, they may find that assumptions underpinning their worldviews are not shared.\n</p>\n<h2><span>General Systems Engineering Foundations</span></h2>\n<p>To bridge the gap between different domains and communities of practice, it is important to first establish a well-grounded definition of the “intellectual foundations of systems engineering,” as well as a common language to describe the relevant <span><a href=\"https://sebokwiki.org/wiki/Concept_(glossary)\"><span>concepts</span></a></span><span>concepts</span> and <span><a href=\"https://sebokwiki.org/wiki/Paradigm_(glossary)\"><span>paradigms</span></a></span><span>paradigms</span>. An integrated systems approach for solving complex problems needs to combine elements of systems theories and systems approaches to practice. This may range from the technical-systems focus that has been dominant in systems engineering to the learning-systems focus of social systems intervention. An integrated systems approach needs to provide a framework and language that allow different communities with highly divergent worldviews and skill sets to work together for a common <span><a href=\"https://sebokwiki.org/wiki/Purpose_(glossary)\"><span>purpose</span></a></span><span>purpose</span>.\n</p><p>The SEBoK as a whole aims to provide principles and concepts which can be used to support all potential applications of systems engineering, and which can be easily translated to any particular application by the reader. Often the published knowledge related to systems engineering has been developed from particular application areas, typically combinations of applications like defense, transport, or medical, business models such as government, commercial or voluntary or technology domains such as mechanical, electrical or cyber. In publishing it, authors will make some effort to <b>specialize</b> it into knowledge which can be applied across related applications.\n</p><p>In the SEBoK, we seek to find or create <b>general</b> descriptions of SE knowledge. A general description should cover all applications of systems engineering and should include an explanation of the special cases it covers and how it applied to them. The generalization of knowledge can be informal, providing coverage of the most common specializations or being the domains current best understanding of the general case. A truly general description must be based upon stronger theoretical considerations and be in some sense proven to predict and cover all special cases. Knowledge described in the SEBoK will usually be informally generalized knowledge, with any specific knowledge being identified as such and related to the general as appropriate.\n</p><p>The INCOSE Vision 2025 includes an aim for systems engineering to be become a discipline with a formally defined theoretical basis. Such a general theory of SE would be largely included in SEBoK Part 2. The current SEBoK part 2 does not include such a theory. It provides generalized descriptions of foundational knowledge which has a pragmatic value to help describe and improve the current and future practice of systems engineering. We would expect any emerging general theory of systems engineering to draw from and expand these foundations. As such a theory is defined, it will be included in Part 2 of the SEBoK.\n</p>\n<h2><span>The Systems Praxis Framework</span></h2>\n<p>The term <b>“systems praxis”</b> refers to the entire intellectual and practical endeavor for creating <span><a href=\"https://sebokwiki.org/wiki/Holistic_(glossary)\"><span>holistic</span></a></span><span>holistic</span> solutions to today’s complex system challenges. <span><a href=\"https://sebokwiki.org/wiki/Praxis_(glossary)\"><span>Praxis</span></a></span><span>Praxis</span> is defined as “translating an idea into action” (Wordnet 2012) and suggests that the best holistic approach to a given complex challenge may require integrating appropriate theory and appropriate practice from a wide variety of sources. Systems praxis requires many communities to work together. To work together we must first communicate; and to communicate, we must first connect.\n</p><p>A framework for unifying systems praxis was developed by members of International Council on Systems Engineering (INCOSE) and International Society for the System Sciences (ISSS) (International Federation for Systems Research (IFSR) 2012)) as the first step towards a “common language for systems praxis”. This <b>Systems Praxis Framework</b> is included here because it represents current thinking on the foundations and common language of systems engineering, making the concepts and principles of systems thinking and practice accessible to anyone applying a systems approach to <span><a href=\"https://sebokwiki.org/wiki/Engineered_System_(glossary)\"><span>engineered system</span></a></span><span>engineered system</span> problems. This framework and thinking have been used to help organize the guide to systems knowledge in the SEBoK.\n</p><p>The diagram below shows the flows and interconnections among element",
        "html": "<div><div><hr/>\n<p><i><b>Lead Author:</b></i> <i>Rick Adcock</i>, <i><b>Contributing Authors:</b></i> <i>Scott Jackson, Janet Singer, Duane Hybertson, Gary Smith</i>\n</p>\n<hr/>\n<p>Part 2 of the Guide to the SE Body of Knowledge (SEBoK) is a guide to foundational knowledge which is relevant or useful to <span><a href=\"https://sebokwiki.org/wiki/Systems_Engineering_(glossary)\"><span>systems engineering</span></a></span><span>systems engineering</span> (SE).\n</p>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SEBoK_Context_Diagram_Inner_P2_Ifezue_Obiako.png\"></a></p></div>\n<p>This knowledge is included in the SEBoK firstly to help <span><a href=\"https://sebokwiki.org/wiki/Systems_Engineer_(glossary)\"><span>systems engineers</span></a></span><span>systems engineers</span> benefit from an understanding of the foundations of their discipline, and to provide them with access to some of the theories and practices of <span><a href=\"https://sebokwiki.org/wiki/Systems_Science_(glossary)\"><span>systems science</span></a></span><span>systems science</span> and other fields of systems practice. Including this wider integrative systems science context in the SEBoK should also help to make SE knowledge more accessible to a wider audience outside of its traditional <span><a href=\"https://sebokwiki.org/wiki/Domain_(glossary)\"><span>domains</span></a></span><span>domains</span>.\n</p>\n<h2><span>Knowledge Areas in Part 2</span></h2>\n<p>Each part of the SEBoK is divided into knowledge areas (KAs), which are groupings of information with a related theme. Part 2 contains the following KAs:\n</p>\n<ul><li><a href=\"https://sebokwiki.org/wiki/Systems_Fundamentals\">Systems Fundamentals</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/The_Nature_of_Systems\">The Nature of Systems</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Systems_Science\">Systems Science</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Systems_Thinking\">Systems Thinking</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Representing_Systems_with_Models\">Representing Systems with Models</a></li>\n<li><a href=\"https://sebokwiki.org/wiki/Systems_Approach_Applied_to_Engineered_Systems\">Systems Approach Applied to Engineered Systems</a></li></ul>\n<h2><span>Introduction</span></h2>\n<p>Most systems engineers are practitioners, applying <span><a href=\"https://sebokwiki.org/wiki/Process_(glossary)\"><span>processes</span></a></span><span>processes</span> and methods that have been developed and evolved over decades. SE is a pragmatic approach, inherently interdisciplinary, yet specialized. Systems engineers usually work within a specific domain using processes and methods that are tailored to their domain’s unique <span><a href=\"https://sebokwiki.org/wiki/Problem_(glossary)\"><span>problems</span></a></span><span>problems</span>, <span><a href=\"https://sebokwiki.org/wiki/Constraint_(glossary)\"><span>constraints</span></a></span><span>constraints</span>, <span><a href=\"https://sebokwiki.org/wiki/Risk_(glossary)\"><span>risks</span></a></span><span>risks</span> and <span><a href=\"https://sebokwiki.org/wiki/Opportunity_(glossary)\"><span>opportunities</span></a></span><span>opportunities</span>. These processes and methods have evolved to capture domain experts’ knowledge regarding the best approach to applying SE to the particular domain.\n</p><p>Specific domains in which <span><a href=\"https://sebokwiki.org/wiki/Systems_Approach_(glossary)\"><span>systems approaches</span></a></span><span>systems approaches</span> are used and adapted include:\n</p>\n<ul><li>Technology products, integrating multiple <span><a href=\"https://sebokwiki.org/wiki/Engineering_(glossary)\"><span>engineering</span></a></span><span>engineering</span> disciplines</li>\n<li>Information-rich systems, e.g. command &amp; control, air traffic management, etc.</li>\n<li>Platforms, e.g. aircraft, civil airliners, cars, trains, etc.</li>\n<li>Organizational and enterprise systems, which may be focused on delivering service or capability</li>\n<li>Civil engineering/infrastructure systems, e.g. roads networks, bridges, builds, communications networks, etc.</li></ul>\n<p>The specific skill-sets for each domain, and the kinds and scales of system it considers, may be quite different. However, there are certain underlying unifying systems principles that can improve the effectiveness of the systems approach in any domain. In particular, shared knowledge of systems principles and terminology will enable communication and improve system engineers’ ability to integrate <span><a href=\"https://sebokwiki.org/wiki/Complex_(glossary)\"><span>complex</span></a></span><span>complex</span> systems that span traditional domain <span><a href=\"https://sebokwiki.org/wiki/Boundary_(glossary)\"><span>boundaries</span></a></span><span>boundaries</span> (Sillitto 2012). This integrated approach is increasingly needed to solve today’s complex system challenges, but as these different communities come together, they may find that assumptions underpinning their worldviews are not shared.\n</p>\n<h2><span>General Systems Engineering Foundations</span></h2>\n<p>To bridge the gap between different domains and communities of practice, it is important to first establish a well-grounded definition of the “intellectual foundations of systems engineering,” as well as a common language to describe the relevant <span><a href=\"https://sebokwiki.org/wiki/Concept_(glossary)\"><span>concepts</span></a></span><span>concepts</span> and <span><a href=\"https://sebokwiki.org/wiki/Paradigm_(glossary)\"><span>paradigms</span></a></span><span>paradigms</span>. An integrated systems approach for solving complex problems needs to combine elements of systems theories and systems approaches to practice. This may range from the technical-systems focus that has been dominant in systems engineering to the learning-systems focus of social systems intervention. An integrated systems approach needs to provide a framework and language that allow different communities with highly divergent worldviews and skill sets to work together for a common <span><a href=\"https://sebokwiki.org/wiki/Purpose_(glossary)\"><span>purpose</span></a></span><span>purpose</span>.\n</p><p>The SEBoK as a whole aims to provide principles and concepts which can be used to support all potential applications of systems engineering, and which can be easily translated to any particular application by the reader. Often the published knowledge related to systems engineering has been developed from particular application areas, typically combinations of applications like defense, transport, or medical, business models such as government, commercial or voluntary or technology domains such as mechanical, electrical or cyber. In publishing it, authors will make some effort to <b>specialize</b> it into knowledge which can be applied across related applications.\n</p><p>In the SEBoK, we seek to find or create <b>general</b> descriptions of SE knowledge. A general description should cover all applications of systems engineering and should include an explanation of the special cases it covers and how it applied to them. The generalization of knowledge can be informal, providing coverage of the most common specializations or being the domains current best understanding of the general case. A truly general description must be based upon stronger theoretical considerations and be in some sense proven to predict and cover all special cases. Knowledge described in the SEBoK will usually be informally generalized knowledge, with any specific knowledge being identified as such and related to the general as appropriate.\n</p><p>The INCOSE Vision 2025 includes an aim for systems engineering to be become a discipline with a formally defined theoretical basis. Such a general theory of SE would be largely included in SEBoK Part 2. The current SEBoK part 2 does not include such a theory. It provides generalized descriptions of foundational knowledge which has a pragmatic value to help describe and improve the current and future practice of systems engineering. We would expect any emerging general theory of systems engineering to draw from and expand these foundations. As such a theory is defined, it will be included in Part 2 of the SEBoK.\n</p>\n<h2><span>The Systems Praxis Framework</span></h2>\n<p>The term <b>“systems praxis”</b> refers to the entire intellectual and practical endeavor for creating <span><a href=\"https://sebokwiki.org/wiki/Holistic_(glossary)\"><span>holistic</span></a></span><span>holistic</span> solutions to today’s complex system challenges. <span><a href=\"https://sebokwiki.org/wiki/Praxis_(glossary)\"><span>Praxis</span></a></span><span>Praxis</span> is defined as “translating an idea into action” (Wordnet 2012) and suggests that the best holistic approach to a given complex challenge may require integrating appropriate theory and appropriate practice from a wide variety of sources. Systems praxis requires many communities to work together. To work together we must first communicate; and to communicate, we must first connect.\n</p><p>A framework for unifying systems praxis was developed by members of International Council on Systems Engineering (INCOSE) and International Society for the System Sciences (ISSS) (International Federation for Systems Research (IFSR) 2012)) as the first step towards a “common language for systems praxis”. This <b>Systems Praxis Framework</b> is included here because it represents current thinking on the foundations and common language of systems engineering, making the concepts and principles of systems thinking and practice accessible to anyone applying a systems approach to <span><a href=\"https://sebokwiki.org/wiki/Engineered_System_(glossary)\"><span>engineered system</span></a></span><span>engineered system</span> problems. This framework and thinking have been used to help organize the guide to systems knowledge in the SEBoK.\n</p><p>The diagram below shows the flows and interconnections among element",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Lead Author:Rick Adcock,Contributing Authors:Scott Jackson, Janet Singer, Duane Hybertson, Gary SmithPart 2 of the Guide to the SE Body of Knowledge (SEBoK) is a guide to foundational knowledge which is relevant or useful tosystems engineeringsystems engineering(SE).This knowledge is included in the SEBoK firstly to helpsystems engineerssystems engineersbenefit from an understanding of the foundations of their discipline, and to provide them with access to some of the theories and practices ofsy",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Lead Author:Rick Adcock,Contributing Authors:Scott Jackson, Janet Singer, Duane Hybertson, Gary SmithPart 2 of the Guide to the SE Body of Knowledge (SEBoK) is a guide to foundational knowledge which is relevant or useful tosystems engineeringsystems engineering(SE).This knowledge is included in the SEBoK firstly to helpsystems engineerssystems engineersbenefit from an understanding of the foundations of their discipline, and to provide them with access to some of the theories and practices ofsy",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Knowledge Areas in Part 2",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "General Systems Engineering Foundations",
              "id": ""
            },
            {
              "level": "h2",
              "text": "The Systems Praxis Framework",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.linkedin.com/pulse/structural-coupling-biological-construct-development-mrizek-mba",
      "title": "Structural Coupling: A Biological Construct for Organizational Development",
      "author": "Jeffrey Mrizek, EdD, MBA",
      "published_date": "2018-03-08T03:12:35.000Z",
      "content": {
        "text": "<div><div>\n<div>\n<article>\n<figure>\n</figure>\n<header>\n<div>\n<p><a href=\"https://www.linkedin.com/in/jmrizek\">\n<span>\nJeffrey Mrizek, EdD, MBA\n</span>\n</a></p><div>\n<h3>\nJeffrey Mrizek, EdD, MBA\n</h3>\n<h4>\n5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento President\n</h4>\n<p>\nPublished Jan 6, 2016\n</p>\n</div>\n</div>\n</header>\n<div><div><p>The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruence between two (or more) systems (p.75).\" While their focus was to describe the biological nature of cellular unity (the balance between internal dynamics and boundaries of cellular structures); the model presented in this simple diagram presents a strong framework for the field of organizational behavior. Specifically, when considering system alignments between discrete but interrelated systems.</p><p>Systems thinking is a hallmark of the field of organizational behavior; often organizations are understood as living entities (a dialectical culture of work). Thus the application of a biological paradigm can be understood by describing any organization, as an organism with a cellular structure having both internal process (functions) and permeable boundaries (inputs and outputs). This conceptualization is a departure from the traditional concepts of bureaucratic organization charts (pyramids).</p><p>The power of this cellular model of organization is the ability to describe system alignments based on the shared and mutual exchanges of inputs and outputs, The extent to which these dialectical exchanges have a heightened degree of \"shared meaning\" is in direct relationship to each \"cell's\" ability to meet its \"unity.\" This is to say, the organization(s) become more sustainable and tolerant of environmental shifts. </p><p>Systems which can align dialectically into mutual reinforcing relationship will find the nature of their structural coupling to be a highly integrated complex network of perturbations (state changes) that produce beneficial adaptations in response to environmental changes. The opposite is also true, those systems which produce destructive interactions will find their cellular unity to be unsustainable. Thus, structural coupling as a model is descriptive of a sustainability model for system alignments when devising organizational change in response to major environmental shifts. </p></div>\n<p>Source: (Manturana &amp; Varela,1987)</p>\n</div>\n</article>\n<section>\n<h2>\nMore articles by Jeffrey Mrizek, EdD, MBA\n</h2>\n<div>\n<ul>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/leadership-paradox-hardened-heart-finding-balance-mrizek-edd-mba-eehec\">\n<span>\nThe Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassion\n</span>\n</a></p>\n<div>\n<p><span>Dec 26, 2024</span>\n</p>\n<h3>\nThe Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassion\n</h3>\n<p>\nby Dr. Jeffrey Mrizek In leadership discourse, we often encounter seemingly contradictory advice.\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/zip-code-lottery-how-geography-race-determine-destiny-mrizek-edd-jbhxc\">\n<span>\nThe Zip Code Lottery: How Geography and Race Determine Destiny in America\n</span>\n</a></p>\n<div>\n<p><span>Aug 7, 2024</span>\n</p>\n<h3>\nThe Zip Code Lottery: How Geography and Race Determine Destiny in America\n</h3>\n<p>\nAugust 2024 by Jeffrey Mrizek, EdD @jmrizek Imagine two children born on the same day, just miles apart. One enters a…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/dawn-reality-revolution-2024-jeffrey-mrizek-edd-3ubgf\">\n<span>\nDawn of the Reality Revolution (2024)\n</span>\n</a></p>\n<div>\n<p><span>Apr 25, 2024</span>\n</p>\n<h3>\nDawn of the Reality Revolution (2024)\n</h3>\n<p>\nThe bravest are surely those who have the clearest vision of what is before them, glory and danger alike, and yet…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/harmony-beyond-borders-psychology-philosophy-love-jeffrey-mrizek-edd-qewcc\">\n<span>\nHarmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural Unions\n</span>\n</a></p>\n<div>\n<p><span>Mar 26, 2024</span>\n</p>\n<h3>\nHarmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural Unions\n</h3>\n<p>\nBy Dr. Jeffrey Mrizek Human social interactions are intricate and multifaceted, influenced by both psychological and…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/meta-social-dynamics-reality-formation-in-between-digital-mrizek-c2tef\">\n<span>\nMeta-Social Dynamics: Reality formation in-between digital and social landscapes\n</span>\n</a></p>\n<div>\n<p><span>Dec 19, 2023</span>\n</p>\n<h3>\nMeta-Social Dynamics: Reality formation in-between digital and social landscapes\n</h3>\n<p>\nHuman relationships are grounded in the concept of the meta-, a Greek preposition meaning, \"beside\" \"with\" or \"among.\"…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/call-action-leading-third-sector-social-renaissance-mrizek-ed-d-\">\n<span>\nCall to Action: Leading the Third Sector Social Renaissance\n</span>\n</a></p>\n<div>\n<p><span>Oct 8, 2020</span>\n</p>\n<h3>\nCall to Action: Leading the Third Sector Social Renaissance\n</h3>\n<p>\n\"Social Renaissance\" defines a process aimed at spreading awareness about the growing weight of the “marginalities,”…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/why-self-advocacy-overcomes-stigma-jeffrey-mrizek-ed-d-\">\n<span>\nWhy Self-Advocacy overcomes Stigma...\n</span>\n</a></p>\n<div>\n<p><span>Sep 21, 2020</span>\n</p>\n<h3>\nWhy Self-Advocacy overcomes Stigma...\n</h3>\n<p>\nAccording to Erving Goffman (1963), Stigma is the phenomenon whereby an individual with an attribute which is deeply…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/effective-adaptive-leadership-practices-innovation-mrizek-ed-d-\">\n<span>\nEffective Adaptive Leadership Practices from Innovation to Implementation\n</span>\n</a></p>\n<div>\n<p><span>May 14, 2019</span>\n</p>\n<h3>\nEffective Adaptive Leadership Practices from Innovation to Implementation\n</h3>\n<p>\nWe often speak of networks and ecosystems as frameworks for complex adaptive systems. This is especially common in the…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/zillow-group-consumer-housing-trends-report-2018-time-mrizek-ed-d-\">\n<span>\nZillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First Time\n</span>\n</a></p>\n<div>\n<p><span>Apr 11, 2019</span>\n</p>\n<h3>\nZillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First Time\n</h3>\n<p>\nMillennials, who already account for nearly half of all home purchases in 2018, are becoming an increasingly large…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/global-urban-nomads-reflection-compassionate-jeffrey-mrizek-ed-d-\">\n<span>\nA Global Urban Nomad's Reflection on Compassionate Leadership\n</span>\n</a></p>\n<div>\n<p><span>Mar 28, 2019</span>\n</p>\n<h3>\nA Global Urban Nomad's Reflection on Compassionate Leadership\n</h3>\n<p>\nThe endless questions into the matters of the heart are perhaps the most complex condition of human nature. The…\n</p>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</section>\n</div>\n<section>\n<section>\n<h2>\nInsights from the community\n</h2>\n</section>\n<section>\n<h2>\nExplore topics\n</h2>\n</section>\n</section>\n</div></div>",
        "html": "<div><div>\n<div>\n<article>\n<figure>\n</figure>\n<header>\n<div>\n<p><a href=\"https://www.linkedin.com/in/jmrizek\">\n<span>\nJeffrey Mrizek, EdD, MBA\n</span>\n</a></p><div>\n<h3>\nJeffrey Mrizek, EdD, MBA\n</h3>\n<h4>\n5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento President\n</h4>\n<p>\nPublished Jan 6, 2016\n</p>\n</div>\n</div>\n</header>\n<div><div><p>The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruence between two (or more) systems (p.75).\" While their focus was to describe the biological nature of cellular unity (the balance between internal dynamics and boundaries of cellular structures); the model presented in this simple diagram presents a strong framework for the field of organizational behavior. Specifically, when considering system alignments between discrete but interrelated systems.</p><p>Systems thinking is a hallmark of the field of organizational behavior; often organizations are understood as living entities (a dialectical culture of work). Thus the application of a biological paradigm can be understood by describing any organization, as an organism with a cellular structure having both internal process (functions) and permeable boundaries (inputs and outputs). This conceptualization is a departure from the traditional concepts of bureaucratic organization charts (pyramids).</p><p>The power of this cellular model of organization is the ability to describe system alignments based on the shared and mutual exchanges of inputs and outputs, The extent to which these dialectical exchanges have a heightened degree of \"shared meaning\" is in direct relationship to each \"cell's\" ability to meet its \"unity.\" This is to say, the organization(s) become more sustainable and tolerant of environmental shifts. </p><p>Systems which can align dialectically into mutual reinforcing relationship will find the nature of their structural coupling to be a highly integrated complex network of perturbations (state changes) that produce beneficial adaptations in response to environmental changes. The opposite is also true, those systems which produce destructive interactions will find their cellular unity to be unsustainable. Thus, structural coupling as a model is descriptive of a sustainability model for system alignments when devising organizational change in response to major environmental shifts. </p></div>\n<p>Source: (Manturana &amp; Varela,1987)</p>\n</div>\n</article>\n<section>\n<h2>\nMore articles by Jeffrey Mrizek, EdD, MBA\n</h2>\n<div>\n<ul>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/leadership-paradox-hardened-heart-finding-balance-mrizek-edd-mba-eehec\">\n<span>\nThe Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassion\n</span>\n</a></p>\n<div>\n<p><span>Dec 26, 2024</span>\n</p>\n<h3>\nThe Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassion\n</h3>\n<p>\nby Dr. Jeffrey Mrizek In leadership discourse, we often encounter seemingly contradictory advice.\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/zip-code-lottery-how-geography-race-determine-destiny-mrizek-edd-jbhxc\">\n<span>\nThe Zip Code Lottery: How Geography and Race Determine Destiny in America\n</span>\n</a></p>\n<div>\n<p><span>Aug 7, 2024</span>\n</p>\n<h3>\nThe Zip Code Lottery: How Geography and Race Determine Destiny in America\n</h3>\n<p>\nAugust 2024 by Jeffrey Mrizek, EdD @jmrizek Imagine two children born on the same day, just miles apart. One enters a…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/dawn-reality-revolution-2024-jeffrey-mrizek-edd-3ubgf\">\n<span>\nDawn of the Reality Revolution (2024)\n</span>\n</a></p>\n<div>\n<p><span>Apr 25, 2024</span>\n</p>\n<h3>\nDawn of the Reality Revolution (2024)\n</h3>\n<p>\nThe bravest are surely those who have the clearest vision of what is before them, glory and danger alike, and yet…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/harmony-beyond-borders-psychology-philosophy-love-jeffrey-mrizek-edd-qewcc\">\n<span>\nHarmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural Unions\n</span>\n</a></p>\n<div>\n<p><span>Mar 26, 2024</span>\n</p>\n<h3>\nHarmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural Unions\n</h3>\n<p>\nBy Dr. Jeffrey Mrizek Human social interactions are intricate and multifaceted, influenced by both psychological and…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/meta-social-dynamics-reality-formation-in-between-digital-mrizek-c2tef\">\n<span>\nMeta-Social Dynamics: Reality formation in-between digital and social landscapes\n</span>\n</a></p>\n<div>\n<p><span>Dec 19, 2023</span>\n</p>\n<h3>\nMeta-Social Dynamics: Reality formation in-between digital and social landscapes\n</h3>\n<p>\nHuman relationships are grounded in the concept of the meta-, a Greek preposition meaning, \"beside\" \"with\" or \"among.\"…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/call-action-leading-third-sector-social-renaissance-mrizek-ed-d-\">\n<span>\nCall to Action: Leading the Third Sector Social Renaissance\n</span>\n</a></p>\n<div>\n<p><span>Oct 8, 2020</span>\n</p>\n<h3>\nCall to Action: Leading the Third Sector Social Renaissance\n</h3>\n<p>\n\"Social Renaissance\" defines a process aimed at spreading awareness about the growing weight of the “marginalities,”…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/why-self-advocacy-overcomes-stigma-jeffrey-mrizek-ed-d-\">\n<span>\nWhy Self-Advocacy overcomes Stigma...\n</span>\n</a></p>\n<div>\n<p><span>Sep 21, 2020</span>\n</p>\n<h3>\nWhy Self-Advocacy overcomes Stigma...\n</h3>\n<p>\nAccording to Erving Goffman (1963), Stigma is the phenomenon whereby an individual with an attribute which is deeply…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/effective-adaptive-leadership-practices-innovation-mrizek-ed-d-\">\n<span>\nEffective Adaptive Leadership Practices from Innovation to Implementation\n</span>\n</a></p>\n<div>\n<p><span>May 14, 2019</span>\n</p>\n<h3>\nEffective Adaptive Leadership Practices from Innovation to Implementation\n</h3>\n<p>\nWe often speak of networks and ecosystems as frameworks for complex adaptive systems. This is especially common in the…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/zillow-group-consumer-housing-trends-report-2018-time-mrizek-ed-d-\">\n<span>\nZillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First Time\n</span>\n</a></p>\n<div>\n<p><span>Apr 11, 2019</span>\n</p>\n<h3>\nZillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First Time\n</h3>\n<p>\nMillennials, who already account for nearly half of all home purchases in 2018, are becoming an increasingly large…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/global-urban-nomads-reflection-compassionate-jeffrey-mrizek-ed-d-\">\n<span>\nA Global Urban Nomad's Reflection on Compassionate Leadership\n</span>\n</a></p>\n<div>\n<p><span>Mar 28, 2019</span>\n</p>\n<h3>\nA Global Urban Nomad's Reflection on Compassionate Leadership\n</h3>\n<p>\nThe endless questions into the matters of the heart are perhaps the most complex condition of human nature. The…\n</p>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</section>\n</div>\n<section>\n<section>\n<h2>\nInsights from the community\n</h2>\n</section>\n<section>\n<h2>\nExplore topics\n</h2>\n</section>\n</section>\n</div></div>",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Jeffrey Mrizek, EdD, MBAJeffrey Mrizek, EdD, MBA5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento PresidentPublished Jan 6, 2016The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruenc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jeffrey Mrizek, EdD, MBAJeffrey Mrizek, EdD, MBA5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento PresidentPublished Jan 6, 2016The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruenc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jeffrey Mrizek, EdD, MBAJeffrey Mrizek, EdD, MBA5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento PresidentPublished Jan 6, 2016The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruenc",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "Jeffrey Mrizek, EdD, MBAJeffrey Mrizek, EdD, MBA5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento PresidentPublished Jan 6, 2016The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruenc",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jeffrey Mrizek, EdD, MBAJeffrey Mrizek, EdD, MBA5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento PresidentPublished Jan 6, 2016",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jeffrey Mrizek, EdD, MBA5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento PresidentPublished Jan 6, 2016",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruence between two (or more) systems (p.75).\" While their focus was to describe the biological nature of cellular unity (the balance between internal dynamics and boundaries of cellular structures); the model presented in this simple diagram presents a strong framework for the field of orga",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The concept of structural coupling as presented by Humberto Maturana and Francisco Varela's book, The Tree of Knowledge (1987), is defined as \"a history of recurrent interactions leading to the structural congruence between two (or more) systems (p.75).\" While their focus was to describe the biological nature of cellular unity (the balance between internal dynamics and boundaries of cellular structures); the model presented in this simple diagram presents a strong framework for the field of orga",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "More articles by Jeffrey Mrizek, EdD, MBAThe Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and CompassionDec 26, 2024The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassionby Dr. Jeffrey Mrizek In leadership discourse, we often encounter seemingly contradictory advice.The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAug 7, 2024The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAugust ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and CompassionDec 26, 2024The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassionby Dr. Jeffrey Mrizek In leadership discourse, we often encounter seemingly contradictory advice.The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAug 7, 2024The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAugust 2024 by Jeffrey Mrizek, EdD @jmrizek Imag",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and CompassionDec 26, 2024The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassionby Dr. Jeffrey Mrizek In leadership discourse, we often encounter seemingly contradictory advice.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dec 26, 2024The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassionby Dr. Jeffrey Mrizek In leadership discourse, we often encounter seemingly contradictory advice.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAug 7, 2024The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAugust 2024 by Jeffrey Mrizek, EdD @jmrizek Imagine two children born on the same day, just miles apart. One enters a…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Aug 7, 2024The Zip Code Lottery: How Geography and Race Determine Destiny in AmericaAugust 2024 by Jeffrey Mrizek, EdD @jmrizek Imagine two children born on the same day, just miles apart. One enters a…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dawn of the Reality Revolution (2024)Apr 25, 2024Dawn of the Reality Revolution (2024)The bravest are surely those who have the clearest vision of what is before them, glory and danger alike, and yet…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Apr 25, 2024Dawn of the Reality Revolution (2024)The bravest are surely those who have the clearest vision of what is before them, glory and danger alike, and yet…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Harmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural UnionsMar 26, 2024Harmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural UnionsBy Dr. Jeffrey Mrizek Human social interactions are intricate and multifaceted, influenced by both psychological and…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mar 26, 2024Harmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural UnionsBy Dr. Jeffrey Mrizek Human social interactions are intricate and multifaceted, influenced by both psychological and…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Meta-Social Dynamics: Reality formation in-between digital and social landscapesDec 19, 2023Meta-Social Dynamics: Reality formation in-between digital and social landscapesHuman relationships are grounded in the concept of the meta-, a Greek preposition meaning, \"beside\" \"with\" or \"among.\"…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dec 19, 2023Meta-Social Dynamics: Reality formation in-between digital and social landscapesHuman relationships are grounded in the concept of the meta-, a Greek preposition meaning, \"beside\" \"with\" or \"among.\"…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Call to Action: Leading the Third Sector Social RenaissanceOct 8, 2020Call to Action: Leading the Third Sector Social Renaissance\"Social Renaissance\" defines a process aimed at spreading awareness about the growing weight of the “marginalities,”…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Oct 8, 2020Call to Action: Leading the Third Sector Social Renaissance\"Social Renaissance\" defines a process aimed at spreading awareness about the growing weight of the “marginalities,”…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Why Self-Advocacy overcomes Stigma...Sep 21, 2020Why Self-Advocacy overcomes Stigma...According to Erving Goffman (1963), Stigma is the phenomenon whereby an individual with an attribute which is deeply…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Sep 21, 2020Why Self-Advocacy overcomes Stigma...According to Erving Goffman (1963), Stigma is the phenomenon whereby an individual with an attribute which is deeply…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Effective Adaptive Leadership Practices from Innovation to ImplementationMay 14, 2019Effective Adaptive Leadership Practices from Innovation to ImplementationWe often speak of networks and ecosystems as frameworks for complex adaptive systems. This is especially common in the…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "May 14, 2019Effective Adaptive Leadership Practices from Innovation to ImplementationWe often speak of networks and ecosystems as frameworks for complex adaptive systems. This is especially common in the…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Zillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First TimeApr 11, 2019Zillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First TimeMillennials, who already account for nearly half of all home purchases in 2018, are becoming an increasingly large…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Apr 11, 2019Zillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First TimeMillennials, who already account for nearly half of all home purchases in 2018, are becoming an increasingly large…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "A Global Urban Nomad's Reflection on Compassionate LeadershipMar 28, 2019A Global Urban Nomad's Reflection on Compassionate LeadershipThe endless questions into the matters of the heart are perhaps the most complex condition of human nature. The…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Mar 28, 2019A Global Urban Nomad's Reflection on Compassionate LeadershipThe endless questions into the matters of the heart are perhaps the most complex condition of human nature. The…",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Insights from the communityExplore topics",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Insights from the community",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Explore topics",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "Jeffrey Mrizek, EdD, MBA",
              "id": ""
            },
            {
              "level": "h4",
              "text": "5X Startup Founder | Social Entrepreneur | Education and Workforce Developer | Mrizek Global | SmartStart AI | CA Real Estate Broker | Former California Community Colleges | Former FTB | Past ASPA Sacramento President",
              "id": ""
            },
            {
              "level": "h2",
              "text": "More articles by Jeffrey Mrizek, EdD, MBA",
              "id": ""
            },
            {
              "level": "h3",
              "text": "The Leadership Paradox of a Hardened Heart: Finding Balance Between Conviction and Compassion",
              "id": ""
            },
            {
              "level": "h3",
              "text": "The Zip Code Lottery: How Geography and Race Determine Destiny in America",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Dawn of the Reality Revolution (2024)",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Harmony Beyond Borders:\nThe Psychology and Philosophy of Love in Intercultural Unions",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Meta-Social Dynamics: Reality formation in-between digital and social landscapes",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Call to Action: Leading the Third Sector Social Renaissance",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Why Self-Advocacy overcomes Stigma...",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Effective Adaptive Leadership Practices from Innovation to Implementation",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Zillow Group Consumer Housing Trends Report 2018: The Challenge of Buying for the First Time",
              "id": ""
            },
            {
              "level": "h3",
              "text": "A Global Urban Nomad's Reflection on Compassionate Leadership",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Insights from the community",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Explore topics",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.lumapps.com/insights/blog/exploring-knowledge-based-systems-enhancing-decision-making-ai",
      "title": "Blog - Exploring knowledge-based systems: Enhancing Decision Making with AI | LumApps",
      "author": "",
      "published_date": "2024-08-28T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<h2><strong>Exploring Knowledge-Based Systems: Enhancing Decision Making with AI</strong></h2><p>In the dynamic and ever-evolving field of artificial intelligence, knowledge-based systems (KBS) have emerged as crucial tools that utilize structured knowledge to address complex challenges and improve decision-making capabilities. As an integral subset of AI, KBS are engineered to mimic human decision-making processes by combining the core principles of artificial intelligence with deep, domain-specific knowledge. This blend enables these systems to execute tasks that typically require human intelligence, such as diagnosing problems, offering expert advice, and generating intelligent solutions.</p><p>This article explores the intricacies of knowledge-based systems, discussing their fundamental components, the architecture that underpins them, and their role in driving industry transformation. Through smart automation and enhanced problem-solving capabilities, KBS are making significant impacts across various sectors. By systematically applying expert knowledge stored within their frameworks, these systems can analyze intricate data, recognize patterns, and make informed decisions swiftly and efficiently. The operational efficiency brought about by KBS not only accelerates business processes but also increases accuracy, reduces human error, and fosters innovation by enabling more complex and nuanced analysis than traditionally possible. As such, knowledge-based systems are becoming indispensable tools in industries looking to leverage AI to its fullest potential.<br/> </p>\n<h2><strong>What is a Knowledge-Based System (KBS)?</strong></h2><p>A knowledge-based system (KBS) represents an advanced implementation of artificial intelligence, uniquely structured to integrate a comprehensive knowledge base with a powerful inference engine that works together to process and analyze information. This system then synthesizes this data to deliver informed decisions or creative solutions. The knowledge base within these systems is a carefully curated repository of domain-specific data, encompassing rules, facts, and relationships that the system utilizes to simulate the level of decision-making that typically requires human expertise.</p><p>In environments where specialized knowledge is critical but access to human experts is limited or impractical, KBS proves invaluable. They function effectively as sophisticated decision support systems, offering expert advice and strategic guidance across various scenarios. By replicating the decision-making capabilities of human experts, KBS can manage complex data sets and intricate processes, providing reliable, consistent, and highly informed responses to user queries or operational challenges.</p><p>These systems are especially beneficial in sectors like healthcare, finance, and engineering, where they help bridge the gap between data collection and decision-making by enabling the analysis and application of expert knowledge at scale. As a result, knowledge-based systems enhance operational efficiency, reduce the likelihood of human error, and improve outcomes by leveraging deep domain insights to inform their outputs. This makes KBS an essential component in the toolkit of organizations aiming to enhance their decision-making processes through technology.<br/> </p>\n<h2><strong>Components of Knowledge-Based Systems</strong></h2><p><br/>The architecture of a knowledge-based system (KBS) is meticulously designed to include three fundamental components, each serving a distinct but interconnected function that is essential to the system’s operation and effectiveness:</p><p>Knowledge Base: Serving as the cornerstone of the system, the knowledge base is a comprehensive repository that stores all the critical knowledge pertinent to a specific domain. This includes a wide array of facts, rules, and relationships that are meticulously curated to support the system’s decision-making processes. The robustness and extensiveness of the knowledge base are vital because they directly influence the quality and accuracy of the decisions and solutions the system can offer. It’s through this extensive accumulation of domain-specific knowledge that the KBS can simulate expert-level understanding and problem-solving capabilities.</p><p>Inference Engine: The inference engine is the brain of the KBS. It dynamically applies logical rules to the stored information in the knowledge base to infer new data or to form conclusions. This component is critical for the reasoning capabilities of the system, enabling it to make intelligent decisions based on the knowledge it has and the data it receives. The inference engine continuously works to derive meaningful insights and answers from complex data sets, thereby enabling the system to address queries and solve problems in a manner akin to human experts.</p><p>User Interface: The user interface of a KBS is designed to bridge the gap between human users and this sophisticated technology. It allows users to easily interact with the system, inputting data and querying information without needing in-depth technical knowledge of the underlying processes. The user interface is crafted to be intuitive and accessible, ensuring that users can effectively communicate with the KBS, make requests, and understand the outputs provided. This component is essential for enhancing the usability of the KBS, making advanced computational intelligence accessible and useful across various user demographics.</p><p>Together, these components of knowledge-based systems form a cohesive system that leverages deep domain knowledge and advanced inferential logic to provide intelligent solutions and expert guidance. This architecture not only enhances the decision-making processes within organizations but also democratizes access to expert knowledge, making it a powerful tool in a variety of fields. Visualizing these components through a knowledge-based system diagram can further aid in comprehending the system’s operational flow and structure.<br/> </p>\n<h2>Turn Your Intranet into the Place to Get Work Done</h2><p>Download our free guide to learn about LumApps' AI-powered features that help turn your intranet into a destination workplace. </p>\n<h2><strong>Knowledge-Based System in Artificial Intelligence</strong></h2><p>Knowledge-based systems, often referred to as expert systems, occupy a critical niche within the field of artificial intelligence. These systems are intricately designed to simulate the decision-making capabilities of a human expert, which makes them extremely valuable across various high-stakes fields such as medical diagnosis, financial services, customer support, and many others. By leveraging their advanced reasoning abilities and their capacity to manage and interpret complex queries, KBS is adept at providing precise, efficient, and reliable solutions.</p><p>In the realm of medical diagnosis, for instance, KBS can analyze symptoms, medical history, and clinical data to suggest diagnoses and recommend treatment plans, much like a seasoned physician would. In financial services, these systems assist in risk assessment, and fraud detection, and even provide personalized financial advice to clients, replicating the analytical and decision-making skills of financial experts. Similarly, in customer support, KBS is utilized to understand and respond to customer inquiries and problems quickly and accurately, ensuring prominent levels of customer satisfaction and engagement. A knowledge-based system example in customer support would be automated platforms that provide instant answers to common queries, streamlining the support process.</p><p>The strength of knowledge-based systems lies in their ability to draw from an extensive pool of domain-specific knowledge and apply predefined logical rules to this data. This process not only helps in making informed decisions but does so with a consistency and speed that often surpasses human capability. Moreover, KBS enhances the scalability of expertise; they allow knowledge derived from expert individuals to be disseminated and utilized by others within the organization without the direct involvement of the experts themselves. This capability not only maximizes the utility of expert knowledge but also ensures that it can be leveraged more broadly and effectively within an organization or industry.<br/> </p>\n<blockquote><h3><em><strong>Examples and Applications</strong></em></h3></blockquote><p>One of the standout applications of knowledge-based systems is observed in the field of medical diagnosis. Here, these systems demonstrate their prowess by assessing and diagnosing diseases using symptoms and data input by healthcare providers or directly by patients. This sophisticated decision-making tool compares the inputted symptoms against a vast database of medical knowledge, including disease characteristics, patient histories, and epidemiological data, to identify possible ailments. This capability not only enhances the accuracy of diagnoses but also speeds up the process, allowing for quicker patient management and treatment planning, which is crucial in medical emergencies. A knowledge-based system example in this context would include systems that aid doctors in diagnosing complex medical conditions, illustrating the real-world impact of these AI-driven tools.</p><p>In the customer service sector, knowledge-based systems are revolutionizing how businesses interact with their customers. These systems are employed to provide automated, yet highly effective customer support by answering frequently asked questions and resolving common issues. By integrating KBS into customer service platforms, companies can ensure that customers receive immediate responses at any time of the day, significantly improving customer satisfaction and efficiency. These systems are programmed to handle a wide range of inquiries from simple billing question",
        "html": "<div><div>\n<h2><strong>Exploring Knowledge-Based Systems: Enhancing Decision Making with AI</strong></h2><p>In the dynamic and ever-evolving field of artificial intelligence, knowledge-based systems (KBS) have emerged as crucial tools that utilize structured knowledge to address complex challenges and improve decision-making capabilities. As an integral subset of AI, KBS are engineered to mimic human decision-making processes by combining the core principles of artificial intelligence with deep, domain-specific knowledge. This blend enables these systems to execute tasks that typically require human intelligence, such as diagnosing problems, offering expert advice, and generating intelligent solutions.</p><p>This article explores the intricacies of knowledge-based systems, discussing their fundamental components, the architecture that underpins them, and their role in driving industry transformation. Through smart automation and enhanced problem-solving capabilities, KBS are making significant impacts across various sectors. By systematically applying expert knowledge stored within their frameworks, these systems can analyze intricate data, recognize patterns, and make informed decisions swiftly and efficiently. The operational efficiency brought about by KBS not only accelerates business processes but also increases accuracy, reduces human error, and fosters innovation by enabling more complex and nuanced analysis than traditionally possible. As such, knowledge-based systems are becoming indispensable tools in industries looking to leverage AI to its fullest potential.<br/> </p>\n<h2><strong>What is a Knowledge-Based System (KBS)?</strong></h2><p>A knowledge-based system (KBS) represents an advanced implementation of artificial intelligence, uniquely structured to integrate a comprehensive knowledge base with a powerful inference engine that works together to process and analyze information. This system then synthesizes this data to deliver informed decisions or creative solutions. The knowledge base within these systems is a carefully curated repository of domain-specific data, encompassing rules, facts, and relationships that the system utilizes to simulate the level of decision-making that typically requires human expertise.</p><p>In environments where specialized knowledge is critical but access to human experts is limited or impractical, KBS proves invaluable. They function effectively as sophisticated decision support systems, offering expert advice and strategic guidance across various scenarios. By replicating the decision-making capabilities of human experts, KBS can manage complex data sets and intricate processes, providing reliable, consistent, and highly informed responses to user queries or operational challenges.</p><p>These systems are especially beneficial in sectors like healthcare, finance, and engineering, where they help bridge the gap between data collection and decision-making by enabling the analysis and application of expert knowledge at scale. As a result, knowledge-based systems enhance operational efficiency, reduce the likelihood of human error, and improve outcomes by leveraging deep domain insights to inform their outputs. This makes KBS an essential component in the toolkit of organizations aiming to enhance their decision-making processes through technology.<br/> </p>\n<h2><strong>Components of Knowledge-Based Systems</strong></h2><p><br/>The architecture of a knowledge-based system (KBS) is meticulously designed to include three fundamental components, each serving a distinct but interconnected function that is essential to the system’s operation and effectiveness:</p><p>Knowledge Base: Serving as the cornerstone of the system, the knowledge base is a comprehensive repository that stores all the critical knowledge pertinent to a specific domain. This includes a wide array of facts, rules, and relationships that are meticulously curated to support the system’s decision-making processes. The robustness and extensiveness of the knowledge base are vital because they directly influence the quality and accuracy of the decisions and solutions the system can offer. It’s through this extensive accumulation of domain-specific knowledge that the KBS can simulate expert-level understanding and problem-solving capabilities.</p><p>Inference Engine: The inference engine is the brain of the KBS. It dynamically applies logical rules to the stored information in the knowledge base to infer new data or to form conclusions. This component is critical for the reasoning capabilities of the system, enabling it to make intelligent decisions based on the knowledge it has and the data it receives. The inference engine continuously works to derive meaningful insights and answers from complex data sets, thereby enabling the system to address queries and solve problems in a manner akin to human experts.</p><p>User Interface: The user interface of a KBS is designed to bridge the gap between human users and this sophisticated technology. It allows users to easily interact with the system, inputting data and querying information without needing in-depth technical knowledge of the underlying processes. The user interface is crafted to be intuitive and accessible, ensuring that users can effectively communicate with the KBS, make requests, and understand the outputs provided. This component is essential for enhancing the usability of the KBS, making advanced computational intelligence accessible and useful across various user demographics.</p><p>Together, these components of knowledge-based systems form a cohesive system that leverages deep domain knowledge and advanced inferential logic to provide intelligent solutions and expert guidance. This architecture not only enhances the decision-making processes within organizations but also democratizes access to expert knowledge, making it a powerful tool in a variety of fields. Visualizing these components through a knowledge-based system diagram can further aid in comprehending the system’s operational flow and structure.<br/> </p>\n<h2>Turn Your Intranet into the Place to Get Work Done</h2><p>Download our free guide to learn about LumApps' AI-powered features that help turn your intranet into a destination workplace. </p>\n<h2><strong>Knowledge-Based System in Artificial Intelligence</strong></h2><p>Knowledge-based systems, often referred to as expert systems, occupy a critical niche within the field of artificial intelligence. These systems are intricately designed to simulate the decision-making capabilities of a human expert, which makes them extremely valuable across various high-stakes fields such as medical diagnosis, financial services, customer support, and many others. By leveraging their advanced reasoning abilities and their capacity to manage and interpret complex queries, KBS is adept at providing precise, efficient, and reliable solutions.</p><p>In the realm of medical diagnosis, for instance, KBS can analyze symptoms, medical history, and clinical data to suggest diagnoses and recommend treatment plans, much like a seasoned physician would. In financial services, these systems assist in risk assessment, and fraud detection, and even provide personalized financial advice to clients, replicating the analytical and decision-making skills of financial experts. Similarly, in customer support, KBS is utilized to understand and respond to customer inquiries and problems quickly and accurately, ensuring prominent levels of customer satisfaction and engagement. A knowledge-based system example in customer support would be automated platforms that provide instant answers to common queries, streamlining the support process.</p><p>The strength of knowledge-based systems lies in their ability to draw from an extensive pool of domain-specific knowledge and apply predefined logical rules to this data. This process not only helps in making informed decisions but does so with a consistency and speed that often surpasses human capability. Moreover, KBS enhances the scalability of expertise; they allow knowledge derived from expert individuals to be disseminated and utilized by others within the organization without the direct involvement of the experts themselves. This capability not only maximizes the utility of expert knowledge but also ensures that it can be leveraged more broadly and effectively within an organization or industry.<br/> </p>\n<blockquote><h3><em><strong>Examples and Applications</strong></em></h3></blockquote><p>One of the standout applications of knowledge-based systems is observed in the field of medical diagnosis. Here, these systems demonstrate their prowess by assessing and diagnosing diseases using symptoms and data input by healthcare providers or directly by patients. This sophisticated decision-making tool compares the inputted symptoms against a vast database of medical knowledge, including disease characteristics, patient histories, and epidemiological data, to identify possible ailments. This capability not only enhances the accuracy of diagnoses but also speeds up the process, allowing for quicker patient management and treatment planning, which is crucial in medical emergencies. A knowledge-based system example in this context would include systems that aid doctors in diagnosing complex medical conditions, illustrating the real-world impact of these AI-driven tools.</p><p>In the customer service sector, knowledge-based systems are revolutionizing how businesses interact with their customers. These systems are employed to provide automated, yet highly effective customer support by answering frequently asked questions and resolving common issues. By integrating KBS into customer service platforms, companies can ensure that customers receive immediate responses at any time of the day, significantly improving customer satisfaction and efficiency. These systems are programmed to handle a wide range of inquiries from simple billing question",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Exploring Knowledge-Based Systems: Enhancing Decision Making with AIIn the dynamic and ever-evolving field of artificial intelligence, knowledge-based systems (KBS) have emerged as crucial tools that utilize structured knowledge to address complex challenges and improve decision-making capabilities. As an integral subset of AI, KBS are engineered to mimic human decision-making processes by combining the core principles of artificial intelligence with deep, domain-specific knowledge. This blend e",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Exploring Knowledge-Based Systems: Enhancing Decision Making with AIIn the dynamic and ever-evolving field of artificial intelligence, knowledge-based systems (KBS) have emerged as crucial tools that utilize structured knowledge to address complex challenges and improve decision-making capabilities. As an integral subset of AI, KBS are engineered to mimic human decision-making processes by combining the core principles of artificial intelligence with deep, domain-specific knowledge. This blend e",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Exploring Knowledge-Based Systems: Enhancing Decision Making with AI",
              "id": ""
            },
            {
              "level": "h2",
              "text": "What is a Knowledge-Based System (KBS)?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Components of Knowledge-Based Systems",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Turn Your Intranet into the Place to Get Work Done",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Knowledge-Based System in Artificial Intelligence",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Examples and Applications",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "technical"
    },
    {
      "url": "https://www.nature.com/articles/s41467-024-49983-7",
      "title": "Exploring the structural landscape of DNA maintenance proteins",
      "author": "Bartek, Jiri",
      "published_date": "2024-09-05T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<div><h2>Introduction</h2><div><p>Genomes of all cellular lifeforms are plagued by the threat of DNA damaging insults, mutations, or copying errors. To counteract the potentially deleterious consequences of such insults, organisms have evolved systems that safeguard genetic information. Past studies have unearthed a plethora of proteins categorized structurally and functionally into several independent DNA repair networks. In humans alone, some &gt;500 caretakers are directly or indirectly involved in GM, and almost as many are engaged in the mitotic and chromosome segregation processes. DNA damage response (DDR) proteins, however, are constructed from combinations of much fewer evolutionary conserved modules, that is by shuffling and recombining a limited repertoire of conserved domain precursors. Hence, the identification and categorization of proteins bearing such conserved structural entities can provide tangible insight into hitherto unknown protein functions. Previous evolutionary annotation methods have been highly successful in uncovering unknown relationships between DNA repair systems<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR1\">1</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR2\">2</a></sup>. However, such profile-to-sequence comparative analysis often fails to identify any significant homology, revealing a limitation of this approach. This is certainly the case for the most intriguing group of DDR proteins in humans, namely those for which no orthologs have yet been studied. Both sensitivity and specificity of the homology searches can be dramatically improved by comparing sequence profiles through iterative profile-to-profile algorithms such as the hidden Markov model (HMM)-based iterative profile-HMM searches<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR3\">3</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR4\">4</a></sup>. These methods compare the profiles of both query and target by exploiting databases of HMMs (such as the protein family (PFAM) database) in which protein profile HMMs rather than sequences are compiled. Profile HMMs are superior to simple sequence profiles since in addition to the amino acid frequencies identified in a multiple sequence alignment, they include the position-specific probabilities for inserts and deletions along the alignment. Among these, profile-HMMs have emerged as powerful tools in decoding the structural and functional landscape of genome maintenance proteins. For example, the elucidation of the S,T-Q phosphopeptide-binding BRCT domain, initially discovered in breast cancer susceptibility protein BRCA1<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR5\">5</a></sup> and later identified in many other proteins almost exclusively functioning in DNA damage response pathways<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR6\">6</a></sup>, has been greatly facilitated by the advent of profile-to-sequence and later profile-HMM- based computational database surveys, enabling reliable detection of subtle sequence homologies indicative of shared structural motifs<sup><a href=\"#ref-CR7\">7</a>,<a href=\"#ref-CR8\">8</a>,<a href=\"#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR10\">10</a></sup>. Similarly, the OB fold domain, known for its role in nucleic acid binding and recognition, has recently witnessed a surge in profile-HMM applications<sup><a href=\"#ref-CR11\">11</a>,<a href=\"#ref-CR12\">12</a>,<a href=\"#ref-CR13\">13</a>,<a href=\"#ref-CR14\">14</a>,<a href=\"#ref-CR15\">15</a>,<a href=\"#ref-CR16\">16</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR17\">17</a></sup>. Profile-HMMs, with their ability to capture remote homologies, have proven indispensable in accurately identifying OB-fold-containing proteins, offering valuable insights into their evolutionary relationships and functional implications. Previously, the systematic application of profile-HMMs has emerged as an efficient tool for identifying DNA repair protein structures in bacteria and metazoa. These studies individually surveyed nuclease and OB fold-bearing protein sequences, effectively revealing family members within DNA repair pathways<sup><a href=\"#ref-CR18\">18</a>,<a href=\"#ref-CR19\">19</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR20\">20</a></sup>.</p><p>By leveraging the evolutionary information encoded in sequences, profile-HMMs have played a pivotal role in advancing our understanding of DNA repair mechanisms, offering a precise and efficient method for the computational annotation of protein structures associated with this vital cellular process. Although profile-HMM methods have been in existence for nearly two decades<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR21\">21</a></sup>, it is only in recent times that their complete potential, robustness, and accuracy in large-scale protein structural assessment through the AlphaFold methods have become evident<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR22\">22</a></sup>. Other recent methods for structural prediction and biomolecule interactions using deep learning, such as convolutional and graph neural networks<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR23\">23</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR24\">24</a></sup>, have been developed. However, the latest version of AlphaFold, AlphaFold 3<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR25\">25</a></sup>, allowing for the highest degree of precision achieved so far in predicting protein structures and protein-biomolecule interactions. To our knowledge, however, the repertoire of GM proteins has so far not been the subject of systematic comparative analysis across domains and species using these state-of-the-art computational profile-HMM strategies. Hence, given the efficacy of the computational methods in dissecting the protein structures and functions, we resorted to an in-depth sequence analysis of all known and putative players in the DNA maintenance networks. Here, we report the results of such an analysis and discuss several previously undetected conserved domains that we have uncovered in the present study.</p></div></div><div><h2>\n<b>Results</b>\n</h2><div><h3>\n<b>Overview of the genome maintenance architectural landscape analyses</b>\n</h3><p>A key goal of comparative sequence studies is the annotation of conserved domains as well as the discovery of structural and evolutionary relationships between cataloged domains. To understand the variety of GM protein structures across eukaryotes, we set out to answer two questions concerning GM architectures and their evolution. First, given the adeptness of profile-HMM methods in detecting remote homologies, can they be applied systematically to uncover unknown structures and relationships of in the human GM proteome? Second, despite the seemingly past eminent functional and evolutionary characterization of existing GM proteins, can we identify additional players in the human DNA damage responses? We, therefore, examined the structural characteristics and relationships among GM proteins across species by methodically evaluating their sequence homologies with protein profiles in the PFAM database through sensitive hidden Markov-based profile-to-profile (profile-HMM) searches. This information was then used to explore possible remote and undiscovered relationships within the human proteome. The result of this survey is summarized in Fig. <a href=\"https://www.nature.com/articles/s41467-024-49983-7#Fig1\">1</a> and -supplementary Fig. <a href=\"https://www.nature.com/articles/s41467-024-49983-7#MOESM1\">1</a> and discussed in additional detail in the following sections. Collectively, we uncovered 113 unknown evolutionary conserved protein families, 59 predicted structures in established GM proteins, and 54 structures in uncharacterized GM candidate proteins.</p><div><figure><figcaption><b>Fig. 1: Overview of the computational survey and summary of results.</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41467-024-49983-7/figures/1\"></a></div><p><b>a</b>, In step 1 unique GM proteins were compiled by three different approaches. Flow diagram summarizing data collection and subsequent sequence searches. GO terms for GM proteins were compiled in the Amigo database<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR105\">105</a></sup> using four search terms across species yielding a total of 28,663 GO terms. Of these, 3635 are unique GM proteins from the seven selected organisms namely <i>H. sapiens</i>, <i>D. melanogaster</i>, <i>C. elegans</i>, <i>A. thaliana</i>, <i>S. cerevisiae</i>, <i>S. pombe</i>, and <i>E. coli (K12)</i>. GM physical interactors were retrieved from the IID database yielding a total of 975,877 interactors across species. Among these are 4618 interactors not previously implicated in GM. Of these, only 441 interactor pairs include one established DNA repair protein and one protein not previously linked to the DDR. Among these, 51 interactors were identified as recurrent contaminants in the CRAPome database yielding a final list of 390 unique GM interactors not previously implicated in the DDR. GM gene co-expressed genes were retrieved from the CEMiTool identifying a total of 36,410 GM co-expressed genes. Among these CEMiTool identifies 3523 overlapping co-expressed genes between two different tissues, which upon filtering for housekeeping genes and registered Crapome entries are reduced to 2820 co-expressed gene pairs (of which one gene per pair is an established GM gene). In Step 2 the compiled list of 4395 unique GM proteins were used as search queries in profile-HMM searches. These searches yielded a total of 108 hitherto unknown human domains in establi",
        "html": "<div><div>\n<div><h2>Introduction</h2><div><p>Genomes of all cellular lifeforms are plagued by the threat of DNA damaging insults, mutations, or copying errors. To counteract the potentially deleterious consequences of such insults, organisms have evolved systems that safeguard genetic information. Past studies have unearthed a plethora of proteins categorized structurally and functionally into several independent DNA repair networks. In humans alone, some &gt;500 caretakers are directly or indirectly involved in GM, and almost as many are engaged in the mitotic and chromosome segregation processes. DNA damage response (DDR) proteins, however, are constructed from combinations of much fewer evolutionary conserved modules, that is by shuffling and recombining a limited repertoire of conserved domain precursors. Hence, the identification and categorization of proteins bearing such conserved structural entities can provide tangible insight into hitherto unknown protein functions. Previous evolutionary annotation methods have been highly successful in uncovering unknown relationships between DNA repair systems<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR1\">1</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR2\">2</a></sup>. However, such profile-to-sequence comparative analysis often fails to identify any significant homology, revealing a limitation of this approach. This is certainly the case for the most intriguing group of DDR proteins in humans, namely those for which no orthologs have yet been studied. Both sensitivity and specificity of the homology searches can be dramatically improved by comparing sequence profiles through iterative profile-to-profile algorithms such as the hidden Markov model (HMM)-based iterative profile-HMM searches<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR3\">3</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR4\">4</a></sup>. These methods compare the profiles of both query and target by exploiting databases of HMMs (such as the protein family (PFAM) database) in which protein profile HMMs rather than sequences are compiled. Profile HMMs are superior to simple sequence profiles since in addition to the amino acid frequencies identified in a multiple sequence alignment, they include the position-specific probabilities for inserts and deletions along the alignment. Among these, profile-HMMs have emerged as powerful tools in decoding the structural and functional landscape of genome maintenance proteins. For example, the elucidation of the S,T-Q phosphopeptide-binding BRCT domain, initially discovered in breast cancer susceptibility protein BRCA1<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR5\">5</a></sup> and later identified in many other proteins almost exclusively functioning in DNA damage response pathways<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR6\">6</a></sup>, has been greatly facilitated by the advent of profile-to-sequence and later profile-HMM- based computational database surveys, enabling reliable detection of subtle sequence homologies indicative of shared structural motifs<sup><a href=\"#ref-CR7\">7</a>,<a href=\"#ref-CR8\">8</a>,<a href=\"#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR10\">10</a></sup>. Similarly, the OB fold domain, known for its role in nucleic acid binding and recognition, has recently witnessed a surge in profile-HMM applications<sup><a href=\"#ref-CR11\">11</a>,<a href=\"#ref-CR12\">12</a>,<a href=\"#ref-CR13\">13</a>,<a href=\"#ref-CR14\">14</a>,<a href=\"#ref-CR15\">15</a>,<a href=\"#ref-CR16\">16</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR17\">17</a></sup>. Profile-HMMs, with their ability to capture remote homologies, have proven indispensable in accurately identifying OB-fold-containing proteins, offering valuable insights into their evolutionary relationships and functional implications. Previously, the systematic application of profile-HMMs has emerged as an efficient tool for identifying DNA repair protein structures in bacteria and metazoa. These studies individually surveyed nuclease and OB fold-bearing protein sequences, effectively revealing family members within DNA repair pathways<sup><a href=\"#ref-CR18\">18</a>,<a href=\"#ref-CR19\">19</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR20\">20</a></sup>.</p><p>By leveraging the evolutionary information encoded in sequences, profile-HMMs have played a pivotal role in advancing our understanding of DNA repair mechanisms, offering a precise and efficient method for the computational annotation of protein structures associated with this vital cellular process. Although profile-HMM methods have been in existence for nearly two decades<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR21\">21</a></sup>, it is only in recent times that their complete potential, robustness, and accuracy in large-scale protein structural assessment through the AlphaFold methods have become evident<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR22\">22</a></sup>. Other recent methods for structural prediction and biomolecule interactions using deep learning, such as convolutional and graph neural networks<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR23\">23</a>,<a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR24\">24</a></sup>, have been developed. However, the latest version of AlphaFold, AlphaFold 3<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR25\">25</a></sup>, allowing for the highest degree of precision achieved so far in predicting protein structures and protein-biomolecule interactions. To our knowledge, however, the repertoire of GM proteins has so far not been the subject of systematic comparative analysis across domains and species using these state-of-the-art computational profile-HMM strategies. Hence, given the efficacy of the computational methods in dissecting the protein structures and functions, we resorted to an in-depth sequence analysis of all known and putative players in the DNA maintenance networks. Here, we report the results of such an analysis and discuss several previously undetected conserved domains that we have uncovered in the present study.</p></div></div><div><h2>\n<b>Results</b>\n</h2><div><h3>\n<b>Overview of the genome maintenance architectural landscape analyses</b>\n</h3><p>A key goal of comparative sequence studies is the annotation of conserved domains as well as the discovery of structural and evolutionary relationships between cataloged domains. To understand the variety of GM protein structures across eukaryotes, we set out to answer two questions concerning GM architectures and their evolution. First, given the adeptness of profile-HMM methods in detecting remote homologies, can they be applied systematically to uncover unknown structures and relationships of in the human GM proteome? Second, despite the seemingly past eminent functional and evolutionary characterization of existing GM proteins, can we identify additional players in the human DNA damage responses? We, therefore, examined the structural characteristics and relationships among GM proteins across species by methodically evaluating their sequence homologies with protein profiles in the PFAM database through sensitive hidden Markov-based profile-to-profile (profile-HMM) searches. This information was then used to explore possible remote and undiscovered relationships within the human proteome. The result of this survey is summarized in Fig. <a href=\"https://www.nature.com/articles/s41467-024-49983-7#Fig1\">1</a> and -supplementary Fig. <a href=\"https://www.nature.com/articles/s41467-024-49983-7#MOESM1\">1</a> and discussed in additional detail in the following sections. Collectively, we uncovered 113 unknown evolutionary conserved protein families, 59 predicted structures in established GM proteins, and 54 structures in uncharacterized GM candidate proteins.</p><div><figure><figcaption><b>Fig. 1: Overview of the computational survey and summary of results.</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s41467-024-49983-7/figures/1\"></a></div><p><b>a</b>, In step 1 unique GM proteins were compiled by three different approaches. Flow diagram summarizing data collection and subsequent sequence searches. GO terms for GM proteins were compiled in the Amigo database<sup><a href=\"https://www.nature.com/articles/s41467-024-49983-7#ref-CR105\">105</a></sup> using four search terms across species yielding a total of 28,663 GO terms. Of these, 3635 are unique GM proteins from the seven selected organisms namely <i>H. sapiens</i>, <i>D. melanogaster</i>, <i>C. elegans</i>, <i>A. thaliana</i>, <i>S. cerevisiae</i>, <i>S. pombe</i>, and <i>E. coli (K12)</i>. GM physical interactors were retrieved from the IID database yielding a total of 975,877 interactors across species. Among these are 4618 interactors not previously implicated in GM. Of these, only 441 interactor pairs include one established DNA repair protein and one protein not previously linked to the DDR. Among these, 51 interactors were identified as recurrent contaminants in the CRAPome database yielding a final list of 390 unique GM interactors not previously implicated in the DDR. GM gene co-expressed genes were retrieved from the CEMiTool identifying a total of 36,410 GM co-expressed genes. Among these CEMiTool identifies 3523 overlapping co-expressed genes between two different tissues, which upon filtering for housekeeping genes and registered Crapome entries are reduced to 2820 co-expressed gene pairs (of which one gene per pair is an established GM gene). In Step 2 the compiled list of 4395 unique GM proteins were used as search queries in profile-HMM searches. These searches yielded a total of 108 hitherto unknown human domains in establi",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "IntroductionGenomes of all cellular lifeforms are plagued by the threat of DNA damaging insults, mutations, or copying errors. To counteract the potentially deleterious consequences of such insults, organisms have evolved systems that safeguard genetic information. Past studies have unearthed a plethora of proteins categorized structurally and functionally into several independent DNA repair networks. In humans alone, some >500 caretakers are directly or indirectly involved in GM, and almost as ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionGenomes of all cellular lifeforms are plagued by the threat of DNA damaging insults, mutations, or copying errors. To counteract the potentially deleterious consequences of such insults, organisms have evolved systems that safeguard genetic information. Past studies have unearthed a plethora of proteins categorized structurally and functionally into several independent DNA repair networks. In humans alone, some >500 caretakers are directly or indirectly involved in GM, and almost as ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "IntroductionGenomes of all cellular lifeforms are plagued by the threat of DNA damaging insults, mutations, or copying errors. To counteract the potentially deleterious consequences of such insults, organisms have evolved systems that safeguard genetic information. Past studies have unearthed a plethora of proteins categorized structurally and functionally into several independent DNA repair networks. In humans alone, some >500 caretakers are directly or indirectly involved in GM, and almost as ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Genomes of all cellular lifeforms are plagued by the threat of DNA damaging insults, mutations, or copying errors. To counteract the potentially deleterious consequences of such insults, organisms have evolved systems that safeguard genetic information. Past studies have unearthed a plethora of proteins categorized structurally and functionally into several independent DNA repair networks. In humans alone, some >500 caretakers are directly or indirectly involved in GM, and almost as many are eng",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "ResultsOverview of the genome maintenance architectural landscape analysesA key goal of comparative sequence studies is the annotation of conserved domains as well as the discovery of structural and evolutionary relationships between cataloged domains. To understand the variety of GM protein structures across eukaryotes, we set out to answer two questions concerning GM architectures and their evolution. First, given the adeptness of profile-HMM methods in detecting remote homologies, can they be",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Overview of the genome maintenance architectural landscape analysesA key goal of comparative sequence studies is the annotation of conserved domains as well as the discovery of structural and evolutionary relationships between cataloged domains. To understand the variety of GM protein structures across eukaryotes, we set out to answer two questions concerning GM architectures and their evolution. First, given the adeptness of profile-HMM methods in detecting remote homologies, can they be applie",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Fig. 1: Overview of the computational survey and summary of results.a, In step 1 unique GM proteins were compiled by three different approaches. Flow diagram summarizing data collection and subsequent sequence searches. GO terms for GM proteins were compiled in the Amigo database105using four search terms across species yielding a total of 28,663 GO terms. Of these, 3635 are unique GM proteins from the seven selected organisms namelyH. sapiens,D. melanogaster,C. elegans,A. thaliana,S. cerevisiae",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "a, In step 1 unique GM proteins were compiled by three different approaches. Flow diagram summarizing data collection and subsequent sequence searches. GO terms for GM proteins were compiled in the Amigo database105using four search terms across species yielding a total of 28,663 GO terms. Of these, 3635 are unique GM proteins from the seven selected organisms namelyH. sapiens,D. melanogaster,C. elegans,A. thaliana,S. cerevisiae,S. pombe, andE. coli (K12). GM physical interactors were retrieved ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Introduction",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Results",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Overview of the genome maintenance architectural landscape analyses",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://hd.media.mit.edu/tech-reports/TR-546.pdf",
      "title": "AI-ED-2001-final",
      "author": "reilly",
      "published_date": "2001-11-08T00:00:00.000Z",
      "content": {
        "text": "1\nPublished in the Proceedings of Artificial Intelligence in Education\nWorkshops (AI-ED), May 2001, San Antonio, Texas\nExternal Representation of Learning Process and\nDomain Knowledge: Affective State as a Determinate\nof its Structure and Function\nBARRY KORT, ROB REILLY, ROSALIND W. PICARD\nMedia Laboratory\nMassachusetts Institute of Technology\n20 Ames Street\nCambridge, MA USA 02139\n{bkort, reilly, picard}@media.mit.edu\nhttp://www.media.mit.edu/affect/AC_research/lc\nABSTRACT\nWe present a model of the generic learning process and associated metacognitive processes that aid\nefficient learning. These models can be used as internal representations of a learner’s cognitive\u0002emotive state while engaged in learning. They can also be used to present to the learner a\nrepresentation of their progress in learning much like a coach or mentor might use to assist a student.\nThese models and associated representations might be displayed alongside the primary external\nrepresentation of the subject being learned or they might be integrated into it. The assessment of the\nmetacognitive processes which shadow the primary learning process needs to be sensitive to the\naffective state of the learner. As the student proceeds through the learning journey, their affective\nstate may cycle through a wide spectrum of emotions, which influence how efficiently, effectively,\nand enjoyably they succeed in the learning task. Based upon an understanding and application of our\nproposed model, the structure and function of external representations would reflect the learner’s\ncognitive-emotive state. For example, some representations would provide copious hints that would\naccelerate the learning at the expense of the playfulness of the exercise, while other representations\nmight transform the le arning experience into an enthralling game. In particular these models enable\nthe system designer to provide alternative intervention strategies for the learner who is laboring under\na misconception, ranging from a no-nonsense remedial intervention to allowing the learner to play out\ntheir misconceptions in a free-wheeling simulation model that ultimately reveals the folly of their\nthinking.\nINTRODUCTION\nThe question is not whether intelligent machines can have emotions,\nbut whether machines can be intelligent without any emotions.\nMarvin Minsky, The Society of Mind\nGiven new computational media such as virtual reality, dynamic animation, and wearable\ndevices, the design of innovative learning environments, their structure, their functional features, and\n2\nthe educational pedagogy that underpins them opens challenging questions about their design and\nhuman factors.\nWhile it is necessary to explore future directions for research in regard to external\nrepresentations of knowledge domains and learning processes, our primary interest is to develop an\nunderstanding of the requisite educational pedagogy. This is necessary in order to answer such\nquestions as: ‘How intrusive should an intervention be and how extensive need a given external\nrepresentation be,’ or ‘How do we manage the trade-off between the amount of information and the\ncognitive load of integrating multiple displays when learning from more than one representation?’ It\nis also necessary to determine the nature of the external representation(s). Too much ‘external\nrepresentation’ could distract a learner from the task at-hand if the learner is developing an\nappropriate understanding of the material, but if the learner is not developing a correct understanding\na highly intrusive intervention may be in order to intentionally distract the learner and provide\nremedial information.\nHowever, current educational pedagogy is lacking in certain areas and must be reengineered\nbefore it can serve as a useful foundation for determining the structure and function for external\nrepresentation(s) of learning process, domain knowledge, and metacognitive aids. In the next section\nwe present a novel theory of emotions and learning that suggests ways to improve the educational\nexperience.\nAFFECTIVE STATE: EMOTIONS AND LEARNING\nDo emotions contribute to intelligence, and if so, what are the\nimplications for the development of a technology of affective\ncomputing?\nRobert Provine, What Questions Are On Psychologist’s Minds Today?\nIn an attempt to reengineer the state of educational pedagogy, we should first look to expert\nteachers who are very adept at recognizing the emotional state of learners and, based upon their\nobservation, taking appropriate action that positively influences learning. But what do these expert\nteachers see and how do they select a course of action? How do students who have strayed from\nlearning return to a productive path, such as the one that Csikszentmihalyi [1990] refers to as the\n“zone of flow”?\nSkilled human mentors can assess emotional cues with varying degrees of perception.\nResearchers are beginning to imbue computers with similar abilities to recognize affective cues [e.g.,\nPicard, 2001; Scheirer, et al, 1999; Chen, et al, 1998; Donato, 1999; DeSilva, 1997; Ekman, 1997].\nAlthough computers perform as well as or better than people in selected domains, they do not yet rise\nto human levels of mentoring. We envision that computers will soon become capable of recognizing\nhuman behaviors indicative of the user’s affective state.\nTo this end it is necessary for us to rethink what is happening during learning and, based\nupon our hypothesis, reengineer accordingly. This supposition is based upon our own preliminary\npilot studies, with elementary school children, suggesting that a human observer can assess the\naffective emotional state of a student with reasonable reliability based on observation of facial\nexpressions, gross body language, and the content and tone of speech. If the human observer is also\nacting in the role of coach or mentor, these assessments can be confirmed or refined by direct\nconversation (e.g. simply asking the student if they are confused or frustrated before offering to\n3\nprovide coaching or hints). Moreover, successful learning (e.g. solving a difficult puzzle) is\nfrequently marked by an unmistakable elation, often jointly celebrated with “high fives.” In some\ncases, the “Aha!” moment is so dramatic, it verges on the epiphanetic. One of the great joys for an\neducator is to bring a student to such a moment of triumph.\nOur first step is to offer a model of a learning cycle (Figures 1a and 1b) and later to describe a\nmodel of emotions (Figure 2) and ultimately to relate them into a single model. Figures 1a and 1b\ninterweave the emotion axes shown in Figure 2 with the cognitive dynamics of the learning process.\nThe horizontal axis in Figures 1a and 1b is an Emotion Axis. It could be one of the specific axes from\nFigure 2, or it could symbolize the n-vector of all relevant emotion axes (thus allowing multi\u0002dimensional combinations of emotions). The positive valence (more pleasurable) emotions are on the\nright; the negative valence (more unpleasant) emotions are on the left. The vertical axis is what we\ncall the Learning Axis, and symbolizes the construction of knowledge upward, and the discarding of\nmisconceptions downward. Note: we do not see learning as being simply a process of\nconstructing/deconstructing or adding/subtracting information; this terminology is merely a projection\nof one aspect of how people can think about learning. Other aspects could be similarly included along\nthe Learning Axis.\nConstructive Learning\nDisappointment Awe\nPuzzlement Satisfaction\nConfusion Curiosity\nII I\nNegative Positive\nAffect Affect\nIII IV\nFrustration Hopefulness\nDiscard Fresh research\nMisconceptions\nUn-learning\nFigure 1a – Proposed model relating phases of learning to emotions in Figure 2\nII I\nIII IV\nFigure 1b – Circular and helical flow of emotion\n4\nAxis -1. 0 -0. 5 0 +0. 5 +1. 0\nAnxiety\u0002ConfidenceAnxiety Worry Discomfort Comfort Hopeful Confident\nBoredom\u0002FascinationEnnui Boredom Indifference Interest Curiosity Intrigue\nFrustration\u0002EuphoriaFrustration Puzzlement Confusion Insight Enlightenment Epiphany\nDispirited\u0002EncouragedDispirited Disappointed Dissatisfied Satisfied Thrilled Enthusiastic\nTerror -\nEnchantment\nTerror Dread Apprehension Calm Anticipatory Excited\nFigure 2 – Emotion sets possibly relevant to learning\nThe student ideally begins in Quadrant I or II: they might be curious and fascinated about a\nnew topic of interest (Quadrant I) or they might be puzzled and motivated to reduce confusion\n(Quadrant II). In either case, they are in the top half of the space, if their focus is on constructing or\ntesting knowledge. Movement happens in this space as learning proceeds. For example, when\nsolving a puzzle in The Incredible Machine, a student gets an idea how to implement a solution and\nthen builds its simulation. When she runs the simulation and it fails, she sees that her idea has some\npart that doesn’t work – that needs to be deconstructed. At this point it is not uncommon for the\nstudent to move down into the lower half of the diagram (Quadrant III) where emotions may be\nnegative and the cognitive focus changes to eliminating some misconception. As she consolidates her\nknowledge—what works and what does not—with awareness of a sense of making progress, she may\nmove to Quadrant IV. Getting a fresh idea propels the student back into the upper half of the space,\nmost likely Quadrant I. Thus, a typical learning experience involves a range of emotions, moving the\nstudent around the space as they learn.\nIf one visualizes a version of Figures 1a and 1b for each axis in Figure 2, then at any given\ninstant, the student might be in multiple Quadrants with respect to different axes. They might be in\nQuadrant II with respect to feeling frustrated; and simultaneously in Quadrant I with respect to\ninterest level. It is important to recognize that a range of emotions occurs naturally in a real learning\nprocess, and it is not simply the case that the positive emotions are the good ones. We do not fores",
        "html": "1\nPublished in the Proceedings of Artificial Intelligence in Education\nWorkshops (AI-ED), May 2001, San Antonio, Texas\nExternal Representation of Learning Process and\nDomain Knowledge: Affective State as a Determinate\nof its Structure and Function\nBARRY KORT, ROB REILLY, ROSALIND W. PICARD\nMedia Laboratory\nMassachusetts Institute of Technology\n20 Ames Street\nCambridge, MA USA 02139\n{bkort, reilly, picard}@media.mit.edu\nhttp://www.media.mit.edu/affect/AC_research/lc\nABSTRACT\nWe present a model of the generic learning process and associated metacognitive processes that aid\nefficient learning. These models can be used as internal representations of a learner’s cognitive\u0002emotive state while engaged in learning. They can also be used to present to the learner a\nrepresentation of their progress in learning much like a coach or mentor might use to assist a student.\nThese models and associated representations might be displayed alongside the primary external\nrepresentation of the subject being learned or they might be integrated into it. The assessment of the\nmetacognitive processes which shadow the primary learning process needs to be sensitive to the\naffective state of the learner. As the student proceeds through the learning journey, their affective\nstate may cycle through a wide spectrum of emotions, which influence how efficiently, effectively,\nand enjoyably they succeed in the learning task. Based upon an understanding and application of our\nproposed model, the structure and function of external representations would reflect the learner’s\ncognitive-emotive state. For example, some representations would provide copious hints that would\naccelerate the learning at the expense of the playfulness of the exercise, while other representations\nmight transform the le arning experience into an enthralling game. In particular these models enable\nthe system designer to provide alternative intervention strategies for the learner who is laboring under\na misconception, ranging from a no-nonsense remedial intervention to allowing the learner to play out\ntheir misconceptions in a free-wheeling simulation model that ultimately reveals the folly of their\nthinking.\nINTRODUCTION\nThe question is not whether intelligent machines can have emotions,\nbut whether machines can be intelligent without any emotions.\nMarvin Minsky, The Society of Mind\nGiven new computational media such as virtual reality, dynamic animation, and wearable\ndevices, the design of innovative learning environments, their structure, their functional features, and\n2\nthe educational pedagogy that underpins them opens challenging questions about their design and\nhuman factors.\nWhile it is necessary to explore future directions for research in regard to external\nrepresentations of knowledge domains and learning processes, our primary interest is to develop an\nunderstanding of the requisite educational pedagogy. This is necessary in order to answer such\nquestions as: ‘How intrusive should an intervention be and how extensive need a given external\nrepresentation be,’ or ‘How do we manage the trade-off between the amount of information and the\ncognitive load of integrating multiple displays when learning from more than one representation?’ It\nis also necessary to determine the nature of the external representation(s). Too much ‘external\nrepresentation’ could distract a learner from the task at-hand if the learner is developing an\nappropriate understanding of the material, but if the learner is not developing a correct understanding\na highly intrusive intervention may be in order to intentionally distract the learner and provide\nremedial information.\nHowever, current educational pedagogy is lacking in certain areas and must be reengineered\nbefore it can serve as a useful foundation for determining the structure and function for external\nrepresentation(s) of learning process, domain knowledge, and metacognitive aids. In the next section\nwe present a novel theory of emotions and learning that suggests ways to improve the educational\nexperience.\nAFFECTIVE STATE: EMOTIONS AND LEARNING\nDo emotions contribute to intelligence, and if so, what are the\nimplications for the development of a technology of affective\ncomputing?\nRobert Provine, What Questions Are On Psychologist’s Minds Today?\nIn an attempt to reengineer the state of educational pedagogy, we should first look to expert\nteachers who are very adept at recognizing the emotional state of learners and, based upon their\nobservation, taking appropriate action that positively influences learning. But what do these expert\nteachers see and how do they select a course of action? How do students who have strayed from\nlearning return to a productive path, such as the one that Csikszentmihalyi [1990] refers to as the\n“zone of flow”?\nSkilled human mentors can assess emotional cues with varying degrees of perception.\nResearchers are beginning to imbue computers with similar abilities to recognize affective cues [e.g.,\nPicard, 2001; Scheirer, et al, 1999; Chen, et al, 1998; Donato, 1999; DeSilva, 1997; Ekman, 1997].\nAlthough computers perform as well as or better than people in selected domains, they do not yet rise\nto human levels of mentoring. We envision that computers will soon become capable of recognizing\nhuman behaviors indicative of the user’s affective state.\nTo this end it is necessary for us to rethink what is happening during learning and, based\nupon our hypothesis, reengineer accordingly. This supposition is based upon our own preliminary\npilot studies, with elementary school children, suggesting that a human observer can assess the\naffective emotional state of a student with reasonable reliability based on observation of facial\nexpressions, gross body language, and the content and tone of speech. If the human observer is also\nacting in the role of coach or mentor, these assessments can be confirmed or refined by direct\nconversation (e.g. simply asking the student if they are confused or frustrated before offering to\n3\nprovide coaching or hints). Moreover, successful learning (e.g. solving a difficult puzzle) is\nfrequently marked by an unmistakable elation, often jointly celebrated with “high fives.” In some\ncases, the “Aha!” moment is so dramatic, it verges on the epiphanetic. One of the great joys for an\neducator is to bring a student to such a moment of triumph.\nOur first step is to offer a model of a learning cycle (Figures 1a and 1b) and later to describe a\nmodel of emotions (Figure 2) and ultimately to relate them into a single model. Figures 1a and 1b\ninterweave the emotion axes shown in Figure 2 with the cognitive dynamics of the learning process.\nThe horizontal axis in Figures 1a and 1b is an Emotion Axis. It could be one of the specific axes from\nFigure 2, or it could symbolize the n-vector of all relevant emotion axes (thus allowing multi\u0002dimensional combinations of emotions). The positive valence (more pleasurable) emotions are on the\nright; the negative valence (more unpleasant) emotions are on the left. The vertical axis is what we\ncall the Learning Axis, and symbolizes the construction of knowledge upward, and the discarding of\nmisconceptions downward. Note: we do not see learning as being simply a process of\nconstructing/deconstructing or adding/subtracting information; this terminology is merely a projection\nof one aspect of how people can think about learning. Other aspects could be similarly included along\nthe Learning Axis.\nConstructive Learning\nDisappointment Awe\nPuzzlement Satisfaction\nConfusion Curiosity\nII I\nNegative Positive\nAffect Affect\nIII IV\nFrustration Hopefulness\nDiscard Fresh research\nMisconceptions\nUn-learning\nFigure 1a – Proposed model relating phases of learning to emotions in Figure 2\nII I\nIII IV\nFigure 1b – Circular and helical flow of emotion\n4\nAxis -1. 0 -0. 5 0 +0. 5 +1. 0\nAnxiety\u0002ConfidenceAnxiety Worry Discomfort Comfort Hopeful Confident\nBoredom\u0002FascinationEnnui Boredom Indifference Interest Curiosity Intrigue\nFrustration\u0002EuphoriaFrustration Puzzlement Confusion Insight Enlightenment Epiphany\nDispirited\u0002EncouragedDispirited Disappointed Dissatisfied Satisfied Thrilled Enthusiastic\nTerror -\nEnchantment\nTerror Dread Apprehension Calm Anticipatory Excited\nFigure 2 – Emotion sets possibly relevant to learning\nThe student ideally begins in Quadrant I or II: they might be curious and fascinated about a\nnew topic of interest (Quadrant I) or they might be puzzled and motivated to reduce confusion\n(Quadrant II). In either case, they are in the top half of the space, if their focus is on constructing or\ntesting knowledge. Movement happens in this space as learning proceeds. For example, when\nsolving a puzzle in The Incredible Machine, a student gets an idea how to implement a solution and\nthen builds its simulation. When she runs the simulation and it fails, she sees that her idea has some\npart that doesn’t work – that needs to be deconstructed. At this point it is not uncommon for the\nstudent to move down into the lower half of the diagram (Quadrant III) where emotions may be\nnegative and the cognitive focus changes to eliminating some misconception. As she consolidates her\nknowledge—what works and what does not—with awareness of a sense of making progress, she may\nmove to Quadrant IV. Getting a fresh idea propels the student back into the upper half of the space,\nmost likely Quadrant I. Thus, a typical learning experience involves a range of emotions, moving the\nstudent around the space as they learn.\nIf one visualizes a version of Figures 1a and 1b for each axis in Figure 2, then at any given\ninstant, the student might be in multiple Quadrants with respect to different axes. They might be in\nQuadrant II with respect to feeling frustrated; and simultaneously in Quadrant I with respect to\ninterest level. It is important to recognize that a range of emotions occurs naturally in a real learning\nprocess, and it is not simply the case that the positive emotions are the good ones. We do not fores",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "knowledge_management"
    },
    {
      "url": "https://er.educause.edu/articles/2016/10/adaptive-learning-systems-surviving-the-storm",
      "title": "Adaptive Learning Systems: Surviving the Storm",
      "author": "",
      "published_date": "2016-10-17T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<p>The effective implementation and use of adaptive learning systems requires a broad, more inclusive conversation among institutions, vendors, and other stakeholders to realize the benefits of next-generation personalized learning.</p>\n<p></p>\n<p>Virtually every academic area that studies various anthropology disciplines has been largely based on the same research method: assemble groups of individuals into an experiment scenario, determine their average response to the conditions, and use the same averaging to extrapolate a general conclusion for all people. Our current didactic, transactional digital learning solutions are designed around the concept of <em>sameness</em>. It's like the lull before a storm: calm and uneventful.</p>\n<p>A <em>haboob</em>—an intense dust storm carried on an atmospheric gravity current—can serve as an analogy of why this strategy doesn't work. Haboobs often arrive without warning, and the dust and debris they carry are blinding, making it impossible to see where you're going until after the sediment has settled. People's reactions to the giant wall of dust vary, from fear and a desire to travel as far in the opposite direction of the storm as possible, to a scientific or adventure-seeking fascination and a desire to chase after it. </p>\n<p>Similarly, the swirl of talk about the innovations surrounding adaptive learning systems arrived unexpectedly (before many of us were fully aware of the developments) and involved high-level, abstract discussions, making it difficult to see where we are now or where we want to go. And reactions in the higher education community have been varied: some have ignored the new technologies, whereas others have quickly (too quickly?) embraced these learning systems. To clear the air, we need a larger, more inclusive conversation among institutions, vendors, and other stakeholders in order to provide more granular thinking around specific minimally viable requirements for the application of adaptive learning systems.</p>\n<h2>Calm Before the Storm: What Problems Do Adaptive Systems Hope to Solve?</h2>\n<p>Intelligent adaptive learning systems are quickly emerging but are still in experimental stages. The intended design of these data-adaptive solutions seeks to enable differentiated instruction at a personalized level of learning. New approaches to diagnostic and formative assessment design making use of adaptive intelligence are becoming more common. Adaptive learning systems are designed to dynamically adjust to the level or type of course content based on an individual student's abilities or skill attainment, in ways that accelerate a learner's performance with both automated and instructor interventions. These adaptive systems achieve this by helping to address learning challenges such as varying student learning ability, diverse student backgrounds, and resource limitations. The intent of these machine learning systems is to use proficiency and determine what a student really knows and to accurately and logically move students through a sequential learning path to prescribed learning outcomes and skill mastery. These specific features will transform first-generation digital learning systems. The advantages include, but are not limited to, the following:</p>\n<ul>\n<li>Automated processes of student assessment and predictive analysis result in significant faculty time efficiencies.</li>\n<li>Adaptive systems have the potential to solve the primary and perennial problem in public education: the overwhelming challenge of teachers or faculty being responsible for accomplishing learning mastery among a demographically diverse set of students.</li>\n<li>Adaptive systems address the fundamentally different levels of prior knowledge, as well as course content progression based on students' skill and outcomes mastery measurement, decreasing faculty load in teaching and remediation to teaching and facilitating.</li>\n<li>Executed effectively, the cost efficiencies in automated feedback and remediation without formal instructor intervention have shown major improvements in student learning. </li>\n<li>Regulating course content degree of difficulty results in better course engagement and progression.</li>\n<li>Students own their learning journey: real-time response to their ongoing coursework provides detailed feedback for self-mediation.</li>\n<li>Adaptive systems encourage student ownership of their learning<em> </em>through automated feedback cycles prompting them to take action and advance independently of the class instructor. </li>\n<li>Adaptive systems conform to individual students' varied lifestyles versus students having to conform to the system.</li>\n<li>Faculty receive data with insights into individual students' needs. Adaptive systems can provide a level of automation allowing faculty to better allocate time to students who need remediation. </li>\n<li>The technology actively uses research about how people learn. Correctly developed, adaptive systems reveal how individual students learn. </li>\n<li>Adaptive systems empower faculty. Rich data analysis of student progression enables faculty to continually improve course design.</li>\n<li>Traditional assessment methods inform both faculty and students too late in the learning cycle. Using timely and comprehensive data-driven feedback, adaptive systems can inform in real time.</li>\n</ul>\n<p>Adaptive systems have the potential to shift education in the service of students by providing a student-centric design. The student-centered capabilities these systems aspire to provide are vastly unlike the current models for traditional classroom support—models deeply rooted in student administration. The underlying data systems and transaction timing (e.g., gradebook, end-of-course exams) are radically different from the real-time, learner-specific data that forms the foundation of student-centered learning. </p>\n<h2>No Two Dust Clouds Are Alike: Adaptive Learning Shapes and Sizes</h2>\n<p>There are many forms of adaptive learning systems. While classifications in other industries are narrower in defining their specific applications and use cases, there are no specific guidelines, taxonomies, or common vernacular for how various types of adaptive capabilities are described in the edtech industry. These new data-driven systems are expansive in categorical descriptions and desperately need more specifics to describe and evaluate appropriateness for any given instructional design and teaching and learning purpose. Key tenants of these first-generation adaptive systems include the following:</p>\n<ul>\n<li><em>Automation</em>: The ability to create automated processes that reduce more manual teaching processes in assessment, evaluation, remediation, and competency attainment</li>\n<li><em>Sequencing</em>: The ability to create a sequenced progression of skills and competencies contained in a finite learning path in a term or non-term unit of time</li>\n<li><em>Assessment</em>: The ability to employ combinations of benchmark, diagnostic, and formative assessments on a more immediate and continuous evaluation</li>\n<li><em>Real-time data collection</em>: The ability to collect, calculate, and evaluate data, from an array of sources, with some assumed inference method in real or near-real time</li>\n<li><em>Self-organizing</em>: The ability to self-organize information and data results from inferences to form ongoing and persistent feedback in the teaching and learning cycle </li>\n</ul>\n<p>With these commonalities in mind, we have identified four types and variants of adaptive learning systems: machine-learning-based adaptive systems; advanced algorithm adaptive systems; rules-based adaptive systems; and decision-tree adaptive systems.</p>\n<h3>Machine-Learning-Based Adaptive Systems</h3>\n<p>Machine-learning-based adaptive platforms are the most sophisticated scientific method in which to establish a truly adaptive state. Machine learning (ML) is synonymous with pattern recognition, statistical modeling, predictive analytics, statistical regularities, and other forms of advanced adaptive capabilities. ML-based systems use programmed algorithms to create the adaptive science core and make real-time predictions about a learner's subject matter mastery. ML-based adaptive platforms use learning algorithms, known also as \"learners,\" to create other algorithms, which in turn create adaptive sequences and predictive analytics that can continuously collect data and use it to move a student through a guided learning path. These ML learners continually harvest data in real time, determining students' proficiency in mastering objective-specific content modules. The data is then used to automatically adjust the overall sequence of skills or the type of content a student experiences. Learning algorithms create analytical models that are designed to produce reliable, repeatable decisions, and results reveal undiscovered insights in student mastery through ongoing evaluation of historical relationships and trends in the data. </p>\n<p>What's unique about ML-based adaptive systems is their ability to detect how an individual learns and approaches a learning task as part of these intelligent systems, as well as provide accurate and timely feedback and improve student performance. Since ML-based systems are highly computational, analyzing billions of data bits in real time, system scalability can be a question from two perspectives: how these systems are efficiently coded; and the provisioning architecture used to process, load, and balance enormous amounts of data. At minimum, ML systems feature the following:</p>\n<ul>\n<li><em>Continuous and dynamic improvement:</em> The instructional method improves over time.</li>\n<li><em>Learner profiles:</em> A baseline profile is used to classify learners' characteristics, such as demographic information, learning style attributes, academic strengths and weaknesses, and learning preferences.</li>\n<li><em",
        "html": "<div><div>\n<p>The effective implementation and use of adaptive learning systems requires a broad, more inclusive conversation among institutions, vendors, and other stakeholders to realize the benefits of next-generation personalized learning.</p>\n<p></p>\n<p>Virtually every academic area that studies various anthropology disciplines has been largely based on the same research method: assemble groups of individuals into an experiment scenario, determine their average response to the conditions, and use the same averaging to extrapolate a general conclusion for all people. Our current didactic, transactional digital learning solutions are designed around the concept of <em>sameness</em>. It's like the lull before a storm: calm and uneventful.</p>\n<p>A <em>haboob</em>—an intense dust storm carried on an atmospheric gravity current—can serve as an analogy of why this strategy doesn't work. Haboobs often arrive without warning, and the dust and debris they carry are blinding, making it impossible to see where you're going until after the sediment has settled. People's reactions to the giant wall of dust vary, from fear and a desire to travel as far in the opposite direction of the storm as possible, to a scientific or adventure-seeking fascination and a desire to chase after it. </p>\n<p>Similarly, the swirl of talk about the innovations surrounding adaptive learning systems arrived unexpectedly (before many of us were fully aware of the developments) and involved high-level, abstract discussions, making it difficult to see where we are now or where we want to go. And reactions in the higher education community have been varied: some have ignored the new technologies, whereas others have quickly (too quickly?) embraced these learning systems. To clear the air, we need a larger, more inclusive conversation among institutions, vendors, and other stakeholders in order to provide more granular thinking around specific minimally viable requirements for the application of adaptive learning systems.</p>\n<h2>Calm Before the Storm: What Problems Do Adaptive Systems Hope to Solve?</h2>\n<p>Intelligent adaptive learning systems are quickly emerging but are still in experimental stages. The intended design of these data-adaptive solutions seeks to enable differentiated instruction at a personalized level of learning. New approaches to diagnostic and formative assessment design making use of adaptive intelligence are becoming more common. Adaptive learning systems are designed to dynamically adjust to the level or type of course content based on an individual student's abilities or skill attainment, in ways that accelerate a learner's performance with both automated and instructor interventions. These adaptive systems achieve this by helping to address learning challenges such as varying student learning ability, diverse student backgrounds, and resource limitations. The intent of these machine learning systems is to use proficiency and determine what a student really knows and to accurately and logically move students through a sequential learning path to prescribed learning outcomes and skill mastery. These specific features will transform first-generation digital learning systems. The advantages include, but are not limited to, the following:</p>\n<ul>\n<li>Automated processes of student assessment and predictive analysis result in significant faculty time efficiencies.</li>\n<li>Adaptive systems have the potential to solve the primary and perennial problem in public education: the overwhelming challenge of teachers or faculty being responsible for accomplishing learning mastery among a demographically diverse set of students.</li>\n<li>Adaptive systems address the fundamentally different levels of prior knowledge, as well as course content progression based on students' skill and outcomes mastery measurement, decreasing faculty load in teaching and remediation to teaching and facilitating.</li>\n<li>Executed effectively, the cost efficiencies in automated feedback and remediation without formal instructor intervention have shown major improvements in student learning. </li>\n<li>Regulating course content degree of difficulty results in better course engagement and progression.</li>\n<li>Students own their learning journey: real-time response to their ongoing coursework provides detailed feedback for self-mediation.</li>\n<li>Adaptive systems encourage student ownership of their learning<em> </em>through automated feedback cycles prompting them to take action and advance independently of the class instructor. </li>\n<li>Adaptive systems conform to individual students' varied lifestyles versus students having to conform to the system.</li>\n<li>Faculty receive data with insights into individual students' needs. Adaptive systems can provide a level of automation allowing faculty to better allocate time to students who need remediation. </li>\n<li>The technology actively uses research about how people learn. Correctly developed, adaptive systems reveal how individual students learn. </li>\n<li>Adaptive systems empower faculty. Rich data analysis of student progression enables faculty to continually improve course design.</li>\n<li>Traditional assessment methods inform both faculty and students too late in the learning cycle. Using timely and comprehensive data-driven feedback, adaptive systems can inform in real time.</li>\n</ul>\n<p>Adaptive systems have the potential to shift education in the service of students by providing a student-centric design. The student-centered capabilities these systems aspire to provide are vastly unlike the current models for traditional classroom support—models deeply rooted in student administration. The underlying data systems and transaction timing (e.g., gradebook, end-of-course exams) are radically different from the real-time, learner-specific data that forms the foundation of student-centered learning. </p>\n<h2>No Two Dust Clouds Are Alike: Adaptive Learning Shapes and Sizes</h2>\n<p>There are many forms of adaptive learning systems. While classifications in other industries are narrower in defining their specific applications and use cases, there are no specific guidelines, taxonomies, or common vernacular for how various types of adaptive capabilities are described in the edtech industry. These new data-driven systems are expansive in categorical descriptions and desperately need more specifics to describe and evaluate appropriateness for any given instructional design and teaching and learning purpose. Key tenants of these first-generation adaptive systems include the following:</p>\n<ul>\n<li><em>Automation</em>: The ability to create automated processes that reduce more manual teaching processes in assessment, evaluation, remediation, and competency attainment</li>\n<li><em>Sequencing</em>: The ability to create a sequenced progression of skills and competencies contained in a finite learning path in a term or non-term unit of time</li>\n<li><em>Assessment</em>: The ability to employ combinations of benchmark, diagnostic, and formative assessments on a more immediate and continuous evaluation</li>\n<li><em>Real-time data collection</em>: The ability to collect, calculate, and evaluate data, from an array of sources, with some assumed inference method in real or near-real time</li>\n<li><em>Self-organizing</em>: The ability to self-organize information and data results from inferences to form ongoing and persistent feedback in the teaching and learning cycle </li>\n</ul>\n<p>With these commonalities in mind, we have identified four types and variants of adaptive learning systems: machine-learning-based adaptive systems; advanced algorithm adaptive systems; rules-based adaptive systems; and decision-tree adaptive systems.</p>\n<h3>Machine-Learning-Based Adaptive Systems</h3>\n<p>Machine-learning-based adaptive platforms are the most sophisticated scientific method in which to establish a truly adaptive state. Machine learning (ML) is synonymous with pattern recognition, statistical modeling, predictive analytics, statistical regularities, and other forms of advanced adaptive capabilities. ML-based systems use programmed algorithms to create the adaptive science core and make real-time predictions about a learner's subject matter mastery. ML-based adaptive platforms use learning algorithms, known also as \"learners,\" to create other algorithms, which in turn create adaptive sequences and predictive analytics that can continuously collect data and use it to move a student through a guided learning path. These ML learners continually harvest data in real time, determining students' proficiency in mastering objective-specific content modules. The data is then used to automatically adjust the overall sequence of skills or the type of content a student experiences. Learning algorithms create analytical models that are designed to produce reliable, repeatable decisions, and results reveal undiscovered insights in student mastery through ongoing evaluation of historical relationships and trends in the data. </p>\n<p>What's unique about ML-based adaptive systems is their ability to detect how an individual learns and approaches a learning task as part of these intelligent systems, as well as provide accurate and timely feedback and improve student performance. Since ML-based systems are highly computational, analyzing billions of data bits in real time, system scalability can be a question from two perspectives: how these systems are efficiently coded; and the provisioning architecture used to process, load, and balance enormous amounts of data. At minimum, ML systems feature the following:</p>\n<ul>\n<li><em>Continuous and dynamic improvement:</em> The instructional method improves over time.</li>\n<li><em>Learner profiles:</em> A baseline profile is used to classify learners' characteristics, such as demographic information, learning style attributes, academic strengths and weaknesses, and learning preferences.</li>\n<li><em",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "The effective implementation and use of adaptive learning systems requires a broad, more inclusive conversation among institutions, vendors, and other stakeholders to realize the benefits of next-generation personalized learning.Virtually every academic area that studies various anthropology disciplines has been largely based on the same research method: assemble groups of individuals into an experiment scenario, determine their average response to the conditions, and use the same averaging to e",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The effective implementation and use of adaptive learning systems requires a broad, more inclusive conversation among institutions, vendors, and other stakeholders to realize the benefits of next-generation personalized learning.Virtually every academic area that studies various anthropology disciplines has been largely based on the same research method: assemble groups of individuals into an experiment scenario, determine their average response to the conditions, and use the same averaging to e",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Calm Before the Storm: What Problems Do Adaptive Systems Hope to Solve?",
              "id": ""
            },
            {
              "level": "h2",
              "text": "No Two Dust Clouds Are Alike: Adaptive Learning Shapes and Sizes",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Machine-Learning-Based Adaptive Systems",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://kremen.fresnostate.edu/centers-projects/weltycenter/documents/leadership_resources/bcii/June%20BCII%20Session%20Days%201%202%203.pdf",
      "title": "",
      "author": "",
      "published_date": null,
      "content": {
        "text": "Building Coherence\nfor Instructional Improvement\nResearch-Practice Partnership\nJune 2015\nMichelle Forman &\nElizabeth Leisy Stosich\nWhat is Internal Coherence?\n• Thinking about leadership and improvement\n• Internal Coherence overview\n• Break\n• Reading and protocol on efficacy\n• Lunch\n• Instructional focus discussion\n• Vision and Consultancy protocols\n• Closing\nLeadership Reflection Protocol\nNew folks:\n• What does it mean to be a “good” leader?\n• How do leaders improve instruction schoolwide?\n• What feels daunting about this task? Manageable?\nCohort I:\n• How, if at all, did your conception of a \"good” leader\nchange over the course of the BCII PD?\n• How, if at all, has your leadership practice changed?\n• Does anything feel easier? More complex?\nPROPORTION OF VARIANCE IN STUDENT\nGROWTH SCORES-- READING, MATH-- EXPLAINED\nBY LEVEL\nCLASS\n60-61%\nREADING\n52-72%\nMATH\nSTUDENTS\n27-28% R\n13-19% M SCHOOLS\n12% R\n10-30 M\nRowan,\tCorren+,\t&\tMiller,\t2002\nWhat does this\nmean to you?\nWhat might\nexplain this?\nBuilding Coherence for Instructional\nImprovement\nContent coverage, including the topics taught and their\nlevel of rigor, varies greatly between classrooms.\nRowan and Correnti (2009) found that the variance in time\nspent on literacy instruction was more than four times\ngreater between classrooms than between elementary\nschools.\nStrong school culture is not enough to support high\nlevels of teaching and learning across the organization.\nMerseth (2009) found that level of tasks’ cognitive demand\nvaried greatly across classrooms in charter schools with\nstrong cultural coherence. These schools focused on “time on\ntask” rather than how teachers and students worked with\ncontent.\nInstructional Core & Academic Tasks\nThe relationships among teacher, student, and content determine the task\nAcademic\nTask\nCONTENT\nTEACHER\tSTUDENTS\nCity,\tElmore,\tFiarman,\t&\tTeitel,\t2009;\tCohen\t&\tBall,\t1999;\tDoyle,\t1983\ninstructional core: the\nrelationships among\nteachers, students, and\ncontent that influence\nstudent learning\nacademic tasks: the work\nthat students actually do\nTask Predicts Performance\nAcademic\nTask\nCONTENT\nTEACHER\tSTUDENTS\n“Students’ academic work in\nschool is defined by the academic\ntasks that are embedded in the\ncontent they encounter on a\ndaily basis… Students will learn\nwhat a task leads them to do,\nthat is, they will acquire\ninformation and operations that are\nnecessary to accomplish the\ntasks they encounter” (Doyle,\n1983).\nWhat is the task in each classroom?\n5th Grade Problem: Farmer Jim keeps 12 hens in every coop. If\nFarmer Jim has 20 coops and every hen lays 3 eggs on Monday,\nhow many eggs will Farmer Jim collect on Monday? Explain\nyour reasoning using words, numbers, or pictures.\nClass 1: The teacher gives students 7 minutes to work alone and\nrecord their work, then 7 minutes to work in pairs to come to\ntheir final solution. The teacher chooses students to explain\nand justify their final solution for the class.\nClass 2: Same as Class 1, but students volunteer to present, and\nafter presentations the teacher always writes the up the final\nsolution for students’ notebooks.\nClass 3: Same as Class 1, except teacher pairs her strongest\nstudents with her weakest ones, lets the students pick who\npresents, and students hand in a joint product at the end.\nVision\nTeam\nProcesses\nWhole-School\nImprovement\nEfforts\nLeadership Practice\nBUILDING COHERENCE FOR\nINSTRUCTIONAL IMPROVEMENT\nSTUDENT\nTEACHER CONTENT\nfor\nInstructional\nCore\nTeachers experiment with new ways of interacting with\ncontent and students to raise the level of academic\ntasks and realize the school’s instructional vision\nTeachers in teams work to realize the\ninstructional vision by discussing teaching\ndecisions based on student work and\nassessment data, evaluating curriculum,\nand planning instruction\nAs a faculty we have a clear strategy\nfor realizing our vision and coordinate\ncurriculum, instruction, and initiatives\nwith this focus\nLeaders articulate a clear vision for\ninstruction, create supportive\nconditions for learning, and hold\nteachers and teacher teams\naccountable for realizing this vision\nAr#culate\tvision\tfor\tinstruc#onal\timprovement\nFocus\ton\tteaching\tprac#ce\tand\tstudent\tlearning\nEnvironment\tsuppor#ve\tof\trisk-taking\n(psychological\tsafety)\nSupport\tstructures,\tprocesses,\tand\tpurpose\tof\tPLC\nwork\nTimely,\tintelligent\tprofessional\tdevelopment\nStructures,\tprocesses\tin\tplace\nTeam\ttask\tfocused\ton\ninstruc#onal\tcore\nExplicit\tgroup\tcommitments\nIncorpora#on\tof\tpeer\nobserva#on\tdata\nBroaden\tinstruc#onal\trepertoires\nTighten\tconnec#on\tbetween\tteaching\tand\tlearning\nGrowth\tof\tindividual\tand\tcollec#ve\tefficacy\tbeliefs\nExpecta#on\tof\tsuccess,\tperseverance\t(lateral\tpress)\nIndividual\tefficacy\tlinked\tto\npowerful\tinstruc#onal\nprac#ces\nCollec#ve\tefficacy\tstrong\npredictor\tof\tachievement\nInternal\tCoherence\tFramework\nBuilding Coherence for Instructional\nImprovement Overview\nFall 2013\nI. Internal\nCoherence &\nInstructional\nFocus\nII. Vision &\nStrategy for\nImproving the\nInstructional\nCore\nSpring 2014\nIII.\nInstructional\nCore &\nAcademic\nTasks\nIV. Team Work\n& Practices of\nEffective Teams\nFall 2014\nV. Instructional\nRounds\nVI. Strategic\nPlan: Going\nDeeper\nVII. Task:\nGoing Deeper\nSpring 2015\nVII. Teams:\nGoing Deeper\nIX. Ownership\nand\nNext Level of\nWork\nLearning from Colleagues\nWhat does growing Internal Coherence in your\nschool look like?\nBreak\nSee you in 10 minutes\n)\n7A\nU\nTeacher Efficacy\n• Albert Bandura, social cognitive theory\n• “I believe our faculty has what it takes”\n• Related to:\n• Aspirations, creativity, resilience, responsibility,\nstudent-directed learning, collaboration\n• Positively and significantly related to achievement\n• Sources of efficacy beliefs: mastery\nexperiences, vicarious experiences, social\npersuasion\n1. Goddard et al., 2000; Goddard et al., 2004; Goddard et al.,\n2011; Hoy et al., 2002\nEfficacy and the Instructional Core\nPlease read the selection from Puchner & Taylor (2006)\nconsidering:\n• How would you describe the nature of the teachers’\ncollaborative work?\n• How do teachers’ understandings, attitudes, or\nbeliefs change as a result of this collaboration?\n• Choose one passage that strikes you as important\nor interesting\nWe will run the Save the Last Word text protocol in 20\nmins\nSave the Last Word Protocol\n1. First\tperson\tiden+fies\tthe\tpart\tof\tthe\tar+cle\tthat\ts/he\tfound\nto\tbe\tmost\tsignificant\tand\treads\tit\tout\tloud\tto\tthe\tgroup.\tThis\nperson\tsays\tnothing\tabout\twhy\ts/he\tchose\tthat\tpar+cular\npassage.\n2. The\tother\tpar+cipants\teach\thave\t1\tminute\tto\trespond\tto\tthe\npassage\t—\tsaying\twhat\tit\tmakes\tthem\tthink\tabout,\twhat\nques+ons\tit\traises\tfor\tthem,\tetc.\n3. The\tfirst\tpar+cipant\tthen\thas\t3\tminutes\tto\tstate\twhy\ts/he\nchose\tthat\tpart\tof\tthe\tar+cle\tand\tto\trespond\tto—\tor\tbuild\ton\n—his/her\tcolleagues’\tcomments.\n4. The\tsame\tpaWern\tis\tfollowed\tun+l\tall\tfour\tmembers\tof\tthe\ngroup\thave\thad\ta\tchance\tto\tbe\tthe\tpresenter\tand\tto\thave\n“the\tlast\tword.”\nUse\tany\taddi+onal\t+me\tto\tdebrief\tthe\texperience.\tHow\twas\tthis\na\tuseful\tway\tto\texplore\tthe\tideas\tin\tthe\ttext\tand\tto\texplore\nyour\town\tthinking?\nAdapted\tfrom\tthe\tNa+onal\tSchool\tReform\tFaculty\nLunch\nSER Priston\nClosing & Reflection\n• New folks\n– How does the IC model align with or differ from\nyour conceptions of leadership and school\nimprovement?\n– Does it make anything feel more simple or\ncomplex?\n– What questions feel most pressing for tomorrow?\n• Cohort I\n– How did today go? Thoughts for best supporting\nnew folks in next 2 days?\nBuilding Coherence\nfor Instructional Improvement\nResearch-Practice Partnership\nJune 2015\nMichelle Forman &\nElizabeth Leisy Stosich\nYour Thoughts from Yesterday\nGood review, affirmation\nAppreciated hearing from the Cohort I schools\nModel aligns with conceptions of leadership\nTiming of IR, wisdom starting before IC?\nBreakout groups for a more productive session\nOverwhelming for new folks\nHow best to partner, mentor, orient new folks?\nHow do you “do” IC?\n• Role of Leadership Team\n• Work on vision and strategy (differentiate)\n• Lunch\n• Supporting Teacher Teams\n• Productive team talk\n• Psychological safety\n• Constructive challenge\n• Close 2:30\nIC Essentials\n• Learn the work by doing the work\n• Attentive to product AND process\n• Focus on the instructional core\n• Iterative and developmental\n• Collective efficacy, agency for change\n• DOK Level 3\n• Teacher learning NOT implementation\nDeveloping a Shared Vision & Strategy FOCUS\nWhat are\nwe working\non?\nVISION\nWhat\nwould it\nlook like?\nSTRATEGY\nHow do\nwe get\nthere?\nambitious\tinstructional\tvision:\tour\tbest\tthinking\nabout\tthe\thigh-level\tteaching\tand\tlearning\twe\twant\nto\tsee\tschool-wide\nstrategy:\tour\tplan\tof\taction\tfor\timproving\tteachers’\ninstruction\tand\tstudents’\tlearning\tto\trealize\tthis\nvision\nDeveloping an Ambitious Instructional\nVision\nObjective: Develop a bold vision for instruction that is\nanchored in the instructional core\nContext: Back to the future! It is 2019. Reflect on the\ncurrent work of teachers and students and just how\nfar you have come.\nDiscuss & Record\n1. What does “it” look like? What are students doing?\nWhat are teachers doing? How are they interacting\nwith content? Use the present tense. [10 min]\n2. Look back to 2015 and describe what the work of\nteachers and students looked like when you\nstarted. Use the past tense. [10 min]\nDeveloping an Ambitious Instructional\nVision\nEvaluating the audacity of our vision [10 min]\n– Is our vision ambitious enough that it requires adults and\nstudents to learn to work in new ways?\n– Would making this vision a reality result in meaningful\nimprovements in student learning?\n– Is our vision observable and grounded in the instructional\ncore? Would we be able to see if students and teachers\nwere working in ways that reflected this vision?\nBe specific! What would it look like? What would it feel like?\nHow would it improve learning?\nBreak!\nMake any adjustments\nCommit your vision to paper\nSee you in 10 minutes\nResearch Partnership\nTeacher Learning Bridge\nSet the direction for improving teaching and\nlearning at your school through the creation\nof a shared instructional v",
        "html": "Building Coherence\nfor Instructional Improvement\nResearch-Practice Partnership\nJune 2015\nMichelle Forman &\nElizabeth Leisy Stosich\nWhat is Internal Coherence?\n• Thinking about leadership and improvement\n• Internal Coherence overview\n• Break\n• Reading and protocol on efficacy\n• Lunch\n• Instructional focus discussion\n• Vision and Consultancy protocols\n• Closing\nLeadership Reflection Protocol\nNew folks:\n• What does it mean to be a “good” leader?\n• How do leaders improve instruction schoolwide?\n• What feels daunting about this task? Manageable?\nCohort I:\n• How, if at all, did your conception of a \"good” leader\nchange over the course of the BCII PD?\n• How, if at all, has your leadership practice changed?\n• Does anything feel easier? More complex?\nPROPORTION OF VARIANCE IN STUDENT\nGROWTH SCORES-- READING, MATH-- EXPLAINED\nBY LEVEL\nCLASS\n60-61%\nREADING\n52-72%\nMATH\nSTUDENTS\n27-28% R\n13-19% M SCHOOLS\n12% R\n10-30 M\nRowan,\tCorren+,\t&\tMiller,\t2002\nWhat does this\nmean to you?\nWhat might\nexplain this?\nBuilding Coherence for Instructional\nImprovement\nContent coverage, including the topics taught and their\nlevel of rigor, varies greatly between classrooms.\nRowan and Correnti (2009) found that the variance in time\nspent on literacy instruction was more than four times\ngreater between classrooms than between elementary\nschools.\nStrong school culture is not enough to support high\nlevels of teaching and learning across the organization.\nMerseth (2009) found that level of tasks’ cognitive demand\nvaried greatly across classrooms in charter schools with\nstrong cultural coherence. These schools focused on “time on\ntask” rather than how teachers and students worked with\ncontent.\nInstructional Core & Academic Tasks\nThe relationships among teacher, student, and content determine the task\nAcademic\nTask\nCONTENT\nTEACHER\tSTUDENTS\nCity,\tElmore,\tFiarman,\t&\tTeitel,\t2009;\tCohen\t&\tBall,\t1999;\tDoyle,\t1983\ninstructional core: the\nrelationships among\nteachers, students, and\ncontent that influence\nstudent learning\nacademic tasks: the work\nthat students actually do\nTask Predicts Performance\nAcademic\nTask\nCONTENT\nTEACHER\tSTUDENTS\n“Students’ academic work in\nschool is defined by the academic\ntasks that are embedded in the\ncontent they encounter on a\ndaily basis… Students will learn\nwhat a task leads them to do,\nthat is, they will acquire\ninformation and operations that are\nnecessary to accomplish the\ntasks they encounter” (Doyle,\n1983).\nWhat is the task in each classroom?\n5th Grade Problem: Farmer Jim keeps 12 hens in every coop. If\nFarmer Jim has 20 coops and every hen lays 3 eggs on Monday,\nhow many eggs will Farmer Jim collect on Monday? Explain\nyour reasoning using words, numbers, or pictures.\nClass 1: The teacher gives students 7 minutes to work alone and\nrecord their work, then 7 minutes to work in pairs to come to\ntheir final solution. The teacher chooses students to explain\nand justify their final solution for the class.\nClass 2: Same as Class 1, but students volunteer to present, and\nafter presentations the teacher always writes the up the final\nsolution for students’ notebooks.\nClass 3: Same as Class 1, except teacher pairs her strongest\nstudents with her weakest ones, lets the students pick who\npresents, and students hand in a joint product at the end.\nVision\nTeam\nProcesses\nWhole-School\nImprovement\nEfforts\nLeadership Practice\nBUILDING COHERENCE FOR\nINSTRUCTIONAL IMPROVEMENT\nSTUDENT\nTEACHER CONTENT\nfor\nInstructional\nCore\nTeachers experiment with new ways of interacting with\ncontent and students to raise the level of academic\ntasks and realize the school’s instructional vision\nTeachers in teams work to realize the\ninstructional vision by discussing teaching\ndecisions based on student work and\nassessment data, evaluating curriculum,\nand planning instruction\nAs a faculty we have a clear strategy\nfor realizing our vision and coordinate\ncurriculum, instruction, and initiatives\nwith this focus\nLeaders articulate a clear vision for\ninstruction, create supportive\nconditions for learning, and hold\nteachers and teacher teams\naccountable for realizing this vision\nAr#culate\tvision\tfor\tinstruc#onal\timprovement\nFocus\ton\tteaching\tprac#ce\tand\tstudent\tlearning\nEnvironment\tsuppor#ve\tof\trisk-taking\n(psychological\tsafety)\nSupport\tstructures,\tprocesses,\tand\tpurpose\tof\tPLC\nwork\nTimely,\tintelligent\tprofessional\tdevelopment\nStructures,\tprocesses\tin\tplace\nTeam\ttask\tfocused\ton\ninstruc#onal\tcore\nExplicit\tgroup\tcommitments\nIncorpora#on\tof\tpeer\nobserva#on\tdata\nBroaden\tinstruc#onal\trepertoires\nTighten\tconnec#on\tbetween\tteaching\tand\tlearning\nGrowth\tof\tindividual\tand\tcollec#ve\tefficacy\tbeliefs\nExpecta#on\tof\tsuccess,\tperseverance\t(lateral\tpress)\nIndividual\tefficacy\tlinked\tto\npowerful\tinstruc#onal\nprac#ces\nCollec#ve\tefficacy\tstrong\npredictor\tof\tachievement\nInternal\tCoherence\tFramework\nBuilding Coherence for Instructional\nImprovement Overview\nFall 2013\nI. Internal\nCoherence &\nInstructional\nFocus\nII. Vision &\nStrategy for\nImproving the\nInstructional\nCore\nSpring 2014\nIII.\nInstructional\nCore &\nAcademic\nTasks\nIV. Team Work\n& Practices of\nEffective Teams\nFall 2014\nV. Instructional\nRounds\nVI. Strategic\nPlan: Going\nDeeper\nVII. Task:\nGoing Deeper\nSpring 2015\nVII. Teams:\nGoing Deeper\nIX. Ownership\nand\nNext Level of\nWork\nLearning from Colleagues\nWhat does growing Internal Coherence in your\nschool look like?\nBreak\nSee you in 10 minutes\n)\n7A\nU\nTeacher Efficacy\n• Albert Bandura, social cognitive theory\n• “I believe our faculty has what it takes”\n• Related to:\n• Aspirations, creativity, resilience, responsibility,\nstudent-directed learning, collaboration\n• Positively and significantly related to achievement\n• Sources of efficacy beliefs: mastery\nexperiences, vicarious experiences, social\npersuasion\n1. Goddard et al., 2000; Goddard et al., 2004; Goddard et al.,\n2011; Hoy et al., 2002\nEfficacy and the Instructional Core\nPlease read the selection from Puchner & Taylor (2006)\nconsidering:\n• How would you describe the nature of the teachers’\ncollaborative work?\n• How do teachers’ understandings, attitudes, or\nbeliefs change as a result of this collaboration?\n• Choose one passage that strikes you as important\nor interesting\nWe will run the Save the Last Word text protocol in 20\nmins\nSave the Last Word Protocol\n1. First\tperson\tiden+fies\tthe\tpart\tof\tthe\tar+cle\tthat\ts/he\tfound\nto\tbe\tmost\tsignificant\tand\treads\tit\tout\tloud\tto\tthe\tgroup.\tThis\nperson\tsays\tnothing\tabout\twhy\ts/he\tchose\tthat\tpar+cular\npassage.\n2. The\tother\tpar+cipants\teach\thave\t1\tminute\tto\trespond\tto\tthe\npassage\t—\tsaying\twhat\tit\tmakes\tthem\tthink\tabout,\twhat\nques+ons\tit\traises\tfor\tthem,\tetc.\n3. The\tfirst\tpar+cipant\tthen\thas\t3\tminutes\tto\tstate\twhy\ts/he\nchose\tthat\tpart\tof\tthe\tar+cle\tand\tto\trespond\tto—\tor\tbuild\ton\n—his/her\tcolleagues’\tcomments.\n4. The\tsame\tpaWern\tis\tfollowed\tun+l\tall\tfour\tmembers\tof\tthe\ngroup\thave\thad\ta\tchance\tto\tbe\tthe\tpresenter\tand\tto\thave\n“the\tlast\tword.”\nUse\tany\taddi+onal\t+me\tto\tdebrief\tthe\texperience.\tHow\twas\tthis\na\tuseful\tway\tto\texplore\tthe\tideas\tin\tthe\ttext\tand\tto\texplore\nyour\town\tthinking?\nAdapted\tfrom\tthe\tNa+onal\tSchool\tReform\tFaculty\nLunch\nSER Priston\nClosing & Reflection\n• New folks\n– How does the IC model align with or differ from\nyour conceptions of leadership and school\nimprovement?\n– Does it make anything feel more simple or\ncomplex?\n– What questions feel most pressing for tomorrow?\n• Cohort I\n– How did today go? Thoughts for best supporting\nnew folks in next 2 days?\nBuilding Coherence\nfor Instructional Improvement\nResearch-Practice Partnership\nJune 2015\nMichelle Forman &\nElizabeth Leisy Stosich\nYour Thoughts from Yesterday\nGood review, affirmation\nAppreciated hearing from the Cohort I schools\nModel aligns with conceptions of leadership\nTiming of IR, wisdom starting before IC?\nBreakout groups for a more productive session\nOverwhelming for new folks\nHow best to partner, mentor, orient new folks?\nHow do you “do” IC?\n• Role of Leadership Team\n• Work on vision and strategy (differentiate)\n• Lunch\n• Supporting Teacher Teams\n• Productive team talk\n• Psychological safety\n• Constructive challenge\n• Close 2:30\nIC Essentials\n• Learn the work by doing the work\n• Attentive to product AND process\n• Focus on the instructional core\n• Iterative and developmental\n• Collective efficacy, agency for change\n• DOK Level 3\n• Teacher learning NOT implementation\nDeveloping a Shared Vision & Strategy FOCUS\nWhat are\nwe working\non?\nVISION\nWhat\nwould it\nlook like?\nSTRATEGY\nHow do\nwe get\nthere?\nambitious\tinstructional\tvision:\tour\tbest\tthinking\nabout\tthe\thigh-level\tteaching\tand\tlearning\twe\twant\nto\tsee\tschool-wide\nstrategy:\tour\tplan\tof\taction\tfor\timproving\tteachers’\ninstruction\tand\tstudents’\tlearning\tto\trealize\tthis\nvision\nDeveloping an Ambitious Instructional\nVision\nObjective: Develop a bold vision for instruction that is\nanchored in the instructional core\nContext: Back to the future! It is 2019. Reflect on the\ncurrent work of teachers and students and just how\nfar you have come.\nDiscuss & Record\n1. What does “it” look like? What are students doing?\nWhat are teachers doing? How are they interacting\nwith content? Use the present tense. [10 min]\n2. Look back to 2015 and describe what the work of\nteachers and students looked like when you\nstarted. Use the past tense. [10 min]\nDeveloping an Ambitious Instructional\nVision\nEvaluating the audacity of our vision [10 min]\n– Is our vision ambitious enough that it requires adults and\nstudents to learn to work in new ways?\n– Would making this vision a reality result in meaningful\nimprovements in student learning?\n– Is our vision observable and grounded in the instructional\ncore? Would we be able to see if students and teachers\nwere working in ways that reflected this vision?\nBe specific! What would it look like? What would it feel like?\nHow would it improve learning?\nBreak!\nMake any adjustments\nCommit your vision to paper\nSee you in 10 minutes\nResearch Partnership\nTeacher Learning Bridge\nSet the direction for improving teaching and\nlearning at your school through the creation\nof a shared instructional v",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.linkedin.com/pulse/evolution-knowledge-systems-why-matters-how-happens-prasad-kaipa",
      "title": "The Evolution of Knowledge Systems: Why It Matters and How It Happens",
      "author": "Prasad Kaipa",
      "published_date": "2023-11-08T04:11:36.000Z",
      "content": {
        "text": "<div><div>\n<div>\n<article>\n<figure>\n<figcaption>How knowledge evolves</figcaption>\n</figure>\n<header>\n<div>\n<p><a href=\"https://www.linkedin.com/in/prasadkaipa\">\n<span>\nPrasad Kaipa\n</span>\n</a></p><div>\n<h3>\nPrasad Kaipa\n</h3>\n<h4>\nCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and Advisor\n</h4>\n<p>\nPublished Oct 3, 2023\n</p>\n</div>\n</div>\n</header>\n<div>\n<p>\n<span>This is 2nd article in the Knowledge Evolution Series.</span>\n</p>\n<p>\n<span>In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between data, information, knowledge, and wisdom. This understanding provides clarity, especially in an era teeming with AI advancements and dynamic information shifts.</span>\n</p>\n<p>\n</p><h3><span>1. The Complex Life Cycle of Knowledge Systems:</span></h3>\n<p></p>\n<p>\n<span>Knowledge systems, ranging from scientific theories and organizational strategies to deep philosophical tenets, evolve through intricate stages. Each phase in this evolution offers insights into the system's acceptance, application, and longevity.</span>\n</p>\n<p>\n<span>Manifesting a Framework or Model</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific Lens</span><span>: Initial hypothesis on climate change.</span></li>\n<li><span>Organizational Lens</span><span>: Visionaries shaping the future of technology.</span></li>\n<li><span>Philosophical Lens</span><span>: Insights of thinkers that set the foundation for various philosophies.</span></li>\n</ul>\n</div>\n<p>\n<span>Contextualizing</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Comparing theories to existing records.</span></li>\n<li><span>Organizational</span><span>: Analyzing market demand.</span></li>\n<li><span>Philosophical</span><span>: Situating philosophical thoughts within traditions.</span></li>\n</ul>\n</div>\n<p>\n<span>Contemporizing</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Adapting theories to new evidence.</span></li>\n<li><span>Organizational</span><span>: Pivoting business models in light of market demands.</span></li>\n<li><span>Philosophical</span><span>: Reinterpreting ancient wisdom for modern challenges.</span></li>\n</ul>\n</div>\n<p>\n<span>Interpreting</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Peer review processes.</span></li>\n<li><span>Organizational</span><span>: Internal training sessions.</span></li>\n<li><span>Philosophical</span><span>: Engaging in public philosophy and discourse.</span></li>\n</ul>\n</div>\n<p>\n<span>Applying to the Problem at Hand</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Field trials and experiments.</span></li>\n<li><span>Organizational</span><span>: Prototyping or beta testing.</span></li>\n<li><span>Philosophical</span><span>: Philosophical discussions guiding real-world ethics.</span></li>\n</ul>\n</div>\n<div>\n<h2>Recommended by LinkedIn</h2>\n</div>\n<p>\n<span>Validating the Results</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Statistical validation and repeat experiments.</span></li>\n<li><span>Organizational</span><span>: ROI analysis and feedback loops.</span></li>\n<li><span>Philosophical</span><span>: Comparative analysis and philosophical debates.</span></li>\n</ul>\n</div>\n<p>\n<span>Recognizing as an Effective Solution</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Integration into educational curricula.</span></li>\n<li><span>Organizational</span><span>: Establishment as best practices.</span></li>\n<li><span>Philosophical</span><span>: Gaining widespread influence.</span></li>\n</ul>\n</div>\n<p>\n<span>Being Accepted as a Superior Solution</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Leading to paradigm shifts.</span></li>\n<li><span>Organizational</span><span>: Becoming an industry standard.</span></li>\n<li><span>Philosophical</span><span>: Being recognized as a foundational text.</span></li>\n</ul>\n</div>\n<p>\n</p><h3><span>2. From Tacit to Explicit: Unraveling the Knowledge Spectrum:</span></h3>\n<p></p>\n<p>\n<span>Knowledge exists in two primary forms: tacit and explicit. Explicit knowledge is documented, structured, and shared, like data in a report or a recorded process in an organization. Tacit knowledge is harder to articulate, rooted in personal experiences, values, or cultural nuances.</span>\n</p>\n<p>\n<span>Example</span><span>: Consider the art of Japanese tea-making. While explicit knowledge might dictate the temperature of water or type of tea leaves, the tacit knowledge encompasses the precise hand movements, the cultural importance of the ceremony, or the ambiance of the setting.</span>\n</p>\n<p>\n</p><h3><span>3. Factors Influencing Knowledge Evolution:</span></h3>\n<p></p>\n<p>\n<span>Several external and internal elements mold the trajectory of knowledge systems. These range from the origins of the system, its adaptability, and its relevance in changing societal contexts.</span>\n</p>\n<div>\n<ul>\n<li><span>Spirituality and Consciousness</span><span>: Ancient knowledge systems rooted in spirituality, like Yoga or Buddhist meditation, have seen resurgent global popularity. Their evolution has required adaptation, yet the core essence remains intact, emphasizing self-awareness, consciousness, and holistic well-being.</span></li>\n<li><span>Cultural Context</span><span>: Cultural nuances significantly influence knowledge. For instance, Traditional Chinese Medicine offers insights into healing that are vastly different from Western medicine, shaped by millennia of Chinese culture and philosophy.</span></li>\n<li><span>Relevance and Adaptation</span><span>: Knowledge systems must evolve to stay relevant. Ancient spiritual practices, for example, have found new life in modern self-care routines and stress management techniques, providing holistic solutions in today's fast-paced world.</span></li>\n</ul>\n</div>\n<p>\n</p><h3><span>Conclusion:</span></h3>\n<p></p>\n<p>\n<span>Understanding the evolution of knowledge systems equips us to navigate our world's intricacies more adeptly. Recognizing the interplay between data, information, knowledge, and wisdom, especially in an AI-driven age, holds the key to progress. As we bridge the ancient and the modern, blending time-tested wisdom with contemporary insights, we pave the path for a more enlightened future.</span>\n</p>\n<p>\n<span>References</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Kuhn, T. S. (1962). </span><span>The Structure of Scientific Revolutions</span><span>. University of Chicago Press.</span></li>\n<li><span>Porter, M. E. (1985). </span><span>Competitive Advantage</span><span>. Free Press.</span></li>\n<li><span>MacIntyre, A. (1981). </span><span>After Virtue</span><span>. University of Notre Dame Press.</span></li>\n<li><span>Kaipa, P. (2000). Knowledge architecture for the twenty-first century. </span><span>Behaviour &amp; Information Technology, 19(3)</span><span>, 153-161.</span></li>\n<li><span>Dalkir, K. (2013). </span><span>Knowledge Management in Theory and Practice</span><span>. MIT Press.</span></li>\n<li><span>Polanyi, M. (2009). </span><span>The Tacit Dimension</span><span>. University of Chicago Press.</span></li>\n<li><span>Stenmark, D. (2002). Information vs. Knowledge: The Role of intranets in Knowledge Management. </span><span>Proceedings of the 35th Hawaii International Conference on System Sciences</span><span>.</span></li>\n<li><span>Zuboff, S. (2019). </span><span>The Age of Surveillance Capitalism</span><span>. PublicAffairs.</span></li>\n<li><span>Bostrom, N. (2014). </span><span>Superintelligence</span><span>. Oxford University Press.</span></li>\n<li><span>Hidalgo, C. A. (2015). </span><span>Why Information Grows</span><span>. Basic Books.</span></li>\n</ul>\n</div>\n</div>\n</article>\n<section>\n<h2>\nMore articles by Prasad Kaipa\n</h2>\n<div>\n<ul>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/new-era-work-why-80-find-meaning-yet-35-still-plan-quit-prasad-kaipa-hmc9c\">\n<span>\nA New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to Quit\n</span>\n</a></p>\n<div>\n<p><span>Jan 4, 2025</span>\n</p>\n<h3>\nA New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to Quit\n</h3>\n<p>\nHere’s the biggest paradox in the global workforce today: 80% of employees say their work is meaningful, yet 35%of them…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/our-gita-project-journey-transformation-renewal-prasad-kaipa-ux7ac\">\n<span>\nOur Gita Project: A Journey of Transformation and Renewal\n</span>\n</a></p>\n<div>\n<p><span>Dec 10, 2024</span>\n</p>\n<h3>\nOur Gita Project: A Journey of Transformation and Renewal\n</h3>\n<p>\nThe Bhagavad Gita, a timeless treasure of wisdom, continues to guide us through the complexities of modern life…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/discovering-your-life-purpose-more-than-roles-job-prasad-kaipa-lwhtc\">\n<span>\nDiscovering Your Life Purpose: More Than Roles, More Than a Job\n</span>\n</a></p>\n<div>\n<p><span>Dec 8, 2024</span>\n</p>\n<h3>\nDiscovering Your Life Purpose: More Than Roles, More Than a Job\n</h3>\n<p>\nWhat does it mean to truly live with purpose? Have you ever wondered if there’s more to your life than just the roles…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/part-2-timeless-wisdom-modern-leaders-indic-us-election-prasad-kaipa-bevxc\">\n<span>\nPart 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US Election\n</span>\n</a></p>\n<div>\n<p><span>Nov 7, 2024</span>\n</p>\n<h3>\nPart 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US Election\n</h3>\n<p>\nWhat makes a leader resonate with millions and make him/her succeed in the face of stiff opposition? I wrote an article…\n</p>\n</div>\n</div>\n</li>\n<li>\n<",
        "html": "<div><div>\n<div>\n<article>\n<figure>\n<figcaption>How knowledge evolves</figcaption>\n</figure>\n<header>\n<div>\n<p><a href=\"https://www.linkedin.com/in/prasadkaipa\">\n<span>\nPrasad Kaipa\n</span>\n</a></p><div>\n<h3>\nPrasad Kaipa\n</h3>\n<h4>\nCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and Advisor\n</h4>\n<p>\nPublished Oct 3, 2023\n</p>\n</div>\n</div>\n</header>\n<div>\n<p>\n<span>This is 2nd article in the Knowledge Evolution Series.</span>\n</p>\n<p>\n<span>In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between data, information, knowledge, and wisdom. This understanding provides clarity, especially in an era teeming with AI advancements and dynamic information shifts.</span>\n</p>\n<p>\n</p><h3><span>1. The Complex Life Cycle of Knowledge Systems:</span></h3>\n<p></p>\n<p>\n<span>Knowledge systems, ranging from scientific theories and organizational strategies to deep philosophical tenets, evolve through intricate stages. Each phase in this evolution offers insights into the system's acceptance, application, and longevity.</span>\n</p>\n<p>\n<span>Manifesting a Framework or Model</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific Lens</span><span>: Initial hypothesis on climate change.</span></li>\n<li><span>Organizational Lens</span><span>: Visionaries shaping the future of technology.</span></li>\n<li><span>Philosophical Lens</span><span>: Insights of thinkers that set the foundation for various philosophies.</span></li>\n</ul>\n</div>\n<p>\n<span>Contextualizing</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Comparing theories to existing records.</span></li>\n<li><span>Organizational</span><span>: Analyzing market demand.</span></li>\n<li><span>Philosophical</span><span>: Situating philosophical thoughts within traditions.</span></li>\n</ul>\n</div>\n<p>\n<span>Contemporizing</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Adapting theories to new evidence.</span></li>\n<li><span>Organizational</span><span>: Pivoting business models in light of market demands.</span></li>\n<li><span>Philosophical</span><span>: Reinterpreting ancient wisdom for modern challenges.</span></li>\n</ul>\n</div>\n<p>\n<span>Interpreting</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Peer review processes.</span></li>\n<li><span>Organizational</span><span>: Internal training sessions.</span></li>\n<li><span>Philosophical</span><span>: Engaging in public philosophy and discourse.</span></li>\n</ul>\n</div>\n<p>\n<span>Applying to the Problem at Hand</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Field trials and experiments.</span></li>\n<li><span>Organizational</span><span>: Prototyping or beta testing.</span></li>\n<li><span>Philosophical</span><span>: Philosophical discussions guiding real-world ethics.</span></li>\n</ul>\n</div>\n<div>\n<h2>Recommended by LinkedIn</h2>\n</div>\n<p>\n<span>Validating the Results</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Statistical validation and repeat experiments.</span></li>\n<li><span>Organizational</span><span>: ROI analysis and feedback loops.</span></li>\n<li><span>Philosophical</span><span>: Comparative analysis and philosophical debates.</span></li>\n</ul>\n</div>\n<p>\n<span>Recognizing as an Effective Solution</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Integration into educational curricula.</span></li>\n<li><span>Organizational</span><span>: Establishment as best practices.</span></li>\n<li><span>Philosophical</span><span>: Gaining widespread influence.</span></li>\n</ul>\n</div>\n<p>\n<span>Being Accepted as a Superior Solution</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Scientific</span><span>: Leading to paradigm shifts.</span></li>\n<li><span>Organizational</span><span>: Becoming an industry standard.</span></li>\n<li><span>Philosophical</span><span>: Being recognized as a foundational text.</span></li>\n</ul>\n</div>\n<p>\n</p><h3><span>2. From Tacit to Explicit: Unraveling the Knowledge Spectrum:</span></h3>\n<p></p>\n<p>\n<span>Knowledge exists in two primary forms: tacit and explicit. Explicit knowledge is documented, structured, and shared, like data in a report or a recorded process in an organization. Tacit knowledge is harder to articulate, rooted in personal experiences, values, or cultural nuances.</span>\n</p>\n<p>\n<span>Example</span><span>: Consider the art of Japanese tea-making. While explicit knowledge might dictate the temperature of water or type of tea leaves, the tacit knowledge encompasses the precise hand movements, the cultural importance of the ceremony, or the ambiance of the setting.</span>\n</p>\n<p>\n</p><h3><span>3. Factors Influencing Knowledge Evolution:</span></h3>\n<p></p>\n<p>\n<span>Several external and internal elements mold the trajectory of knowledge systems. These range from the origins of the system, its adaptability, and its relevance in changing societal contexts.</span>\n</p>\n<div>\n<ul>\n<li><span>Spirituality and Consciousness</span><span>: Ancient knowledge systems rooted in spirituality, like Yoga or Buddhist meditation, have seen resurgent global popularity. Their evolution has required adaptation, yet the core essence remains intact, emphasizing self-awareness, consciousness, and holistic well-being.</span></li>\n<li><span>Cultural Context</span><span>: Cultural nuances significantly influence knowledge. For instance, Traditional Chinese Medicine offers insights into healing that are vastly different from Western medicine, shaped by millennia of Chinese culture and philosophy.</span></li>\n<li><span>Relevance and Adaptation</span><span>: Knowledge systems must evolve to stay relevant. Ancient spiritual practices, for example, have found new life in modern self-care routines and stress management techniques, providing holistic solutions in today's fast-paced world.</span></li>\n</ul>\n</div>\n<p>\n</p><h3><span>Conclusion:</span></h3>\n<p></p>\n<p>\n<span>Understanding the evolution of knowledge systems equips us to navigate our world's intricacies more adeptly. Recognizing the interplay between data, information, knowledge, and wisdom, especially in an AI-driven age, holds the key to progress. As we bridge the ancient and the modern, blending time-tested wisdom with contemporary insights, we pave the path for a more enlightened future.</span>\n</p>\n<p>\n<span>References</span><span>:</span>\n</p>\n<div>\n<ul>\n<li><span>Kuhn, T. S. (1962). </span><span>The Structure of Scientific Revolutions</span><span>. University of Chicago Press.</span></li>\n<li><span>Porter, M. E. (1985). </span><span>Competitive Advantage</span><span>. Free Press.</span></li>\n<li><span>MacIntyre, A. (1981). </span><span>After Virtue</span><span>. University of Notre Dame Press.</span></li>\n<li><span>Kaipa, P. (2000). Knowledge architecture for the twenty-first century. </span><span>Behaviour &amp; Information Technology, 19(3)</span><span>, 153-161.</span></li>\n<li><span>Dalkir, K. (2013). </span><span>Knowledge Management in Theory and Practice</span><span>. MIT Press.</span></li>\n<li><span>Polanyi, M. (2009). </span><span>The Tacit Dimension</span><span>. University of Chicago Press.</span></li>\n<li><span>Stenmark, D. (2002). Information vs. Knowledge: The Role of intranets in Knowledge Management. </span><span>Proceedings of the 35th Hawaii International Conference on System Sciences</span><span>.</span></li>\n<li><span>Zuboff, S. (2019). </span><span>The Age of Surveillance Capitalism</span><span>. PublicAffairs.</span></li>\n<li><span>Bostrom, N. (2014). </span><span>Superintelligence</span><span>. Oxford University Press.</span></li>\n<li><span>Hidalgo, C. A. (2015). </span><span>Why Information Grows</span><span>. Basic Books.</span></li>\n</ul>\n</div>\n</div>\n</article>\n<section>\n<h2>\nMore articles by Prasad Kaipa\n</h2>\n<div>\n<ul>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/new-era-work-why-80-find-meaning-yet-35-still-plan-quit-prasad-kaipa-hmc9c\">\n<span>\nA New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to Quit\n</span>\n</a></p>\n<div>\n<p><span>Jan 4, 2025</span>\n</p>\n<h3>\nA New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to Quit\n</h3>\n<p>\nHere’s the biggest paradox in the global workforce today: 80% of employees say their work is meaningful, yet 35%of them…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/our-gita-project-journey-transformation-renewal-prasad-kaipa-ux7ac\">\n<span>\nOur Gita Project: A Journey of Transformation and Renewal\n</span>\n</a></p>\n<div>\n<p><span>Dec 10, 2024</span>\n</p>\n<h3>\nOur Gita Project: A Journey of Transformation and Renewal\n</h3>\n<p>\nThe Bhagavad Gita, a timeless treasure of wisdom, continues to guide us through the complexities of modern life…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/discovering-your-life-purpose-more-than-roles-job-prasad-kaipa-lwhtc\">\n<span>\nDiscovering Your Life Purpose: More Than Roles, More Than a Job\n</span>\n</a></p>\n<div>\n<p><span>Dec 8, 2024</span>\n</p>\n<h3>\nDiscovering Your Life Purpose: More Than Roles, More Than a Job\n</h3>\n<p>\nWhat does it mean to truly live with purpose? Have you ever wondered if there’s more to your life than just the roles…\n</p>\n</div>\n</div>\n</li>\n<li>\n<div>\n<p><a href=\"https://www.linkedin.com/pulse/part-2-timeless-wisdom-modern-leaders-indic-us-election-prasad-kaipa-bevxc\">\n<span>\nPart 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US Election\n</span>\n</a></p>\n<div>\n<p><span>Nov 7, 2024</span>\n</p>\n<h3>\nPart 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US Election\n</h3>\n<p>\nWhat makes a leader resonate with millions and make him/her succeed in the face of stiff opposition? I wrote an article…\n</p>\n</div>\n</div>\n</li>\n<li>\n<",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "How knowledge evolvesPrasad KaipaPrasad KaipaCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and AdvisorPublished Oct 3, 2023This is 2nd article in the Knowledge Evolution Series.In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "How knowledge evolvesPrasad KaipaPrasad KaipaCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and AdvisorPublished Oct 3, 2023This is 2nd article in the Knowledge Evolution Series.In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "How knowledge evolvesPrasad KaipaPrasad KaipaCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and AdvisorPublished Oct 3, 2023This is 2nd article in the Knowledge Evolution Series.In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between ",
              "class": [],
              "id": ""
            },
            {
              "type": "article",
              "content": "How knowledge evolvesPrasad KaipaPrasad KaipaCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and AdvisorPublished Oct 3, 2023This is 2nd article in the Knowledge Evolution Series.In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Prasad KaipaPrasad KaipaCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and AdvisorPublished Oct 3, 2023",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Prasad KaipaCo-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and AdvisorPublished Oct 3, 2023",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "This is 2nd article in the Knowledge Evolution Series.In today's rapidly digitizing world, deciphering the evolution of knowledge systems is vital. Knowledge, often regarded as the 'currency' of our age, influences academia, businesses, and society at large. As we navigate this vast landscape, it becomes crucial to recognize the distinctions between data, information, knowledge, and wisdom. This understanding provides clarity, especially in an era teeming with AI advancements and dynamic informa",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific Lens: Initial hypothesis on climate change.Organizational Lens: Visionaries shaping the future of technology.Philosophical Lens: Insights of thinkers that set the foundation for various philosophies.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Comparing theories to existing records.Organizational: Analyzing market demand.Philosophical: Situating philosophical thoughts within traditions.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Adapting theories to new evidence.Organizational: Pivoting business models in light of market demands.Philosophical: Reinterpreting ancient wisdom for modern challenges.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Peer review processes.Organizational: Internal training sessions.Philosophical: Engaging in public philosophy and discourse.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Field trials and experiments.Organizational: Prototyping or beta testing.Philosophical: Philosophical discussions guiding real-world ethics.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Recommended by LinkedIn",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Statistical validation and repeat experiments.Organizational: ROI analysis and feedback loops.Philosophical: Comparative analysis and philosophical debates.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Integration into educational curricula.Organizational: Establishment as best practices.Philosophical: Gaining widespread influence.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Scientific: Leading to paradigm shifts.Organizational: Becoming an industry standard.Philosophical: Being recognized as a foundational text.",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Spirituality and Consciousness: Ancient knowledge systems rooted in spirituality, like Yoga or Buddhist meditation, have seen resurgent global popularity. Their evolution has required adaptation, yet the core essence remains intact, emphasizing self-awareness, consciousness, and holistic well-being.Cultural Context: Cultural nuances significantly influence knowledge. For instance, Traditional Chinese Medicine offers insights into healing that are vastly different from Western medicine, shaped by",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Kuhn, T. S. (1962).The Structure of Scientific Revolutions. University of Chicago Press.Porter, M. E. (1985).Competitive Advantage. Free Press.MacIntyre, A. (1981).After Virtue. University of Notre Dame Press.Kaipa, P. (2000). Knowledge architecture for the twenty-first century.Behaviour & Information Technology, 19(3), 153-161.Dalkir, K. (2013).Knowledge Management in Theory and Practice. MIT Press.Polanyi, M. (2009).The Tacit Dimension. University of Chicago Press.Stenmark, D. (2002). Informat",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "More articles by Prasad KaipaA New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitJan 4, 2025A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitHere’s the biggest paradox in the global workforce today: 80% of employees say their work is meaningful, yet 35%of them…Our Gita Project: A Journey of Transformation and RenewalDec 10, 2024Our Gita Project: A Journey of Transformation and RenewalThe Bhagavad Gita, a timeless treasure of wisdom, continues to guide us through th",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitJan 4, 2025A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitHere’s the biggest paradox in the global workforce today: 80% of employees say their work is meaningful, yet 35%of them…Our Gita Project: A Journey of Transformation and RenewalDec 10, 2024Our Gita Project: A Journey of Transformation and RenewalThe Bhagavad Gita, a timeless treasure of wisdom, continues to guide us through the complexities of modern life",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitJan 4, 2025A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitHere’s the biggest paradox in the global workforce today: 80% of employees say their work is meaningful, yet 35%of them…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Jan 4, 2025A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to QuitHere’s the biggest paradox in the global workforce today: 80% of employees say their work is meaningful, yet 35%of them…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Our Gita Project: A Journey of Transformation and RenewalDec 10, 2024Our Gita Project: A Journey of Transformation and RenewalThe Bhagavad Gita, a timeless treasure of wisdom, continues to guide us through the complexities of modern life…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dec 10, 2024Our Gita Project: A Journey of Transformation and RenewalThe Bhagavad Gita, a timeless treasure of wisdom, continues to guide us through the complexities of modern life…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Discovering Your Life Purpose: More Than Roles, More Than a JobDec 8, 2024Discovering Your Life Purpose: More Than Roles, More Than a JobWhat does it mean to truly live with purpose? Have you ever wondered if there’s more to your life than just the roles…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Dec 8, 2024Discovering Your Life Purpose: More Than Roles, More Than a JobWhat does it mean to truly live with purpose? Have you ever wondered if there’s more to your life than just the roles…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Part 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US ElectionNov 7, 2024Part 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US ElectionWhat makes a leader resonate with millions and make him/her succeed in the face of stiff opposition? I wrote an article…",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Nov 7, 2024Part 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US ElectionWhat makes a leader resonate with millions and make him/her succeed in the face of stiff opposition? I wrote an article…",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h3",
              "text": "Prasad Kaipa",
              "id": ""
            },
            {
              "level": "h4",
              "text": "Co-founder, Institute of Indic Wisdom, Board Member, Retired CEO Coach and Advisor",
              "id": ""
            },
            {
              "level": "h3",
              "text": "1. The Complex Life Cycle of Knowledge Systems:",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Recommended by LinkedIn",
              "id": ""
            },
            {
              "level": "h3",
              "text": "2. From Tacit to Explicit: Unraveling the Knowledge Spectrum:",
              "id": ""
            },
            {
              "level": "h3",
              "text": "3. Factors Influencing Knowledge Evolution:",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Conclusion:",
              "id": ""
            },
            {
              "level": "h2",
              "text": "More articles by Prasad Kaipa",
              "id": ""
            },
            {
              "level": "h3",
              "text": "A New Era of Work: Why 80% Find Meaning Yet 35% Still Plan to Quit",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Our Gita Project: A Journey of Transformation and Renewal",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Discovering Your Life Purpose: More Than Roles, More Than a Job",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Part 2: Timeless Wisdom for Modern Leaders: Indic Perspectives on US Election",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://scholarworks.umb.edu/cgi/viewcontent.cgi?article=1826&context=nejpp",
      "title": "Complex Adaptive Systems in a Contentious World",
      "author": "Yasmin Merali",
      "published_date": "2023-07-27T00:00:00.000Z",
      "content": {
        "text": "New England Journal of Public Policy\nVolume 34 Issue 2 Article 3\n10-19-2022\nComplex Adaptive Systems in a Contentious World\nYasmin Merali\nUniversity of Hull\nFollow this and additional works at: https://scholarworks.umb.edu/nejpp\nPart of the Infrastructure Commons, Peace and Conflict Studies Commons, and the Public Policy\nCommons\nRecommended Citation\nMerali, Yasmin (2022) \"Complex Adaptive Systems in a Contentious World,\" New England Journal of\nPublic Policy: Vol. 34: Iss. 2, Article 3.\nAvailable at: https://scholarworks.umb.edu/nejpp/vol34/iss2/3\nThis Article is brought to you for free and open access by ScholarWorks at UMass Boston. It has been accepted for\ninclusion in New England Journal of Public Policy by an authorized editor of ScholarWorks at UMass Boston. For\nmore information, please contact scholarworks@umb.edu.\nNew England Journal of Public Policy\n1\nComplex Adaptive Systems in a Contentious World\nYasmin Merali\nUniversity of Hull, Hull, UK\nAbstract\nThis article is about developing and implementing interventions that are systemically viable in\na world that is constantly evolving. Geopolitical and economic forces, environmental stressors,\nand the weaponization of information confront us with an unprecedented level of complexity,\nrequiring new ways of seeing and being when intervening in conflictual situations. I draw on\nthe Complex Adaptive Systems paradigm to explore how world order emerges from the\ndynamics of network relationships between the players in the cyber-social landscape. This\ntreatment elaborates on mechanisms underpinning resilience, adaptation, and transformation\nof socioeconomic systems in turbulent contexts. It emphasizes a need to reconsider\nconventional logics and mindsets. In its final analysis the article suggests that world leaders\nneed to choose whether to persist in defending the international rule-based order or to embrace\nnetwork thinking and create conditions under which each country can find a sustainable niche\nin a global ecosystem.\nYasmin Merali is Emeritus Professor of Systems Thinking at the University of Hull and an expert evaluator for\nthe European Union. She serves on the executive board of the UNESCO UniNet on Complex Systems Science.\nNew England Journal of Public Policy\n2\nThe name of Lord Alderdice’s Centre for the Resolution of Intractable Conflict is perhaps the\nmost compact and communicable encapsulation of my motivation for writing this article: there\nis a need for innovative ways of thinking that take us past conflict to spaces more amenable to\ngiving peace (and peaceful co-existence) a chance. Beyond this imperative is a growing,\ncollective realization that the interplay between geopolitical and economic forces,\nenvironmental stressors, and the weaponization of information confront us with an\nunprecedented level of complexity, requiring new ways of seeing and being in the world.\nTwo things are clear: in the networked world, local actions can have unintended\nconsequences with systemic impacts, and the nonlinear network mode of transmission\nexponentially increases the speed with which undesirable effects are propagated across the\nworld. Isolationism is no longer a viable strategy—addressing the challenges of the networked\nworld entails understanding the relative positioning of players in the ecosystem, and the\nnetworks that connect them. The “shocks” that threaten global order and stability are diverse,\ntheir origins complex, and their antecedents and causes open to interpretation. The unfeasibility\nof future-proofing against all possible “assaults” brings to the fore the importance of resilience\nand the capacity to adapt and transform in the face of destabilizing influences.\nFor those concerned with the resolution of conflict, the complexity and dynamism of this\nemerging world give rise to increased uncertainty and unpredictability about the consequences\nof actions and interventions. The focus of this article is the mode of thinking and discourse that\naccompanies (or even constitutes) interventions aspiring to resolve or de-escalate conflict, or\nto restore stability post conflict. It addresses the problem of how to go about developing and\ndelivering interventions that are not irrecoverably “wrong” in the face of unfolding events and\ntheir representations on digital media. It uses concepts from Complex Systems Science and the\nstudy of Complex Adaptive Systems to explain how adaptability and resilience can be built\ninto the process of developing and implementing interventions that are systemically viable in\nthe longer term, in a world that is constantly evolving.\nThe study of Complex Adaptive Systems in the biological sciences provides much of the\ninspiration for new thinking to advance our understanding of the mechanisms underpinning the\ncollective behaviors and systemic phenomena displayed by social systems and the quest for\ngreater resilience in today’s turbulent world. Of particular relevance when looking for ways for\ncivil society to survive and evolve in turbulent times is the resilience of these systems.\nThe most powerful insight from the study of Complex Adaptive Systems is that the\nnetwork form of organization and communication underpins the ability of systems to adapt and\nevolve, overcoming adverse conditions and improving fitness for survival in a changing\nlandscape. Social systems are essentially networked systems, and intervention in the trajectory\nof war or peace requires an understanding of how the structure and dynamics of networks give\nrise to the phenomenology of both disruption and stabilization. A failure to understand the\nnetworked nature of social systems has two significant consequences for politicians and\npeacemakers:\n• they fail to leverage the power of networks and network capabilities for developing\ncreative, sustainable paths for conflict avoidance/resolution and\n• they fail to anticipate the strategies and impact of opponents who do understand how to\nuse networks.1\nThis article advocates a paradigm shift from a Weltanshauung predicated on the protection\nof boundaries to one predicated on harnessing the power of networks. The next section\nintroduces the relevant concepts from Complex Systems Science and examines the mechanisms\nunderpinning resilience, adaptation, and transformation of Complex Adaptive Systems in\nturbulent contexts. This treatment elucidates the mechanisms for realizing the power of the\nnetwork form of organizing, the importance of diversity, and the role of information and\nNew England Journal of Public Policy\n3\ncommunication. The sections that follow show how these generic characteristics afford the\nrequisite scaffolding for understanding the emergence of social phenomena across networks\nstraddling the embodied world and cyberspace. The final sections reflect on the utility of this\nway of thinking for guiding discourse in the development of interventions to resolve conflict.\nComplex Adaptive Systems\nComplex Systems Science is an umbrella term for the endeavors of scientists from different\ndisciplines to develop plausible explanations for the emergent behavior over time of complex\nsystems, that is, network systems that comprise large numbers of variously interconnected\ndiverse components.2 The complexity of structure and composition and the nonlinear dynamics\nof the interactions between components makes it difficult to precisely predict the behavior and\nstate of the system at a given future point in time: hence the popular saying that the whole\n(system) is more than the sum of its parts. Of particular relevance for this article is the Complex\nAdaptive Systems paradigm derived from the study of biological systems that display resilience\nor generative potential (e.g., by developing new features) under changing environmental\nconditions.\nA viable Complex Adaptive System is\n• an open system: it interacts with its environment;\n• an adaptive system: it is able to adapt to changes in its environment and to co-evolve\nwith its environment (the adaptation may result in the maintenance of a steady state, or\nit may entail a transformational process and the acquisition or generation of novel\ncharacteristics) and\n• a self-organizing system: the interactions of the components of the system are\ncontingent on the characteristics of individual components and what they know about\ntheir environment: there is no deus ex machina, no central entity or locus of control to\npredetermine the actions of individual components.\nThe phenomenology of a Complex Adaptive System is characterized by its emergence: the\ndiversity and dynamics of the relationships between its components give rise to macro-level\nproperties (i.e., those that we can observe when we describe the behavior and characteristics of\nthe system as a whole), which are different in kind from the sum of the properties of its\nindividual components.\nThese fundamental properties of Complex Adaptive Systems hold for systems at all scales,\nfrom individual micro-organisms to entire ecosystems. Social systems can also be viewed as\nComplex Adaptive Systems. The observable macro-level collective behavior of social systems\nis an emergent phenomenon, arising from the interactions and behaviors of individual, locally\nsituated actors based on only the information and knowledge they can access from where they\nare. The financial crisis of 2008, the trajectory of the COVID pandemic, the materialization of\nthe gig economy, the evolution of QAnon, the storming of the US Capitol on January 6, 2021,\nand the evolution of the war in Ukraine are all examples of emergent macro-level phenomena.\nIn all these instances, causality cannot be attributed to a simple chain of events: there is a\nconcatenation of factors and context-sensitive dynamics that give rise to the observed\nphenomenology.\nThe discipline of systems thinking is concerned with understanding the mechanisms that\nunderpin the emergence of such macro-level, systemic phenomena from the locally situated,\nmicro-level properties, relationships and behaviors o",
        "html": "New England Journal of Public Policy\nVolume 34 Issue 2 Article 3\n10-19-2022\nComplex Adaptive Systems in a Contentious World\nYasmin Merali\nUniversity of Hull\nFollow this and additional works at: https://scholarworks.umb.edu/nejpp\nPart of the Infrastructure Commons, Peace and Conflict Studies Commons, and the Public Policy\nCommons\nRecommended Citation\nMerali, Yasmin (2022) \"Complex Adaptive Systems in a Contentious World,\" New England Journal of\nPublic Policy: Vol. 34: Iss. 2, Article 3.\nAvailable at: https://scholarworks.umb.edu/nejpp/vol34/iss2/3\nThis Article is brought to you for free and open access by ScholarWorks at UMass Boston. It has been accepted for\ninclusion in New England Journal of Public Policy by an authorized editor of ScholarWorks at UMass Boston. For\nmore information, please contact scholarworks@umb.edu.\nNew England Journal of Public Policy\n1\nComplex Adaptive Systems in a Contentious World\nYasmin Merali\nUniversity of Hull, Hull, UK\nAbstract\nThis article is about developing and implementing interventions that are systemically viable in\na world that is constantly evolving. Geopolitical and economic forces, environmental stressors,\nand the weaponization of information confront us with an unprecedented level of complexity,\nrequiring new ways of seeing and being when intervening in conflictual situations. I draw on\nthe Complex Adaptive Systems paradigm to explore how world order emerges from the\ndynamics of network relationships between the players in the cyber-social landscape. This\ntreatment elaborates on mechanisms underpinning resilience, adaptation, and transformation\nof socioeconomic systems in turbulent contexts. It emphasizes a need to reconsider\nconventional logics and mindsets. In its final analysis the article suggests that world leaders\nneed to choose whether to persist in defending the international rule-based order or to embrace\nnetwork thinking and create conditions under which each country can find a sustainable niche\nin a global ecosystem.\nYasmin Merali is Emeritus Professor of Systems Thinking at the University of Hull and an expert evaluator for\nthe European Union. She serves on the executive board of the UNESCO UniNet on Complex Systems Science.\nNew England Journal of Public Policy\n2\nThe name of Lord Alderdice’s Centre for the Resolution of Intractable Conflict is perhaps the\nmost compact and communicable encapsulation of my motivation for writing this article: there\nis a need for innovative ways of thinking that take us past conflict to spaces more amenable to\ngiving peace (and peaceful co-existence) a chance. Beyond this imperative is a growing,\ncollective realization that the interplay between geopolitical and economic forces,\nenvironmental stressors, and the weaponization of information confront us with an\nunprecedented level of complexity, requiring new ways of seeing and being in the world.\nTwo things are clear: in the networked world, local actions can have unintended\nconsequences with systemic impacts, and the nonlinear network mode of transmission\nexponentially increases the speed with which undesirable effects are propagated across the\nworld. Isolationism is no longer a viable strategy—addressing the challenges of the networked\nworld entails understanding the relative positioning of players in the ecosystem, and the\nnetworks that connect them. The “shocks” that threaten global order and stability are diverse,\ntheir origins complex, and their antecedents and causes open to interpretation. The unfeasibility\nof future-proofing against all possible “assaults” brings to the fore the importance of resilience\nand the capacity to adapt and transform in the face of destabilizing influences.\nFor those concerned with the resolution of conflict, the complexity and dynamism of this\nemerging world give rise to increased uncertainty and unpredictability about the consequences\nof actions and interventions. The focus of this article is the mode of thinking and discourse that\naccompanies (or even constitutes) interventions aspiring to resolve or de-escalate conflict, or\nto restore stability post conflict. It addresses the problem of how to go about developing and\ndelivering interventions that are not irrecoverably “wrong” in the face of unfolding events and\ntheir representations on digital media. It uses concepts from Complex Systems Science and the\nstudy of Complex Adaptive Systems to explain how adaptability and resilience can be built\ninto the process of developing and implementing interventions that are systemically viable in\nthe longer term, in a world that is constantly evolving.\nThe study of Complex Adaptive Systems in the biological sciences provides much of the\ninspiration for new thinking to advance our understanding of the mechanisms underpinning the\ncollective behaviors and systemic phenomena displayed by social systems and the quest for\ngreater resilience in today’s turbulent world. Of particular relevance when looking for ways for\ncivil society to survive and evolve in turbulent times is the resilience of these systems.\nThe most powerful insight from the study of Complex Adaptive Systems is that the\nnetwork form of organization and communication underpins the ability of systems to adapt and\nevolve, overcoming adverse conditions and improving fitness for survival in a changing\nlandscape. Social systems are essentially networked systems, and intervention in the trajectory\nof war or peace requires an understanding of how the structure and dynamics of networks give\nrise to the phenomenology of both disruption and stabilization. A failure to understand the\nnetworked nature of social systems has two significant consequences for politicians and\npeacemakers:\n• they fail to leverage the power of networks and network capabilities for developing\ncreative, sustainable paths for conflict avoidance/resolution and\n• they fail to anticipate the strategies and impact of opponents who do understand how to\nuse networks.1\nThis article advocates a paradigm shift from a Weltanshauung predicated on the protection\nof boundaries to one predicated on harnessing the power of networks. The next section\nintroduces the relevant concepts from Complex Systems Science and examines the mechanisms\nunderpinning resilience, adaptation, and transformation of Complex Adaptive Systems in\nturbulent contexts. This treatment elucidates the mechanisms for realizing the power of the\nnetwork form of organizing, the importance of diversity, and the role of information and\nNew England Journal of Public Policy\n3\ncommunication. The sections that follow show how these generic characteristics afford the\nrequisite scaffolding for understanding the emergence of social phenomena across networks\nstraddling the embodied world and cyberspace. The final sections reflect on the utility of this\nway of thinking for guiding discourse in the development of interventions to resolve conflict.\nComplex Adaptive Systems\nComplex Systems Science is an umbrella term for the endeavors of scientists from different\ndisciplines to develop plausible explanations for the emergent behavior over time of complex\nsystems, that is, network systems that comprise large numbers of variously interconnected\ndiverse components.2 The complexity of structure and composition and the nonlinear dynamics\nof the interactions between components makes it difficult to precisely predict the behavior and\nstate of the system at a given future point in time: hence the popular saying that the whole\n(system) is more than the sum of its parts. Of particular relevance for this article is the Complex\nAdaptive Systems paradigm derived from the study of biological systems that display resilience\nor generative potential (e.g., by developing new features) under changing environmental\nconditions.\nA viable Complex Adaptive System is\n• an open system: it interacts with its environment;\n• an adaptive system: it is able to adapt to changes in its environment and to co-evolve\nwith its environment (the adaptation may result in the maintenance of a steady state, or\nit may entail a transformational process and the acquisition or generation of novel\ncharacteristics) and\n• a self-organizing system: the interactions of the components of the system are\ncontingent on the characteristics of individual components and what they know about\ntheir environment: there is no deus ex machina, no central entity or locus of control to\npredetermine the actions of individual components.\nThe phenomenology of a Complex Adaptive System is characterized by its emergence: the\ndiversity and dynamics of the relationships between its components give rise to macro-level\nproperties (i.e., those that we can observe when we describe the behavior and characteristics of\nthe system as a whole), which are different in kind from the sum of the properties of its\nindividual components.\nThese fundamental properties of Complex Adaptive Systems hold for systems at all scales,\nfrom individual micro-organisms to entire ecosystems. Social systems can also be viewed as\nComplex Adaptive Systems. The observable macro-level collective behavior of social systems\nis an emergent phenomenon, arising from the interactions and behaviors of individual, locally\nsituated actors based on only the information and knowledge they can access from where they\nare. The financial crisis of 2008, the trajectory of the COVID pandemic, the materialization of\nthe gig economy, the evolution of QAnon, the storming of the US Capitol on January 6, 2021,\nand the evolution of the war in Ukraine are all examples of emergent macro-level phenomena.\nIn all these instances, causality cannot be attributed to a simple chain of events: there is a\nconcatenation of factors and context-sensitive dynamics that give rise to the observed\nphenomenology.\nThe discipline of systems thinking is concerned with understanding the mechanisms that\nunderpin the emergence of such macro-level, systemic phenomena from the locally situated,\nmicro-level properties, relationships and behaviors o",
        "metadata": {
          "sections": [],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.researchgate.net/publication/322576560_The_Role_of_Sense_of_Coherence_in_Knowledge_Sharing",
      "title": "(PDF) The Role of Sense of Coherence in Knowledge Sharing",
      "author": "",
      "published_date": "2018-01-01T00:00:00.000Z",
      "content": {
        "text": "<div><section><div><div><p>Knowledge sharing is a key competence in a work context. In this study we address knowledge sharing from an individual difference perspective, exploring whether an employee’s sense of coherence influences knowledge sharing. Additionally, we investigate whether dedication to diversified learning mediates the relationship between Sense of Coherence (SOC) and knowledge sharing. A survey was conducted in a multinational organization. We received 403 responses. Partial least square structural equation modeling was used to analyze the data. The results show that SOC significantly influences the respondents’ self-perceived knowledge sharing activities. However, the relationship is partially mediated by dedication to diversified learning. Results suggest that an employee’s knowledge sharing partly arise from personal characteristics. How much is shared in actuality, however, depends on motivation and contextual factors.</p><div><a href=\"https://www.researchgate.net/figure/The-impact-of-sense-of-coherence-on-knowledge-sharing-through-dedication-to-diversified_fig1_322576560\"><div></div></a></div><div><p>Figures - uploaded by <a href=\"https://www.researchgate.net/publication/profile/Farhan-Ahmad-34\">Farhan Ahmad</a></p><div><p><span>Author content</span></p><div><p>All figure content in this area was uploaded by Farhan Ahmad</p></div></div></div><p>Content may be subject to copyright.</p></div><div><p><strong>Discover the world's research</strong></p><ul><li>25+ million members</li><li>160+ million publication pages</li><li>2.3+ billion citations</li></ul><p><a href=\"https://www.researchgate.net/publication/signup.SignUp.html\"><span>Join for free</span></a></p></div></div><section><span></span><a href=\"https://www.researchgate.net/publication/publication/322576560_The_Role_of_Sense_of_Coherence_in_Knowledge_Sharing#read-preview\"></a><div>\n<div><div><p>The Role of Sense of Coherence in Know<span></span>ledge Sharing </p><p>Jannica Heinström<span>1</span>, Farhan Ahmad<span>1</span><span> </span><span> </span></p><p><span>1</span><span>Information Studies, Åbo Akademi University, Finland<span></span> </span></p><p>{jannica.heinstrom@abo.fi, farhan.ahmad@abo.fi} <span></span> </p><p>Ab<span>stract.<span> Knowledge <span></span>sharing is <span></span>a <span></span>key <span></span>competence in <span></span>a work <span></span>context. In <span></span>this <span></span>study </span></span></p><p>we <span> </span>address <span> </span>knowledge <span> </span>sharing <span> </span>from <span> </span>an <span> </span>individual <span> </span>difference <span> </span>perspective, </p><p>exploring <span>whether an employee’s</span> sense <span> </span>of coherence influences knowledge </p><p>sharing. Additionally, <span></span>we <span></span>investigate whether <span></span>dedication <span></span>to <span></span>diversified learning </p><p>mediates <span></span>the <span></span>relationship <span></span>between <span></span>SOC <span></span>and <span></span>knowledge <span></span>sharing. <span></span>A <span></span>survey <span></span>was </p><p>conducted <span></span>in <span></span>a <span></span>multinational organization. We received 403 responses. Partial </p><p>least square <span></span>structural eq<span></span>uation modeling <span></span>was <span></span>used to <span></span>analyze <span></span>the data. <span></span>The results </p><p>show that sense of coherence significantly inf<span></span>luences the respondents’ self<span>-</span></p><p>perceived k<span></span>nowledge <span></span>sharing activities. <span></span>However, the <span></span>relationship is <span></span>partially </p><p>mediated by <span></span>dedication <span></span>to diversified <span></span>learning. <span></span>Results <span></span>suggest that <span></span><span>an <span></span>employee’<span>s </span></span></p><p>knowledge sharing <span></span>partly arise <span></span>from <span></span>personal characteristics. <span></span>How much <span></span>is shared </p><p>in actuality, however, depends on motivation and contextual factors. </p><p>Keywords: <span>sense of coherence, information mastering, information literacy<span></span>, </span></p><p>knowledge sharing </p><p>1 <span> </span>Introduction <span> </span></p><p>Workplaces <span></span>are <span></span>collaborative <span></span>spaces <span></span>where <span></span>success <span></span>depends <span></span>on <span></span>mutual <span></span>collaboration </p><p>between <span></span>employees. Particularly, <span></span>exchange of<span></span> <span></span>task<span></span>-related <span></span>infor<span></span>mation <span></span>and personal </p><p>know-how <span></span>is cr<span></span>itical not <span></span>only <span></span>for <span></span>d<span></span>eveloping new <span></span>products <span></span>and <span></span>services, <span></span>but <span></span>also <span></span>for </p><p>execution of <span> </span>daily tasks at <span> </span>work. T<span></span>his act of <span> </span>mutual collaboration <span> </span>is known <span> </span>as </p><p>knowledge sharing. <span></span>More specifically, <span></span>it refers <span></span>to exchange <span></span>of advice <span></span>and expertise <span></span>to </p><p>help others carry <span></span>out daily <span></span>tasks and solve <span></span>problems [1]. A<span></span> plethora of <span></span>research has <span></span>been </p><p>done on knowledge sharing, and its importance for organizatio<span></span>nal as well as individual </p><p>performance is we<span></span>ll established [2<span></span>-<span>4]</span>. Although an <span></span>essential activity at <span></span>the workplace, </p><p>knowledge <span></span>sharing is a very <span></span>complex <span></span>b<span></span>ehavior. <span></span>An <span></span>extensive <span></span>review on <span></span>knowledge </p><p>sharing <span></span>l<span></span>iterature <span></span>b<span></span>y <span></span>Wang and <span></span>No<span></span>e [5] <span></span>shows that <span></span>knowledge sharing <span></span>is not <span></span>only </p><p>influenced by organizational factors <span></span>such as culture, m<span></span>anagement support, reward </p><p>system, diversity and social n<span></span>etworks but also by <span></span>individual characteristics such as self-</p><p>efficacy, personality, trust and an <span>individual’s</span> belie<span></span>fs about knowledge ownership. </p><p>Personal characteristics make <span></span>individuals predisposed to <span></span>certain work <span></span>behaviors and </p><p>attitudes. <span></span>Therefore, <span></span>organizational <span></span>strate<span></span>gies <span></span>aimed <span></span>at <span></span>enhancing <span></span>knowledge <span></span>shari<span></span>ng </p></div><div><p>Cite this paper as: </p><p>Heinström J., Ahmad F. (2018) The Role of Sense of Coherence in Knowledge </p><p>Sharing. In: Kurbano<span>ğ</span>lu S., Boustany J., Špiranec S., Grassian E., Mizrachi D., Roy L. (eds) </p><p>Information Literacy in the Workplace. ECIL 2017. Communications in Computer and </p><p>Information Science, vol 810. Springer, Cham</p></div></div>\n<div><p>between employees need to <span> </span>take into account individual <span> </span>characteristics. Previous </p><p>research has explored the <span></span>relationship between <span>individuals’</span> personal <span></span>characteristics and </p><p>knowledge <span></span>shari<span></span>ng <span></span>behavior [e.g. <span></span>6-<span>7]</span><span>. <span></span></span>Ho<span></span>wever, <span></span>sense of <span></span>coherence, <span></span>a <span></span>salutoge<span></span>nic </p><p>disposition, has <span></span>not attracted <span></span>any attention <span></span>so far, eve<span></span>n though researc<span></span>h in ps<span></span>ychology </p><p>has clearly established its influence in working life [8<span></span>]<span>. <span></span></span> </p><p>In our <span></span>study <span></span>we, <span></span>therefore, wanted<span></span> to <span></span>investigate <span></span>the co<span></span>nnection between sense of </p><p>coherence and knowledge sharing. </p><p>2 <span></span><span> <span> </span>Literature review<span> </span></span></p><p>Sense <span></span>of <span></span>coherence <span></span>[SO<span></span>C] <span></span>describes <span></span>a <span></span>resilience <span></span>to<span></span> <span></span>stress <span></span>which <span></span>explains w<span></span>hy <span></span>some </p><p>people cope well <span></span>with stressors in<span></span> situations that <span></span>others find overwhelming. <span></span>People with </p><p>a high <span></span>sense of co<span></span>herence find <span></span>that their en<span></span>vironment makes <span></span>sense, a<span></span>nd trust that <span></span>they </p><p>have the <span></span>needed resources <span></span>to cop<span></span>e with challe<span></span>nging situations <span></span>[9, 10]. <span></span>This mindset <span></span>is </p><p>also manifested <span></span>in a <span></span>work environment <span></span>[Antonovsky, <span>11</span>, <span></span>cited from <span></span>Feldt, 12]. <span></span>Those </p><p>with a high SOC in general cope better w<span></span>ith stress at the workplace and experience less </p><p>stress symptoms [13-<span>14]</span>. <span></span>A strong <span></span>SOC can <span></span>moderate feelings <span></span>of pressure <span></span>and reactions </p><p>to work conditions [14]. </p><p>A <span></span>person’s <span></span>SOC <span> </span>is <span> </span>also link<span></span>ed <span> </span>to <span> </span>perceptions <span> </span>of <span></span>the <span></span>social <span> </span>environment <span> </span>at w<span></span>ork. </p><p>Those <span></span>with <span></span>a high SOC generally p<span></span>erceive <span></span>the <span></span>organizati",
        "html": "<div><section><div><div><p>Knowledge sharing is a key competence in a work context. In this study we address knowledge sharing from an individual difference perspective, exploring whether an employee’s sense of coherence influences knowledge sharing. Additionally, we investigate whether dedication to diversified learning mediates the relationship between Sense of Coherence (SOC) and knowledge sharing. A survey was conducted in a multinational organization. We received 403 responses. Partial least square structural equation modeling was used to analyze the data. The results show that SOC significantly influences the respondents’ self-perceived knowledge sharing activities. However, the relationship is partially mediated by dedication to diversified learning. Results suggest that an employee’s knowledge sharing partly arise from personal characteristics. How much is shared in actuality, however, depends on motivation and contextual factors.</p><div><a href=\"https://www.researchgate.net/figure/The-impact-of-sense-of-coherence-on-knowledge-sharing-through-dedication-to-diversified_fig1_322576560\"><div></div></a></div><div><p>Figures - uploaded by <a href=\"https://www.researchgate.net/publication/profile/Farhan-Ahmad-34\">Farhan Ahmad</a></p><div><p><span>Author content</span></p><div><p>All figure content in this area was uploaded by Farhan Ahmad</p></div></div></div><p>Content may be subject to copyright.</p></div><div><p><strong>Discover the world's research</strong></p><ul><li>25+ million members</li><li>160+ million publication pages</li><li>2.3+ billion citations</li></ul><p><a href=\"https://www.researchgate.net/publication/signup.SignUp.html\"><span>Join for free</span></a></p></div></div><section><span></span><a href=\"https://www.researchgate.net/publication/publication/322576560_The_Role_of_Sense_of_Coherence_in_Knowledge_Sharing#read-preview\"></a><div>\n<div><div><p>The Role of Sense of Coherence in Know<span></span>ledge Sharing </p><p>Jannica Heinström<span>1</span>, Farhan Ahmad<span>1</span><span> </span><span> </span></p><p><span>1</span><span>Information Studies, Åbo Akademi University, Finland<span></span> </span></p><p>{jannica.heinstrom@abo.fi, farhan.ahmad@abo.fi} <span></span> </p><p>Ab<span>stract.<span> Knowledge <span></span>sharing is <span></span>a <span></span>key <span></span>competence in <span></span>a work <span></span>context. In <span></span>this <span></span>study </span></span></p><p>we <span> </span>address <span> </span>knowledge <span> </span>sharing <span> </span>from <span> </span>an <span> </span>individual <span> </span>difference <span> </span>perspective, </p><p>exploring <span>whether an employee’s</span> sense <span> </span>of coherence influences knowledge </p><p>sharing. Additionally, <span></span>we <span></span>investigate whether <span></span>dedication <span></span>to <span></span>diversified learning </p><p>mediates <span></span>the <span></span>relationship <span></span>between <span></span>SOC <span></span>and <span></span>knowledge <span></span>sharing. <span></span>A <span></span>survey <span></span>was </p><p>conducted <span></span>in <span></span>a <span></span>multinational organization. We received 403 responses. Partial </p><p>least square <span></span>structural eq<span></span>uation modeling <span></span>was <span></span>used to <span></span>analyze <span></span>the data. <span></span>The results </p><p>show that sense of coherence significantly inf<span></span>luences the respondents’ self<span>-</span></p><p>perceived k<span></span>nowledge <span></span>sharing activities. <span></span>However, the <span></span>relationship is <span></span>partially </p><p>mediated by <span></span>dedication <span></span>to diversified <span></span>learning. <span></span>Results <span></span>suggest that <span></span><span>an <span></span>employee’<span>s </span></span></p><p>knowledge sharing <span></span>partly arise <span></span>from <span></span>personal characteristics. <span></span>How much <span></span>is shared </p><p>in actuality, however, depends on motivation and contextual factors. </p><p>Keywords: <span>sense of coherence, information mastering, information literacy<span></span>, </span></p><p>knowledge sharing </p><p>1 <span> </span>Introduction <span> </span></p><p>Workplaces <span></span>are <span></span>collaborative <span></span>spaces <span></span>where <span></span>success <span></span>depends <span></span>on <span></span>mutual <span></span>collaboration </p><p>between <span></span>employees. Particularly, <span></span>exchange of<span></span> <span></span>task<span></span>-related <span></span>infor<span></span>mation <span></span>and personal </p><p>know-how <span></span>is cr<span></span>itical not <span></span>only <span></span>for <span></span>d<span></span>eveloping new <span></span>products <span></span>and <span></span>services, <span></span>but <span></span>also <span></span>for </p><p>execution of <span> </span>daily tasks at <span> </span>work. T<span></span>his act of <span> </span>mutual collaboration <span> </span>is known <span> </span>as </p><p>knowledge sharing. <span></span>More specifically, <span></span>it refers <span></span>to exchange <span></span>of advice <span></span>and expertise <span></span>to </p><p>help others carry <span></span>out daily <span></span>tasks and solve <span></span>problems [1]. A<span></span> plethora of <span></span>research has <span></span>been </p><p>done on knowledge sharing, and its importance for organizatio<span></span>nal as well as individual </p><p>performance is we<span></span>ll established [2<span></span>-<span>4]</span>. Although an <span></span>essential activity at <span></span>the workplace, </p><p>knowledge <span></span>sharing is a very <span></span>complex <span></span>b<span></span>ehavior. <span></span>An <span></span>extensive <span></span>review on <span></span>knowledge </p><p>sharing <span></span>l<span></span>iterature <span></span>b<span></span>y <span></span>Wang and <span></span>No<span></span>e [5] <span></span>shows that <span></span>knowledge sharing <span></span>is not <span></span>only </p><p>influenced by organizational factors <span></span>such as culture, m<span></span>anagement support, reward </p><p>system, diversity and social n<span></span>etworks but also by <span></span>individual characteristics such as self-</p><p>efficacy, personality, trust and an <span>individual’s</span> belie<span></span>fs about knowledge ownership. </p><p>Personal characteristics make <span></span>individuals predisposed to <span></span>certain work <span></span>behaviors and </p><p>attitudes. <span></span>Therefore, <span></span>organizational <span></span>strate<span></span>gies <span></span>aimed <span></span>at <span></span>enhancing <span></span>knowledge <span></span>shari<span></span>ng </p></div><div><p>Cite this paper as: </p><p>Heinström J., Ahmad F. (2018) The Role of Sense of Coherence in Knowledge </p><p>Sharing. In: Kurbano<span>ğ</span>lu S., Boustany J., Špiranec S., Grassian E., Mizrachi D., Roy L. (eds) </p><p>Information Literacy in the Workplace. ECIL 2017. Communications in Computer and </p><p>Information Science, vol 810. Springer, Cham</p></div></div>\n<div><p>between employees need to <span> </span>take into account individual <span> </span>characteristics. Previous </p><p>research has explored the <span></span>relationship between <span>individuals’</span> personal <span></span>characteristics and </p><p>knowledge <span></span>shari<span></span>ng <span></span>behavior [e.g. <span></span>6-<span>7]</span><span>. <span></span></span>Ho<span></span>wever, <span></span>sense of <span></span>coherence, <span></span>a <span></span>salutoge<span></span>nic </p><p>disposition, has <span></span>not attracted <span></span>any attention <span></span>so far, eve<span></span>n though researc<span></span>h in ps<span></span>ychology </p><p>has clearly established its influence in working life [8<span></span>]<span>. <span></span></span> </p><p>In our <span></span>study <span></span>we, <span></span>therefore, wanted<span></span> to <span></span>investigate <span></span>the co<span></span>nnection between sense of </p><p>coherence and knowledge sharing. </p><p>2 <span></span><span> <span> </span>Literature review<span> </span></span></p><p>Sense <span></span>of <span></span>coherence <span></span>[SO<span></span>C] <span></span>describes <span></span>a <span></span>resilience <span></span>to<span></span> <span></span>stress <span></span>which <span></span>explains w<span></span>hy <span></span>some </p><p>people cope well <span></span>with stressors in<span></span> situations that <span></span>others find overwhelming. <span></span>People with </p><p>a high <span></span>sense of co<span></span>herence find <span></span>that their en<span></span>vironment makes <span></span>sense, a<span></span>nd trust that <span></span>they </p><p>have the <span></span>needed resources <span></span>to cop<span></span>e with challe<span></span>nging situations <span></span>[9, 10]. <span></span>This mindset <span></span>is </p><p>also manifested <span></span>in a <span></span>work environment <span></span>[Antonovsky, <span>11</span>, <span></span>cited from <span></span>Feldt, 12]. <span></span>Those </p><p>with a high SOC in general cope better w<span></span>ith stress at the workplace and experience less </p><p>stress symptoms [13-<span>14]</span>. <span></span>A strong <span></span>SOC can <span></span>moderate feelings <span></span>of pressure <span></span>and reactions </p><p>to work conditions [14]. </p><p>A <span></span>person’s <span></span>SOC <span> </span>is <span> </span>also link<span></span>ed <span> </span>to <span> </span>perceptions <span> </span>of <span></span>the <span></span>social <span> </span>environment <span> </span>at w<span></span>ork. </p><p>Those <span></span>with <span></span>a high SOC generally p<span></span>erceive <span></span>the <span></span>organizati",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Knowledge sharing is a key competence in a work context. In this study we address knowledge sharing from an individual difference perspective, exploring whether an employee’s sense of coherence influences knowledge sharing. Additionally, we investigate whether dedication to diversified learning mediates the relationship between Sense of Coherence (SOC) and knowledge sharing. A survey was conducted in a multinational organization. We received 403 responses. Partial least square structural equatio",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "Knowledge sharing is a key competence in a work context. In this study we address knowledge sharing from an individual difference perspective, exploring whether an employee’s sense of coherence influences knowledge sharing. Additionally, we investigate whether dedication to diversified learning mediates the relationship between Sense of Coherence (SOC) and knowledge sharing. A survey was conducted in a multinational organization. We received 403 responses. Partial least square structural equatio",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Knowledge sharing is a key competence in a work context. In this study we address knowledge sharing from an individual difference perspective, exploring whether an employee’s sense of coherence influences knowledge sharing. Additionally, we investigate whether dedication to diversified learning mediates the relationship between Sense of Coherence (SOC) and knowledge sharing. A survey was conducted in a multinational organization. We received 403 responses. Partial least square structural equatio",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Knowledge sharing is a key competence in a work context. In this study we address knowledge sharing from an individual difference perspective, exploring whether an employee’s sense of coherence influences knowledge sharing. Additionally, we investigate whether dedication to diversified learning mediates the relationship between Sense of Coherence (SOC) and knowledge sharing. A survey was conducted in a multinational organization. We received 403 responses. Partial least square structural equatio",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figures - uploaded byFarhan AhmadAuthor contentAll figure content in this area was uploaded by Farhan Ahmad",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Author contentAll figure content in this area was uploaded by Farhan Ahmad",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "All figure content in this area was uploaded by Farhan Ahmad",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Discover the world's research25+ million members160+ million publication pages2.3+ billion citationsJoin for free",
              "class": [],
              "id": ""
            },
            {
              "type": "section",
              "content": "The Role of Sense of Coherence in Knowledge SharingJannica Heinström1, Farhan Ahmad11Information Studies, Åbo Akademi University, Finland{jannica.heinstrom@abo.fi, farhan.ahmad@abo.fi}Abstract.Knowledgesharing isakeycompetence ina workcontext. Inthisstudyweaddressknowledgesharingfromanindividualdifferenceperspective,exploringwhether an employee’ssenseof coherence influences knowledgesharing. Additionally,weinvestigate whetherdedicationtodiversified learningmediatestherelationshipbetweenSOCandkno",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Role of Sense of Coherence in Knowledge SharingJannica Heinström1, Farhan Ahmad11Information Studies, Åbo Akademi University, Finland{jannica.heinstrom@abo.fi, farhan.ahmad@abo.fi}Abstract.Knowledgesharing isakeycompetence ina workcontext. Inthisstudyweaddressknowledgesharingfromanindividualdifferenceperspective,exploringwhether an employee’ssenseof coherence influences knowledgesharing. Additionally,weinvestigate whetherdedicationtodiversified learningmediatestherelationshipbetweenSOCandkno",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Role of Sense of Coherence in Knowledge SharingJannica Heinström1, Farhan Ahmad11Information Studies, Åbo Akademi University, Finland{jannica.heinstrom@abo.fi, farhan.ahmad@abo.fi}Abstract.Knowledgesharing isakeycompetence ina workcontext. Inthisstudyweaddressknowledgesharingfromanindividualdifferenceperspective,exploringwhether an employee’ssenseof coherence influences knowledgesharing. Additionally,weinvestigate whetherdedicationtodiversified learningmediatestherelationshipbetweenSOCandkno",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "The Role of Sense of Coherence in Knowledge SharingJannica Heinström1, Farhan Ahmad11Information Studies, Åbo Akademi University, Finland{jannica.heinstrom@abo.fi, farhan.ahmad@abo.fi}Abstract.Knowledgesharing isakeycompetence ina workcontext. Inthisstudyweaddressknowledgesharingfromanindividualdifferenceperspective,exploringwhether an employee’ssenseof coherence influences knowledgesharing. Additionally,weinvestigate whetherdedicationtodiversified learningmediatestherelationshipbetweenSOCandkno",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Cite this paper as:Heinström J., Ahmad F. (2018) The Role of Sense of Coherence in KnowledgeSharing. In: Kurbanoğlu S., Boustany J., Špiranec S., Grassian E., Mizrachi D., Roy L. (eds)Information Literacy in the Workplace. ECIL 2017. Communications in Computer andInformation Science, vol 810. Springer, Cham",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "between employees need totake into account individualcharacteristics. Previousresearch has explored therelationship betweenindividuals’personalcharacteristics andknowledgesharingbehavior [e.g.6-7].However,sense ofcoherence,asalutogenicdisposition, hasnot attractedany attentionso far, even though research in psychologyhas clearly established its influence in working life [8].In ourstudywe,therefore, wantedtoinvestigatethe connection between sense ofcoherence and knowledge sharing.2Literature revi",
              "class": [],
              "id": ""
            }
          ],
          "headings": [],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/future-proof-solving-the-adaptability-paradox-for-the-long-term",
      "title": "Future proof: Solving the ‘adaptability paradox’ for the long term",
      "author": "",
      "published_date": "2021-08-02T00:00:00.000Z",
      "content": {
        "text": "<div><div>\n<p><strong>Shutdowns and supply-chain</strong> hacks. Hybrid work, remote shopping, settling up via blockchain. The past year has made it abundantly clear, if it wasn’t already, that a volatile and complex world is <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-nine-traits-of-future-ready-companies\">serving up change at an accelerating pace</a>. </p>\n<p>Individuals and organizations <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-impact-of-agility-how-to-shape-your-organization-to-compete\">need to be ready</a>. That doesn’t mean reacting to the next challenge that comes our way but rather <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/how-to-future-proof-your-organization\">being prepared to meet it</a> when it arrives. There’s one tool above all others that can help leaders do that: adaptability. </p>\n<p>Adaptability is the ability to learn flexibly and efficiently and to apply that knowledge across situations. It’s not so much a skill as a meta-skill—learning how to learn and being conscious of when to put that learner’s mind into action. By becoming aware of and open to change now, we can maintain control over uncertainty before pressures build to the point where altering course is much more difficult, or even futile.</p>\n<p>Our research shows that adaptability is the critical success factor during <a href=\"https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-eight-trends-that-will-define-2021-and-beyond\">periods of transformation and systemic change</a>. It allows us to be faster and better at learning, and it orients us toward the opportunities ahead, not just the challenges.</p>\n<p>Yet the same conditions that make adapting so important can also trigger fear, making us default to familiar patterns or whatever solutions worked the last time. We call this the “adaptability paradox”: when we most need to learn and change, we stick with what we know, often in a way that stifles learning and innovation. Even positive events, such as receiving a promotion or beginning a new workstream, can turn negative unless we can maintain <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/zoning-in-and-out-of-stress\">a learning mindset while under pressure</a>.</p>\n<p>But people often don’t put in the hard work of learning and mastering something new unless there is compelling motivation to do so. When that motivation arrives, it’s often accompanied by pressure—to avert failure, for instance, or to attain a high-stakes reward or incentive.<span><span><sup>1</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>To avoid this trap, leaders must work on transforming their relationship with change and uncertainty by building <a href=\"https://www.mckinsey.com/industries/public-sector/our-insights/defining-the-skills-citizens-will-need-in-the-future-world-of-work\">adaptability as an evergreen skill</a> that benefits themselves and their organizations at a deeper level.</p>\n<p>This is not a natural skill—even for the most successful among us—but it can be nurtured. And the rewards are worth the effort: companies with strong cultures that emphasize adaptability turn in better financial performance than entities that lack those attributes, research shows.<span><span><sup>2</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>In this article, we delve into five steps that leaders can take to become more adaptable, including emphasizing both well-being and purpose, practicing an adaptive mindset, building deeper human connections, and making it safe to learn.</p>\n<h2>Why building an adaptability muscle is so important</h2>\n<p><a href=\"https://www.mckinsey.com/featured-insights/business-resilience\">The power of resilience</a> has been amply demonstrated during the COVID-19 crisis. Although resilience and adaptability are linked, they are different in important ways. Resilience often entails responding well to an external event, while adaptability moves us from enduring a challenge to thriving beyond it. We don’t just “bounce back” from difficult situations—we “bounce forward” into new realms, learning to be more adaptable as our circumstances evolve and change. </p>\n<p>Learning agility,<span><span><sup>3</sup><span><span></span></span><span><span></span></span></span></span> emotional flexibility, and openness to experience are all part of a multidimensional understanding of adaptability.<span><span><sup>4</sup><span><span></span></span><span><span></span></span></span></span> They help us <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/how-to-demonstrate-calm-and-optimism-in-a-crisis\">maintain deliberate calm under pressure</a> and display curiosity amid change. They allow us to respond in ways that are the opposite of a knee-jerk reaction by making thoughtful choices. </p>\n<p>Studies have shown that adaptability is also linked to important psychological skills, ranging from coping to personal growth. In the workplace,<span><span><sup>5</sup><span><span></span></span><span><span></span></span></span></span> higher levels of adaptability are associated with greater levels of learning ability and better performance, confidence, and creative output.<span><span><sup>6</sup><span><span></span></span><span><span></span></span></span></span> Adaptability is also crucial for psychological and physical well-being and is linked to higher levels of social support and overall life satisfaction.<span><span><sup>7</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>Now that we’ve enumerated the benefits of adaptability, let’s go through the five ways leaders can invest in it to prepare for a fast-paced and uncertain future.</p>\n<h3>Step 1: Practice well-being as a foundational skill</h3>\n<p>From the beginning of the COVID-19 pandemic, executives have made sure to <a href=\"https://www.mckinsey.com/featured-insights/asia-pacific/out-of-the-shadows-sustainably-improving-workplace-mental-health\">check on employees’ health</a>. But that may have been putting the cart before the horse: research shows that leaders <a href=\"https://www.mckinsey.com/industries/healthcare/our-insights/mental-health-in-the-workplace-the-coming-revolution\">experienced anxiety and burnout symptoms</a> at unprecedented rates<span><span><sup>8</sup><span><span></span></span><span><span></span></span></span></span> as they focused on others without restoring their own energy levels. </p>\n<p>A <em>Harvard Business Review</em>–sponsored survey conducted in the fall of 2020 gathered feedback from more than 1,500 respondents from 46 countries<span><span><sup>9</sup><span><span></span></span><span><span></span></span></span></span>—the majority of whom were at or above supervisor level. Eighty-five percent of these respondents said their well-being had declined, while 56 percent said their job demands had increased. Moreover, 62 percent who were struggling to manage their workloads said they had experienced burnout “often” or “extremely often” in the previous three months. </p>\n<p>The number of people reporting more symptoms of <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/what-employees-are-saying-about-the-future-of-remote-work\">burnout has increased since then</a>, not only in C-suites but also <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/overcoming-pandemic-fatigue-how-to-reenergize-organizations-for-the-long-run\">across organizations</a>. When people are exhausted, they fall into a scarcity mindset (thinking about what they don’t have) and aren’t as adaptable or open to learning. We expect to see these mental-health and <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/what-employees-are-saying-about-the-future-of-remote-work\">well-being challenges continue</a> for at least the next year or two. </p>\n<p>The best way to handle demanding situations is by investing in one’s own well-being first. Just like athletes who continually invest in their own physical and mental health—not only before a game or a race—leaders have to be fit to face whatever comes their way and to support others for however long it takes. Leaders should focus on allowing themselves to thrive, and then helping others to be at their physical, mental, and emotional best.<span><span><sup>10</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>The CEO of a global mobility tech company told us that when the pandemic began, he took advantage of not having to travel by restarting a daily running routine. He started at five kilometers a day, using the time and physical activity to reflect and refresh, eventually building his runs to marathon length. After injuring himself, however, he realized that he had begun to approach running as a goal to be achieved rather than as a nurturing practice to enjoy. So he shifted back to his original goal of giving himself time to reflect, which in turn helped him perform and nurture his team. </p>\n<p>Research shows that taking deliberate breaks accelerates learning and skill acquisition. For example, a study of violin prodigies<span><span><sup>11</sup><span><span></span></span><span><span></span></span></span></span> revealed that students who were quickest to master the instrument took regular and significant breaks, including naps between practice sessions, rather than playing for hours on end. In another study of people trying to perform a task involving new skills, those who took breaks to mentally reset improved much more quickly under performance pressure.<span><span><sup>12</sup><span><span></span></span><sp",
        "html": "<div><div>\n<p><strong>Shutdowns and supply-chain</strong> hacks. Hybrid work, remote shopping, settling up via blockchain. The past year has made it abundantly clear, if it wasn’t already, that a volatile and complex world is <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-nine-traits-of-future-ready-companies\">serving up change at an accelerating pace</a>. </p>\n<p>Individuals and organizations <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-impact-of-agility-how-to-shape-your-organization-to-compete\">need to be ready</a>. That doesn’t mean reacting to the next challenge that comes our way but rather <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/how-to-future-proof-your-organization\">being prepared to meet it</a> when it arrives. There’s one tool above all others that can help leaders do that: adaptability. </p>\n<p>Adaptability is the ability to learn flexibly and efficiently and to apply that knowledge across situations. It’s not so much a skill as a meta-skill—learning how to learn and being conscious of when to put that learner’s mind into action. By becoming aware of and open to change now, we can maintain control over uncertainty before pressures build to the point where altering course is much more difficult, or even futile.</p>\n<p>Our research shows that adaptability is the critical success factor during <a href=\"https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-eight-trends-that-will-define-2021-and-beyond\">periods of transformation and systemic change</a>. It allows us to be faster and better at learning, and it orients us toward the opportunities ahead, not just the challenges.</p>\n<p>Yet the same conditions that make adapting so important can also trigger fear, making us default to familiar patterns or whatever solutions worked the last time. We call this the “adaptability paradox”: when we most need to learn and change, we stick with what we know, often in a way that stifles learning and innovation. Even positive events, such as receiving a promotion or beginning a new workstream, can turn negative unless we can maintain <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/zoning-in-and-out-of-stress\">a learning mindset while under pressure</a>.</p>\n<p>But people often don’t put in the hard work of learning and mastering something new unless there is compelling motivation to do so. When that motivation arrives, it’s often accompanied by pressure—to avert failure, for instance, or to attain a high-stakes reward or incentive.<span><span><sup>1</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>To avoid this trap, leaders must work on transforming their relationship with change and uncertainty by building <a href=\"https://www.mckinsey.com/industries/public-sector/our-insights/defining-the-skills-citizens-will-need-in-the-future-world-of-work\">adaptability as an evergreen skill</a> that benefits themselves and their organizations at a deeper level.</p>\n<p>This is not a natural skill—even for the most successful among us—but it can be nurtured. And the rewards are worth the effort: companies with strong cultures that emphasize adaptability turn in better financial performance than entities that lack those attributes, research shows.<span><span><sup>2</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>In this article, we delve into five steps that leaders can take to become more adaptable, including emphasizing both well-being and purpose, practicing an adaptive mindset, building deeper human connections, and making it safe to learn.</p>\n<h2>Why building an adaptability muscle is so important</h2>\n<p><a href=\"https://www.mckinsey.com/featured-insights/business-resilience\">The power of resilience</a> has been amply demonstrated during the COVID-19 crisis. Although resilience and adaptability are linked, they are different in important ways. Resilience often entails responding well to an external event, while adaptability moves us from enduring a challenge to thriving beyond it. We don’t just “bounce back” from difficult situations—we “bounce forward” into new realms, learning to be more adaptable as our circumstances evolve and change. </p>\n<p>Learning agility,<span><span><sup>3</sup><span><span></span></span><span><span></span></span></span></span> emotional flexibility, and openness to experience are all part of a multidimensional understanding of adaptability.<span><span><sup>4</sup><span><span></span></span><span><span></span></span></span></span> They help us <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/how-to-demonstrate-calm-and-optimism-in-a-crisis\">maintain deliberate calm under pressure</a> and display curiosity amid change. They allow us to respond in ways that are the opposite of a knee-jerk reaction by making thoughtful choices. </p>\n<p>Studies have shown that adaptability is also linked to important psychological skills, ranging from coping to personal growth. In the workplace,<span><span><sup>5</sup><span><span></span></span><span><span></span></span></span></span> higher levels of adaptability are associated with greater levels of learning ability and better performance, confidence, and creative output.<span><span><sup>6</sup><span><span></span></span><span><span></span></span></span></span> Adaptability is also crucial for psychological and physical well-being and is linked to higher levels of social support and overall life satisfaction.<span><span><sup>7</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>Now that we’ve enumerated the benefits of adaptability, let’s go through the five ways leaders can invest in it to prepare for a fast-paced and uncertain future.</p>\n<h3>Step 1: Practice well-being as a foundational skill</h3>\n<p>From the beginning of the COVID-19 pandemic, executives have made sure to <a href=\"https://www.mckinsey.com/featured-insights/asia-pacific/out-of-the-shadows-sustainably-improving-workplace-mental-health\">check on employees’ health</a>. But that may have been putting the cart before the horse: research shows that leaders <a href=\"https://www.mckinsey.com/industries/healthcare/our-insights/mental-health-in-the-workplace-the-coming-revolution\">experienced anxiety and burnout symptoms</a> at unprecedented rates<span><span><sup>8</sup><span><span></span></span><span><span></span></span></span></span> as they focused on others without restoring their own energy levels. </p>\n<p>A <em>Harvard Business Review</em>–sponsored survey conducted in the fall of 2020 gathered feedback from more than 1,500 respondents from 46 countries<span><span><sup>9</sup><span><span></span></span><span><span></span></span></span></span>—the majority of whom were at or above supervisor level. Eighty-five percent of these respondents said their well-being had declined, while 56 percent said their job demands had increased. Moreover, 62 percent who were struggling to manage their workloads said they had experienced burnout “often” or “extremely often” in the previous three months. </p>\n<p>The number of people reporting more symptoms of <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/what-employees-are-saying-about-the-future-of-remote-work\">burnout has increased since then</a>, not only in C-suites but also <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/overcoming-pandemic-fatigue-how-to-reenergize-organizations-for-the-long-run\">across organizations</a>. When people are exhausted, they fall into a scarcity mindset (thinking about what they don’t have) and aren’t as adaptable or open to learning. We expect to see these mental-health and <a href=\"https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/what-employees-are-saying-about-the-future-of-remote-work\">well-being challenges continue</a> for at least the next year or two. </p>\n<p>The best way to handle demanding situations is by investing in one’s own well-being first. Just like athletes who continually invest in their own physical and mental health—not only before a game or a race—leaders have to be fit to face whatever comes their way and to support others for however long it takes. Leaders should focus on allowing themselves to thrive, and then helping others to be at their physical, mental, and emotional best.<span><span><sup>10</sup><span><span></span></span><span><span></span></span></span></span></p>\n<p>The CEO of a global mobility tech company told us that when the pandemic began, he took advantage of not having to travel by restarting a daily running routine. He started at five kilometers a day, using the time and physical activity to reflect and refresh, eventually building his runs to marathon length. After injuring himself, however, he realized that he had begun to approach running as a goal to be achieved rather than as a nurturing practice to enjoy. So he shifted back to his original goal of giving himself time to reflect, which in turn helped him perform and nurture his team. </p>\n<p>Research shows that taking deliberate breaks accelerates learning and skill acquisition. For example, a study of violin prodigies<span><span><sup>11</sup><span><span></span></span><span><span></span></span></span></span> revealed that students who were quickest to master the instrument took regular and significant breaks, including naps between practice sessions, rather than playing for hours on end. In another study of people trying to perform a task involving new skills, those who took breaks to mentally reset improved much more quickly under performance pressure.<span><span><sup>12</sup><span><span></span></span><sp",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Shutdowns and supply-chainhacks. Hybrid work, remote shopping, settling up via blockchain. The past year has made it abundantly clear, if it wasn’t already, that a volatile and complex world isserving up change at an accelerating pace.Individuals and organizationsneed to be ready. That doesn’t mean reacting to the next challenge that comes our way but ratherbeing prepared to meet itwhen it arrives. There’s one tool above all others that can help leaders do that: adaptability.Adaptability is the ",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Shutdowns and supply-chainhacks. Hybrid work, remote shopping, settling up via blockchain. The past year has made it abundantly clear, if it wasn’t already, that a volatile and complex world isserving up change at an accelerating pace.Individuals and organizationsneed to be ready. That doesn’t mean reacting to the next challenge that comes our way but ratherbeing prepared to meet itwhen it arrives. There’s one tool above all others that can help leaders do that: adaptability.Adaptability is the ",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Why building an adaptability muscle is so important",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Step 1: Practice well-being as a foundational skill",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    },
    {
      "url": "https://sebokwiki.org/wiki/System_Adaptability",
      "title": "System Adaptability - SEBoK",
      "author": "",
      "published_date": "2024-05-02T23:02:00.000Z",
      "content": {
        "text": "<div><div><hr/>\n<p><i><b>Lead Authors:</b></i> <i>Haifeng Zhu</i> and <i>Eileen Patrice Arnold</i>\n</p>\n<hr/>\n<p>To <i>adapt</i> means “to make fit (as for a new use) often by modification” (Merriam-Webster, Inc. n.d.). The term adaptation is traditionally used in natural ecosystems as the “modification of an organism or its parts that makes it more fit for existence under the conditions of its environment” where the conditions can be either positive or negative (Andersen and Gronau 2005). Following from the dictionary definition, System Adaptability is a system’s ability to satisfy mission and requirement changes, with or without modifications (Zhu 2015) (Jackson 2016). One common way to judge whether a system is more adaptable than another is if it is able to support mission and requirement changes at lower cost – an indication of how difficult a system is to adapt. Note that the term <i>cost</i> here may not necessarily be financial. It may include time, fuel, complexity as adopted in Zhu, et al. (2016) or any metric that designers, users, and other stakeholders value with regard to the difficulty of modifications.\n</p>\n<h2><span>Adaptability in Systems Engineering</span></h2>\n<p>The adaptability concept is applicable to both real and conceptual systems as defined in Sillitto, Hillary, et al. (2017). Many concepts are related to system adaptability such as system resilience, flexible design, and design reuse.\n</p>\n<ul><li>System resilience has traditionally focused on graceful degradation and recovery of a system's performance, triggered by adverse events and planned for in advance. (see <a href=\"https://sebokwiki.org/wiki/System_Resilience\">System Resilience</a>) System adaptability focuses on solutions for changes caused by either adversarial or beneficial events.</li>\n<li>Flexible design in industrial engineering (Saleh, et al. 2009) often requires up-front investment and justification of redundant design components or facilities, with more than 50 kinds of flexibilities defined and studied.</li>\n<li>System adaptability looks into future changes to inform current design choices for reduction of unnecessarily redundant design components. System adaptability encourages reuse, but generally does not promote it at the expense of higher cost.</li></ul>\n<h2><span>Three Fundamental Factors</span></h2>\n<p>Comparing adaptability among different systems relies on three fundamental factors:\n</p>\n<ul><li>Mission and Requirement Evaluation Space (MRES)</li>\n<li>Design Space</li>\n<li>Switching Cost</li></ul>\n<p>These factors are explained in the next three subsections.\n</p>\n<h3><span></span><span>Mission and Requirement Evaluation Space (MRES)</span></h3>\n<p>Common development practice assumes each requirement is for current needs and is often subject to budget constraint perceptions. MRES differs in that it uses systems thinking (see <a href=\"https://sebokwiki.org/wiki/Systems_Thinking\">Systems Thinking</a>) to project into the future and identifies requirements with high risk of change. These uncertain requirements come from stakeholder decisions, market changes, technology progression, engineering uncertainties, and other sources. They are potential needs that can optionally be considered. (Zhu, 2023) MRES is a collection of current needs (i.e. requirements and missions) and optional potential needs. These projections into the future offer valuable information when designing for adaptability. Of course, predicting possible future needs is an uncertain task and itself incurs costs. Important optional potential needs could be overlooked or poorly stated. Under cost and schedule pressure, developing optional potential needs could be shortchanged. Nevertheless, anticipating optional possible future needs and their potential impact on design is a valuable systems engineering (SE) activity.\n</p>\n<h3><span>Design Space</span></h3>\n<p>SE normally includes developing alternative possible designs and comparing them to pick the best one among the alternatives. A collection of different possible system designs is called the <i>design space</i> or <i>trade space</i> in which tradeoff studies or trade studies are performed to pick the one that will be implemented. (Cilli &amp; Parnell 2014) (NASA 2016) In modern design approaches, design spaces can be enormous with automated and semi-automated means to conduct the trade study. (Raz, et al. 2018) The trade study is based on a set of decision factors, which can include system adaptability.\n</p>\n<h3><span>Switching Cost</span></h3>\n<p>If adapting the system requires modifying it, the ease of modification indicates the degree of adaptability. The cost of switching from one system design/state to another design/state is called the <i>switching cost</i> which is a good indicator of how difficult it is to adapt. As stated at the beginning of this article, the term <i>cost</i> here may not necessarily be financial.\n</p><p>Traditional financial cost estimation assumes a system is developed from scratch, which in reality is rarely done. Many products are developed by modifying designs from prior products, where the cost is actually a switching cost. Methods of estimating switching cost for a complete generic system, rather than individual components or systems of a specific kind, were initiated mainly by two research teams: a process-based method was developed and later reported in Zhu (2018) and a parametric approach was developed in COSYSMO (Alstad 2019).\n</p>\n<h2><span>Development History</span></h2>\n<p>Two major prior works on system adaptability were authored by Gu, Hashemian, and Nee (2004) and by Ross, Rhodes, and Hastings (2007). The first defines adaptability as a normalized savings in switching from one product to another, emphasizing the costs as the main consideration. In Ross, Rhodes, and Hastings (2007), for two designs <i>A</i> and <i>B</i>, if <i>A</i> can be modified to become <i>B</i>, then a link is created between them. They define the adaptability of a design as the outdegree or filtered outdegree from that design. A design’s outdegree counts the links from this design to the other designs.\n</p><p>In a design space, some designs support the mission better than others. Without considering the support to missions or requirements, measuring the cost to switch to another design (Gu, Hashemian, &amp; Nee 2004) or how many other designs one design can switch to (Ross, Rhodes, &amp; Hastings 2007) can result in inverted measures, where an entity that would receive a higher value of the measurement result than another entity receives with a lower value result. A design that is able to switch with low cost to many other designs that are of no or low value for missions may receive a higher adaptability score than another design that actually supports the needed missions. Fundamentally, these two works capture only two of the three fundamental factors described in section <i>Mission and Requirements Evaluation Space</i> above - the MRES factor, which is needed to prevent inverted measures.\n</p><p>In an eco-system, a species adapts in order to survive and exist longer. In SE, being able to support future missions/requirement needs prolongs the service life of the system and extends its existence, which is well aligned with the eco-system definition of adaptability.\n</p><p>There are also domain-specific definitions of adaptability and switching costs in such domains as IT, control, and self-adaptive systems areas. (Zhu, et al. 2016).\n</p>\n<h2><span>Demonstrating Adaptability: An Aerospace Example</span></h2>\n<p>In the following example, a high-level abstraction of an aircraft engine is used to illustrate how to evaluate the adaptability of system designs (Zhu, et al., 2016) using the three critical factors: MRES, Design Space, and Switching Costs.\n</p>\n<h3><span>MRES</span></h3>\n<p>Capturing flight missions for the engine example is the first step. The following operations set the stage for key mission requirements:\n</p>\n<ol><li>One engine inoperative</li>\n<li>Takeoff Gradient of Climb</li>\n<li>Climb Rate</li>\n<li>Cruise Range</li></ol>\n<p>Three typical types of aircraft are used in commercial airline operations:\n</p>\n<ul><li>a city-to-city short range aircraft</li>\n<li>a regional jet</li>\n<li>a transatlantic jet</li></ul>\n<p>Support for one engine becoming inoperative is required by aviation regulations. In addition, Takeoff Gradient of Climb, Climb Rates, and Cruise Range are as indicated in Table 1.\n</p>\n<p>Suppose a customer wants to build a customized aircraft that has different mission preferences beyond the three regular types of aircraft, and the engine supplier is asked to design an engine to support that customization. Enumerating all possible values for each mission parameter, where each parameter takes three values (low, median and high), would produce 27 missions. However, here the customer prefers to consider only the 6 missions described in Table 2. The remaining 21 missions are deemed not needed and omitted from the design space. In this table, “optional” preferences refer to possible future mission needs such as fuel economy.\n</p>\n<h3><span>Design Space</span></h3>\n<p>In this top abstraction level, an exhaustive search for all possible engine designs is conducted, and 12 design architectures are found. Each engine architecture may support one or more of these 6 missions. To simplify the discussion, three representative architectures were selected and shown in Figures 1, 2, and 3 which will be used to illustrate how architecture optimization is performed.\n</p>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_Figure3_SEBoK_Original.png\"></a></p><div><p><b>Figure 1.</b> Selected Engine Architecture 3</p></div></div>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_Figure2_SEBoK_Original.png\"></a></p><div><p><b>Figure 2.</b> Selected Engine Architecture 6</p></div></div>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_",
        "html": "<div><div><hr/>\n<p><i><b>Lead Authors:</b></i> <i>Haifeng Zhu</i> and <i>Eileen Patrice Arnold</i>\n</p>\n<hr/>\n<p>To <i>adapt</i> means “to make fit (as for a new use) often by modification” (Merriam-Webster, Inc. n.d.). The term adaptation is traditionally used in natural ecosystems as the “modification of an organism or its parts that makes it more fit for existence under the conditions of its environment” where the conditions can be either positive or negative (Andersen and Gronau 2005). Following from the dictionary definition, System Adaptability is a system’s ability to satisfy mission and requirement changes, with or without modifications (Zhu 2015) (Jackson 2016). One common way to judge whether a system is more adaptable than another is if it is able to support mission and requirement changes at lower cost – an indication of how difficult a system is to adapt. Note that the term <i>cost</i> here may not necessarily be financial. It may include time, fuel, complexity as adopted in Zhu, et al. (2016) or any metric that designers, users, and other stakeholders value with regard to the difficulty of modifications.\n</p>\n<h2><span>Adaptability in Systems Engineering</span></h2>\n<p>The adaptability concept is applicable to both real and conceptual systems as defined in Sillitto, Hillary, et al. (2017). Many concepts are related to system adaptability such as system resilience, flexible design, and design reuse.\n</p>\n<ul><li>System resilience has traditionally focused on graceful degradation and recovery of a system's performance, triggered by adverse events and planned for in advance. (see <a href=\"https://sebokwiki.org/wiki/System_Resilience\">System Resilience</a>) System adaptability focuses on solutions for changes caused by either adversarial or beneficial events.</li>\n<li>Flexible design in industrial engineering (Saleh, et al. 2009) often requires up-front investment and justification of redundant design components or facilities, with more than 50 kinds of flexibilities defined and studied.</li>\n<li>System adaptability looks into future changes to inform current design choices for reduction of unnecessarily redundant design components. System adaptability encourages reuse, but generally does not promote it at the expense of higher cost.</li></ul>\n<h2><span>Three Fundamental Factors</span></h2>\n<p>Comparing adaptability among different systems relies on three fundamental factors:\n</p>\n<ul><li>Mission and Requirement Evaluation Space (MRES)</li>\n<li>Design Space</li>\n<li>Switching Cost</li></ul>\n<p>These factors are explained in the next three subsections.\n</p>\n<h3><span></span><span>Mission and Requirement Evaluation Space (MRES)</span></h3>\n<p>Common development practice assumes each requirement is for current needs and is often subject to budget constraint perceptions. MRES differs in that it uses systems thinking (see <a href=\"https://sebokwiki.org/wiki/Systems_Thinking\">Systems Thinking</a>) to project into the future and identifies requirements with high risk of change. These uncertain requirements come from stakeholder decisions, market changes, technology progression, engineering uncertainties, and other sources. They are potential needs that can optionally be considered. (Zhu, 2023) MRES is a collection of current needs (i.e. requirements and missions) and optional potential needs. These projections into the future offer valuable information when designing for adaptability. Of course, predicting possible future needs is an uncertain task and itself incurs costs. Important optional potential needs could be overlooked or poorly stated. Under cost and schedule pressure, developing optional potential needs could be shortchanged. Nevertheless, anticipating optional possible future needs and their potential impact on design is a valuable systems engineering (SE) activity.\n</p>\n<h3><span>Design Space</span></h3>\n<p>SE normally includes developing alternative possible designs and comparing them to pick the best one among the alternatives. A collection of different possible system designs is called the <i>design space</i> or <i>trade space</i> in which tradeoff studies or trade studies are performed to pick the one that will be implemented. (Cilli &amp; Parnell 2014) (NASA 2016) In modern design approaches, design spaces can be enormous with automated and semi-automated means to conduct the trade study. (Raz, et al. 2018) The trade study is based on a set of decision factors, which can include system adaptability.\n</p>\n<h3><span>Switching Cost</span></h3>\n<p>If adapting the system requires modifying it, the ease of modification indicates the degree of adaptability. The cost of switching from one system design/state to another design/state is called the <i>switching cost</i> which is a good indicator of how difficult it is to adapt. As stated at the beginning of this article, the term <i>cost</i> here may not necessarily be financial.\n</p><p>Traditional financial cost estimation assumes a system is developed from scratch, which in reality is rarely done. Many products are developed by modifying designs from prior products, where the cost is actually a switching cost. Methods of estimating switching cost for a complete generic system, rather than individual components or systems of a specific kind, were initiated mainly by two research teams: a process-based method was developed and later reported in Zhu (2018) and a parametric approach was developed in COSYSMO (Alstad 2019).\n</p>\n<h2><span>Development History</span></h2>\n<p>Two major prior works on system adaptability were authored by Gu, Hashemian, and Nee (2004) and by Ross, Rhodes, and Hastings (2007). The first defines adaptability as a normalized savings in switching from one product to another, emphasizing the costs as the main consideration. In Ross, Rhodes, and Hastings (2007), for two designs <i>A</i> and <i>B</i>, if <i>A</i> can be modified to become <i>B</i>, then a link is created between them. They define the adaptability of a design as the outdegree or filtered outdegree from that design. A design’s outdegree counts the links from this design to the other designs.\n</p><p>In a design space, some designs support the mission better than others. Without considering the support to missions or requirements, measuring the cost to switch to another design (Gu, Hashemian, &amp; Nee 2004) or how many other designs one design can switch to (Ross, Rhodes, &amp; Hastings 2007) can result in inverted measures, where an entity that would receive a higher value of the measurement result than another entity receives with a lower value result. A design that is able to switch with low cost to many other designs that are of no or low value for missions may receive a higher adaptability score than another design that actually supports the needed missions. Fundamentally, these two works capture only two of the three fundamental factors described in section <i>Mission and Requirements Evaluation Space</i> above - the MRES factor, which is needed to prevent inverted measures.\n</p><p>In an eco-system, a species adapts in order to survive and exist longer. In SE, being able to support future missions/requirement needs prolongs the service life of the system and extends its existence, which is well aligned with the eco-system definition of adaptability.\n</p><p>There are also domain-specific definitions of adaptability and switching costs in such domains as IT, control, and self-adaptive systems areas. (Zhu, et al. 2016).\n</p>\n<h2><span>Demonstrating Adaptability: An Aerospace Example</span></h2>\n<p>In the following example, a high-level abstraction of an aircraft engine is used to illustrate how to evaluate the adaptability of system designs (Zhu, et al., 2016) using the three critical factors: MRES, Design Space, and Switching Costs.\n</p>\n<h3><span>MRES</span></h3>\n<p>Capturing flight missions for the engine example is the first step. The following operations set the stage for key mission requirements:\n</p>\n<ol><li>One engine inoperative</li>\n<li>Takeoff Gradient of Climb</li>\n<li>Climb Rate</li>\n<li>Cruise Range</li></ol>\n<p>Three typical types of aircraft are used in commercial airline operations:\n</p>\n<ul><li>a city-to-city short range aircraft</li>\n<li>a regional jet</li>\n<li>a transatlantic jet</li></ul>\n<p>Support for one engine becoming inoperative is required by aviation regulations. In addition, Takeoff Gradient of Climb, Climb Rates, and Cruise Range are as indicated in Table 1.\n</p>\n<p>Suppose a customer wants to build a customized aircraft that has different mission preferences beyond the three regular types of aircraft, and the engine supplier is asked to design an engine to support that customization. Enumerating all possible values for each mission parameter, where each parameter takes three values (low, median and high), would produce 27 missions. However, here the customer prefers to consider only the 6 missions described in Table 2. The remaining 21 missions are deemed not needed and omitted from the design space. In this table, “optional” preferences refer to possible future mission needs such as fuel economy.\n</p>\n<h3><span>Design Space</span></h3>\n<p>In this top abstraction level, an exhaustive search for all possible engine designs is conducted, and 12 design architectures are found. Each engine architecture may support one or more of these 6 missions. To simplify the discussion, three representative architectures were selected and shown in Figures 1, 2, and 3 which will be used to illustrate how architecture optimization is performed.\n</p>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_Figure3_SEBoK_Original.png\"></a></p><div><p><b>Figure 1.</b> Selected Engine Architecture 3</p></div></div>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_Figure2_SEBoK_Original.png\"></a></p><div><p><b>Figure 2.</b> Selected Engine Architecture 6</p></div></div>\n<div><p><a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_",
        "metadata": {
          "sections": [
            {
              "type": "div",
              "content": "Lead Authors:Haifeng ZhuandEileen Patrice ArnoldToadaptmeans “to make fit (as for a new use) often by modification” (Merriam-Webster, Inc. n.d.). The term adaptation is traditionally used in natural ecosystems as the “modification of an organism or its parts that makes it more fit for existence under the conditions of its environment” where the conditions can be either positive or negative (Andersen and Gronau 2005). Following from the dictionary definition, System Adaptability is a system’s abi",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Lead Authors:Haifeng ZhuandEileen Patrice ArnoldToadaptmeans “to make fit (as for a new use) often by modification” (Merriam-Webster, Inc. n.d.). The term adaptation is traditionally used in natural ecosystems as the “modification of an organism or its parts that makes it more fit for existence under the conditions of its environment” where the conditions can be either positive or negative (Andersen and Gronau 2005). Following from the dictionary definition, System Adaptability is a system’s abi",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 1.Selected Engine Architecture 3",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 1.Selected Engine Architecture 3",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 2.Selected Engine Architecture 6",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "Figure 2.Selected Engine Architecture 6",
              "class": [],
              "id": ""
            },
            {
              "type": "div",
              "content": "<a href=\"https://sebokwiki.org/wiki/File:SysAdaptability_",
              "class": [],
              "id": ""
            }
          ],
          "headings": [
            {
              "level": "h2",
              "text": "Adaptability in Systems Engineering",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Three Fundamental Factors",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Mission and Requirement Evaluation Space (MRES)",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Design Space",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Switching Cost",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Development History",
              "id": ""
            },
            {
              "level": "h2",
              "text": "Demonstrating Adaptability: An Aerospace Example",
              "id": ""
            },
            {
              "level": "h3",
              "text": "MRES",
              "id": ""
            },
            {
              "level": "h3",
              "text": "Design Space",
              "id": ""
            }
          ],
          "media_counts": {
            "images": 0,
            "videos": 0,
            "audio": 0
          }
        }
      },
      "category": "research"
    }
  ]
}